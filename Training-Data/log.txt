Epoch 001 batch 00001: Loss 36.0971 Regression loss 0.1650 Classification loss 35.9321 AP 0.0009 AR 0.0500
Epoch 001 batch 00002: Loss 42.2658 Regression loss 0.1326 Classification loss 42.1331 AP 0.0000 AR 0.0000
Epoch 001 batch 00003: Loss 60.6553 Regression loss 0.1013 Classification loss 60.5541 AP 0.0000 AR 0.2000
Epoch 001 batch 00004: Loss 55.1904 Regression loss 0.1164 Classification loss 55.0740 AP 0.0000 AR 0.0000
Epoch 001 batch 00005: Loss 23.8931 Regression loss 0.1693 Classification loss 23.7238 AP 0.0000 AR 0.0000
Epoch 001 batch 00006: Loss 26.7840 Regression loss 0.1921 Classification loss 26.5919 AP 0.0000 AR 0.0000
Epoch 001 batch 00007: Loss 22.8566 Regression loss 0.2350 Classification loss 22.6216 AP 0.0000 AR 0.0000
Epoch 001 batch 00008: Loss 14.7448 Regression loss 0.2924 Classification loss 14.4524 AP 0.0009 AR 0.0400
Epoch 001 batch 00009: Loss 9.4311 Regression loss 0.3535 Classification loss 9.0776 AP 0.0000 AR 0.0000
Epoch 001 batch 00010: Loss 6.4388 Regression loss 0.4138 Classification loss 6.0250 AP 0.0000 AR 0.0000
Epoch 002 batch 00001: Loss 4.4445 Regression loss 0.4967 Classification loss 3.9478 AP 0.0000 AR 0.0000
Epoch 002 batch 00002: Loss 2.5117 Regression loss 0.5689 Classification loss 1.9428 AP 0.0000 AR 0.0000
Epoch 002 batch 00003: Loss 1.7690 Regression loss 0.6912 Classification loss 1.0778 AP 0.0000 AR 0.0000
Epoch 002 batch 00004: Loss 1.8272 Regression loss 0.6910 Classification loss 1.1362 AP 1.0000 AR 0.0000
Epoch 002 batch 00005: Loss 1.9093 Regression loss 0.7651 Classification loss 1.1442 AP 1.0000 AR 0.0000
Epoch 002 batch 00006: Loss 2.3025 Regression loss 0.8395 Classification loss 1.4630 AP 1.0000 AR 0.0000
Epoch 002 batch 00007: Loss 2.2215 Regression loss 0.7708 Classification loss 1.4507 AP 1.0000 AR 0.0000
Epoch 002 batch 00008: Loss 2.2847 Regression loss 0.7837 Classification loss 1.5011 AP 1.0000 AR 0.0000
Epoch 002 batch 00009: Loss 3.0979 Regression loss 0.7165 Classification loss 2.3813 AP 1.0000 AR 0.0000
Epoch 002 batch 00010: Loss 2.9651 Regression loss 0.6151 Classification loss 2.3500 AP 1.0000 AR 0.2000
Epoch 003 batch 00001: Loss 2.7274 Regression loss 0.6066 Classification loss 2.1209 AP 1.0000 AR 0.2000
Epoch 003 batch 00002: Loss 3.0313 Regression loss 0.5485 Classification loss 2.4828 AP 1.0000 AR 0.0000
Epoch 003 batch 00003: Loss 2.8719 Regression loss 0.5578 Classification loss 2.3141 AP 1.0000 AR 0.0000
Epoch 003 batch 00004: Loss 2.9469 Regression loss 0.4583 Classification loss 2.4885 AP 1.0000 AR 0.0000
Epoch 003 batch 00005: Loss 2.6582 Regression loss 0.4247 Classification loss 2.2335 AP 1.0000 AR 0.0000
Epoch 003 batch 00006: Loss 2.4154 Regression loss 0.3423 Classification loss 2.0731 AP 1.0000 AR 0.0000
Epoch 003 batch 00007: Loss 2.7471 Regression loss 0.2666 Classification loss 2.4804 AP 1.0000 AR 0.0000
Epoch 003 batch 00008: Loss 2.4205 Regression loss 0.1921 Classification loss 2.2284 AP 1.0000 AR 0.0000
Epoch 003 batch 00009: Loss 2.1672 Regression loss 0.1368 Classification loss 2.0304 AP 1.0000 AR 0.0000
Epoch 003 batch 00010: Loss 2.0688 Regression loss 0.1080 Classification loss 1.9608 AP 1.0000 AR 0.0000
Epoch 004 batch 00001: Loss 2.5764 Regression loss 0.0672 Classification loss 2.5092 AP 1.0000 AR 0.0000
Epoch 004 batch 00002: Loss 2.5527 Regression loss 0.0749 Classification loss 2.4778 AP 1.0000 AR 0.2000
Epoch 004 batch 00003: Loss 2.1686 Regression loss 0.0605 Classification loss 2.1080 AP 1.0000 AR 0.0000
Epoch 004 batch 00004: Loss 1.9761 Regression loss 0.0680 Classification loss 1.9081 AP 1.0000 AR 0.0000
Epoch 004 batch 00005: Loss 1.9654 Regression loss 0.0709 Classification loss 1.8945 AP 1.0000 AR 0.0000
Epoch 004 batch 00006: Loss 1.8971 Regression loss 0.0841 Classification loss 1.8130 AP 1.0000 AR 0.0000
Epoch 004 batch 00007: Loss 1.7673 Regression loss 0.0928 Classification loss 1.6745 AP 1.0000 AR 0.0000
Epoch 004 batch 00008: Loss 1.5469 Regression loss 0.1115 Classification loss 1.4354 AP 1.0000 AR 0.0000
Epoch 004 batch 00009: Loss 1.7067 Regression loss 0.1276 Classification loss 1.5792 AP 1.0000 AR 0.0000
Epoch 004 batch 00010: Loss 1.7922 Regression loss 0.0980 Classification loss 1.6942 AP 1.0000 AR 0.0000
Epoch 005 batch 00001: Loss 1.3803 Regression loss 0.1288 Classification loss 1.2515 AP 1.0000 AR 0.0000
Epoch 005 batch 00002: Loss 1.4046 Regression loss 0.1299 Classification loss 1.2747 AP 1.0000 AR 0.0000
Epoch 005 batch 00003: Loss 1.5094 Regression loss 0.1058 Classification loss 1.4036 AP 1.0000 AR 0.0000
Epoch 005 batch 00004: Loss 1.6053 Regression loss 0.1067 Classification loss 1.4986 AP 1.0000 AR 0.0000
Epoch 005 batch 00005: Loss 1.5537 Regression loss 0.0929 Classification loss 1.4608 AP 1.0000 AR 0.0000
Epoch 005 batch 00006: Loss 1.1482 Regression loss 0.0777 Classification loss 1.0705 AP 1.0000 AR 0.0000
Epoch 005 batch 00007: Loss 1.2469 Regression loss 0.0970 Classification loss 1.1498 AP 1.0000 AR 0.0000
Epoch 005 batch 00008: Loss 1.0341 Regression loss 0.0666 Classification loss 0.9675 AP 1.0000 AR 0.0000
Epoch 005 batch 00009: Loss 1.1855 Regression loss 0.0661 Classification loss 1.1193 AP 1.0000 AR 0.0000
Epoch 005 batch 00010: Loss 0.9739 Regression loss 0.0614 Classification loss 0.9125 AP 1.0000 AR 0.2000
Epoch 006 batch 00001: Loss 0.9942 Regression loss 0.0525 Classification loss 0.9416 AP 1.0000 AR 0.0000
Epoch 006 batch 00002: Loss 0.8047 Regression loss 0.0602 Classification loss 0.7445 AP 1.0000 AR 0.0000
Epoch 006 batch 00003: Loss 1.0583 Regression loss 0.0550 Classification loss 1.0033 AP 1.0000 AR 0.0000
Epoch 006 batch 00004: Loss 0.9480 Regression loss 0.0430 Classification loss 0.9050 AP 0.0000 AR 0.0000
Epoch 006 batch 00005: Loss 0.9775 Regression loss 0.0341 Classification loss 0.9434 AP 0.0000 AR 0.0000
Epoch 006 batch 00006: Loss 0.9634 Regression loss 0.0383 Classification loss 0.9250 AP 0.0000 AR 0.2000
Epoch 006 batch 00007: Loss 0.9083 Regression loss 0.0278 Classification loss 0.8806 AP 0.0000 AR 0.0000
Epoch 006 batch 00008: Loss 1.0641 Regression loss 0.0257 Classification loss 1.0384 AP 1.0000 AR 0.0000
Epoch 006 batch 00009: Loss 0.8659 Regression loss 0.0345 Classification loss 0.8314 AP 1.0000 AR 0.0000
Epoch 006 batch 00010: Loss 0.8188 Regression loss 0.0310 Classification loss 0.7877 AP 1.0000 AR 0.0000
Epoch 007 batch 00001: Loss 0.7889 Regression loss 0.0354 Classification loss 0.7535 AP 1.0000 AR 0.2000
Epoch 007 batch 00002: Loss 0.8207 Regression loss 0.0356 Classification loss 0.7850 AP 1.0000 AR 0.0000
Epoch 007 batch 00003: Loss 0.7540 Regression loss 0.0289 Classification loss 0.7252 AP 1.0000 AR 0.0000
Epoch 007 batch 00004: Loss 0.9937 Regression loss 0.0332 Classification loss 0.9605 AP 1.0000 AR 0.0000
Epoch 007 batch 00005: Loss 0.9317 Regression loss 0.0360 Classification loss 0.8957 AP 1.0000 AR 0.0000
Epoch 007 batch 00006: Loss 0.7442 Regression loss 0.0359 Classification loss 0.7083 AP 1.0000 AR 0.0000
Epoch 007 batch 00007: Loss 1.0312 Regression loss 0.0395 Classification loss 0.9918 AP 1.0000 AR 0.0000
Epoch 007 batch 00008: Loss 0.9098 Regression loss 0.0314 Classification loss 0.8784 AP 1.0000 AR 0.0000
Epoch 007 batch 00009: Loss 0.6708 Regression loss 0.0343 Classification loss 0.6365 AP 1.0000 AR 0.0000
Epoch 007 batch 00010: Loss 0.7731 Regression loss 0.0275 Classification loss 0.7457 AP 1.0000 AR 0.0000
Epoch 008 batch 00001: Loss 0.8853 Regression loss 0.0256 Classification loss 0.8597 AP 1.0000 AR 0.0000
Epoch 008 batch 00002: Loss 0.7402 Regression loss 0.0341 Classification loss 0.7061 AP 1.0000 AR 0.0000
Epoch 008 batch 00003: Loss 0.5888 Regression loss 0.0285 Classification loss 0.5604 AP 1.0000 AR 0.0000
Epoch 008 batch 00004: Loss 0.8169 Regression loss 0.0294 Classification loss 0.7876 AP 1.0000 AR 0.0000
Epoch 008 batch 00005: Loss 0.7667 Regression loss 0.0282 Classification loss 0.7385 AP 1.0000 AR 0.0000
Epoch 008 batch 00006: Loss 0.6369 Regression loss 0.0376 Classification loss 0.5993 AP 1.0000 AR 0.0000
Epoch 008 batch 00007: Loss 0.8050 Regression loss 0.0313 Classification loss 0.7737 AP 1.0000 AR 0.0000
Epoch 008 batch 00008: Loss 0.6222 Regression loss 0.0290 Classification loss 0.5931 AP 1.0000 AR 0.0000
Epoch 008 batch 00009: Loss 0.6876 Regression loss 0.0359 Classification loss 0.6517 AP 1.0000 AR 0.2000
Epoch 008 batch 00010: Loss 0.6757 Regression loss 0.0260 Classification loss 0.6497 AP 1.0000 AR 0.0000
Epoch 009 batch 00001: Loss 0.6879 Regression loss 0.0255 Classification loss 0.6624 AP 1.0000 AR 0.0000
Epoch 009 batch 00002: Loss 0.5498 Regression loss 0.0319 Classification loss 0.5179 AP 1.0000 AR 0.0000
Epoch 009 batch 00003: Loss 0.8677 Regression loss 0.0353 Classification loss 0.8324 AP 1.0000 AR 0.0000
Epoch 009 batch 00004: Loss 0.5635 Regression loss 0.0293 Classification loss 0.5342 AP 1.0000 AR 0.0000
Epoch 009 batch 00005: Loss 0.5785 Regression loss 0.0285 Classification loss 0.5499 AP 1.0000 AR 0.0000
Epoch 009 batch 00006: Loss 0.4872 Regression loss 0.0253 Classification loss 0.4620 AP 1.0000 AR 0.0000
Epoch 009 batch 00007: Loss 0.6116 Regression loss 0.0376 Classification loss 0.5740 AP 1.0000 AR 0.0000
Epoch 009 batch 00008: Loss 0.6618 Regression loss 0.0317 Classification loss 0.6301 AP 0.8000 AR 0.0000
Epoch 009 batch 00009: Loss 0.8267 Regression loss 0.0243 Classification loss 0.8024 AP 1.0000 AR 0.2000
Epoch 009 batch 00010: Loss 0.6764 Regression loss 0.0272 Classification loss 0.6492 AP 1.0000 AR 0.0000
Epoch 010 batch 00001: Loss 0.6730 Regression loss 0.0376 Classification loss 0.6354 AP 1.0000 AR 0.0000
Epoch 010 batch 00002: Loss 0.6076 Regression loss 0.0313 Classification loss 0.5764 AP 1.0000 AR 0.0000
Epoch 010 batch 00003: Loss 0.5090 Regression loss 0.0248 Classification loss 0.4842 AP 0.8000 AR 0.2000
Epoch 010 batch 00004: Loss 0.6836 Regression loss 0.0365 Classification loss 0.6471 AP 1.0000 AR 0.0000
Epoch 010 batch 00005: Loss 0.5474 Regression loss 0.0301 Classification loss 0.5173 AP 1.0000 AR 0.0000
Epoch 010 batch 00006: Loss 0.5783 Regression loss 0.0311 Classification loss 0.5472 AP 0.6000 AR 0.0000
Epoch 010 batch 00007: Loss 0.5651 Regression loss 0.0298 Classification loss 0.5353 AP 1.0000 AR 0.0000
Epoch 010 batch 00008: Loss 0.5834 Regression loss 0.0313 Classification loss 0.5521 AP 1.0000 AR 0.0000
Epoch 010 batch 00009: Loss 0.5726 Regression loss 0.0345 Classification loss 0.5381 AP 1.0000 AR 0.0000
Epoch 010 batch 00010: Loss 0.5782 Regression loss 0.0243 Classification loss 0.5539 AP 1.0000 AR 0.0000
Epoch 011 batch 00001: Loss 0.7205 Regression loss 0.0293 Classification loss 0.6913 AP 1.0000 AR 0.2000
Epoch 011 batch 00002: Loss 0.5274 Regression loss 0.0323 Classification loss 0.4950 AP 1.0000 AR 0.0000
Epoch 011 batch 00003: Loss 0.6136 Regression loss 0.0373 Classification loss 0.5762 AP 0.8000 AR 0.0000
Epoch 011 batch 00004: Loss 0.5642 Regression loss 0.0335 Classification loss 0.5307 AP 0.8000 AR 0.0000
Epoch 011 batch 00005: Loss 0.6173 Regression loss 0.0314 Classification loss 0.5859 AP 1.0000 AR 0.0000
Epoch 011 batch 00006: Loss 0.6937 Regression loss 0.0313 Classification loss 0.6624 AP 0.8000 AR 0.0000
Epoch 011 batch 00007: Loss 0.6728 Regression loss 0.0295 Classification loss 0.6433 AP 1.0000 AR 0.0000
Epoch 011 batch 00008: Loss 0.5410 Regression loss 0.0305 Classification loss 0.5105 AP 0.8000 AR 0.0000
Epoch 011 batch 00009: Loss 0.5487 Regression loss 0.0283 Classification loss 0.5204 AP 0.8000 AR 0.0000
Epoch 011 batch 00010: Loss 0.4867 Regression loss 0.0274 Classification loss 0.4593 AP 1.0000 AR 0.0000
Epoch 012 batch 00001: Loss 0.5498 Regression loss 0.0298 Classification loss 0.5200 AP 0.6000 AR 0.0000
Epoch 012 batch 00002: Loss 0.7416 Regression loss 0.0294 Classification loss 0.7122 AP 1.0000 AR 0.2000
Epoch 012 batch 00003: Loss 0.4463 Regression loss 0.0271 Classification loss 0.4192 AP 1.0000 AR 0.0000
Epoch 012 batch 00004: Loss 0.5495 Regression loss 0.0304 Classification loss 0.5190 AP 1.0000 AR 0.0000
Epoch 012 batch 00005: Loss 0.6307 Regression loss 0.0335 Classification loss 0.5972 AP 1.0000 AR 0.0000
Epoch 012 batch 00006: Loss 0.5585 Regression loss 0.0301 Classification loss 0.5284 AP 1.0000 AR 0.0000
Epoch 012 batch 00007: Loss 0.5221 Regression loss 0.0320 Classification loss 0.4901 AP 1.0000 AR 0.0000
Epoch 012 batch 00008: Loss 0.6719 Regression loss 0.0306 Classification loss 0.6414 AP 1.0000 AR 0.0000
Epoch 012 batch 00009: Loss 0.6584 Regression loss 0.0279 Classification loss 0.6306 AP 1.0000 AR 0.0000
Epoch 012 batch 00010: Loss 0.5963 Regression loss 0.0265 Classification loss 0.5698 AP 0.8000 AR 0.0000
Epoch 013 batch 00001: Loss 0.5375 Regression loss 0.0279 Classification loss 0.5097 AP 1.0000 AR 0.0000
Epoch 013 batch 00002: Loss 0.5772 Regression loss 0.0346 Classification loss 0.5426 AP 1.0000 AR 0.0000
Epoch 013 batch 00003: Loss 0.5278 Regression loss 0.0331 Classification loss 0.4947 AP 1.0000 AR 0.2000
Epoch 013 batch 00004: Loss 0.6778 Regression loss 0.0313 Classification loss 0.6465 AP 1.0000 AR 0.0000
Epoch 013 batch 00005: Loss 0.5405 Regression loss 0.0330 Classification loss 0.5075 AP 1.0000 AR 0.0000
Epoch 013 batch 00006: Loss 0.5224 Regression loss 0.0265 Classification loss 0.4958 AP 1.0000 AR 0.0000
Epoch 013 batch 00007: Loss 0.4914 Regression loss 0.0274 Classification loss 0.4641 AP 1.0000 AR 0.0000
Epoch 013 batch 00008: Loss 0.7159 Regression loss 0.0274 Classification loss 0.6885 AP 1.0000 AR 0.0000
Epoch 013 batch 00009: Loss 0.5247 Regression loss 0.0252 Classification loss 0.4995 AP 0.8000 AR 0.0000
Epoch 013 batch 00010: Loss 0.6921 Regression loss 0.0290 Classification loss 0.6631 AP 0.8000 AR 0.0000
Epoch 014 batch 00001: Loss 0.5687 Regression loss 0.0283 Classification loss 0.5404 AP 0.8000 AR 0.0000
Epoch 014 batch 00002: Loss 0.5460 Regression loss 0.0281 Classification loss 0.5179 AP 1.0000 AR 0.0000
Epoch 014 batch 00003: Loss 0.5756 Regression loss 0.0267 Classification loss 0.5489 AP 1.0000 AR 0.0000
Epoch 014 batch 00004: Loss 0.4857 Regression loss 0.0299 Classification loss 0.4557 AP 1.0000 AR 0.0000
Epoch 014 batch 00005: Loss 0.5377 Regression loss 0.0323 Classification loss 0.5053 AP 1.0000 AR 0.2000
Epoch 014 batch 00006: Loss 0.5771 Regression loss 0.0251 Classification loss 0.5520 AP 1.0000 AR 0.0000
Epoch 014 batch 00007: Loss 0.6172 Regression loss 0.0247 Classification loss 0.5925 AP 1.0000 AR 0.0000
Epoch 014 batch 00008: Loss 0.5162 Regression loss 0.0291 Classification loss 0.4871 AP 0.8000 AR 0.0000
Epoch 014 batch 00009: Loss 0.6763 Regression loss 0.0325 Classification loss 0.6438 AP 1.0000 AR 0.0000
Epoch 014 batch 00010: Loss 0.5715 Regression loss 0.0283 Classification loss 0.5432 AP 1.0000 AR 0.0000
Epoch 015 batch 00001: Loss 0.5245 Regression loss 0.0258 Classification loss 0.4988 AP 1.0000 AR 0.0000
Epoch 015 batch 00002: Loss 0.5918 Regression loss 0.0287 Classification loss 0.5631 AP 1.0000 AR 0.0000
Epoch 015 batch 00003: Loss 0.4999 Regression loss 0.0283 Classification loss 0.4716 AP 1.0000 AR 0.0000
Epoch 015 batch 00004: Loss 0.6484 Regression loss 0.0310 Classification loss 0.6174 AP 1.0000 AR 0.0000
Epoch 015 batch 00005: Loss 0.5569 Regression loss 0.0317 Classification loss 0.5252 AP 0.8000 AR 0.0000
Epoch 015 batch 00006: Loss 0.6017 Regression loss 0.0189 Classification loss 0.5828 AP 0.8000 AR 0.0000
Epoch 015 batch 00007: Loss 0.5722 Regression loss 0.0298 Classification loss 0.5425 AP 1.0000 AR 0.2000
Epoch 015 batch 00008: Loss 0.6660 Regression loss 0.0260 Classification loss 0.6400 AP 1.0000 AR 0.0000
Epoch 015 batch 00009: Loss 0.5736 Regression loss 0.0281 Classification loss 0.5455 AP 1.0000 AR 0.0000
Epoch 015 batch 00010: Loss 0.4689 Regression loss 0.0308 Classification loss 0.4381 AP 1.0000 AR 0.0000
Epoch 016 batch 00001: Loss 0.5002 Regression loss 0.0273 Classification loss 0.4729 AP 1.0000 AR 0.0000
Epoch 016 batch 00002: Loss 0.5592 Regression loss 0.0339 Classification loss 0.5253 AP 1.0000 AR 0.2000
Epoch 016 batch 00003: Loss 0.5749 Regression loss 0.0245 Classification loss 0.5504 AP 0.8000 AR 0.0000
Epoch 016 batch 00004: Loss 0.6781 Regression loss 0.0278 Classification loss 0.6502 AP 1.0000 AR 0.0000
Epoch 016 batch 00005: Loss 0.6396 Regression loss 0.0251 Classification loss 0.6145 AP 1.0000 AR 0.0000
Epoch 016 batch 00006: Loss 0.6139 Regression loss 0.0237 Classification loss 0.5902 AP 1.0000 AR 0.0000
Epoch 016 batch 00007: Loss 0.5730 Regression loss 0.0295 Classification loss 0.5435 AP 0.8000 AR 0.0000
Epoch 016 batch 00008: Loss 0.4992 Regression loss 0.0307 Classification loss 0.4685 AP 1.0000 AR 0.0000
Epoch 016 batch 00009: Loss 0.5209 Regression loss 0.0289 Classification loss 0.4921 AP 0.8000 AR 0.0000
Epoch 016 batch 00010: Loss 0.6280 Regression loss 0.0290 Classification loss 0.5990 AP 1.0000 AR 0.0000
Epoch 017 batch 00001: Loss 0.5584 Regression loss 0.0345 Classification loss 0.5240 AP 0.8000 AR 0.0000
Epoch 017 batch 00002: Loss 0.6360 Regression loss 0.0214 Classification loss 0.6146 AP 0.8000 AR 0.0000
Epoch 017 batch 00003: Loss 0.4715 Regression loss 0.0271 Classification loss 0.4443 AP 1.0000 AR 0.0000
Epoch 017 batch 00004: Loss 0.5755 Regression loss 0.0321 Classification loss 0.5434 AP 1.0000 AR 0.0000
Epoch 017 batch 00005: Loss 0.6318 Regression loss 0.0255 Classification loss 0.6064 AP 1.0000 AR 0.0000
Epoch 017 batch 00006: Loss 0.5896 Regression loss 0.0272 Classification loss 0.5624 AP 1.0000 AR 0.0000
Epoch 017 batch 00007: Loss 0.8551 Regression loss 0.0207 Classification loss 0.8344 AP 1.0000 AR 0.0000
Epoch 017 batch 00008: Loss 0.6065 Regression loss 0.0279 Classification loss 0.5785 AP 1.0000 AR 0.0000
Epoch 017 batch 00009: Loss 0.4541 Regression loss 0.0270 Classification loss 0.4271 AP 1.0000 AR 0.0000
Epoch 017 batch 00010: Loss 0.4858 Regression loss 0.0246 Classification loss 0.4612 AP 1.0000 AR 0.2000
Epoch 018 batch 00001: Loss 0.6045 Regression loss 0.0265 Classification loss 0.5780 AP 1.0000 AR 0.0000
Epoch 018 batch 00002: Loss 0.5739 Regression loss 0.0258 Classification loss 0.5481 AP 1.0000 AR 0.0000
Epoch 018 batch 00003: Loss 0.4010 Regression loss 0.0265 Classification loss 0.3746 AP 1.0000 AR 0.0000
Epoch 018 batch 00004: Loss 0.5608 Regression loss 0.0277 Classification loss 0.5331 AP 1.0000 AR 0.0000
Epoch 018 batch 00005: Loss 0.6077 Regression loss 0.0196 Classification loss 0.5881 AP 1.0000 AR 0.0000
Epoch 018 batch 00006: Loss 0.4869 Regression loss 0.0316 Classification loss 0.4553 AP 0.8000 AR 0.0000
Epoch 018 batch 00007: Loss 0.6826 Regression loss 0.0271 Classification loss 0.6555 AP 1.0000 AR 0.0000
Epoch 018 batch 00008: Loss 0.5266 Regression loss 0.0317 Classification loss 0.4950 AP 1.0000 AR 0.2000
Epoch 018 batch 00009: Loss 0.7723 Regression loss 0.0278 Classification loss 0.7445 AP 1.0000 AR 0.0000
Epoch 018 batch 00010: Loss 0.4246 Regression loss 0.0256 Classification loss 0.3990 AP 0.6000 AR 0.0000
Epoch 019 batch 00001: Loss 0.5690 Regression loss 0.0190 Classification loss 0.5500 AP 1.0000 AR 0.0000
Epoch 019 batch 00002: Loss 0.5694 Regression loss 0.0315 Classification loss 0.5379 AP 1.0000 AR 0.0000
Epoch 019 batch 00003: Loss 0.5509 Regression loss 0.0256 Classification loss 0.5253 AP 1.0000 AR 0.0000
Epoch 019 batch 00004: Loss 0.6503 Regression loss 0.0270 Classification loss 0.6233 AP 1.0000 AR 0.0000
Epoch 019 batch 00005: Loss 0.5395 Regression loss 0.0265 Classification loss 0.5130 AP 1.0000 AR 0.0000
Epoch 019 batch 00006: Loss 0.4785 Regression loss 0.0275 Classification loss 0.4510 AP 0.8000 AR 0.0000
Epoch 019 batch 00007: Loss 0.6310 Regression loss 0.0279 Classification loss 0.6032 AP 1.0000 AR 0.0000
Epoch 019 batch 00008: Loss 0.5691 Regression loss 0.0290 Classification loss 0.5401 AP 1.0000 AR 0.0000
Epoch 019 batch 00009: Loss 0.6014 Regression loss 0.0245 Classification loss 0.5769 AP 1.0000 AR 0.0000
Epoch 019 batch 00010: Loss 0.4462 Regression loss 0.0270 Classification loss 0.4192 AP 1.0000 AR 0.2000
Epoch 020 batch 00001: Loss 0.5038 Regression loss 0.0309 Classification loss 0.4728 AP 1.0000 AR 0.0000
Epoch 020 batch 00002: Loss 0.4647 Regression loss 0.0239 Classification loss 0.4408 AP 0.8000 AR 0.0000
Epoch 020 batch 00003: Loss 0.5771 Regression loss 0.0259 Classification loss 0.5512 AP 1.0000 AR 0.2000
Epoch 020 batch 00004: Loss 0.7288 Regression loss 0.0322 Classification loss 0.6966 AP 1.0000 AR 0.0000
Epoch 020 batch 00005: Loss 0.5258 Regression loss 0.0242 Classification loss 0.5016 AP 1.0000 AR 0.0000
Epoch 020 batch 00006: Loss 0.5352 Regression loss 0.0258 Classification loss 0.5094 AP 1.0000 AR 0.0000
Epoch 020 batch 00007: Loss 0.5191 Regression loss 0.0285 Classification loss 0.4906 AP 1.0000 AR 0.0000
Epoch 020 batch 00008: Loss 0.5500 Regression loss 0.0222 Classification loss 0.5278 AP 1.0000 AR 0.0000
Epoch 020 batch 00009: Loss 0.5267 Regression loss 0.0272 Classification loss 0.4995 AP 0.8000 AR 0.0000
Epoch 020 batch 00010: Loss 0.6210 Regression loss 0.0263 Classification loss 0.5947 AP 0.8000 AR 0.0000
Epoch 021 batch 00001: Loss 0.5571 Regression loss 0.0333 Classification loss 0.5238 AP 1.0000 AR 0.0000
Epoch 021 batch 00002: Loss 0.4276 Regression loss 0.0219 Classification loss 0.4057 AP 0.8000 AR 0.0000
Epoch 021 batch 00003: Loss 0.5467 Regression loss 0.0293 Classification loss 0.5175 AP 1.0000 AR 0.0000
Epoch 021 batch 00004: Loss 0.6610 Regression loss 0.0235 Classification loss 0.6374 AP 1.0000 AR 0.2000
Epoch 021 batch 00005: Loss 0.5534 Regression loss 0.0233 Classification loss 0.5301 AP 1.0000 AR 0.0000
Epoch 021 batch 00006: Loss 0.4770 Regression loss 0.0260 Classification loss 0.4510 AP 1.0000 AR 0.0000
Epoch 021 batch 00007: Loss 0.5499 Regression loss 0.0230 Classification loss 0.5269 AP 1.0000 AR 0.0000
Epoch 021 batch 00008: Loss 0.6167 Regression loss 0.0291 Classification loss 0.5876 AP 1.0000 AR 0.0000
Epoch 021 batch 00009: Loss 0.5213 Regression loss 0.0290 Classification loss 0.4923 AP 0.8000 AR 0.0000
Epoch 021 batch 00010: Loss 0.6752 Regression loss 0.0229 Classification loss 0.6523 AP 0.6000 AR 0.0000
Epoch 022 batch 00001: Loss 0.6585 Regression loss 0.0286 Classification loss 0.6298 AP 1.0000 AR 0.0000
Epoch 022 batch 00002: Loss 0.5003 Regression loss 0.0260 Classification loss 0.4743 AP 1.0000 AR 0.0000
Epoch 022 batch 00003: Loss 0.5778 Regression loss 0.0273 Classification loss 0.5506 AP 1.0000 AR 0.0000
Epoch 022 batch 00004: Loss 0.6496 Regression loss 0.0219 Classification loss 0.6278 AP 1.0000 AR 0.0000
Epoch 022 batch 00005: Loss 0.4732 Regression loss 0.0204 Classification loss 0.4528 AP 1.0000 AR 0.0000
Epoch 022 batch 00006: Loss 0.4486 Regression loss 0.0340 Classification loss 0.4145 AP 1.0000 AR 0.0000
Epoch 022 batch 00007: Loss 0.4542 Regression loss 0.0246 Classification loss 0.4295 AP 1.0000 AR 0.0000
Epoch 022 batch 00008: Loss 0.6290 Regression loss 0.0298 Classification loss 0.5992 AP 1.0000 AR 0.0000
Epoch 022 batch 00009: Loss 0.5693 Regression loss 0.0283 Classification loss 0.5410 AP 1.0000 AR 0.0000
Epoch 022 batch 00010: Loss 0.5768 Regression loss 0.0295 Classification loss 0.5474 AP 1.0000 AR 0.2000
Epoch 023 batch 00001: Loss 0.6244 Regression loss 0.0294 Classification loss 0.5950 AP 1.0000 AR 0.0000
Epoch 023 batch 00002: Loss 0.6300 Regression loss 0.0308 Classification loss 0.5992 AP 1.0000 AR 0.0000
Epoch 023 batch 00003: Loss 0.4305 Regression loss 0.0255 Classification loss 0.4050 AP 1.0000 AR 0.0000
Epoch 023 batch 00004: Loss 0.7153 Regression loss 0.0313 Classification loss 0.6840 AP 1.0000 AR 0.0000
Epoch 023 batch 00005: Loss 0.5210 Regression loss 0.0342 Classification loss 0.4868 AP 1.0000 AR 0.0000
Epoch 023 batch 00006: Loss 0.6506 Regression loss 0.0209 Classification loss 0.6296 AP 1.0000 AR 0.0000
Epoch 023 batch 00007: Loss 0.5859 Regression loss 0.0240 Classification loss 0.5620 AP 1.0000 AR 0.0000
Epoch 023 batch 00008: Loss 0.5049 Regression loss 0.0269 Classification loss 0.4779 AP 0.8000 AR 0.0000
Epoch 023 batch 00009: Loss 0.5965 Regression loss 0.0279 Classification loss 0.5686 AP 0.8000 AR 0.2000
Epoch 023 batch 00010: Loss 0.5038 Regression loss 0.0261 Classification loss 0.4778 AP 1.0000 AR 0.0000
Epoch 024 batch 00001: Loss 0.6203 Regression loss 0.0298 Classification loss 0.5906 AP 1.0000 AR 0.0000
Epoch 024 batch 00002: Loss 0.5012 Regression loss 0.0282 Classification loss 0.4730 AP 1.0000 AR 0.0000
Epoch 024 batch 00003: Loss 0.6241 Regression loss 0.0283 Classification loss 0.5958 AP 1.0000 AR 0.0000
Epoch 024 batch 00004: Loss 0.6501 Regression loss 0.0261 Classification loss 0.6240 AP 1.0000 AR 0.0000
Epoch 024 batch 00005: Loss 0.5339 Regression loss 0.0213 Classification loss 0.5125 AP 1.0000 AR 0.0000
Epoch 024 batch 00006: Loss 0.7137 Regression loss 0.0259 Classification loss 0.6878 AP 1.0000 AR 0.0000
Epoch 024 batch 00007: Loss 0.6569 Regression loss 0.0206 Classification loss 0.6363 AP 1.0000 AR 0.0000
Epoch 024 batch 00008: Loss 0.4897 Regression loss 0.0256 Classification loss 0.4641 AP 1.0000 AR 0.0000
Epoch 024 batch 00009: Loss 0.5666 Regression loss 0.0273 Classification loss 0.5393 AP 1.0000 AR 0.0000
Epoch 024 batch 00010: Loss 0.4785 Regression loss 0.0335 Classification loss 0.4450 AP 1.0000 AR 0.2000
Epoch 025 batch 00001: Loss 0.5064 Regression loss 0.0286 Classification loss 0.4778 AP 1.0000 AR 0.0000
Epoch 025 batch 00002: Loss 0.6743 Regression loss 0.0267 Classification loss 0.6477 AP 1.0000 AR 0.0000
Epoch 025 batch 00003: Loss 0.5810 Regression loss 0.0248 Classification loss 0.5562 AP 1.0000 AR 0.0000
Epoch 025 batch 00004: Loss 0.6991 Regression loss 0.0316 Classification loss 0.6675 AP 1.0000 AR 0.0000
Epoch 025 batch 00005: Loss 0.4978 Regression loss 0.0214 Classification loss 0.4764 AP 1.0000 AR 0.0000
Epoch 025 batch 00006: Loss 0.4931 Regression loss 0.0255 Classification loss 0.4676 AP 1.0000 AR 0.2000
Epoch 025 batch 00007: Loss 0.4915 Regression loss 0.0299 Classification loss 0.4616 AP 1.0000 AR 0.0000
Epoch 025 batch 00008: Loss 0.5440 Regression loss 0.0211 Classification loss 0.5228 AP 1.0000 AR 0.0000
Epoch 025 batch 00009: Loss 0.5212 Regression loss 0.0297 Classification loss 0.4915 AP 1.0000 AR 0.0000
Epoch 025 batch 00010: Loss 0.4736 Regression loss 0.0276 Classification loss 0.4460 AP 1.0000 AR 0.0000
Epoch 026 batch 00001: Loss 0.4421 Regression loss 0.0271 Classification loss 0.4150 AP 1.0000 AR 0.0000
Epoch 026 batch 00002: Loss 0.6741 Regression loss 0.0215 Classification loss 0.6526 AP 1.0000 AR 0.2000
Epoch 026 batch 00003: Loss 0.4495 Regression loss 0.0288 Classification loss 0.4207 AP 1.0000 AR 0.0000
Epoch 026 batch 00004: Loss 0.5359 Regression loss 0.0285 Classification loss 0.5074 AP 1.0000 AR 0.0000
Epoch 026 batch 00005: Loss 0.7402 Regression loss 0.0215 Classification loss 0.7187 AP 1.0000 AR 0.0000
Epoch 026 batch 00006: Loss 0.5257 Regression loss 0.0225 Classification loss 0.5031 AP 1.0000 AR 0.0000
Epoch 026 batch 00007: Loss 0.4748 Regression loss 0.0273 Classification loss 0.4476 AP 1.0000 AR 0.0000
Epoch 026 batch 00008: Loss 0.5969 Regression loss 0.0238 Classification loss 0.5731 AP 1.0000 AR 0.0000
Epoch 026 batch 00009: Loss 0.6269 Regression loss 0.0282 Classification loss 0.5987 AP 1.0000 AR 0.0000
Epoch 026 batch 00010: Loss 0.5243 Regression loss 0.0252 Classification loss 0.4991 AP 1.0000 AR 0.0000
Epoch 027 batch 00001: Loss 0.5136 Regression loss 0.0238 Classification loss 0.4898 AP 1.0000 AR 0.0000
Epoch 027 batch 00002: Loss 0.4758 Regression loss 0.0273 Classification loss 0.4486 AP 1.0000 AR 0.0000
Epoch 027 batch 00003: Loss 0.6524 Regression loss 0.0255 Classification loss 0.6269 AP 1.0000 AR 0.0000
Epoch 027 batch 00004: Loss 0.5157 Regression loss 0.0259 Classification loss 0.4898 AP 1.0000 AR 0.0000
Epoch 027 batch 00005: Loss 0.5888 Regression loss 0.0260 Classification loss 0.5627 AP 1.0000 AR 0.0000
Epoch 027 batch 00006: Loss 0.5694 Regression loss 0.0350 Classification loss 0.5344 AP 1.0000 AR 0.0000
Epoch 027 batch 00007: Loss 0.4837 Regression loss 0.0227 Classification loss 0.4611 AP 1.0000 AR 0.0000
Epoch 027 batch 00008: Loss 0.4581 Regression loss 0.0204 Classification loss 0.4378 AP 1.0000 AR 0.2000
Epoch 027 batch 00009: Loss 0.4725 Regression loss 0.0263 Classification loss 0.4463 AP 1.0000 AR 0.0000
Epoch 027 batch 00010: Loss 0.7328 Regression loss 0.0282 Classification loss 0.7046 AP 1.0000 AR 0.0000
Epoch 028 batch 00001: Loss 0.5662 Regression loss 0.0260 Classification loss 0.5402 AP 1.0000 AR 0.0000
Epoch 028 batch 00002: Loss 0.4972 Regression loss 0.0324 Classification loss 0.4647 AP 1.0000 AR 0.0000
Epoch 028 batch 00003: Loss 0.6213 Regression loss 0.0275 Classification loss 0.5939 AP 1.0000 AR 0.0000
Epoch 028 batch 00004: Loss 0.5558 Regression loss 0.0238 Classification loss 0.5320 AP 1.0000 AR 0.0000
Epoch 028 batch 00005: Loss 0.4990 Regression loss 0.0247 Classification loss 0.4742 AP 1.0000 AR 0.0000
Epoch 028 batch 00006: Loss 0.5091 Regression loss 0.0262 Classification loss 0.4829 AP 1.0000 AR 0.0000
Epoch 028 batch 00007: Loss 0.5168 Regression loss 0.0241 Classification loss 0.4926 AP 1.0000 AR 0.0000
Epoch 028 batch 00008: Loss 0.5484 Regression loss 0.0251 Classification loss 0.5233 AP 1.0000 AR 0.2000
Epoch 028 batch 00009: Loss 0.5784 Regression loss 0.0220 Classification loss 0.5563 AP 1.0000 AR 0.0000
Epoch 028 batch 00010: Loss 0.5416 Regression loss 0.0277 Classification loss 0.5138 AP 1.0000 AR 0.0000
Epoch 029 batch 00001: Loss 0.3852 Regression loss 0.0232 Classification loss 0.3621 AP 1.0000 AR 0.0000
Epoch 029 batch 00002: Loss 0.6066 Regression loss 0.0251 Classification loss 0.5815 AP 1.0000 AR 0.0000
Epoch 029 batch 00003: Loss 0.6853 Regression loss 0.0167 Classification loss 0.6686 AP 1.0000 AR 0.2000
Epoch 029 batch 00004: Loss 0.4561 Regression loss 0.0262 Classification loss 0.4299 AP 1.0000 AR 0.0000
Epoch 029 batch 00005: Loss 0.6147 Regression loss 0.0241 Classification loss 0.5906 AP 1.0000 AR 0.0000
Epoch 029 batch 00006: Loss 0.6054 Regression loss 0.0237 Classification loss 0.5818 AP 1.0000 AR 0.0000
Epoch 029 batch 00007: Loss 0.5465 Regression loss 0.0247 Classification loss 0.5218 AP 1.0000 AR 0.0000
Epoch 029 batch 00008: Loss 0.4502 Regression loss 0.0307 Classification loss 0.4195 AP 1.0000 AR 0.0000
Epoch 029 batch 00009: Loss 0.4874 Regression loss 0.0263 Classification loss 0.4611 AP 1.0000 AR 0.0000
Epoch 029 batch 00010: Loss 0.5419 Regression loss 0.0296 Classification loss 0.5123 AP 1.0000 AR 0.0000
Epoch 030 batch 00001: Loss 0.4661 Regression loss 0.0239 Classification loss 0.4422 AP 1.0000 AR 0.0000
Epoch 030 batch 00002: Loss 0.5775 Regression loss 0.0212 Classification loss 0.5563 AP 1.0000 AR 0.0000
Epoch 030 batch 00003: Loss 0.6065 Regression loss 0.0192 Classification loss 0.5873 AP 1.0000 AR 0.0000
Epoch 030 batch 00004: Loss 0.5671 Regression loss 0.0317 Classification loss 0.5354 AP 1.0000 AR 0.0000
Epoch 030 batch 00005: Loss 0.6662 Regression loss 0.0260 Classification loss 0.6401 AP 1.0000 AR 0.0000
Epoch 030 batch 00006: Loss 0.5425 Regression loss 0.0264 Classification loss 0.5162 AP 1.0000 AR 0.0000
Epoch 030 batch 00007: Loss 0.4977 Regression loss 0.0246 Classification loss 0.4731 AP 1.0000 AR 0.0000
Epoch 030 batch 00008: Loss 0.5456 Regression loss 0.0225 Classification loss 0.5231 AP 1.0000 AR 0.0000
Epoch 030 batch 00009: Loss 0.4432 Regression loss 0.0259 Classification loss 0.4173 AP 1.0000 AR 0.0000
Epoch 030 batch 00010: Loss 0.5369 Regression loss 0.0279 Classification loss 0.5090 AP 1.0000 AR 0.2000
Epoch 031 batch 00001: Loss 0.5151 Regression loss 0.0242 Classification loss 0.4909 AP 1.0000 AR 0.0000
Epoch 031 batch 00002: Loss 0.5467 Regression loss 0.0256 Classification loss 0.5211 AP 1.0000 AR 0.0000
Epoch 031 batch 00003: Loss 0.4973 Regression loss 0.0290 Classification loss 0.4683 AP 1.0000 AR 0.0000
Epoch 031 batch 00004: Loss 0.4581 Regression loss 0.0207 Classification loss 0.4374 AP 1.0000 AR 0.0000
Epoch 031 batch 00005: Loss 0.5472 Regression loss 0.0299 Classification loss 0.5173 AP 1.0000 AR 0.0000
Epoch 031 batch 00006: Loss 0.4973 Regression loss 0.0209 Classification loss 0.4763 AP 1.0000 AR 0.0000
Epoch 031 batch 00007: Loss 0.5641 Regression loss 0.0277 Classification loss 0.5364 AP 1.0000 AR 0.0000
Epoch 031 batch 00008: Loss 0.5823 Regression loss 0.0272 Classification loss 0.5550 AP 1.0000 AR 0.2000
Epoch 031 batch 00009: Loss 0.5474 Regression loss 0.0291 Classification loss 0.5183 AP 1.0000 AR 0.0000
Epoch 031 batch 00010: Loss 0.5408 Regression loss 0.0216 Classification loss 0.5192 AP 1.0000 AR 0.0000
Epoch 032 batch 00001: Loss 0.5995 Regression loss 0.0209 Classification loss 0.5786 AP 1.0000 AR 0.0000
Epoch 032 batch 00002: Loss 0.5214 Regression loss 0.0281 Classification loss 0.4933 AP 1.0000 AR 0.0000
Epoch 032 batch 00003: Loss 0.5357 Regression loss 0.0264 Classification loss 0.5093 AP 1.0000 AR 0.0000
Epoch 032 batch 00004: Loss 0.6585 Regression loss 0.0216 Classification loss 0.6369 AP 1.0000 AR 0.2000
Epoch 032 batch 00005: Loss 0.4139 Regression loss 0.0274 Classification loss 0.3865 AP 1.0000 AR 0.0000
Epoch 032 batch 00006: Loss 0.4793 Regression loss 0.0251 Classification loss 0.4542 AP 1.0000 AR 0.0000
Epoch 032 batch 00007: Loss 0.5676 Regression loss 0.0276 Classification loss 0.5400 AP 1.0000 AR 0.0000
Epoch 032 batch 00008: Loss 0.5781 Regression loss 0.0231 Classification loss 0.5550 AP 1.0000 AR 0.0000
Epoch 032 batch 00009: Loss 0.5918 Regression loss 0.0228 Classification loss 0.5690 AP 1.0000 AR 0.0000
Epoch 032 batch 00010: Loss 0.5622 Regression loss 0.0295 Classification loss 0.5326 AP 1.0000 AR 0.0000
Epoch 033 batch 00001: Loss 0.7088 Regression loss 0.0225 Classification loss 0.6863 AP 1.0000 AR 0.2000
Epoch 033 batch 00002: Loss 0.4895 Regression loss 0.0275 Classification loss 0.4620 AP 1.0000 AR 0.0000
Epoch 033 batch 00003: Loss 0.5281 Regression loss 0.0262 Classification loss 0.5019 AP 1.0000 AR 0.0000
Epoch 033 batch 00004: Loss 0.5737 Regression loss 0.0320 Classification loss 0.5417 AP 1.0000 AR 0.0000
Epoch 033 batch 00005: Loss 0.6734 Regression loss 0.0259 Classification loss 0.6475 AP 1.0000 AR 0.0000
Epoch 033 batch 00006: Loss 0.5137 Regression loss 0.0295 Classification loss 0.4842 AP 1.0000 AR 0.0000
Epoch 033 batch 00007: Loss 0.5527 Regression loss 0.0236 Classification loss 0.5291 AP 1.0000 AR 0.0000
Epoch 033 batch 00008: Loss 0.6987 Regression loss 0.0186 Classification loss 0.6801 AP 1.0000 AR 0.0000
Epoch 033 batch 00009: Loss 0.5113 Regression loss 0.0239 Classification loss 0.4874 AP 1.0000 AR 0.0000
Epoch 033 batch 00010: Loss 0.6495 Regression loss 0.0235 Classification loss 0.6260 AP 1.0000 AR 0.0000
Epoch 034 batch 00001: Loss 0.6735 Regression loss 0.0245 Classification loss 0.6490 AP 1.0000 AR 0.0000
Epoch 034 batch 00002: Loss 0.6859 Regression loss 0.0244 Classification loss 0.6615 AP 1.0000 AR 0.0000
Epoch 034 batch 00003: Loss 0.4926 Regression loss 0.0233 Classification loss 0.4693 AP 1.0000 AR 0.0000
Epoch 034 batch 00004: Loss 0.4466 Regression loss 0.0252 Classification loss 0.4214 AP 1.0000 AR 0.0000
Epoch 034 batch 00005: Loss 0.4963 Regression loss 0.0223 Classification loss 0.4740 AP 1.0000 AR 0.0000
Epoch 034 batch 00006: Loss 0.5218 Regression loss 0.0243 Classification loss 0.4975 AP 1.0000 AR 0.0000
Epoch 034 batch 00007: Loss 0.6142 Regression loss 0.0341 Classification loss 0.5801 AP 1.0000 AR 0.0000
Epoch 034 batch 00008: Loss 0.6179 Regression loss 0.0187 Classification loss 0.5992 AP 1.0000 AR 0.2000
Epoch 034 batch 00009: Loss 0.6420 Regression loss 0.0293 Classification loss 0.6127 AP 1.0000 AR 0.0000
Epoch 034 batch 00010: Loss 0.5157 Regression loss 0.0260 Classification loss 0.4897 AP 1.0000 AR 0.0000
Epoch 035 batch 00001: Loss 0.6715 Regression loss 0.0295 Classification loss 0.6420 AP 1.0000 AR 0.0000
Epoch 035 batch 00002: Loss 0.5645 Regression loss 0.0206 Classification loss 0.5439 AP 1.0000 AR 0.0000
Epoch 035 batch 00003: Loss 0.5853 Regression loss 0.0289 Classification loss 0.5564 AP 1.0000 AR 0.0000
Epoch 035 batch 00004: Loss 0.5313 Regression loss 0.0194 Classification loss 0.5119 AP 1.0000 AR 0.0000
Epoch 035 batch 00005: Loss 0.4845 Regression loss 0.0282 Classification loss 0.4563 AP 1.0000 AR 0.2000
Epoch 035 batch 00006: Loss 0.4674 Regression loss 0.0234 Classification loss 0.4439 AP 1.0000 AR 0.0000
Epoch 035 batch 00007: Loss 0.6148 Regression loss 0.0212 Classification loss 0.5936 AP 1.0000 AR 0.0000
Epoch 035 batch 00008: Loss 0.5452 Regression loss 0.0288 Classification loss 0.5164 AP 1.0000 AR 0.0000
Epoch 035 batch 00009: Loss 0.8320 Regression loss 0.0222 Classification loss 0.8098 AP 1.0000 AR 0.0000
Epoch 035 batch 00010: Loss 0.4425 Regression loss 0.0259 Classification loss 0.4165 AP 1.0000 AR 0.0000
Epoch 036 batch 00001: Loss 0.5503 Regression loss 0.0256 Classification loss 0.5247 AP 1.0000 AR 0.2000
Epoch 036 batch 00002: Loss 0.7365 Regression loss 0.0215 Classification loss 0.7150 AP 1.0000 AR 0.0000
Epoch 036 batch 00003: Loss 0.5426 Regression loss 0.0229 Classification loss 0.5198 AP 1.0000 AR 0.0000
Epoch 036 batch 00004: Loss 0.7402 Regression loss 0.0244 Classification loss 0.7158 AP 1.0000 AR 0.0000
Epoch 036 batch 00005: Loss 0.4734 Regression loss 0.0266 Classification loss 0.4468 AP 1.0000 AR 0.0000
Epoch 036 batch 00006: Loss 0.5040 Regression loss 0.0241 Classification loss 0.4799 AP 1.0000 AR 0.0000
Epoch 036 batch 00007: Loss 0.5008 Regression loss 0.0281 Classification loss 0.4726 AP 1.0000 AR 0.0000
Epoch 036 batch 00008: Loss 0.6596 Regression loss 0.0208 Classification loss 0.6388 AP 0.8000 AR 0.0000
Epoch 036 batch 00009: Loss 0.5216 Regression loss 0.0305 Classification loss 0.4910 AP 1.0000 AR 0.0000
Epoch 036 batch 00010: Loss 0.5594 Regression loss 0.0287 Classification loss 0.5307 AP 1.0000 AR 0.0000
Epoch 037 batch 00001: Loss 0.6021 Regression loss 0.0283 Classification loss 0.5738 AP 1.0000 AR 0.0000
Epoch 037 batch 00002: Loss 0.5464 Regression loss 0.0244 Classification loss 0.5220 AP 1.0000 AR 0.0000
Epoch 037 batch 00003: Loss 0.4805 Regression loss 0.0290 Classification loss 0.4515 AP 1.0000 AR 0.0000
Epoch 037 batch 00004: Loss 0.4932 Regression loss 0.0226 Classification loss 0.4706 AP 1.0000 AR 0.0000
Epoch 037 batch 00005: Loss 0.5682 Regression loss 0.0252 Classification loss 0.5430 AP 1.0000 AR 0.0000
Epoch 037 batch 00006: Loss 0.4962 Regression loss 0.0269 Classification loss 0.4693 AP 1.0000 AR 0.0000
Epoch 037 batch 00007: Loss 0.6736 Regression loss 0.0231 Classification loss 0.6505 AP 1.0000 AR 0.0000
Epoch 037 batch 00008: Loss 0.5462 Regression loss 0.0300 Classification loss 0.5162 AP 1.0000 AR 0.2000
Epoch 037 batch 00009: Loss 0.4971 Regression loss 0.0221 Classification loss 0.4750 AP 1.0000 AR 0.0000
Epoch 037 batch 00010: Loss 0.5337 Regression loss 0.0224 Classification loss 0.5113 AP 1.0000 AR 0.0000
Epoch 038 batch 00001: Loss 0.4682 Regression loss 0.0313 Classification loss 0.4369 AP 1.0000 AR 0.0000
Epoch 038 batch 00002: Loss 0.5746 Regression loss 0.0230 Classification loss 0.5516 AP 1.0000 AR 0.0000
Epoch 038 batch 00003: Loss 0.6202 Regression loss 0.0202 Classification loss 0.5999 AP 1.0000 AR 0.0000
Epoch 038 batch 00004: Loss 0.5401 Regression loss 0.0289 Classification loss 0.5112 AP 1.0000 AR 0.0000
Epoch 038 batch 00005: Loss 0.4395 Regression loss 0.0260 Classification loss 0.4134 AP 1.0000 AR 0.2000
Epoch 038 batch 00006: Loss 0.4539 Regression loss 0.0245 Classification loss 0.4294 AP 1.0000 AR 0.0000
Epoch 038 batch 00007: Loss 0.5426 Regression loss 0.0211 Classification loss 0.5215 AP 1.0000 AR 0.0000
Epoch 038 batch 00008: Loss 0.5986 Regression loss 0.0245 Classification loss 0.5741 AP 1.0000 AR 0.0000
Epoch 038 batch 00009: Loss 0.4942 Regression loss 0.0194 Classification loss 0.4748 AP 1.0000 AR 0.0000
Epoch 038 batch 00010: Loss 0.5482 Regression loss 0.0293 Classification loss 0.5189 AP 1.0000 AR 0.0000
Epoch 039 batch 00001: Loss 0.5869 Regression loss 0.0299 Classification loss 0.5570 AP 1.0000 AR 0.0000
Epoch 039 batch 00002: Loss 0.5499 Regression loss 0.0216 Classification loss 0.5283 AP 1.0000 AR 0.0000
Epoch 039 batch 00003: Loss 0.7131 Regression loss 0.0216 Classification loss 0.6915 AP 1.0000 AR 0.2000
Epoch 039 batch 00004: Loss 0.5040 Regression loss 0.0303 Classification loss 0.4737 AP 1.0000 AR 0.0000
Epoch 039 batch 00005: Loss 0.6086 Regression loss 0.0267 Classification loss 0.5820 AP 1.0000 AR 0.0000
Epoch 039 batch 00006: Loss 0.4412 Regression loss 0.0236 Classification loss 0.4176 AP 1.0000 AR 0.0000
Epoch 039 batch 00007: Loss 0.3921 Regression loss 0.0285 Classification loss 0.3636 AP 1.0000 AR 0.0000
Epoch 039 batch 00008: Loss 0.4398 Regression loss 0.0223 Classification loss 0.4175 AP 1.0000 AR 0.0000
Epoch 039 batch 00009: Loss 0.5344 Regression loss 0.0210 Classification loss 0.5134 AP 1.0000 AR 0.0000
Epoch 039 batch 00010: Loss 0.5443 Regression loss 0.0206 Classification loss 0.5237 AP 1.0000 AR 0.0000
Epoch 040 batch 00001: Loss 0.5281 Regression loss 0.0266 Classification loss 0.5015 AP 1.0000 AR 0.0000
Epoch 040 batch 00002: Loss 0.4540 Regression loss 0.0226 Classification loss 0.4314 AP 1.0000 AR 0.2000
Epoch 040 batch 00003: Loss 0.5352 Regression loss 0.0265 Classification loss 0.5086 AP 1.0000 AR 0.0000
Epoch 040 batch 00004: Loss 0.6116 Regression loss 0.0203 Classification loss 0.5913 AP 1.0000 AR 0.0000
Epoch 040 batch 00005: Loss 0.5259 Regression loss 0.0274 Classification loss 0.4984 AP 1.0000 AR 0.0000
Epoch 040 batch 00006: Loss 0.7129 Regression loss 0.0282 Classification loss 0.6847 AP 1.0000 AR 0.0000
Epoch 040 batch 00007: Loss 0.5305 Regression loss 0.0214 Classification loss 0.5090 AP 1.0000 AR 0.0000
Epoch 040 batch 00008: Loss 0.5498 Regression loss 0.0255 Classification loss 0.5243 AP 1.0000 AR 0.0000
Epoch 040 batch 00009: Loss 0.4509 Regression loss 0.0222 Classification loss 0.4287 AP 1.0000 AR 0.0000
Epoch 040 batch 00010: Loss 0.4691 Regression loss 0.0258 Classification loss 0.4433 AP 1.0000 AR 0.0000
Epoch 041 batch 00001: Loss 0.7102 Regression loss 0.0177 Classification loss 0.6925 AP 1.0000 AR 0.0000
Epoch 041 batch 00002: Loss 0.5207 Regression loss 0.0263 Classification loss 0.4944 AP 1.0000 AR 0.0000
Epoch 041 batch 00003: Loss 0.6029 Regression loss 0.0209 Classification loss 0.5820 AP 1.0000 AR 0.2000
Epoch 041 batch 00004: Loss 0.5259 Regression loss 0.0279 Classification loss 0.4980 AP 1.0000 AR 0.0000
Epoch 041 batch 00005: Loss 0.7023 Regression loss 0.0208 Classification loss 0.6814 AP 1.0000 AR 0.0000
Epoch 041 batch 00006: Loss 0.4340 Regression loss 0.0199 Classification loss 0.4141 AP 1.0000 AR 0.0000
Epoch 041 batch 00007: Loss 0.4874 Regression loss 0.0245 Classification loss 0.4630 AP 1.0000 AR 0.0000
Epoch 041 batch 00008: Loss 0.4788 Regression loss 0.0309 Classification loss 0.4479 AP 1.0000 AR 0.0000
Epoch 041 batch 00009: Loss 0.4714 Regression loss 0.0271 Classification loss 0.4442 AP 1.0000 AR 0.0000
Epoch 041 batch 00010: Loss 0.5586 Regression loss 0.0270 Classification loss 0.5316 AP 1.0000 AR 0.0000
Epoch 042 batch 00001: Loss 0.4460 Regression loss 0.0271 Classification loss 0.4189 AP 1.0000 AR 0.0000
Epoch 042 batch 00002: Loss 0.6105 Regression loss 0.0222 Classification loss 0.5883 AP 1.0000 AR 0.0000
Epoch 042 batch 00003: Loss 0.5163 Regression loss 0.0229 Classification loss 0.4933 AP 1.0000 AR 0.0000
Epoch 042 batch 00004: Loss 0.4974 Regression loss 0.0242 Classification loss 0.4732 AP 1.0000 AR 0.2000
Epoch 042 batch 00005: Loss 0.4968 Regression loss 0.0279 Classification loss 0.4690 AP 1.0000 AR 0.0000
Epoch 042 batch 00006: Loss 0.5536 Regression loss 0.0273 Classification loss 0.5263 AP 1.0000 AR 0.0000
Epoch 042 batch 00007: Loss 0.5448 Regression loss 0.0252 Classification loss 0.5196 AP 1.0000 AR 0.0000
Epoch 042 batch 00008: Loss 0.4556 Regression loss 0.0278 Classification loss 0.4278 AP 1.0000 AR 0.0000
Epoch 042 batch 00009: Loss 0.6929 Regression loss 0.0261 Classification loss 0.6668 AP 1.0000 AR 0.0000
Epoch 042 batch 00010: Loss 0.4999 Regression loss 0.0232 Classification loss 0.4768 AP 1.0000 AR 0.0000
Epoch 043 batch 00001: Loss 0.4617 Regression loss 0.0250 Classification loss 0.4367 AP 1.0000 AR 0.0000
Epoch 043 batch 00002: Loss 0.4818 Regression loss 0.0204 Classification loss 0.4614 AP 1.0000 AR 0.0000
Epoch 043 batch 00003: Loss 0.7652 Regression loss 0.0250 Classification loss 0.7401 AP 1.0000 AR 0.0000
Epoch 043 batch 00004: Loss 0.6369 Regression loss 0.0236 Classification loss 0.6134 AP 1.0000 AR 0.0000
Epoch 043 batch 00005: Loss 0.5425 Regression loss 0.0314 Classification loss 0.5112 AP 1.0000 AR 0.0000
Epoch 043 batch 00006: Loss 0.5915 Regression loss 0.0222 Classification loss 0.5693 AP 1.0000 AR 0.2000
Epoch 043 batch 00007: Loss 0.6369 Regression loss 0.0231 Classification loss 0.6137 AP 1.0000 AR 0.0000
Epoch 043 batch 00008: Loss 0.6477 Regression loss 0.0269 Classification loss 0.6208 AP 1.0000 AR 0.0000
Epoch 043 batch 00009: Loss 0.5938 Regression loss 0.0256 Classification loss 0.5682 AP 1.0000 AR 0.0000
Epoch 043 batch 00010: Loss 0.4527 Regression loss 0.0257 Classification loss 0.4270 AP 1.0000 AR 0.0000
Epoch 044 batch 00001: Loss 0.6480 Regression loss 0.0268 Classification loss 0.6212 AP 1.0000 AR 0.0000
Epoch 044 batch 00002: Loss 1.2547 Regression loss 0.0287 Classification loss 1.2260 AP 1.0000 AR 0.2000
Epoch 044 batch 00003: Loss 0.7335 Regression loss 0.0252 Classification loss 0.7083 AP 1.0000 AR 0.0000
Epoch 044 batch 00004: Loss 0.5954 Regression loss 0.0278 Classification loss 0.5676 AP 1.0000 AR 0.0000
Epoch 044 batch 00005: Loss 0.9249 Regression loss 0.0283 Classification loss 0.8965 AP 1.0000 AR 0.0000
Epoch 044 batch 00006: Loss 0.9577 Regression loss 0.0248 Classification loss 0.9329 AP 1.0000 AR 0.0000
Epoch 044 batch 00007: Loss 0.7581 Regression loss 0.0253 Classification loss 0.7328 AP 1.0000 AR 0.0000
Epoch 044 batch 00008: Loss 1.0637 Regression loss 0.0250 Classification loss 1.0387 AP 1.0000 AR 0.0000
Epoch 044 batch 00009: Loss 0.9096 Regression loss 0.0274 Classification loss 0.8822 AP 1.0000 AR 0.0000
Epoch 044 batch 00010: Loss 0.9381 Regression loss 0.0260 Classification loss 0.9121 AP 1.0000 AR 0.0000
Epoch 045 batch 00001: Loss 0.8315 Regression loss 0.0237 Classification loss 0.8079 AP 1.0000 AR 0.0000
Epoch 045 batch 00002: Loss 0.7872 Regression loss 0.0268 Classification loss 0.7605 AP 1.0000 AR 0.0000
Epoch 045 batch 00003: Loss 0.6601 Regression loss 0.0246 Classification loss 0.6355 AP 1.0000 AR 0.0000
Epoch 045 batch 00004: Loss 0.5644 Regression loss 0.0286 Classification loss 0.5358 AP 1.0000 AR 0.0000
Epoch 045 batch 00005: Loss 0.5565 Regression loss 0.0253 Classification loss 0.5312 AP 1.0000 AR 0.2000
Epoch 045 batch 00006: Loss 0.6440 Regression loss 0.0276 Classification loss 0.6163 AP 1.0000 AR 0.0000
Epoch 045 batch 00007: Loss 0.6272 Regression loss 0.0289 Classification loss 0.5982 AP 1.0000 AR 0.0000
Epoch 045 batch 00008: Loss 0.9059 Regression loss 0.0281 Classification loss 0.8778 AP 0.8000 AR 0.0000
Epoch 045 batch 00009: Loss 0.5855 Regression loss 0.0200 Classification loss 0.5655 AP 1.0000 AR 0.0000
Epoch 045 batch 00010: Loss 0.5792 Regression loss 0.0272 Classification loss 0.5519 AP 1.0000 AR 0.0000
Epoch 046 batch 00001: Loss 0.5670 Regression loss 0.0245 Classification loss 0.5425 AP 1.0000 AR 0.0000
Epoch 046 batch 00002: Loss 0.4766 Regression loss 0.0238 Classification loss 0.4529 AP 1.0000 AR 0.0000
Epoch 046 batch 00003: Loss 0.5651 Regression loss 0.0304 Classification loss 0.5346 AP 1.0000 AR 0.0000
Epoch 046 batch 00004: Loss 0.5689 Regression loss 0.0293 Classification loss 0.5396 AP 1.0000 AR 0.0000
Epoch 046 batch 00005: Loss 0.8263 Regression loss 0.0196 Classification loss 0.8067 AP 1.0000 AR 0.0000
Epoch 046 batch 00006: Loss 0.7016 Regression loss 0.0196 Classification loss 0.6819 AP 1.0000 AR 0.0000
Epoch 046 batch 00007: Loss 0.7244 Regression loss 0.0303 Classification loss 0.6941 AP 1.0000 AR 0.0000
Epoch 046 batch 00008: Loss 0.5928 Regression loss 0.0247 Classification loss 0.5681 AP 1.0000 AR 0.0000
Epoch 046 batch 00009: Loss 0.6080 Regression loss 0.0270 Classification loss 0.5810 AP 1.0000 AR 0.0000
Epoch 046 batch 00010: Loss 0.6101 Regression loss 0.0224 Classification loss 0.5877 AP 1.0000 AR 0.2000
Epoch 047 batch 00001: Loss 0.6573 Regression loss 0.0234 Classification loss 0.6339 AP 1.0000 AR 0.0000
Epoch 047 batch 00002: Loss 0.5231 Regression loss 0.0264 Classification loss 0.4967 AP 1.0000 AR 0.0000
Epoch 047 batch 00003: Loss 0.5317 Regression loss 0.0209 Classification loss 0.5109 AP 1.0000 AR 0.0000
Epoch 047 batch 00004: Loss 0.5907 Regression loss 0.0235 Classification loss 0.5671 AP 1.0000 AR 0.0000
Epoch 047 batch 00005: Loss 0.4737 Regression loss 0.0272 Classification loss 0.4465 AP 1.0000 AR 0.0000
Epoch 047 batch 00006: Loss 0.5175 Regression loss 0.0228 Classification loss 0.4946 AP 1.0000 AR 0.2000
Epoch 047 batch 00007: Loss 0.4577 Regression loss 0.0310 Classification loss 0.4267 AP 1.0000 AR 0.0000
Epoch 047 batch 00008: Loss 0.5635 Regression loss 0.0271 Classification loss 0.5364 AP 1.0000 AR 0.0000
Epoch 047 batch 00009: Loss 0.6272 Regression loss 0.0231 Classification loss 0.6041 AP 1.0000 AR 0.0000
Epoch 047 batch 00010: Loss 0.5803 Regression loss 0.0239 Classification loss 0.5564 AP 1.0000 AR 0.0000
Epoch 048 batch 00001: Loss 0.6147 Regression loss 0.0193 Classification loss 0.5954 AP 1.0000 AR 0.0000
Epoch 048 batch 00002: Loss 0.5077 Regression loss 0.0212 Classification loss 0.4866 AP 1.0000 AR 0.0000
Epoch 048 batch 00003: Loss 0.6062 Regression loss 0.0252 Classification loss 0.5810 AP 1.0000 AR 0.0000
Epoch 048 batch 00004: Loss 0.5390 Regression loss 0.0276 Classification loss 0.5114 AP 1.0000 AR 0.0000
Epoch 048 batch 00005: Loss 0.5317 Regression loss 0.0263 Classification loss 0.5054 AP 1.0000 AR 0.0000
Epoch 048 batch 00006: Loss 0.4290 Regression loss 0.0317 Classification loss 0.3973 AP 1.0000 AR 0.0000
Epoch 048 batch 00007: Loss 0.6697 Regression loss 0.0209 Classification loss 0.6488 AP 1.0000 AR 0.2000
Epoch 048 batch 00008: Loss 0.6120 Regression loss 0.0244 Classification loss 0.5876 AP 1.0000 AR 0.0000
Epoch 048 batch 00009: Loss 0.4546 Regression loss 0.0218 Classification loss 0.4328 AP 1.0000 AR 0.0000
Epoch 048 batch 00010: Loss 0.5990 Regression loss 0.0266 Classification loss 0.5724 AP 1.0000 AR 0.0000
Epoch 049 batch 00001: Loss 0.5311 Regression loss 0.0235 Classification loss 0.5076 AP 1.0000 AR 0.0000
Epoch 049 batch 00002: Loss 0.4960 Regression loss 0.0252 Classification loss 0.4708 AP 1.0000 AR 0.0000
Epoch 049 batch 00003: Loss 0.5042 Regression loss 0.0224 Classification loss 0.4818 AP 1.0000 AR 0.0000
Epoch 049 batch 00004: Loss 0.5227 Regression loss 0.0256 Classification loss 0.4971 AP 1.0000 AR 0.0000
Epoch 049 batch 00005: Loss 0.5759 Regression loss 0.0240 Classification loss 0.5518 AP 1.0000 AR 0.0000
Epoch 049 batch 00006: Loss 0.4950 Regression loss 0.0211 Classification loss 0.4739 AP 1.0000 AR 0.2000
Epoch 049 batch 00007: Loss 0.5547 Regression loss 0.0264 Classification loss 0.5283 AP 1.0000 AR 0.0000
Epoch 049 batch 00008: Loss 0.5357 Regression loss 0.0260 Classification loss 0.5097 AP 1.0000 AR 0.0000
Epoch 049 batch 00009: Loss 0.5143 Regression loss 0.0237 Classification loss 0.4906 AP 1.0000 AR 0.0000
Epoch 049 batch 00010: Loss 0.5408 Regression loss 0.0279 Classification loss 0.5129 AP 1.0000 AR 0.0000
Epoch 050 batch 00001: Loss 0.6290 Regression loss 0.0219 Classification loss 0.6070 AP 1.0000 AR 0.2000
Epoch 050 batch 00002: Loss 0.6198 Regression loss 0.0281 Classification loss 0.5917 AP 1.0000 AR 0.0000
Epoch 050 batch 00003: Loss 0.5176 Regression loss 0.0247 Classification loss 0.4930 AP 1.0000 AR 0.0000
Epoch 050 batch 00004: Loss 0.5670 Regression loss 0.0195 Classification loss 0.5475 AP 1.0000 AR 0.0000
Epoch 050 batch 00005: Loss 0.5191 Regression loss 0.0209 Classification loss 0.4981 AP 1.0000 AR 0.0000
Epoch 050 batch 00006: Loss 0.4624 Regression loss 0.0249 Classification loss 0.4375 AP 1.0000 AR 0.0000
Epoch 050 batch 00007: Loss 0.4071 Regression loss 0.0246 Classification loss 0.3825 AP 1.0000 AR 0.0000
Epoch 050 batch 00008: Loss 0.5223 Regression loss 0.0268 Classification loss 0.4955 AP 1.0000 AR 0.0000
Epoch 050 batch 00009: Loss 0.4233 Regression loss 0.0298 Classification loss 0.3935 AP 1.0000 AR 0.0000
Epoch 050 batch 00010: Loss 0.6738 Regression loss 0.0283 Classification loss 0.6455 AP 1.0000 AR 0.0000
Epoch 051 batch 00001: Loss 0.6476 Regression loss 0.0260 Classification loss 0.6216 AP 1.0000 AR 0.2000
Epoch 051 batch 00002: Loss 0.4845 Regression loss 0.0238 Classification loss 0.4607 AP 1.0000 AR 0.0000
Epoch 051 batch 00003: Loss 0.4712 Regression loss 0.0269 Classification loss 0.4443 AP 1.0000 AR 0.0000
Epoch 051 batch 00004: Loss 0.6765 Regression loss 0.0264 Classification loss 0.6500 AP 1.0000 AR 0.0000
Epoch 051 batch 00005: Loss 0.4274 Regression loss 0.0213 Classification loss 0.4061 AP 1.0000 AR 0.0000
Epoch 051 batch 00006: Loss 0.5350 Regression loss 0.0274 Classification loss 0.5076 AP 1.0000 AR 0.0000
Epoch 051 batch 00007: Loss 0.6013 Regression loss 0.0244 Classification loss 0.5769 AP 1.0000 AR 0.0000
Epoch 051 batch 00008: Loss 0.4633 Regression loss 0.0244 Classification loss 0.4389 AP 1.0000 AR 0.0000
Epoch 051 batch 00009: Loss 0.5025 Regression loss 0.0228 Classification loss 0.4796 AP 1.0000 AR 0.0000
Epoch 051 batch 00010: Loss 0.5861 Regression loss 0.0246 Classification loss 0.5615 AP 1.0000 AR 0.0000
Epoch 052 batch 00001: Loss 0.4623 Regression loss 0.0259 Classification loss 0.4364 AP 1.0000 AR 0.0000
Epoch 052 batch 00002: Loss 0.5077 Regression loss 0.0218 Classification loss 0.4859 AP 1.0000 AR 0.2000
Epoch 052 batch 00003: Loss 0.5683 Regression loss 0.0227 Classification loss 0.5456 AP 1.0000 AR 0.0000
Epoch 052 batch 00004: Loss 0.5106 Regression loss 0.0325 Classification loss 0.4781 AP 1.0000 AR 0.0000
Epoch 052 batch 00005: Loss 0.6170 Regression loss 0.0213 Classification loss 0.5957 AP 1.0000 AR 0.0000
Epoch 052 batch 00006: Loss 0.5216 Regression loss 0.0244 Classification loss 0.4971 AP 1.0000 AR 0.0000
Epoch 052 batch 00007: Loss 0.4964 Regression loss 0.0247 Classification loss 0.4718 AP 1.0000 AR 0.0000
Epoch 052 batch 00008: Loss 0.5432 Regression loss 0.0214 Classification loss 0.5218 AP 1.0000 AR 0.0000
Epoch 052 batch 00009: Loss 0.6467 Regression loss 0.0253 Classification loss 0.6214 AP 1.0000 AR 0.0000
Epoch 052 batch 00010: Loss 0.4377 Regression loss 0.0240 Classification loss 0.4137 AP 1.0000 AR 0.0000
Epoch 053 batch 00001: Loss 0.5102 Regression loss 0.0258 Classification loss 0.4844 AP 1.0000 AR 0.2000
Epoch 053 batch 00002: Loss 0.5431 Regression loss 0.0229 Classification loss 0.5203 AP 1.0000 AR 0.0000
Epoch 053 batch 00003: Loss 0.5268 Regression loss 0.0244 Classification loss 0.5024 AP 1.0000 AR 0.0000
Epoch 053 batch 00004: Loss 0.4542 Regression loss 0.0257 Classification loss 0.4285 AP 1.0000 AR 0.0000
Epoch 053 batch 00005: Loss 0.5510 Regression loss 0.0202 Classification loss 0.5308 AP 1.0000 AR 0.0000
Epoch 053 batch 00006: Loss 0.4741 Regression loss 0.0241 Classification loss 0.4500 AP 1.0000 AR 0.0000
Epoch 053 batch 00007: Loss 0.5406 Regression loss 0.0210 Classification loss 0.5196 AP 1.0000 AR 0.0000
Epoch 053 batch 00008: Loss 0.4191 Regression loss 0.0243 Classification loss 0.3948 AP 1.0000 AR 0.0000
Epoch 053 batch 00009: Loss 0.6591 Regression loss 0.0266 Classification loss 0.6326 AP 1.0000 AR 0.0000
Epoch 053 batch 00010: Loss 0.4516 Regression loss 0.0332 Classification loss 0.4183 AP 1.0000 AR 0.0000
Epoch 054 batch 00001: Loss 0.5725 Regression loss 0.0218 Classification loss 0.5507 AP 1.0000 AR 0.0000
Epoch 054 batch 00002: Loss 0.4782 Regression loss 0.0295 Classification loss 0.4488 AP 1.0000 AR 0.0000
Epoch 054 batch 00003: Loss 0.5597 Regression loss 0.0245 Classification loss 0.5352 AP 1.0000 AR 0.0000
Epoch 054 batch 00004: Loss 0.5229 Regression loss 0.0241 Classification loss 0.4987 AP 1.0000 AR 0.0000
Epoch 054 batch 00005: Loss 0.4898 Regression loss 0.0200 Classification loss 0.4698 AP 1.0000 AR 0.0000
Epoch 054 batch 00006: Loss 0.5421 Regression loss 0.0205 Classification loss 0.5217 AP 1.0000 AR 0.0000
Epoch 054 batch 00007: Loss 0.5687 Regression loss 0.0258 Classification loss 0.5429 AP 1.0000 AR 0.0000
Epoch 054 batch 00008: Loss 0.4049 Regression loss 0.0262 Classification loss 0.3786 AP 1.0000 AR 0.0000
Epoch 054 batch 00009: Loss 0.5360 Regression loss 0.0272 Classification loss 0.5088 AP 1.0000 AR 0.2000
Epoch 054 batch 00010: Loss 0.4978 Regression loss 0.0251 Classification loss 0.4728 AP 1.0000 AR 0.0000
Epoch 055 batch 00001: Loss 0.4989 Regression loss 0.0200 Classification loss 0.4789 AP 1.0000 AR 0.0000
Epoch 055 batch 00002: Loss 0.5645 Regression loss 0.0225 Classification loss 0.5421 AP 1.0000 AR 0.0000
Epoch 055 batch 00003: Loss 0.6326 Regression loss 0.0253 Classification loss 0.6073 AP 1.0000 AR 0.0000
Epoch 055 batch 00004: Loss 0.5127 Regression loss 0.0262 Classification loss 0.4865 AP 1.0000 AR 0.0000
Epoch 055 batch 00005: Loss 0.5403 Regression loss 0.0240 Classification loss 0.5163 AP 1.0000 AR 0.0000
Epoch 055 batch 00006: Loss 0.4449 Regression loss 0.0271 Classification loss 0.4178 AP 1.0000 AR 0.0000
Epoch 055 batch 00007: Loss 0.3950 Regression loss 0.0251 Classification loss 0.3699 AP 1.0000 AR 0.0000
Epoch 055 batch 00008: Loss 0.4245 Regression loss 0.0224 Classification loss 0.4021 AP 1.0000 AR 0.0000
Epoch 055 batch 00009: Loss 0.6413 Regression loss 0.0296 Classification loss 0.6117 AP 1.0000 AR 0.2000
Epoch 055 batch 00010: Loss 0.4941 Regression loss 0.0234 Classification loss 0.4707 AP 1.0000 AR 0.0000
Epoch 056 batch 00001: Loss 0.4337 Regression loss 0.0284 Classification loss 0.4053 AP 1.0000 AR 0.0000
Epoch 056 batch 00002: Loss 0.4358 Regression loss 0.0251 Classification loss 0.4107 AP 1.0000 AR 0.2000
Epoch 056 batch 00003: Loss 0.4705 Regression loss 0.0240 Classification loss 0.4465 AP 1.0000 AR 0.0000
Epoch 056 batch 00004: Loss 0.5480 Regression loss 0.0232 Classification loss 0.5248 AP 1.0000 AR 0.0000
Epoch 056 batch 00005: Loss 0.5392 Regression loss 0.0225 Classification loss 0.5166 AP 1.0000 AR 0.0000
Epoch 056 batch 00006: Loss 0.5560 Regression loss 0.0237 Classification loss 0.5323 AP 1.0000 AR 0.0000
Epoch 056 batch 00007: Loss 0.6194 Regression loss 0.0264 Classification loss 0.5930 AP 1.0000 AR 0.0000
Epoch 056 batch 00008: Loss 0.6678 Regression loss 0.0194 Classification loss 0.6483 AP 1.0000 AR 0.0000
Epoch 056 batch 00009: Loss 0.4572 Regression loss 0.0238 Classification loss 0.4334 AP 1.0000 AR 0.0000
Epoch 056 batch 00010: Loss 0.4822 Regression loss 0.0262 Classification loss 0.4561 AP 1.0000 AR 0.0000
Epoch 057 batch 00001: Loss 0.5687 Regression loss 0.0239 Classification loss 0.5448 AP 1.0000 AR 0.0000
Epoch 057 batch 00002: Loss 0.5736 Regression loss 0.0218 Classification loss 0.5517 AP 1.0000 AR 0.0000
Epoch 057 batch 00003: Loss 0.5236 Regression loss 0.0223 Classification loss 0.5013 AP 1.0000 AR 0.0000
Epoch 057 batch 00004: Loss 0.5853 Regression loss 0.0249 Classification loss 0.5605 AP 1.0000 AR 0.0000
Epoch 057 batch 00005: Loss 0.4133 Regression loss 0.0278 Classification loss 0.3855 AP 1.0000 AR 0.0000
Epoch 057 batch 00006: Loss 0.5327 Regression loss 0.0254 Classification loss 0.5074 AP 1.0000 AR 0.0000
Epoch 057 batch 00007: Loss 0.4579 Regression loss 0.0288 Classification loss 0.4291 AP 1.0000 AR 0.0000
Epoch 057 batch 00008: Loss 0.4864 Regression loss 0.0271 Classification loss 0.4593 AP 1.0000 AR 0.0000
Epoch 057 batch 00009: Loss 0.5850 Regression loss 0.0208 Classification loss 0.5641 AP 1.0000 AR 0.2000
Epoch 057 batch 00010: Loss 0.5216 Regression loss 0.0232 Classification loss 0.4984 AP 1.0000 AR 0.0000
Epoch 058 batch 00001: Loss 0.4694 Regression loss 0.0265 Classification loss 0.4429 AP 1.0000 AR 0.2000
Epoch 058 batch 00002: Loss 0.4988 Regression loss 0.0231 Classification loss 0.4757 AP 1.0000 AR 0.0000
Epoch 058 batch 00003: Loss 0.5328 Regression loss 0.0248 Classification loss 0.5080 AP 1.0000 AR 0.0000
Epoch 058 batch 00004: Loss 0.4945 Regression loss 0.0254 Classification loss 0.4691 AP 1.0000 AR 0.0000
Epoch 058 batch 00005: Loss 0.4541 Regression loss 0.0279 Classification loss 0.4262 AP 1.0000 AR 0.0000
Epoch 058 batch 00006: Loss 0.5061 Regression loss 0.0273 Classification loss 0.4789 AP 1.0000 AR 0.0000
Epoch 058 batch 00007: Loss 0.4904 Regression loss 0.0264 Classification loss 0.4640 AP 1.0000 AR 0.0000
Epoch 058 batch 00008: Loss 0.7160 Regression loss 0.0225 Classification loss 0.6936 AP 1.0000 AR 0.0000
Epoch 058 batch 00009: Loss 0.5057 Regression loss 0.0249 Classification loss 0.4809 AP 1.0000 AR 0.0000
Epoch 058 batch 00010: Loss 0.5850 Regression loss 0.0265 Classification loss 0.5584 AP 1.0000 AR 0.0000
Epoch 059 batch 00001: Loss 0.4475 Regression loss 0.0256 Classification loss 0.4219 AP 1.0000 AR 0.0000
Epoch 059 batch 00002: Loss 0.4604 Regression loss 0.0239 Classification loss 0.4365 AP 1.0000 AR 0.0000
Epoch 059 batch 00003: Loss 0.6011 Regression loss 0.0278 Classification loss 0.5734 AP 1.0000 AR 0.0000
Epoch 059 batch 00004: Loss 0.4782 Regression loss 0.0231 Classification loss 0.4550 AP 1.0000 AR 0.0000
Epoch 059 batch 00005: Loss 0.5049 Regression loss 0.0235 Classification loss 0.4814 AP 1.0000 AR 0.2000
Epoch 059 batch 00006: Loss 0.6768 Regression loss 0.0218 Classification loss 0.6550 AP 1.0000 AR 0.0000
Epoch 059 batch 00007: Loss 0.4374 Regression loss 0.0246 Classification loss 0.4128 AP 1.0000 AR 0.0000
Epoch 059 batch 00008: Loss 0.4251 Regression loss 0.0288 Classification loss 0.3964 AP 1.0000 AR 0.0000
Epoch 059 batch 00009: Loss 0.6187 Regression loss 0.0253 Classification loss 0.5935 AP 1.0000 AR 0.0000
Epoch 059 batch 00010: Loss 0.6054 Regression loss 0.0227 Classification loss 0.5827 AP 1.0000 AR 0.0000
Epoch 060 batch 00001: Loss 0.6370 Regression loss 0.0299 Classification loss 0.6072 AP 1.0000 AR 0.0000
Epoch 060 batch 00002: Loss 0.5295 Regression loss 0.0234 Classification loss 0.5061 AP 1.0000 AR 0.0000
Epoch 060 batch 00003: Loss 0.5270 Regression loss 0.0181 Classification loss 0.5089 AP 1.0000 AR 0.0000
Epoch 060 batch 00004: Loss 0.4125 Regression loss 0.0237 Classification loss 0.3888 AP 1.0000 AR 0.0000
Epoch 060 batch 00005: Loss 0.5350 Regression loss 0.0241 Classification loss 0.5109 AP 1.0000 AR 0.0000
Epoch 060 batch 00006: Loss 0.5477 Regression loss 0.0255 Classification loss 0.5222 AP 1.0000 AR 0.0000
Epoch 060 batch 00007: Loss 0.5094 Regression loss 0.0272 Classification loss 0.4822 AP 1.0000 AR 0.2000
Epoch 060 batch 00008: Loss 0.4967 Regression loss 0.0263 Classification loss 0.4704 AP 1.0000 AR 0.0000
Epoch 060 batch 00009: Loss 0.5435 Regression loss 0.0222 Classification loss 0.5213 AP 1.0000 AR 0.0000
Epoch 060 batch 00010: Loss 0.4034 Regression loss 0.0244 Classification loss 0.3790 AP 1.0000 AR 0.0000
Epoch 061 batch 00001: Loss 0.7677 Regression loss 0.0247 Classification loss 0.7430 AP 1.0000 AR 0.0000
Epoch 061 batch 00002: Loss 0.6620 Regression loss 0.0190 Classification loss 0.6429 AP 1.0000 AR 0.2000
Epoch 061 batch 00003: Loss 0.5921 Regression loss 0.0258 Classification loss 0.5663 AP 1.0000 AR 0.0000
Epoch 061 batch 00004: Loss 0.4802 Regression loss 0.0250 Classification loss 0.4552 AP 1.0000 AR 0.0000
Epoch 061 batch 00005: Loss 0.5506 Regression loss 0.0212 Classification loss 0.5293 AP 1.0000 AR 0.0000
Epoch 061 batch 00006: Loss 0.6511 Regression loss 0.0241 Classification loss 0.6271 AP 1.0000 AR 0.0000
Epoch 061 batch 00007: Loss 0.4843 Regression loss 0.0222 Classification loss 0.4621 AP 1.0000 AR 0.0000
Epoch 061 batch 00008: Loss 0.4780 Regression loss 0.0250 Classification loss 0.4530 AP 1.0000 AR 0.0000
Epoch 061 batch 00009: Loss 0.4913 Regression loss 0.0202 Classification loss 0.4711 AP 1.0000 AR 0.0000
Epoch 061 batch 00010: Loss 0.4457 Regression loss 0.0273 Classification loss 0.4185 AP 1.0000 AR 0.0000
Epoch 062 batch 00001: Loss 0.4908 Regression loss 0.0238 Classification loss 0.4670 AP 1.0000 AR 0.0000
Epoch 062 batch 00002: Loss 0.5194 Regression loss 0.0239 Classification loss 0.4955 AP 0.8000 AR 0.0000
Epoch 062 batch 00003: Loss 0.5191 Regression loss 0.0215 Classification loss 0.4976 AP 1.0000 AR 0.0000
Epoch 062 batch 00004: Loss 0.4581 Regression loss 0.0282 Classification loss 0.4298 AP 1.0000 AR 0.0000
Epoch 062 batch 00005: Loss 0.4884 Regression loss 0.0220 Classification loss 0.4663 AP 1.0000 AR 0.0000
Epoch 062 batch 00006: Loss 0.7308 Regression loss 0.0217 Classification loss 0.7091 AP 1.0000 AR 0.0000
Epoch 062 batch 00007: Loss 0.4999 Regression loss 0.0264 Classification loss 0.4735 AP 1.0000 AR 0.0000
Epoch 062 batch 00008: Loss 0.5067 Regression loss 0.0212 Classification loss 0.4855 AP 1.0000 AR 0.0000
Epoch 062 batch 00009: Loss 0.4689 Regression loss 0.0315 Classification loss 0.4374 AP 1.0000 AR 0.2000
Epoch 062 batch 00010: Loss 0.5183 Regression loss 0.0255 Classification loss 0.4928 AP 1.0000 AR 0.0000
Epoch 063 batch 00001: Loss 0.4044 Regression loss 0.0293 Classification loss 0.3751 AP 1.0000 AR 0.0000
Epoch 063 batch 00002: Loss 0.4470 Regression loss 0.0276 Classification loss 0.4195 AP 0.8000 AR 0.0000
Epoch 063 batch 00003: Loss 0.5397 Regression loss 0.0235 Classification loss 0.5161 AP 1.0000 AR 0.0000
Epoch 063 batch 00004: Loss 0.5237 Regression loss 0.0275 Classification loss 0.4963 AP 1.0000 AR 0.0000
Epoch 063 batch 00005: Loss 0.6498 Regression loss 0.0177 Classification loss 0.6321 AP 1.0000 AR 0.0000
Epoch 063 batch 00006: Loss 0.5619 Regression loss 0.0225 Classification loss 0.5394 AP 1.0000 AR 0.0000
Epoch 063 batch 00007: Loss 0.6391 Regression loss 0.0248 Classification loss 0.6143 AP 1.0000 AR 0.2000
Epoch 063 batch 00008: Loss 0.4875 Regression loss 0.0236 Classification loss 0.4639 AP 1.0000 AR 0.0000
Epoch 063 batch 00009: Loss 0.4090 Regression loss 0.0210 Classification loss 0.3880 AP 1.0000 AR 0.0000
Epoch 063 batch 00010: Loss 0.5309 Regression loss 0.0241 Classification loss 0.5068 AP 1.0000 AR 0.0000
Epoch 064 batch 00001: Loss 0.5958 Regression loss 0.0253 Classification loss 0.5705 AP 1.0000 AR 0.0000
Epoch 064 batch 00002: Loss 0.3746 Regression loss 0.0258 Classification loss 0.3488 AP 1.0000 AR 0.0000
Epoch 064 batch 00003: Loss 0.5031 Regression loss 0.0210 Classification loss 0.4822 AP 1.0000 AR 0.0000
Epoch 064 batch 00004: Loss 0.5983 Regression loss 0.0292 Classification loss 0.5691 AP 1.0000 AR 0.0000
Epoch 064 batch 00005: Loss 0.5109 Regression loss 0.0272 Classification loss 0.4837 AP 1.0000 AR 0.2000
Epoch 064 batch 00006: Loss 0.4890 Regression loss 0.0209 Classification loss 0.4681 AP 1.0000 AR 0.0000
Epoch 064 batch 00007: Loss 0.4350 Regression loss 0.0225 Classification loss 0.4125 AP 1.0000 AR 0.0000
Epoch 064 batch 00008: Loss 0.6952 Regression loss 0.0229 Classification loss 0.6724 AP 1.0000 AR 0.0000
Epoch 064 batch 00009: Loss 0.4853 Regression loss 0.0209 Classification loss 0.4644 AP 1.0000 AR 0.0000
Epoch 064 batch 00010: Loss 0.4820 Regression loss 0.0235 Classification loss 0.4584 AP 1.0000 AR 0.0000
Epoch 065 batch 00001: Loss 0.6251 Regression loss 0.0207 Classification loss 0.6044 AP 1.0000 AR 0.2000
Epoch 065 batch 00002: Loss 0.5217 Regression loss 0.0269 Classification loss 0.4948 AP 1.0000 AR 0.0000
Epoch 065 batch 00003: Loss 0.5562 Regression loss 0.0207 Classification loss 0.5356 AP 1.0000 AR 0.0000
Epoch 065 batch 00004: Loss 0.4434 Regression loss 0.0225 Classification loss 0.4209 AP 1.0000 AR 0.0000
Epoch 065 batch 00005: Loss 0.5247 Regression loss 0.0187 Classification loss 0.5060 AP 1.0000 AR 0.0000
Epoch 065 batch 00006: Loss 0.4678 Regression loss 0.0221 Classification loss 0.4457 AP 1.0000 AR 0.0000
Epoch 065 batch 00007: Loss 0.4073 Regression loss 0.0218 Classification loss 0.3855 AP 1.0000 AR 0.0000
Epoch 065 batch 00008: Loss 0.4970 Regression loss 0.0299 Classification loss 0.4671 AP 1.0000 AR 0.0000
Epoch 065 batch 00009: Loss 0.5429 Regression loss 0.0304 Classification loss 0.5124 AP 1.0000 AR 0.0000
Epoch 065 batch 00010: Loss 0.5021 Regression loss 0.0253 Classification loss 0.4768 AP 1.0000 AR 0.0000
Epoch 066 batch 00001: Loss 0.5093 Regression loss 0.0222 Classification loss 0.4871 AP 1.0000 AR 0.0000
Epoch 066 batch 00002: Loss 0.5107 Regression loss 0.0247 Classification loss 0.4860 AP 1.0000 AR 0.0000
Epoch 066 batch 00003: Loss 0.5795 Regression loss 0.0189 Classification loss 0.5606 AP 1.0000 AR 0.0000
Epoch 066 batch 00004: Loss 0.4819 Regression loss 0.0251 Classification loss 0.4568 AP 0.8000 AR 0.2000
Epoch 066 batch 00005: Loss 0.5327 Regression loss 0.0253 Classification loss 0.5074 AP 1.0000 AR 0.0000
Epoch 066 batch 00006: Loss 0.5723 Regression loss 0.0251 Classification loss 0.5472 AP 1.0000 AR 0.0000
Epoch 066 batch 00007: Loss 0.4975 Regression loss 0.0181 Classification loss 0.4794 AP 1.0000 AR 0.0000
Epoch 066 batch 00008: Loss 0.3880 Regression loss 0.0263 Classification loss 0.3617 AP 1.0000 AR 0.0000
Epoch 066 batch 00009: Loss 0.5191 Regression loss 0.0274 Classification loss 0.4917 AP 1.0000 AR 0.0000
Epoch 066 batch 00010: Loss 0.4694 Regression loss 0.0246 Classification loss 0.4448 AP 1.0000 AR 0.0000
Epoch 067 batch 00001: Loss 0.6288 Regression loss 0.0240 Classification loss 0.6048 AP 1.0000 AR 0.0000
Epoch 067 batch 00002: Loss 0.4214 Regression loss 0.0213 Classification loss 0.4001 AP 1.0000 AR 0.0000
Epoch 067 batch 00003: Loss 0.5818 Regression loss 0.0240 Classification loss 0.5577 AP 1.0000 AR 0.2000
Epoch 067 batch 00004: Loss 0.4954 Regression loss 0.0274 Classification loss 0.4680 AP 1.0000 AR 0.0000
Epoch 067 batch 00005: Loss 0.4748 Regression loss 0.0228 Classification loss 0.4520 AP 1.0000 AR 0.0000
Epoch 067 batch 00006: Loss 0.6555 Regression loss 0.0182 Classification loss 0.6373 AP 1.0000 AR 0.0000
Epoch 067 batch 00007: Loss 0.4969 Regression loss 0.0233 Classification loss 0.4736 AP 1.0000 AR 0.0000
Epoch 067 batch 00008: Loss 0.4042 Regression loss 0.0244 Classification loss 0.3798 AP 1.0000 AR 0.0000
Epoch 067 batch 00009: Loss 0.5110 Regression loss 0.0238 Classification loss 0.4872 AP 1.0000 AR 0.0000
Epoch 067 batch 00010: Loss 0.4451 Regression loss 0.0262 Classification loss 0.4189 AP 1.0000 AR 0.0000
Epoch 068 batch 00001: Loss 0.4573 Regression loss 0.0226 Classification loss 0.4347 AP 1.0000 AR 0.0000
Epoch 068 batch 00002: Loss 0.5644 Regression loss 0.0226 Classification loss 0.5418 AP 1.0000 AR 0.0000
Epoch 068 batch 00003: Loss 0.4876 Regression loss 0.0248 Classification loss 0.4628 AP 1.0000 AR 0.0000
Epoch 068 batch 00004: Loss 0.4793 Regression loss 0.0249 Classification loss 0.4544 AP 1.0000 AR 0.0000
Epoch 068 batch 00005: Loss 0.4259 Regression loss 0.0232 Classification loss 0.4028 AP 1.0000 AR 0.0000
Epoch 068 batch 00006: Loss 0.5045 Regression loss 0.0213 Classification loss 0.4831 AP 1.0000 AR 0.0000
Epoch 068 batch 00007: Loss 0.4617 Regression loss 0.0246 Classification loss 0.4371 AP 1.0000 AR 0.0000
Epoch 068 batch 00008: Loss 0.5760 Regression loss 0.0275 Classification loss 0.5485 AP 1.0000 AR 0.0000
Epoch 068 batch 00009: Loss 0.5064 Regression loss 0.0227 Classification loss 0.4837 AP 1.0000 AR 0.0000
Epoch 068 batch 00010: Loss 0.5016 Regression loss 0.0245 Classification loss 0.4772 AP 1.0000 AR 0.2000
Epoch 069 batch 00001: Loss 0.4931 Regression loss 0.0255 Classification loss 0.4675 AP 1.0000 AR 0.0000
Epoch 069 batch 00002: Loss 0.5696 Regression loss 0.0194 Classification loss 0.5502 AP 1.0000 AR 0.0000
Epoch 069 batch 00003: Loss 0.3219 Regression loss 0.0228 Classification loss 0.2991 AP 1.0000 AR 0.0000
Epoch 069 batch 00004: Loss 0.5873 Regression loss 0.0254 Classification loss 0.5619 AP 1.0000 AR 0.0000
Epoch 069 batch 00005: Loss 0.4885 Regression loss 0.0231 Classification loss 0.4654 AP 1.0000 AR 0.2000
Epoch 069 batch 00006: Loss 0.4297 Regression loss 0.0268 Classification loss 0.4029 AP 1.0000 AR 0.0000
Epoch 069 batch 00007: Loss 0.5644 Regression loss 0.0191 Classification loss 0.5453 AP 1.0000 AR 0.0000
Epoch 069 batch 00008: Loss 0.4701 Regression loss 0.0262 Classification loss 0.4438 AP 1.0000 AR 0.0000
Epoch 069 batch 00009: Loss 0.5950 Regression loss 0.0259 Classification loss 0.5692 AP 1.0000 AR 0.0000
Epoch 069 batch 00010: Loss 0.5283 Regression loss 0.0215 Classification loss 0.5067 AP 0.8000 AR 0.0000
Epoch 070 batch 00001: Loss 0.4501 Regression loss 0.0203 Classification loss 0.4299 AP 1.0000 AR 0.0000
Epoch 070 batch 00002: Loss 0.4681 Regression loss 0.0196 Classification loss 0.4485 AP 1.0000 AR 0.0000
Epoch 070 batch 00003: Loss 0.5131 Regression loss 0.0249 Classification loss 0.4883 AP 1.0000 AR 0.2000
Epoch 070 batch 00004: Loss 0.5865 Regression loss 0.0256 Classification loss 0.5609 AP 1.0000 AR 0.0000
Epoch 070 batch 00005: Loss 0.4190 Regression loss 0.0243 Classification loss 0.3947 AP 0.8000 AR 0.0000
Epoch 070 batch 00006: Loss 0.6528 Regression loss 0.0247 Classification loss 0.6281 AP 1.0000 AR 0.0000
Epoch 070 batch 00007: Loss 0.4506 Regression loss 0.0280 Classification loss 0.4226 AP 1.0000 AR 0.0000
Epoch 070 batch 00008: Loss 0.4558 Regression loss 0.0233 Classification loss 0.4326 AP 1.0000 AR 0.0000
Epoch 070 batch 00009: Loss 0.5651 Regression loss 0.0261 Classification loss 0.5390 AP 1.0000 AR 0.0000
Epoch 070 batch 00010: Loss 0.6050 Regression loss 0.0203 Classification loss 0.5847 AP 1.0000 AR 0.0000
Epoch 071 batch 00001: Loss 0.5406 Regression loss 0.0248 Classification loss 0.5158 AP 1.0000 AR 0.0000
Epoch 071 batch 00002: Loss 0.4294 Regression loss 0.0279 Classification loss 0.4016 AP 1.0000 AR 0.0000
Epoch 071 batch 00003: Loss 0.6222 Regression loss 0.0181 Classification loss 0.6040 AP 1.0000 AR 0.0000
Epoch 071 batch 00004: Loss 0.5813 Regression loss 0.0259 Classification loss 0.5554 AP 1.0000 AR 0.2000
Epoch 071 batch 00005: Loss 0.4805 Regression loss 0.0250 Classification loss 0.4554 AP 0.8000 AR 0.0000
Epoch 071 batch 00006: Loss 0.4839 Regression loss 0.0236 Classification loss 0.4603 AP 0.8000 AR 0.0000
Epoch 071 batch 00007: Loss 0.5279 Regression loss 0.0251 Classification loss 0.5027 AP 1.0000 AR 0.0000
Epoch 071 batch 00008: Loss 0.4119 Regression loss 0.0270 Classification loss 0.3848 AP 1.0000 AR 0.0000
Epoch 071 batch 00009: Loss 0.4571 Regression loss 0.0217 Classification loss 0.4355 AP 1.0000 AR 0.0000
Epoch 071 batch 00010: Loss 0.5390 Regression loss 0.0195 Classification loss 0.5195 AP 1.0000 AR 0.0000
Epoch 072 batch 00001: Loss 0.4802 Regression loss 0.0210 Classification loss 0.4592 AP 1.0000 AR 0.0000
Epoch 072 batch 00002: Loss 0.4368 Regression loss 0.0229 Classification loss 0.4139 AP 1.0000 AR 0.0000
Epoch 072 batch 00003: Loss 0.4902 Regression loss 0.0242 Classification loss 0.4660 AP 1.0000 AR 0.0000
Epoch 072 batch 00004: Loss 0.5052 Regression loss 0.0201 Classification loss 0.4851 AP 1.0000 AR 0.0000
Epoch 072 batch 00005: Loss 0.4721 Regression loss 0.0294 Classification loss 0.4427 AP 1.0000 AR 0.0000
Epoch 072 batch 00006: Loss 0.5261 Regression loss 0.0246 Classification loss 0.5015 AP 1.0000 AR 0.0000
Epoch 072 batch 00007: Loss 0.4769 Regression loss 0.0225 Classification loss 0.4544 AP 1.0000 AR 0.2000
Epoch 072 batch 00008: Loss 0.6714 Regression loss 0.0271 Classification loss 0.6443 AP 1.0000 AR 0.0000
Epoch 072 batch 00009: Loss 0.4494 Regression loss 0.0243 Classification loss 0.4250 AP 1.0000 AR 0.0000
Epoch 072 batch 00010: Loss 0.6367 Regression loss 0.0215 Classification loss 0.6152 AP 1.0000 AR 0.0000
Epoch 073 batch 00001: Loss 0.4719 Regression loss 0.0280 Classification loss 0.4439 AP 1.0000 AR 0.0000
Epoch 073 batch 00002: Loss 0.4994 Regression loss 0.0243 Classification loss 0.4751 AP 1.0000 AR 0.0000
Epoch 073 batch 00003: Loss 0.5281 Regression loss 0.0278 Classification loss 0.5003 AP 1.0000 AR 0.0000
Epoch 073 batch 00004: Loss 0.5310 Regression loss 0.0199 Classification loss 0.5111 AP 1.0000 AR 0.0000
Epoch 073 batch 00005: Loss 0.4569 Regression loss 0.0226 Classification loss 0.4343 AP 1.0000 AR 0.0000
Epoch 073 batch 00006: Loss 0.5181 Regression loss 0.0259 Classification loss 0.4922 AP 1.0000 AR 0.0000
Epoch 073 batch 00007: Loss 0.4735 Regression loss 0.0229 Classification loss 0.4506 AP 1.0000 AR 0.0000
Epoch 073 batch 00008: Loss 0.5189 Regression loss 0.0238 Classification loss 0.4952 AP 1.0000 AR 0.2000
Epoch 073 batch 00009: Loss 0.5530 Regression loss 0.0201 Classification loss 0.5329 AP 1.0000 AR 0.0000
Epoch 073 batch 00010: Loss 0.5317 Regression loss 0.0215 Classification loss 0.5102 AP 1.0000 AR 0.0000
Epoch 074 batch 00001: Loss 0.4917 Regression loss 0.0214 Classification loss 0.4703 AP 1.0000 AR 0.0000
Epoch 074 batch 00002: Loss 0.4624 Regression loss 0.0204 Classification loss 0.4420 AP 0.8000 AR 0.0000
Epoch 074 batch 00003: Loss 0.5335 Regression loss 0.0253 Classification loss 0.5082 AP 1.0000 AR 0.0000
Epoch 074 batch 00004: Loss 0.5387 Regression loss 0.0286 Classification loss 0.5100 AP 1.0000 AR 0.0000
Epoch 074 batch 00005: Loss 0.5557 Regression loss 0.0240 Classification loss 0.5316 AP 1.0000 AR 0.0000
Epoch 074 batch 00006: Loss 0.6010 Regression loss 0.0185 Classification loss 0.5825 AP 1.0000 AR 0.2000
Epoch 074 batch 00007: Loss 0.5017 Regression loss 0.0255 Classification loss 0.4761 AP 1.0000 AR 0.0000
Epoch 074 batch 00008: Loss 0.3986 Regression loss 0.0207 Classification loss 0.3779 AP 1.0000 AR 0.0000
Epoch 074 batch 00009: Loss 0.5658 Regression loss 0.0214 Classification loss 0.5444 AP 1.0000 AR 0.0000
Epoch 074 batch 00010: Loss 0.5002 Regression loss 0.0247 Classification loss 0.4755 AP 1.0000 AR 0.0000
Epoch 075 batch 00001: Loss 0.5117 Regression loss 0.0252 Classification loss 0.4865 AP 1.0000 AR 0.0000
Epoch 075 batch 00002: Loss 0.4803 Regression loss 0.0202 Classification loss 0.4601 AP 1.0000 AR 0.0000
Epoch 075 batch 00003: Loss 0.4493 Regression loss 0.0267 Classification loss 0.4227 AP 1.0000 AR 0.0000
Epoch 075 batch 00004: Loss 0.4882 Regression loss 0.0213 Classification loss 0.4668 AP 1.0000 AR 0.0000
Epoch 075 batch 00005: Loss 0.4867 Regression loss 0.0249 Classification loss 0.4618 AP 0.8000 AR 0.0000
Epoch 075 batch 00006: Loss 0.5710 Regression loss 0.0191 Classification loss 0.5519 AP 1.0000 AR 0.0000
Epoch 075 batch 00007: Loss 0.5180 Regression loss 0.0285 Classification loss 0.4896 AP 1.0000 AR 0.0000
Epoch 075 batch 00008: Loss 0.5067 Regression loss 0.0251 Classification loss 0.4816 AP 1.0000 AR 0.0000
Epoch 075 batch 00009: Loss 0.4522 Regression loss 0.0246 Classification loss 0.4276 AP 1.0000 AR 0.0000
Epoch 075 batch 00010: Loss 0.6857 Regression loss 0.0176 Classification loss 0.6681 AP 1.0000 AR 0.2000
Epoch 076 batch 00001: Loss 0.5474 Regression loss 0.0225 Classification loss 0.5249 AP 1.0000 AR 0.0000
Epoch 076 batch 00002: Loss 0.5021 Regression loss 0.0227 Classification loss 0.4794 AP 1.0000 AR 0.2000
Epoch 076 batch 00003: Loss 0.5267 Regression loss 0.0203 Classification loss 0.5064 AP 1.0000 AR 0.0000
Epoch 076 batch 00004: Loss 0.4389 Regression loss 0.0238 Classification loss 0.4151 AP 1.0000 AR 0.0000
Epoch 076 batch 00005: Loss 0.6087 Regression loss 0.0222 Classification loss 0.5865 AP 1.0000 AR 0.0000
Epoch 076 batch 00006: Loss 0.4311 Regression loss 0.0231 Classification loss 0.4079 AP 1.0000 AR 0.0000
Epoch 076 batch 00007: Loss 0.4958 Regression loss 0.0328 Classification loss 0.4630 AP 1.0000 AR 0.0000
Epoch 076 batch 00008: Loss 0.4564 Regression loss 0.0219 Classification loss 0.4345 AP 1.0000 AR 0.0000
Epoch 076 batch 00009: Loss 0.5050 Regression loss 0.0247 Classification loss 0.4803 AP 1.0000 AR 0.0000
Epoch 076 batch 00010: Loss 0.5030 Regression loss 0.0231 Classification loss 0.4799 AP 1.0000 AR 0.0000
Epoch 077 batch 00001: Loss 0.6514 Regression loss 0.0198 Classification loss 0.6316 AP 1.0000 AR 0.0000
Epoch 077 batch 00002: Loss 0.5489 Regression loss 0.0240 Classification loss 0.5249 AP 1.0000 AR 0.0000
Epoch 077 batch 00003: Loss 0.5171 Regression loss 0.0227 Classification loss 0.4944 AP 0.8000 AR 0.0000
Epoch 077 batch 00004: Loss 0.4615 Regression loss 0.0271 Classification loss 0.4345 AP 1.0000 AR 0.0000
Epoch 077 batch 00005: Loss 0.4976 Regression loss 0.0216 Classification loss 0.4760 AP 1.0000 AR 0.2000
Epoch 077 batch 00006: Loss 0.4806 Regression loss 0.0265 Classification loss 0.4541 AP 1.0000 AR 0.0000
Epoch 077 batch 00007: Loss 0.5151 Regression loss 0.0224 Classification loss 0.4927 AP 1.0000 AR 0.0000
Epoch 077 batch 00008: Loss 0.4053 Regression loss 0.0250 Classification loss 0.3802 AP 1.0000 AR 0.0000
Epoch 077 batch 00009: Loss 0.3530 Regression loss 0.0190 Classification loss 0.3340 AP 1.0000 AR 0.0000
Epoch 077 batch 00010: Loss 0.6164 Regression loss 0.0211 Classification loss 0.5953 AP 1.0000 AR 0.0000
Epoch 078 batch 00001: Loss 0.5795 Regression loss 0.0206 Classification loss 0.5589 AP 1.0000 AR 0.0000
Epoch 078 batch 00002: Loss 0.4945 Regression loss 0.0211 Classification loss 0.4734 AP 0.8000 AR 0.0000
Epoch 078 batch 00003: Loss 0.5898 Regression loss 0.0235 Classification loss 0.5664 AP 0.8000 AR 0.0000
Epoch 078 batch 00004: Loss 0.5501 Regression loss 0.0249 Classification loss 0.5251 AP 1.0000 AR 0.0000
Epoch 078 batch 00005: Loss 0.4881 Regression loss 0.0200 Classification loss 0.4681 AP 1.0000 AR 0.0000
Epoch 078 batch 00006: Loss 0.5075 Regression loss 0.0258 Classification loss 0.4817 AP 1.0000 AR 0.2000
Epoch 078 batch 00007: Loss 0.4511 Regression loss 0.0238 Classification loss 0.4273 AP 1.0000 AR 0.0000
Epoch 078 batch 00008: Loss 0.4588 Regression loss 0.0274 Classification loss 0.4314 AP 1.0000 AR 0.0000
Epoch 078 batch 00009: Loss 0.4017 Regression loss 0.0244 Classification loss 0.3772 AP 1.0000 AR 0.0000
Epoch 078 batch 00010: Loss 0.5391 Regression loss 0.0237 Classification loss 0.5153 AP 1.0000 AR 0.0000
Epoch 079 batch 00001: Loss 0.6502 Regression loss 0.0289 Classification loss 0.6213 AP 1.0000 AR 0.0000
Epoch 079 batch 00002: Loss 0.4103 Regression loss 0.0250 Classification loss 0.3853 AP 1.0000 AR 0.0000
Epoch 079 batch 00003: Loss 0.5363 Regression loss 0.0216 Classification loss 0.5147 AP 0.8000 AR 0.2000
Epoch 079 batch 00004: Loss 0.4475 Regression loss 0.0207 Classification loss 0.4268 AP 1.0000 AR 0.0000
Epoch 079 batch 00005: Loss 0.4682 Regression loss 0.0225 Classification loss 0.4458 AP 1.0000 AR 0.0000
Epoch 079 batch 00006: Loss 0.5079 Regression loss 0.0240 Classification loss 0.4839 AP 1.0000 AR 0.0000
Epoch 079 batch 00007: Loss 0.5113 Regression loss 0.0243 Classification loss 0.4870 AP 1.0000 AR 0.0000
Epoch 079 batch 00008: Loss 0.5611 Regression loss 0.0180 Classification loss 0.5431 AP 1.0000 AR 0.0000
Epoch 079 batch 00009: Loss 0.3785 Regression loss 0.0233 Classification loss 0.3552 AP 1.0000 AR 0.0000
Epoch 079 batch 00010: Loss 0.5786 Regression loss 0.0260 Classification loss 0.5527 AP 1.0000 AR 0.0000
Epoch 080 batch 00001: Loss 0.4878 Regression loss 0.0254 Classification loss 0.4623 AP 1.0000 AR 0.0000
Epoch 080 batch 00002: Loss 0.5055 Regression loss 0.0211 Classification loss 0.4844 AP 1.0000 AR 0.0000
Epoch 080 batch 00003: Loss 0.6670 Regression loss 0.0260 Classification loss 0.6410 AP 1.0000 AR 0.0000
Epoch 080 batch 00004: Loss 0.4259 Regression loss 0.0278 Classification loss 0.3981 AP 0.8000 AR 0.0000
Epoch 080 batch 00005: Loss 0.5136 Regression loss 0.0183 Classification loss 0.4953 AP 0.8000 AR 0.2000
Epoch 080 batch 00006: Loss 0.4877 Regression loss 0.0199 Classification loss 0.4678 AP 1.0000 AR 0.0000
Epoch 080 batch 00007: Loss 0.4812 Regression loss 0.0211 Classification loss 0.4601 AP 1.0000 AR 0.0000
Epoch 080 batch 00008: Loss 0.5403 Regression loss 0.0237 Classification loss 0.5167 AP 1.0000 AR 0.0000
Epoch 080 batch 00009: Loss 0.5323 Regression loss 0.0253 Classification loss 0.5070 AP 1.0000 AR 0.0000
Epoch 080 batch 00010: Loss 0.3940 Regression loss 0.0227 Classification loss 0.3713 AP 1.0000 AR 0.0000
Epoch 081 batch 00001: Loss 0.4525 Regression loss 0.0223 Classification loss 0.4302 AP 1.0000 AR 0.0000
Epoch 081 batch 00002: Loss 0.4809 Regression loss 0.0193 Classification loss 0.4616 AP 1.0000 AR 0.0000
Epoch 081 batch 00003: Loss 0.4630 Regression loss 0.0223 Classification loss 0.4407 AP 0.8000 AR 0.0000
Epoch 081 batch 00004: Loss 0.5028 Regression loss 0.0246 Classification loss 0.4782 AP 1.0000 AR 0.0000
Epoch 081 batch 00005: Loss 0.5397 Regression loss 0.0226 Classification loss 0.5171 AP 0.8000 AR 0.0000
Epoch 081 batch 00006: Loss 0.5059 Regression loss 0.0209 Classification loss 0.4850 AP 1.0000 AR 0.2000
Epoch 081 batch 00007: Loss 0.4306 Regression loss 0.0250 Classification loss 0.4057 AP 1.0000 AR 0.0000
Epoch 081 batch 00008: Loss 0.5883 Regression loss 0.0250 Classification loss 0.5633 AP 1.0000 AR 0.0000
Epoch 081 batch 00009: Loss 0.5603 Regression loss 0.0248 Classification loss 0.5355 AP 1.0000 AR 0.0000
Epoch 081 batch 00010: Loss 0.4150 Regression loss 0.0264 Classification loss 0.3886 AP 1.0000 AR 0.0000
Epoch 082 batch 00001: Loss 0.4827 Regression loss 0.0229 Classification loss 0.4598 AP 1.0000 AR 0.0000
Epoch 082 batch 00002: Loss 0.6604 Regression loss 0.0206 Classification loss 0.6398 AP 1.0000 AR 0.0000
Epoch 082 batch 00003: Loss 0.4017 Regression loss 0.0239 Classification loss 0.3778 AP 1.0000 AR 0.0000
Epoch 082 batch 00004: Loss 0.4311 Regression loss 0.0235 Classification loss 0.4076 AP 0.6000 AR 0.0000
Epoch 082 batch 00005: Loss 0.4614 Regression loss 0.0250 Classification loss 0.4364 AP 0.8000 AR 0.0000
Epoch 082 batch 00006: Loss 0.5401 Regression loss 0.0221 Classification loss 0.5180 AP 1.0000 AR 0.0000
Epoch 082 batch 00007: Loss 0.4533 Regression loss 0.0196 Classification loss 0.4337 AP 1.0000 AR 0.2000
Epoch 082 batch 00008: Loss 0.6137 Regression loss 0.0243 Classification loss 0.5894 AP 1.0000 AR 0.0000
Epoch 082 batch 00009: Loss 0.5362 Regression loss 0.0257 Classification loss 0.5105 AP 1.0000 AR 0.0000
Epoch 082 batch 00010: Loss 0.5002 Regression loss 0.0223 Classification loss 0.4778 AP 1.0000 AR 0.0000
Epoch 083 batch 00001: Loss 0.5204 Regression loss 0.0267 Classification loss 0.4937 AP 1.0000 AR 0.0000
Epoch 083 batch 00002: Loss 0.4683 Regression loss 0.0279 Classification loss 0.4405 AP 1.0000 AR 0.2000
Epoch 083 batch 00003: Loss 0.4790 Regression loss 0.0232 Classification loss 0.4558 AP 0.8000 AR 0.0000
Epoch 083 batch 00004: Loss 0.5145 Regression loss 0.0201 Classification loss 0.4944 AP 1.0000 AR 0.0000
Epoch 083 batch 00005: Loss 0.6561 Regression loss 0.0215 Classification loss 0.6346 AP 1.0000 AR 0.0000
Epoch 083 batch 00006: Loss 0.4147 Regression loss 0.0213 Classification loss 0.3935 AP 1.0000 AR 0.0000
Epoch 083 batch 00007: Loss 0.5161 Regression loss 0.0189 Classification loss 0.4972 AP 1.0000 AR 0.0000
Epoch 083 batch 00008: Loss 0.4228 Regression loss 0.0224 Classification loss 0.4005 AP 1.0000 AR 0.0000
Epoch 083 batch 00009: Loss 0.4419 Regression loss 0.0243 Classification loss 0.4176 AP 1.0000 AR 0.0000
Epoch 083 batch 00010: Loss 0.5944 Regression loss 0.0268 Classification loss 0.5676 AP 1.0000 AR 0.0000
Epoch 084 batch 00001: Loss 0.4630 Regression loss 0.0224 Classification loss 0.4405 AP 0.8000 AR 0.0000
Epoch 084 batch 00002: Loss 0.4653 Regression loss 0.0247 Classification loss 0.4406 AP 0.8000 AR 0.0000
Epoch 084 batch 00003: Loss 0.5167 Regression loss 0.0262 Classification loss 0.4904 AP 1.0000 AR 0.0000
Epoch 084 batch 00004: Loss 0.5097 Regression loss 0.0223 Classification loss 0.4873 AP 1.0000 AR 0.0000
Epoch 084 batch 00005: Loss 0.5437 Regression loss 0.0271 Classification loss 0.5166 AP 1.0000 AR 0.0000
Epoch 084 batch 00006: Loss 0.5686 Regression loss 0.0257 Classification loss 0.5429 AP 1.0000 AR 0.0000
Epoch 084 batch 00007: Loss 0.4993 Regression loss 0.0236 Classification loss 0.4757 AP 1.0000 AR 0.0000
Epoch 084 batch 00008: Loss 0.4629 Regression loss 0.0221 Classification loss 0.4408 AP 1.0000 AR 0.0000
Epoch 084 batch 00009: Loss 0.4248 Regression loss 0.0238 Classification loss 0.4010 AP 1.0000 AR 0.0000
Epoch 084 batch 00010: Loss 0.5726 Regression loss 0.0204 Classification loss 0.5523 AP 1.0000 AR 0.2000
Epoch 085 batch 00001: Loss 0.5620 Regression loss 0.0192 Classification loss 0.5429 AP 1.0000 AR 0.2000
Epoch 085 batch 00002: Loss 0.4376 Regression loss 0.0253 Classification loss 0.4123 AP 1.0000 AR 0.0000
Epoch 085 batch 00003: Loss 0.4772 Regression loss 0.0186 Classification loss 0.4586 AP 1.0000 AR 0.0000
Epoch 085 batch 00004: Loss 0.5384 Regression loss 0.0262 Classification loss 0.5123 AP 1.0000 AR 0.0000
Epoch 085 batch 00005: Loss 0.4626 Regression loss 0.0244 Classification loss 0.4383 AP 1.0000 AR 0.0000
Epoch 085 batch 00006: Loss 0.5057 Regression loss 0.0261 Classification loss 0.4797 AP 1.0000 AR 0.0000
Epoch 085 batch 00007: Loss 0.4362 Regression loss 0.0236 Classification loss 0.4127 AP 1.0000 AR 0.0000
Epoch 085 batch 00008: Loss 0.5763 Regression loss 0.0260 Classification loss 0.5503 AP 0.8000 AR 0.0000
Epoch 085 batch 00009: Loss 0.4538 Regression loss 0.0205 Classification loss 0.4333 AP 1.0000 AR 0.2000
Epoch 085 batch 00010: Loss 0.5129 Regression loss 0.0245 Classification loss 0.4885 AP 0.8000 AR 0.0000
Epoch 086 batch 00001: Loss 0.5361 Regression loss 0.0251 Classification loss 0.5111 AP 1.0000 AR 0.0000
Epoch 086 batch 00002: Loss 0.5327 Regression loss 0.0225 Classification loss 0.5102 AP 1.0000 AR 0.0000
Epoch 086 batch 00003: Loss 0.5546 Regression loss 0.0245 Classification loss 0.5301 AP 1.0000 AR 0.0000
Epoch 086 batch 00004: Loss 0.4384 Regression loss 0.0215 Classification loss 0.4169 AP 1.0000 AR 0.0000
Epoch 086 batch 00005: Loss 0.5937 Regression loss 0.0205 Classification loss 0.5732 AP 1.0000 AR 0.0000
Epoch 086 batch 00006: Loss 0.4919 Regression loss 0.0242 Classification loss 0.4677 AP 1.0000 AR 0.2000
Epoch 086 batch 00007: Loss 0.5460 Regression loss 0.0210 Classification loss 0.5250 AP 1.0000 AR 0.0000
Epoch 086 batch 00008: Loss 0.5803 Regression loss 0.0308 Classification loss 0.5495 AP 1.0000 AR 0.0000
Epoch 086 batch 00009: Loss 0.5155 Regression loss 0.0197 Classification loss 0.4958 AP 0.6000 AR 0.0000
Epoch 086 batch 00010: Loss 0.4046 Regression loss 0.0250 Classification loss 0.3796 AP 1.0000 AR 0.0000
Epoch 087 batch 00001: Loss 0.4787 Regression loss 0.0267 Classification loss 0.4520 AP 1.0000 AR 0.0000
Epoch 087 batch 00002: Loss 0.5231 Regression loss 0.0203 Classification loss 0.5028 AP 1.0000 AR 0.0000
Epoch 087 batch 00003: Loss 0.4051 Regression loss 0.0248 Classification loss 0.3803 AP 1.0000 AR 0.2000
Epoch 087 batch 00004: Loss 0.4417 Regression loss 0.0253 Classification loss 0.4165 AP 1.0000 AR 0.0000
Epoch 087 batch 00005: Loss 0.5430 Regression loss 0.0205 Classification loss 0.5225 AP 1.0000 AR 0.0000
Epoch 087 batch 00006: Loss 0.4375 Regression loss 0.0225 Classification loss 0.4150 AP 1.0000 AR 0.0000
Epoch 087 batch 00007: Loss 0.5008 Regression loss 0.0242 Classification loss 0.4766 AP 0.8000 AR 0.0000
Epoch 087 batch 00008: Loss 0.5819 Regression loss 0.0200 Classification loss 0.5618 AP 0.7000 AR 0.0500
Epoch 087 batch 00009: Loss 0.5262 Regression loss 0.0243 Classification loss 0.5019 AP 1.0000 AR 0.0000
Epoch 087 batch 00010: Loss 0.5035 Regression loss 0.0208 Classification loss 0.4827 AP 0.6000 AR 0.0000
Epoch 088 batch 00001: Loss 0.5516 Regression loss 0.0171 Classification loss 0.5346 AP 0.8000 AR 0.0000
Epoch 088 batch 00002: Loss 0.3742 Regression loss 0.0209 Classification loss 0.3534 AP 1.0000 AR 0.2000
Epoch 088 batch 00003: Loss 0.6146 Regression loss 0.0246 Classification loss 0.5900 AP 1.0000 AR 0.0000
Epoch 088 batch 00004: Loss 0.5895 Regression loss 0.0232 Classification loss 0.5663 AP 1.0000 AR 0.0000
Epoch 088 batch 00005: Loss 0.4698 Regression loss 0.0244 Classification loss 0.4453 AP 1.0000 AR 0.0000
Epoch 088 batch 00006: Loss 0.4068 Regression loss 0.0234 Classification loss 0.3834 AP 1.0000 AR 0.0000
Epoch 088 batch 00007: Loss 0.5092 Regression loss 0.0227 Classification loss 0.4865 AP 1.0000 AR 0.2000
Epoch 088 batch 00008: Loss 0.4575 Regression loss 0.0172 Classification loss 0.4403 AP 0.8000 AR 0.0000
Epoch 088 batch 00009: Loss 0.4556 Regression loss 0.0236 Classification loss 0.4320 AP 1.0000 AR 0.0000
Epoch 088 batch 00010: Loss 0.5074 Regression loss 0.0319 Classification loss 0.4755 AP 1.0000 AR 0.0000
Epoch 089 batch 00001: Loss 0.4622 Regression loss 0.0232 Classification loss 0.4390 AP 1.0000 AR 0.2000
Epoch 089 batch 00002: Loss 0.4359 Regression loss 0.0218 Classification loss 0.4140 AP 1.0000 AR 0.0000
Epoch 089 batch 00003: Loss 0.4329 Regression loss 0.0314 Classification loss 0.4015 AP 1.0000 AR 0.0000
Epoch 089 batch 00004: Loss 0.4769 Regression loss 0.0214 Classification loss 0.4555 AP 1.0000 AR 0.0000
Epoch 089 batch 00005: Loss 0.5676 Regression loss 0.0195 Classification loss 0.5482 AP 1.0000 AR 0.0500
Epoch 089 batch 00006: Loss 0.5698 Regression loss 0.0246 Classification loss 0.5451 AP 0.8000 AR 0.0000
Epoch 089 batch 00007: Loss 0.5254 Regression loss 0.0237 Classification loss 0.5016 AP 0.8000 AR 0.0000
Epoch 089 batch 00008: Loss 0.5715 Regression loss 0.0215 Classification loss 0.5500 AP 1.0000 AR 0.0000
Epoch 089 batch 00009: Loss 0.3614 Regression loss 0.0245 Classification loss 0.3369 AP 1.0000 AR 0.0000
Epoch 089 batch 00010: Loss 0.5295 Regression loss 0.0216 Classification loss 0.5079 AP 0.8000 AR 0.0000
Epoch 090 batch 00001: Loss 0.4272 Regression loss 0.0237 Classification loss 0.4036 AP 1.0000 AR 0.0000
Epoch 090 batch 00002: Loss 0.3948 Regression loss 0.0204 Classification loss 0.3744 AP 1.0000 AR 0.0000
Epoch 090 batch 00003: Loss 0.5042 Regression loss 0.0258 Classification loss 0.4784 AP 1.0000 AR 0.2000
Epoch 090 batch 00004: Loss 0.4572 Regression loss 0.0219 Classification loss 0.4354 AP 1.0000 AR 0.0000
Epoch 090 batch 00005: Loss 0.4531 Regression loss 0.0252 Classification loss 0.4280 AP 0.8000 AR 0.0000
Epoch 090 batch 00006: Loss 0.6462 Regression loss 0.0197 Classification loss 0.6265 AP 1.0000 AR 0.0000
Epoch 090 batch 00007: Loss 0.5735 Regression loss 0.0186 Classification loss 0.5549 AP 1.0000 AR 0.0000
Epoch 090 batch 00008: Loss 0.4968 Regression loss 0.0242 Classification loss 0.4726 AP 1.0000 AR 0.0000
Epoch 090 batch 00009: Loss 0.5802 Regression loss 0.0233 Classification loss 0.5569 AP 1.0000 AR 0.0000
Epoch 090 batch 00010: Loss 0.4750 Regression loss 0.0258 Classification loss 0.4492 AP 1.0000 AR 0.0000
Epoch 091 batch 00001: Loss 0.4762 Regression loss 0.0215 Classification loss 0.4546 AP 1.0000 AR 0.0000
Epoch 091 batch 00002: Loss 0.5409 Regression loss 0.0256 Classification loss 0.5153 AP 1.0000 AR 0.0000
Epoch 091 batch 00003: Loss 0.5159 Regression loss 0.0226 Classification loss 0.4933 AP 1.0000 AR 0.0000
Epoch 091 batch 00004: Loss 0.4752 Regression loss 0.0259 Classification loss 0.4493 AP 1.0000 AR 0.0000
Epoch 091 batch 00005: Loss 0.4653 Regression loss 0.0260 Classification loss 0.4393 AP 1.0000 AR 0.2000
Epoch 091 batch 00006: Loss 0.4270 Regression loss 0.0173 Classification loss 0.4097 AP 1.0000 AR 0.0500
Epoch 091 batch 00007: Loss 0.5321 Regression loss 0.0213 Classification loss 0.5108 AP 1.0000 AR 0.0000
Epoch 091 batch 00008: Loss 0.5112 Regression loss 0.0262 Classification loss 0.4850 AP 1.0000 AR 0.0000
Epoch 091 batch 00009: Loss 0.4450 Regression loss 0.0202 Classification loss 0.4248 AP 1.0000 AR 0.0000
Epoch 091 batch 00010: Loss 0.4512 Regression loss 0.0245 Classification loss 0.4267 AP 0.8000 AR 0.0000
Epoch 092 batch 00001: Loss 0.4558 Regression loss 0.0225 Classification loss 0.4332 AP 0.8000 AR 0.0000
Epoch 092 batch 00002: Loss 0.4602 Regression loss 0.0232 Classification loss 0.4370 AP 1.0000 AR 0.0000
Epoch 092 batch 00003: Loss 0.3975 Regression loss 0.0202 Classification loss 0.3772 AP 1.0000 AR 0.2000
Epoch 092 batch 00004: Loss 0.4679 Regression loss 0.0229 Classification loss 0.4450 AP 0.8000 AR 0.0000
Epoch 092 batch 00005: Loss 0.4390 Regression loss 0.0234 Classification loss 0.4156 AP 1.0000 AR 0.0000
Epoch 092 batch 00006: Loss 0.4405 Regression loss 0.0256 Classification loss 0.4148 AP 1.0000 AR 0.0000
Epoch 092 batch 00007: Loss 0.6584 Regression loss 0.0219 Classification loss 0.6365 AP 1.0000 AR 0.0000
Epoch 092 batch 00008: Loss 0.4972 Regression loss 0.0214 Classification loss 0.4758 AP 1.0000 AR 0.2000
Epoch 092 batch 00009: Loss 0.4729 Regression loss 0.0221 Classification loss 0.4508 AP 1.0000 AR 0.0000
Epoch 092 batch 00010: Loss 0.6470 Regression loss 0.0270 Classification loss 0.6200 AP 1.0000 AR 0.0000
Epoch 093 batch 00001: Loss 0.5038 Regression loss 0.0219 Classification loss 0.4818 AP 0.8000 AR 0.0000
Epoch 093 batch 00002: Loss 0.5116 Regression loss 0.0219 Classification loss 0.4897 AP 1.0000 AR 0.0000
Epoch 093 batch 00003: Loss 0.4955 Regression loss 0.0216 Classification loss 0.4739 AP 0.8000 AR 0.0000
Epoch 093 batch 00004: Loss 0.5156 Regression loss 0.0234 Classification loss 0.4922 AP 1.0000 AR 0.0000
Epoch 093 batch 00005: Loss 0.4195 Regression loss 0.0255 Classification loss 0.3941 AP 1.0000 AR 0.0000
Epoch 093 batch 00006: Loss 0.4186 Regression loss 0.0206 Classification loss 0.3980 AP 1.0000 AR 0.0000
Epoch 093 batch 00007: Loss 0.5433 Regression loss 0.0242 Classification loss 0.5190 AP 1.0000 AR 0.2000
Epoch 093 batch 00008: Loss 0.5919 Regression loss 0.0276 Classification loss 0.5643 AP 1.0000 AR 0.0000
Epoch 093 batch 00009: Loss 0.4339 Regression loss 0.0219 Classification loss 0.4120 AP 1.0000 AR 0.0000
Epoch 093 batch 00010: Loss 0.4538 Regression loss 0.0248 Classification loss 0.4290 AP 1.0000 AR 0.0000
Epoch 094 batch 00001: Loss 0.4154 Regression loss 0.0226 Classification loss 0.3928 AP 0.8000 AR 0.0000
Epoch 094 batch 00002: Loss 0.5805 Regression loss 0.0269 Classification loss 0.5536 AP 1.0000 AR 0.0000
Epoch 094 batch 00003: Loss 0.4546 Regression loss 0.0235 Classification loss 0.4311 AP 1.0000 AR 0.0000
Epoch 094 batch 00004: Loss 0.5976 Regression loss 0.0223 Classification loss 0.5753 AP 1.0000 AR 0.0000
Epoch 094 batch 00005: Loss 0.5609 Regression loss 0.0267 Classification loss 0.5341 AP 0.8000 AR 0.0000
Epoch 094 batch 00006: Loss 0.4437 Regression loss 0.0215 Classification loss 0.4222 AP 1.0000 AR 0.2000
Epoch 094 batch 00007: Loss 0.5705 Regression loss 0.0233 Classification loss 0.5472 AP 1.0000 AR 0.0000
Epoch 094 batch 00008: Loss 0.4591 Regression loss 0.0244 Classification loss 0.4347 AP 1.0000 AR 0.0000
Epoch 094 batch 00009: Loss 0.5981 Regression loss 0.0199 Classification loss 0.5783 AP 1.0000 AR 0.2000
Epoch 094 batch 00010: Loss 0.3780 Regression loss 0.0187 Classification loss 0.3593 AP 1.0000 AR 0.0000
Epoch 095 batch 00001: Loss 0.6240 Regression loss 0.0213 Classification loss 0.6026 AP 1.0000 AR 0.2000
Epoch 095 batch 00002: Loss 0.4689 Regression loss 0.0253 Classification loss 0.4436 AP 1.0000 AR 0.0000
Epoch 095 batch 00003: Loss 0.4752 Regression loss 0.0192 Classification loss 0.4560 AP 1.0000 AR 0.0000
Epoch 095 batch 00004: Loss 0.4554 Regression loss 0.0209 Classification loss 0.4345 AP 1.0000 AR 0.0500
Epoch 095 batch 00005: Loss 0.5040 Regression loss 0.0227 Classification loss 0.4813 AP 1.0000 AR 0.2000
Epoch 095 batch 00006: Loss 0.5457 Regression loss 0.0260 Classification loss 0.5196 AP 1.0000 AR 0.0000
Epoch 095 batch 00007: Loss 0.4849 Regression loss 0.0214 Classification loss 0.4635 AP 1.0000 AR 0.0000
Epoch 095 batch 00008: Loss 0.4779 Regression loss 0.0228 Classification loss 0.4551 AP 1.0000 AR 0.0000
Epoch 095 batch 00009: Loss 0.3947 Regression loss 0.0223 Classification loss 0.3723 AP 0.8000 AR 0.0000
Epoch 095 batch 00010: Loss 0.4866 Regression loss 0.0247 Classification loss 0.4619 AP 0.8000 AR 0.0000
Epoch 096 batch 00001: Loss 0.4470 Regression loss 0.0288 Classification loss 0.4182 AP 1.0000 AR 0.0000
Epoch 096 batch 00002: Loss 0.4399 Regression loss 0.0230 Classification loss 0.4169 AP 1.0000 AR 0.2000
Epoch 096 batch 00003: Loss 0.4774 Regression loss 0.0239 Classification loss 0.4536 AP 1.0000 AR 0.0000
Epoch 096 batch 00004: Loss 0.4943 Regression loss 0.0216 Classification loss 0.4726 AP 0.8000 AR 0.0000
Epoch 096 batch 00005: Loss 0.4196 Regression loss 0.0221 Classification loss 0.3975 AP 0.6000 AR 0.0000
Epoch 096 batch 00006: Loss 0.5547 Regression loss 0.0248 Classification loss 0.5298 AP 0.8000 AR 0.0000
Epoch 096 batch 00007: Loss 0.4474 Regression loss 0.0225 Classification loss 0.4249 AP 1.0000 AR 0.0000
Epoch 096 batch 00008: Loss 0.6179 Regression loss 0.0241 Classification loss 0.5938 AP 1.0000 AR 0.0000
Epoch 096 batch 00009: Loss 0.4152 Regression loss 0.0213 Classification loss 0.3939 AP 0.8000 AR 0.0000
Epoch 096 batch 00010: Loss 0.5815 Regression loss 0.0189 Classification loss 0.5625 AP 1.0000 AR 0.0000
Epoch 097 batch 00001: Loss 0.5481 Regression loss 0.0231 Classification loss 0.5249 AP 1.0000 AR 0.0000
Epoch 097 batch 00002: Loss 0.5846 Regression loss 0.0198 Classification loss 0.5648 AP 1.0000 AR 0.0000
Epoch 097 batch 00003: Loss 0.6163 Regression loss 0.0245 Classification loss 0.5919 AP 0.8000 AR 0.0000
Epoch 097 batch 00004: Loss 0.4932 Regression loss 0.0263 Classification loss 0.4669 AP 1.0000 AR 0.0000
Epoch 097 batch 00005: Loss 0.5212 Regression loss 0.0282 Classification loss 0.4930 AP 1.0000 AR 0.0000
Epoch 097 batch 00006: Loss 0.4173 Regression loss 0.0219 Classification loss 0.3954 AP 0.8000 AR 0.2000
Epoch 097 batch 00007: Loss 0.4379 Regression loss 0.0202 Classification loss 0.4177 AP 1.0000 AR 0.2000
Epoch 097 batch 00008: Loss 0.4354 Regression loss 0.0228 Classification loss 0.4126 AP 1.0000 AR 0.0000
Epoch 097 batch 00009: Loss 0.4536 Regression loss 0.0220 Classification loss 0.4316 AP 1.0000 AR 0.0000
Epoch 097 batch 00010: Loss 0.4963 Regression loss 0.0245 Classification loss 0.4719 AP 1.0000 AR 0.0000
Epoch 098 batch 00001: Loss 0.5073 Regression loss 0.0245 Classification loss 0.4828 AP 1.0000 AR 0.2000
Epoch 098 batch 00002: Loss 0.4848 Regression loss 0.0276 Classification loss 0.4573 AP 0.8000 AR 0.0000
Epoch 098 batch 00003: Loss 0.4289 Regression loss 0.0227 Classification loss 0.4062 AP 0.8000 AR 0.0400
Epoch 098 batch 00004: Loss 0.5681 Regression loss 0.0276 Classification loss 0.5406 AP 1.0000 AR 0.0000
Epoch 098 batch 00005: Loss 0.5355 Regression loss 0.0200 Classification loss 0.5155 AP 1.0000 AR 0.2000
Epoch 098 batch 00006: Loss 0.6152 Regression loss 0.0242 Classification loss 0.5910 AP 1.0000 AR 0.0000
Epoch 098 batch 00007: Loss 0.5283 Regression loss 0.0246 Classification loss 0.5037 AP 1.0000 AR 0.0000
Epoch 098 batch 00008: Loss 0.5072 Regression loss 0.0227 Classification loss 0.4845 AP 1.0000 AR 0.0000
Epoch 098 batch 00009: Loss 0.4836 Regression loss 0.0220 Classification loss 0.4616 AP 1.0000 AR 0.0000
Epoch 098 batch 00010: Loss 0.5420 Regression loss 0.0235 Classification loss 0.5185 AP 1.0000 AR 0.0000
Epoch 099 batch 00001: Loss 0.4582 Regression loss 0.0240 Classification loss 0.4342 AP 1.0000 AR 0.0000
Epoch 099 batch 00002: Loss 0.6056 Regression loss 0.0223 Classification loss 0.5832 AP 0.9000 AR 0.3000
Epoch 099 batch 00003: Loss 0.5559 Regression loss 0.0216 Classification loss 0.5342 AP 1.0000 AR 0.2000
Epoch 099 batch 00004: Loss 0.4698 Regression loss 0.0239 Classification loss 0.4459 AP 0.8000 AR 0.0000
Epoch 099 batch 00005: Loss 0.5513 Regression loss 0.0212 Classification loss 0.5301 AP 0.8000 AR 0.0000
Epoch 099 batch 00006: Loss 0.5613 Regression loss 0.0230 Classification loss 0.5383 AP 1.0000 AR 0.0000
Epoch 099 batch 00007: Loss 0.3703 Regression loss 0.0254 Classification loss 0.3449 AP 1.0000 AR 0.0000
Epoch 099 batch 00008: Loss 0.5243 Regression loss 0.0238 Classification loss 0.5006 AP 1.0000 AR 0.0000
Epoch 099 batch 00009: Loss 0.5968 Regression loss 0.0203 Classification loss 0.5765 AP 1.0000 AR 0.0000
Epoch 099 batch 00010: Loss 0.4185 Regression loss 0.0193 Classification loss 0.3992 AP 1.0000 AR 0.0000
Epoch 100 batch 00001: Loss 0.6011 Regression loss 0.0248 Classification loss 0.5763 AP 1.0000 AR 0.0000
Epoch 100 batch 00002: Loss 0.4451 Regression loss 0.0273 Classification loss 0.4178 AP 1.0000 AR 0.0000
Epoch 100 batch 00003: Loss 0.5855 Regression loss 0.0264 Classification loss 0.5591 AP 1.0000 AR 0.0000
Epoch 100 batch 00004: Loss 0.3316 Regression loss 0.0220 Classification loss 0.3096 AP 1.0000 AR 0.0000
Epoch 100 batch 00005: Loss 0.5421 Regression loss 0.0170 Classification loss 0.5251 AP 1.0000 AR 0.0000
Epoch 100 batch 00006: Loss 0.4677 Regression loss 0.0215 Classification loss 0.4462 AP 1.0000 AR 0.0000
Epoch 100 batch 00007: Loss 0.5576 Regression loss 0.0247 Classification loss 0.5329 AP 1.0000 AR 0.0000
Epoch 100 batch 00008: Loss 0.5362 Regression loss 0.0233 Classification loss 0.5129 AP 1.0000 AR 0.0000
Epoch 100 batch 00009: Loss 0.4618 Regression loss 0.0242 Classification loss 0.4376 AP 0.8000 AR 0.2000
Epoch 100 batch 00010: Loss 0.4588 Regression loss 0.0232 Classification loss 0.4356 AP 1.0000 AR 0.1000
Epoch 101 batch 00001: Loss 0.4944 Regression loss 0.0238 Classification loss 0.4706 AP 0.9000 AR 0.1000
Epoch 101 batch 00002: Loss 0.4439 Regression loss 0.0205 Classification loss 0.4234 AP 0.8000 AR 0.0400
Epoch 101 batch 00003: Loss 0.3809 Regression loss 0.0234 Classification loss 0.3575 AP 1.0000 AR 0.0000
Epoch 101 batch 00004: Loss 0.5729 Regression loss 0.0268 Classification loss 0.5460 AP 1.0000 AR 0.2000
Epoch 101 batch 00005: Loss 0.4971 Regression loss 0.0250 Classification loss 0.4721 AP 0.8000 AR 0.2000
Epoch 101 batch 00006: Loss 0.5197 Regression loss 0.0198 Classification loss 0.5000 AP 1.0000 AR 0.0000
Epoch 101 batch 00007: Loss 0.4502 Regression loss 0.0222 Classification loss 0.4281 AP 1.0000 AR 0.0000
Epoch 101 batch 00008: Loss 0.3821 Regression loss 0.0201 Classification loss 0.3621 AP 1.0000 AR 0.0000
Epoch 101 batch 00009: Loss 0.5877 Regression loss 0.0205 Classification loss 0.5671 AP 1.0000 AR 0.0000
Epoch 101 batch 00010: Loss 0.5147 Regression loss 0.0271 Classification loss 0.4876 AP 1.0000 AR 0.0000
Epoch 102 batch 00001: Loss 0.5299 Regression loss 0.0239 Classification loss 0.5060 AP 1.0000 AR 0.0000
Epoch 102 batch 00002: Loss 0.4937 Regression loss 0.0236 Classification loss 0.4701 AP 0.8000 AR 0.0000
Epoch 102 batch 00003: Loss 0.4876 Regression loss 0.0222 Classification loss 0.4654 AP 1.0000 AR 0.1000
Epoch 102 batch 00004: Loss 0.4432 Regression loss 0.0230 Classification loss 0.4201 AP 1.0000 AR 0.2000
Epoch 102 batch 00005: Loss 0.4644 Regression loss 0.0242 Classification loss 0.4402 AP 1.0000 AR 0.2000
Epoch 102 batch 00006: Loss 0.4928 Regression loss 0.0233 Classification loss 0.4695 AP 1.0000 AR 0.0000
Epoch 102 batch 00007: Loss 0.4999 Regression loss 0.0327 Classification loss 0.4671 AP 1.0000 AR 0.0000
Epoch 102 batch 00008: Loss 0.4681 Regression loss 0.0154 Classification loss 0.4527 AP 1.0000 AR 0.0000
Epoch 102 batch 00009: Loss 0.4861 Regression loss 0.0217 Classification loss 0.4644 AP 0.8000 AR 0.0000
Epoch 102 batch 00010: Loss 0.4385 Regression loss 0.0206 Classification loss 0.4179 AP 1.0000 AR 0.0000
Epoch 103 batch 00001: Loss 0.3941 Regression loss 0.0209 Classification loss 0.3732 AP 1.0000 AR 0.0000
Epoch 103 batch 00002: Loss 0.4742 Regression loss 0.0228 Classification loss 0.4514 AP 0.6667 AR 0.2500
Epoch 103 batch 00003: Loss 0.5013 Regression loss 0.0313 Classification loss 0.4700 AP 0.6000 AR 0.0000
Epoch 103 batch 00004: Loss 0.5799 Regression loss 0.0227 Classification loss 0.5572 AP 0.6000 AR 0.0000
Epoch 103 batch 00005: Loss 0.4359 Regression loss 0.0222 Classification loss 0.4137 AP 0.8000 AR 0.0000
Epoch 103 batch 00006: Loss 0.5287 Regression loss 0.0207 Classification loss 0.5080 AP 1.0000 AR 0.0000
Epoch 103 batch 00007: Loss 0.4992 Regression loss 0.0186 Classification loss 0.4806 AP 1.0000 AR 0.0000
Epoch 103 batch 00008: Loss 0.4300 Regression loss 0.0230 Classification loss 0.4070 AP 1.0000 AR 0.0000
Epoch 103 batch 00009: Loss 0.4846 Regression loss 0.0250 Classification loss 0.4596 AP 1.0000 AR 0.2000
Epoch 103 batch 00010: Loss 0.5956 Regression loss 0.0220 Classification loss 0.5735 AP 0.8000 AR 0.0000
Epoch 104 batch 00001: Loss 0.4991 Regression loss 0.0218 Classification loss 0.4772 AP 1.0000 AR 0.0000
Epoch 104 batch 00002: Loss 0.4628 Regression loss 0.0235 Classification loss 0.4392 AP 0.8000 AR 0.2000
Epoch 104 batch 00003: Loss 0.4664 Regression loss 0.0191 Classification loss 0.4472 AP 0.6000 AR 0.0000
Epoch 104 batch 00004: Loss 0.4446 Regression loss 0.0228 Classification loss 0.4218 AP 0.8000 AR 0.1000
Epoch 104 batch 00005: Loss 0.5199 Regression loss 0.0258 Classification loss 0.4941 AP 1.0000 AR 0.0000
Epoch 104 batch 00006: Loss 0.4444 Regression loss 0.0208 Classification loss 0.4236 AP 1.0000 AR 0.0400
Epoch 104 batch 00007: Loss 0.4600 Regression loss 0.0250 Classification loss 0.4350 AP 1.0000 AR 0.0000
Epoch 104 batch 00008: Loss 0.4024 Regression loss 0.0177 Classification loss 0.3846 AP 1.0000 AR 0.0000
Epoch 104 batch 00009: Loss 0.5282 Regression loss 0.0247 Classification loss 0.5035 AP 1.0000 AR 0.0000
Epoch 104 batch 00010: Loss 0.5244 Regression loss 0.0291 Classification loss 0.4953 AP 1.0000 AR 0.2000
Epoch 105 batch 00001: Loss 0.4646 Regression loss 0.0225 Classification loss 0.4421 AP 1.0000 AR 0.0000
Epoch 105 batch 00002: Loss 0.5209 Regression loss 0.0249 Classification loss 0.4960 AP 0.8000 AR 0.0000
Epoch 105 batch 00003: Loss 0.5603 Regression loss 0.0172 Classification loss 0.5431 AP 1.0000 AR 0.0000
Epoch 105 batch 00004: Loss 0.4820 Regression loss 0.0259 Classification loss 0.4561 AP 1.0000 AR 0.0000
Epoch 105 batch 00005: Loss 0.4969 Regression loss 0.0239 Classification loss 0.4730 AP 0.9000 AR 0.0500
Epoch 105 batch 00006: Loss 0.5040 Regression loss 0.0211 Classification loss 0.4829 AP 0.6000 AR 0.0000
Epoch 105 batch 00007: Loss 0.3359 Regression loss 0.0201 Classification loss 0.3158 AP 0.8000 AR 0.0000
Epoch 105 batch 00008: Loss 0.5429 Regression loss 0.0185 Classification loss 0.5244 AP 1.0000 AR 0.4000
Epoch 105 batch 00009: Loss 0.5433 Regression loss 0.0215 Classification loss 0.5219 AP 1.0000 AR 0.0000
Epoch 105 batch 00010: Loss 0.5077 Regression loss 0.0268 Classification loss 0.4809 AP 1.0000 AR 0.0000
Epoch 106 batch 00001: Loss 0.5238 Regression loss 0.0222 Classification loss 0.5016 AP 1.0000 AR 0.0000
Epoch 106 batch 00002: Loss 0.5012 Regression loss 0.0207 Classification loss 0.4805 AP 1.0000 AR 0.0000
Epoch 106 batch 00003: Loss 0.3780 Regression loss 0.0236 Classification loss 0.3544 AP 1.0000 AR 0.2000
Epoch 106 batch 00004: Loss 0.6066 Regression loss 0.0247 Classification loss 0.5819 AP 1.0000 AR 0.0000
Epoch 106 batch 00005: Loss 0.4692 Regression loss 0.0267 Classification loss 0.4426 AP 0.8000 AR 0.0400
Epoch 106 batch 00006: Loss 0.5068 Regression loss 0.0247 Classification loss 0.4821 AP 0.8000 AR 0.0000
Epoch 106 batch 00007: Loss 0.5915 Regression loss 0.0192 Classification loss 0.5722 AP 1.0000 AR 0.2000
Epoch 106 batch 00008: Loss 0.5421 Regression loss 0.0257 Classification loss 0.5164 AP 1.0000 AR 0.0000
Epoch 106 batch 00009: Loss 0.4791 Regression loss 0.0192 Classification loss 0.4599 AP 1.0000 AR 0.0000
Epoch 106 batch 00010: Loss 0.4649 Regression loss 0.0220 Classification loss 0.4429 AP 0.8000 AR 0.0000
Epoch 107 batch 00001: Loss 0.5179 Regression loss 0.0237 Classification loss 0.4942 AP 0.8000 AR 0.0000
Epoch 107 batch 00002: Loss 0.4773 Regression loss 0.0211 Classification loss 0.4562 AP 1.0000 AR 0.2000
Epoch 107 batch 00003: Loss 0.3821 Regression loss 0.0224 Classification loss 0.3596 AP 1.0000 AR 0.0000
Epoch 107 batch 00004: Loss 0.4511 Regression loss 0.0231 Classification loss 0.4280 AP 0.8000 AR 0.0400
Epoch 107 batch 00005: Loss 0.4331 Regression loss 0.0188 Classification loss 0.4143 AP 0.8000 AR 0.2000
Epoch 107 batch 00006: Loss 0.6431 Regression loss 0.0216 Classification loss 0.6215 AP 1.0000 AR 0.1000
Epoch 107 batch 00007: Loss 0.4236 Regression loss 0.0264 Classification loss 0.3972 AP 1.0000 AR 0.0000
Epoch 107 batch 00008: Loss 0.5346 Regression loss 0.0233 Classification loss 0.5113 AP 1.0000 AR 0.0000
Epoch 107 batch 00009: Loss 0.4695 Regression loss 0.0235 Classification loss 0.4460 AP 1.0000 AR 0.0000
Epoch 107 batch 00010: Loss 0.4720 Regression loss 0.0244 Classification loss 0.4476 AP 1.0000 AR 0.0000
Epoch 108 batch 00001: Loss 0.5110 Regression loss 0.0173 Classification loss 0.4937 AP 1.0000 AR 0.0000
Epoch 108 batch 00002: Loss 0.4149 Regression loss 0.0222 Classification loss 0.3927 AP 1.0000 AR 0.0000
Epoch 108 batch 00003: Loss 0.4367 Regression loss 0.0237 Classification loss 0.4130 AP 0.8000 AR 0.0000
Epoch 108 batch 00004: Loss 0.5922 Regression loss 0.0270 Classification loss 0.5652 AP 1.0000 AR 0.2000
Epoch 108 batch 00005: Loss 0.4085 Regression loss 0.0204 Classification loss 0.3881 AP 0.6667 AR 0.0500
Epoch 108 batch 00006: Loss 0.4252 Regression loss 0.0235 Classification loss 0.4017 AP 1.0000 AR 0.2000
Epoch 108 batch 00007: Loss 0.5014 Regression loss 0.0223 Classification loss 0.4791 AP 0.8000 AR 0.0000
Epoch 108 batch 00008: Loss 0.5238 Regression loss 0.0203 Classification loss 0.5035 AP 1.0000 AR 0.0000
Epoch 108 batch 00009: Loss 0.5395 Regression loss 0.0279 Classification loss 0.5116 AP 1.0000 AR 0.0000
Epoch 108 batch 00010: Loss 0.5145 Regression loss 0.0207 Classification loss 0.4938 AP 1.0000 AR 0.0000
Epoch 109 batch 00001: Loss 0.4579 Regression loss 0.0239 Classification loss 0.4340 AP 0.6000 AR 0.0000
Epoch 109 batch 00002: Loss 0.3863 Regression loss 0.0251 Classification loss 0.3612 AP 1.0000 AR 0.0000
Epoch 109 batch 00003: Loss 0.5620 Regression loss 0.0170 Classification loss 0.5449 AP 0.8000 AR 0.2000
Epoch 109 batch 00004: Loss 0.4406 Regression loss 0.0220 Classification loss 0.4185 AP 1.0000 AR 0.0000
Epoch 109 batch 00005: Loss 0.5206 Regression loss 0.0208 Classification loss 0.4998 AP 0.8000 AR 0.0000
Epoch 109 batch 00006: Loss 0.5507 Regression loss 0.0219 Classification loss 0.5288 AP 1.0000 AR 0.0000
Epoch 109 batch 00007: Loss 0.4695 Regression loss 0.0225 Classification loss 0.4470 AP 1.0000 AR 0.0000
Epoch 109 batch 00008: Loss 0.4916 Regression loss 0.0246 Classification loss 0.4670 AP 1.0000 AR 0.0000
Epoch 109 batch 00009: Loss 0.4620 Regression loss 0.0217 Classification loss 0.4403 AP 1.0000 AR 0.0000
Epoch 109 batch 00010: Loss 0.4859 Regression loss 0.0245 Classification loss 0.4614 AP 1.0000 AR 0.2000
Epoch 110 batch 00001: Loss 0.3932 Regression loss 0.0241 Classification loss 0.3691 AP 0.8000 AR 0.0000
Epoch 110 batch 00002: Loss 0.3743 Regression loss 0.0227 Classification loss 0.3516 AP 1.0000 AR 0.0000
Epoch 110 batch 00003: Loss 0.4514 Regression loss 0.0231 Classification loss 0.4283 AP 1.0000 AR 0.0400
Epoch 110 batch 00004: Loss 0.4785 Regression loss 0.0213 Classification loss 0.4572 AP 0.8000 AR 0.0000
Epoch 110 batch 00005: Loss 0.5024 Regression loss 0.0202 Classification loss 0.4822 AP 1.0000 AR 0.0000
Epoch 110 batch 00006: Loss 0.5611 Regression loss 0.0218 Classification loss 0.5393 AP 0.8000 AR 0.0000
Epoch 110 batch 00007: Loss 0.5313 Regression loss 0.0195 Classification loss 0.5118 AP 1.0000 AR 0.0000
Epoch 110 batch 00008: Loss 0.4510 Regression loss 0.0245 Classification loss 0.4265 AP 0.8000 AR 0.4000
Epoch 110 batch 00009: Loss 0.5091 Regression loss 0.0274 Classification loss 0.4816 AP 1.0000 AR 0.0000
Epoch 110 batch 00010: Loss 0.5269 Regression loss 0.0238 Classification loss 0.5031 AP 1.0000 AR 0.0000
Epoch 111 batch 00001: Loss 0.3906 Regression loss 0.0231 Classification loss 0.3674 AP 1.0000 AR 0.0000
Epoch 111 batch 00002: Loss 0.6050 Regression loss 0.0264 Classification loss 0.5786 AP 1.0000 AR 0.0000
Epoch 111 batch 00003: Loss 0.5287 Regression loss 0.0216 Classification loss 0.5070 AP 1.0000 AR 0.0000
Epoch 111 batch 00004: Loss 0.4282 Regression loss 0.0188 Classification loss 0.4094 AP 0.8000 AR 0.0000
Epoch 111 batch 00005: Loss 0.4225 Regression loss 0.0236 Classification loss 0.3989 AP 0.6000 AR 0.0000
Epoch 111 batch 00006: Loss 0.4579 Regression loss 0.0233 Classification loss 0.4346 AP 1.0000 AR 0.0000
Epoch 111 batch 00007: Loss 0.6786 Regression loss 0.0202 Classification loss 0.6584 AP 0.9000 AR 0.3000
Epoch 111 batch 00008: Loss 0.4857 Regression loss 0.0191 Classification loss 0.4666 AP 0.8000 AR 0.0000
Epoch 111 batch 00009: Loss 0.4877 Regression loss 0.0252 Classification loss 0.4625 AP 1.0000 AR 0.0000
Epoch 111 batch 00010: Loss 0.4385 Regression loss 0.0254 Classification loss 0.4131 AP 1.0000 AR 0.2000
Epoch 112 batch 00001: Loss 0.4764 Regression loss 0.0231 Classification loss 0.4533 AP 1.0000 AR 0.0000
Epoch 112 batch 00002: Loss 0.4446 Regression loss 0.0227 Classification loss 0.4219 AP 0.8000 AR 0.1000
Epoch 112 batch 00003: Loss 0.5661 Regression loss 0.0164 Classification loss 0.5497 AP 0.8000 AR 0.0000
Epoch 112 batch 00004: Loss 0.4801 Regression loss 0.0177 Classification loss 0.4625 AP 1.0000 AR 0.0000
Epoch 112 batch 00005: Loss 0.4178 Regression loss 0.0259 Classification loss 0.3918 AP 1.0000 AR 0.0000
Epoch 112 batch 00006: Loss 0.5127 Regression loss 0.0280 Classification loss 0.4847 AP 1.0000 AR 0.2000
Epoch 112 batch 00007: Loss 0.4909 Regression loss 0.0241 Classification loss 0.4668 AP 1.0000 AR 0.0000
Epoch 112 batch 00008: Loss 0.3794 Regression loss 0.0176 Classification loss 0.3618 AP 0.8000 AR 0.0000
Epoch 112 batch 00009: Loss 0.5839 Regression loss 0.0227 Classification loss 0.5613 AP 1.0000 AR 0.2000
Epoch 112 batch 00010: Loss 0.5168 Regression loss 0.0231 Classification loss 0.4936 AP 0.8000 AR 0.0000
Epoch 113 batch 00001: Loss 0.3622 Regression loss 0.0270 Classification loss 0.3352 AP 1.0000 AR 0.2000
Epoch 113 batch 00002: Loss 0.5353 Regression loss 0.0274 Classification loss 0.5079 AP 1.0000 AR 0.0000
Epoch 113 batch 00003: Loss 0.4360 Regression loss 0.0228 Classification loss 0.4131 AP 0.8000 AR 0.0000
Epoch 113 batch 00004: Loss 0.4954 Regression loss 0.0205 Classification loss 0.4749 AP 0.8000 AR 0.0000
Epoch 113 batch 00005: Loss 0.4718 Regression loss 0.0233 Classification loss 0.4486 AP 0.8000 AR 0.0000
Epoch 113 batch 00006: Loss 0.4552 Regression loss 0.0181 Classification loss 0.4371 AP 1.0000 AR 0.0000
Epoch 113 batch 00007: Loss 0.4445 Regression loss 0.0205 Classification loss 0.4240 AP 0.8000 AR 0.0000
Epoch 113 batch 00008: Loss 0.5816 Regression loss 0.0253 Classification loss 0.5563 AP 1.0000 AR 0.1000
Epoch 113 batch 00009: Loss 0.4580 Regression loss 0.0211 Classification loss 0.4368 AP 0.6000 AR 0.0000
Epoch 113 batch 00010: Loss 0.4514 Regression loss 0.0210 Classification loss 0.4304 AP 0.8000 AR 0.0000
Epoch 114 batch 00001: Loss 0.4123 Regression loss 0.0246 Classification loss 0.3878 AP 0.8000 AR 0.0400
Epoch 114 batch 00002: Loss 0.4302 Regression loss 0.0202 Classification loss 0.4099 AP 0.8000 AR 0.0000
Epoch 114 batch 00003: Loss 0.4649 Regression loss 0.0241 Classification loss 0.4409 AP 0.8000 AR 0.2000
Epoch 114 batch 00004: Loss 0.4946 Regression loss 0.0230 Classification loss 0.4717 AP 0.8000 AR 0.0000
Epoch 114 batch 00005: Loss 0.3951 Regression loss 0.0204 Classification loss 0.3747 AP 1.0000 AR 0.3000
Epoch 114 batch 00006: Loss 0.4770 Regression loss 0.0199 Classification loss 0.4571 AP 1.0000 AR 0.0000
Epoch 114 batch 00007: Loss 0.4767 Regression loss 0.0256 Classification loss 0.4511 AP 0.8000 AR 0.0000
Epoch 114 batch 00008: Loss 0.4384 Regression loss 0.0204 Classification loss 0.4180 AP 1.0000 AR 0.0000
Epoch 114 batch 00009: Loss 0.5501 Regression loss 0.0245 Classification loss 0.5255 AP 1.0000 AR 0.0000
Epoch 114 batch 00010: Loss 0.6427 Regression loss 0.0212 Classification loss 0.6215 AP 1.0000 AR 0.0000
Epoch 115 batch 00001: Loss 0.4571 Regression loss 0.0213 Classification loss 0.4358 AP 1.0000 AR 0.1000
Epoch 115 batch 00002: Loss 0.4625 Regression loss 0.0297 Classification loss 0.4328 AP 0.8000 AR 0.0000
Epoch 115 batch 00003: Loss 0.6699 Regression loss 0.0270 Classification loss 0.6429 AP 1.0000 AR 0.2000
Epoch 115 batch 00004: Loss 0.4880 Regression loss 0.0214 Classification loss 0.4667 AP 1.0000 AR 0.0000
Epoch 115 batch 00005: Loss 0.4325 Regression loss 0.0213 Classification loss 0.4112 AP 0.8000 AR 0.0000
Epoch 115 batch 00006: Loss 0.4557 Regression loss 0.0226 Classification loss 0.4331 AP 1.0000 AR 0.0000
Epoch 115 batch 00007: Loss 0.4023 Regression loss 0.0255 Classification loss 0.3768 AP 1.0000 AR 0.2000
Epoch 115 batch 00008: Loss 0.5239 Regression loss 0.0216 Classification loss 0.5024 AP 1.0000 AR 0.0000
Epoch 115 batch 00009: Loss 0.6790 Regression loss 0.0171 Classification loss 0.6619 AP 1.0000 AR 0.0000
Epoch 115 batch 00010: Loss 0.4192 Regression loss 0.0233 Classification loss 0.3959 AP 1.0000 AR 0.0000
Epoch 116 batch 00001: Loss 0.5117 Regression loss 0.0220 Classification loss 0.4897 AP 1.0000 AR 0.2000
Epoch 116 batch 00002: Loss 0.5556 Regression loss 0.0228 Classification loss 0.5328 AP 1.0000 AR 0.0000
Epoch 116 batch 00003: Loss 0.4111 Regression loss 0.0226 Classification loss 0.3885 AP 1.0000 AR 0.0000
Epoch 116 batch 00004: Loss 0.4866 Regression loss 0.0274 Classification loss 0.4592 AP 0.6000 AR 0.0000
Epoch 116 batch 00005: Loss 0.5125 Regression loss 0.0201 Classification loss 0.4924 AP 0.7000 AR 0.1000
Epoch 116 batch 00006: Loss 0.3619 Regression loss 0.0208 Classification loss 0.3411 AP 0.8000 AR 0.2000
Epoch 116 batch 00007: Loss 0.4674 Regression loss 0.0250 Classification loss 0.4424 AP 0.8000 AR 0.0000
Epoch 116 batch 00008: Loss 0.4612 Regression loss 0.0228 Classification loss 0.4384 AP 1.0000 AR 0.0000
Epoch 116 batch 00009: Loss 0.4682 Regression loss 0.0203 Classification loss 0.4480 AP 0.8000 AR 0.0000
Epoch 116 batch 00010: Loss 0.5584 Regression loss 0.0279 Classification loss 0.5305 AP 0.8000 AR 0.0000
Epoch 117 batch 00001: Loss 0.3555 Regression loss 0.0293 Classification loss 0.3262 AP 1.0000 AR 0.2000
Epoch 117 batch 00002: Loss 0.4602 Regression loss 0.0243 Classification loss 0.4359 AP 1.0000 AR 0.0000
Epoch 117 batch 00003: Loss 0.4855 Regression loss 0.0189 Classification loss 0.4666 AP 1.0000 AR 0.0000
Epoch 117 batch 00004: Loss 0.4812 Regression loss 0.0247 Classification loss 0.4565 AP 1.0000 AR 0.0000
Epoch 117 batch 00005: Loss 0.4027 Regression loss 0.0262 Classification loss 0.3765 AP 1.0000 AR 0.0000
Epoch 117 batch 00006: Loss 0.4923 Regression loss 0.0232 Classification loss 0.4691 AP 0.6000 AR 0.0000
Epoch 117 batch 00007: Loss 0.4740 Regression loss 0.0187 Classification loss 0.4553 AP 1.0000 AR 0.2000
Epoch 117 batch 00008: Loss 0.5308 Regression loss 0.0218 Classification loss 0.5090 AP 0.8000 AR 0.0000
Epoch 117 batch 00009: Loss 0.4752 Regression loss 0.0209 Classification loss 0.4543 AP 0.8000 AR 0.1000
Epoch 117 batch 00010: Loss 0.6076 Regression loss 0.0225 Classification loss 0.5850 AP 1.0000 AR 0.0000
Epoch 118 batch 00001: Loss 0.4717 Regression loss 0.0217 Classification loss 0.4499 AP 0.8000 AR 0.0000
Epoch 118 batch 00002: Loss 0.4711 Regression loss 0.0242 Classification loss 0.4469 AP 0.8000 AR 0.0000
Epoch 118 batch 00003: Loss 0.4160 Regression loss 0.0243 Classification loss 0.3917 AP 0.8000 AR 0.0000
Epoch 118 batch 00004: Loss 0.4212 Regression loss 0.0253 Classification loss 0.3959 AP 1.0000 AR 0.2000
Epoch 118 batch 00005: Loss 0.5493 Regression loss 0.0262 Classification loss 0.5231 AP 1.0000 AR 0.3000
Epoch 118 batch 00006: Loss 0.4411 Regression loss 0.0215 Classification loss 0.4196 AP 0.6000 AR 0.0000
Epoch 118 batch 00007: Loss 0.4497 Regression loss 0.0189 Classification loss 0.4307 AP 0.8000 AR 0.0000
Epoch 118 batch 00008: Loss 0.5338 Regression loss 0.0229 Classification loss 0.5109 AP 1.0000 AR 0.0000
Epoch 118 batch 00009: Loss 0.4489 Regression loss 0.0225 Classification loss 0.4264 AP 1.0000 AR 0.0000
Epoch 118 batch 00010: Loss 0.5226 Regression loss 0.0222 Classification loss 0.5005 AP 0.8000 AR 0.0000
Epoch 119 batch 00001: Loss 0.4656 Regression loss 0.0220 Classification loss 0.4436 AP 0.8000 AR 0.0000
Epoch 119 batch 00002: Loss 0.5545 Regression loss 0.0220 Classification loss 0.5325 AP 1.0000 AR 0.0000
Epoch 119 batch 00003: Loss 0.5436 Regression loss 0.0198 Classification loss 0.5238 AP 1.0000 AR 0.2000
Epoch 119 batch 00004: Loss 0.4196 Regression loss 0.0259 Classification loss 0.3937 AP 1.0000 AR 0.0000
Epoch 119 batch 00005: Loss 0.4502 Regression loss 0.0220 Classification loss 0.4282 AP 1.0000 AR 0.0000
Epoch 119 batch 00006: Loss 0.5522 Regression loss 0.0231 Classification loss 0.5291 AP 1.0000 AR 0.2000
Epoch 119 batch 00007: Loss 0.4219 Regression loss 0.0247 Classification loss 0.3973 AP 0.8000 AR 0.0000
Epoch 119 batch 00008: Loss 0.3764 Regression loss 0.0211 Classification loss 0.3553 AP 1.0000 AR 0.0000
Epoch 119 batch 00009: Loss 0.4771 Regression loss 0.0219 Classification loss 0.4552 AP 0.8000 AR 0.0000
Epoch 119 batch 00010: Loss 0.4850 Regression loss 0.0235 Classification loss 0.4616 AP 1.0000 AR 0.0000
Epoch 120 batch 00001: Loss 0.4196 Regression loss 0.0220 Classification loss 0.3976 AP 0.2000 AR 0.0000
Epoch 120 batch 00002: Loss 0.4246 Regression loss 0.0254 Classification loss 0.3992 AP 1.0000 AR 0.0000
Epoch 120 batch 00003: Loss 0.4902 Regression loss 0.0195 Classification loss 0.4706 AP 0.8000 AR 0.2000
Epoch 120 batch 00004: Loss 0.6145 Regression loss 0.0217 Classification loss 0.5928 AP 1.0000 AR 0.0000
Epoch 120 batch 00005: Loss 0.5538 Regression loss 0.0230 Classification loss 0.5308 AP 1.0000 AR 0.2000
Epoch 120 batch 00006: Loss 0.5170 Regression loss 0.0232 Classification loss 0.4937 AP 1.0000 AR 0.1400
Epoch 120 batch 00007: Loss 0.3696 Regression loss 0.0224 Classification loss 0.3472 AP 0.8000 AR 0.0000
Epoch 120 batch 00008: Loss 0.4286 Regression loss 0.0174 Classification loss 0.4112 AP 0.6000 AR 0.0000
Epoch 120 batch 00009: Loss 0.5416 Regression loss 0.0256 Classification loss 0.5160 AP 1.0000 AR 0.0000
Epoch 120 batch 00010: Loss 0.4463 Regression loss 0.0242 Classification loss 0.4221 AP 1.0000 AR 0.0000
Epoch 121 batch 00001: Loss 0.4689 Regression loss 0.0241 Classification loss 0.4448 AP 1.0000 AR 0.0000
Epoch 121 batch 00002: Loss 0.5162 Regression loss 0.0203 Classification loss 0.4959 AP 0.6000 AR 0.0000
Epoch 121 batch 00003: Loss 0.4649 Regression loss 0.0204 Classification loss 0.4445 AP 0.8000 AR 0.0000
Epoch 121 batch 00004: Loss 0.4936 Regression loss 0.0256 Classification loss 0.4680 AP 1.0000 AR 0.2000
Epoch 121 batch 00005: Loss 0.5269 Regression loss 0.0229 Classification loss 0.5039 AP 1.0000 AR 0.0000
Epoch 121 batch 00006: Loss 0.3958 Regression loss 0.0188 Classification loss 0.3769 AP 0.8000 AR 0.2000
Epoch 121 batch 00007: Loss 0.3951 Regression loss 0.0224 Classification loss 0.3726 AP 1.0000 AR 0.0000
Epoch 121 batch 00008: Loss 0.5327 Regression loss 0.0252 Classification loss 0.5076 AP 1.0000 AR 0.0000
Epoch 121 batch 00009: Loss 0.4177 Regression loss 0.0215 Classification loss 0.3961 AP 0.8000 AR 0.0000
Epoch 121 batch 00010: Loss 0.4603 Regression loss 0.0244 Classification loss 0.4359 AP 1.0000 AR 0.0000
Epoch 122 batch 00001: Loss 0.4411 Regression loss 0.0238 Classification loss 0.4173 AP 0.8000 AR 0.0000
Epoch 122 batch 00002: Loss 0.5201 Regression loss 0.0201 Classification loss 0.5000 AP 1.0000 AR 0.2400
Epoch 122 batch 00003: Loss 0.3556 Regression loss 0.0225 Classification loss 0.3330 AP 1.0000 AR 0.0000
Epoch 122 batch 00004: Loss 0.6290 Regression loss 0.0264 Classification loss 0.6026 AP 0.8000 AR 0.0000
Epoch 122 batch 00005: Loss 0.4487 Regression loss 0.0203 Classification loss 0.4284 AP 0.8000 AR 0.0000
Epoch 122 batch 00006: Loss 0.4694 Regression loss 0.0174 Classification loss 0.4520 AP 1.0000 AR 0.0000
Epoch 122 batch 00007: Loss 0.5322 Regression loss 0.0223 Classification loss 0.5098 AP 1.0000 AR 0.0000
Epoch 122 batch 00008: Loss 0.5544 Regression loss 0.0240 Classification loss 0.5304 AP 0.8000 AR 0.0000
Epoch 122 batch 00009: Loss 0.3803 Regression loss 0.0263 Classification loss 0.3540 AP 1.0000 AR 0.0000
Epoch 122 batch 00010: Loss 0.4407 Regression loss 0.0197 Classification loss 0.4210 AP 1.0000 AR 0.2000
Epoch 123 batch 00001: Loss 0.4279 Regression loss 0.0204 Classification loss 0.4075 AP 0.4000 AR 0.0000
Epoch 123 batch 00002: Loss 0.5908 Regression loss 0.0260 Classification loss 0.5649 AP 1.0000 AR 0.0000
Epoch 123 batch 00003: Loss 0.4461 Regression loss 0.0229 Classification loss 0.4232 AP 1.0000 AR 0.0000
Epoch 123 batch 00004: Loss 0.4743 Regression loss 0.0186 Classification loss 0.4557 AP 0.6000 AR 0.0000
Epoch 123 batch 00005: Loss 0.4872 Regression loss 0.0288 Classification loss 0.4584 AP 1.0000 AR 0.0000
Epoch 123 batch 00006: Loss 0.4265 Regression loss 0.0217 Classification loss 0.4048 AP 1.0000 AR 0.0000
Epoch 123 batch 00007: Loss 0.4625 Regression loss 0.0237 Classification loss 0.4388 AP 0.8000 AR 0.0000
Epoch 123 batch 00008: Loss 0.4593 Regression loss 0.0216 Classification loss 0.4377 AP 0.8000 AR 0.0000
Epoch 123 batch 00009: Loss 0.5671 Regression loss 0.0229 Classification loss 0.5442 AP 1.0000 AR 0.5000
Epoch 123 batch 00010: Loss 0.3929 Regression loss 0.0191 Classification loss 0.3739 AP 1.0000 AR 0.0000
Epoch 124 batch 00001: Loss 0.3859 Regression loss 0.0199 Classification loss 0.3660 AP 0.6000 AR 0.0400
Epoch 124 batch 00002: Loss 0.4175 Regression loss 0.0243 Classification loss 0.3932 AP 0.8000 AR 0.0000
Epoch 124 batch 00003: Loss 0.6211 Regression loss 0.0255 Classification loss 0.5955 AP 1.0000 AR 0.0400
Epoch 124 batch 00004: Loss 0.4137 Regression loss 0.0196 Classification loss 0.3941 AP 0.7000 AR 0.2000
Epoch 124 batch 00005: Loss 0.4596 Regression loss 0.0202 Classification loss 0.4393 AP 0.4000 AR 0.0000
Epoch 124 batch 00006: Loss 0.5392 Regression loss 0.0242 Classification loss 0.5150 AP 1.0000 AR 0.0000
Epoch 124 batch 00007: Loss 0.5666 Regression loss 0.0278 Classification loss 0.5388 AP 1.0000 AR 0.2000
Epoch 124 batch 00008: Loss 0.3990 Regression loss 0.0155 Classification loss 0.3836 AP 1.0000 AR 0.0000
Epoch 124 batch 00009: Loss 0.5064 Regression loss 0.0248 Classification loss 0.4816 AP 1.0000 AR 0.0000
Epoch 124 batch 00010: Loss 0.5002 Regression loss 0.0241 Classification loss 0.4761 AP 1.0000 AR 0.0000
Epoch 125 batch 00001: Loss 0.4859 Regression loss 0.0242 Classification loss 0.4617 AP 1.0000 AR 0.0000
Epoch 125 batch 00002: Loss 0.5372 Regression loss 0.0193 Classification loss 0.5180 AP 0.6000 AR 0.0000
Epoch 125 batch 00003: Loss 0.4017 Regression loss 0.0278 Classification loss 0.3739 AP 0.6000 AR 0.0000
Epoch 125 batch 00004: Loss 0.6092 Regression loss 0.0282 Classification loss 0.5810 AP 1.0000 AR 0.0000
Epoch 125 batch 00005: Loss 0.5611 Regression loss 0.0202 Classification loss 0.5409 AP 1.0000 AR 0.0000
Epoch 125 batch 00006: Loss 0.5631 Regression loss 0.0213 Classification loss 0.5418 AP 1.0000 AR 0.0000
Epoch 125 batch 00007: Loss 0.4622 Regression loss 0.0207 Classification loss 0.4415 AP 1.0000 AR 0.0000
Epoch 125 batch 00008: Loss 0.5565 Regression loss 0.0205 Classification loss 0.5360 AP 1.0000 AR 0.2000
Epoch 125 batch 00009: Loss 0.4213 Regression loss 0.0223 Classification loss 0.3990 AP 1.0000 AR 0.0000
Epoch 125 batch 00010: Loss 0.5352 Regression loss 0.0198 Classification loss 0.5154 AP 0.8000 AR 0.0000
Epoch 126 batch 00001: Loss 0.4021 Regression loss 0.0241 Classification loss 0.3780 AP 0.8000 AR 0.0000
Epoch 126 batch 00002: Loss 0.6589 Regression loss 0.0198 Classification loss 0.6391 AP 1.0000 AR 0.1000
Epoch 126 batch 00003: Loss 0.4290 Regression loss 0.0239 Classification loss 0.4051 AP 0.6667 AR 0.0500
Epoch 126 batch 00004: Loss 0.5646 Regression loss 0.0187 Classification loss 0.5459 AP 1.0000 AR 0.0000
Epoch 126 batch 00005: Loss 0.3279 Regression loss 0.0162 Classification loss 0.3117 AP 0.8000 AR 0.2000
Epoch 126 batch 00006: Loss 0.5973 Regression loss 0.0291 Classification loss 0.5682 AP 1.0000 AR 0.0000
Epoch 126 batch 00007: Loss 0.4937 Regression loss 0.0245 Classification loss 0.4693 AP 0.8000 AR 0.0000
Epoch 126 batch 00008: Loss 0.5129 Regression loss 0.0230 Classification loss 0.4900 AP 1.0000 AR 0.0000
Epoch 126 batch 00009: Loss 0.4160 Regression loss 0.0219 Classification loss 0.3941 AP 1.0000 AR 0.2000
Epoch 126 batch 00010: Loss 0.5128 Regression loss 0.0195 Classification loss 0.4934 AP 0.8000 AR 0.0000
Epoch 127 batch 00001: Loss 0.4912 Regression loss 0.0216 Classification loss 0.4696 AP 1.0000 AR 0.0000
Epoch 127 batch 00002: Loss 0.4054 Regression loss 0.0218 Classification loss 0.3836 AP 0.6000 AR 0.0000
Epoch 127 batch 00003: Loss 0.3608 Regression loss 0.0221 Classification loss 0.3387 AP 0.8000 AR 0.0000
Epoch 127 batch 00004: Loss 0.4569 Regression loss 0.0186 Classification loss 0.4383 AP 1.0000 AR 0.2000
Epoch 127 batch 00005: Loss 0.4940 Regression loss 0.0210 Classification loss 0.4730 AP 1.0000 AR 0.0000
Epoch 127 batch 00006: Loss 0.4711 Regression loss 0.0224 Classification loss 0.4487 AP 1.0000 AR 0.0000
Epoch 127 batch 00007: Loss 0.5314 Regression loss 0.0299 Classification loss 0.5016 AP 1.0000 AR 0.0000
Epoch 127 batch 00008: Loss 0.4667 Regression loss 0.0272 Classification loss 0.4395 AP 1.0000 AR 0.2000
Epoch 127 batch 00009: Loss 0.4702 Regression loss 0.0214 Classification loss 0.4488 AP 0.8000 AR 0.1000
Epoch 127 batch 00010: Loss 0.5980 Regression loss 0.0248 Classification loss 0.5732 AP 0.8000 AR 0.0400
Epoch 128 batch 00001: Loss 0.4585 Regression loss 0.0231 Classification loss 0.4354 AP 0.6000 AR 0.0000
Epoch 128 batch 00002: Loss 0.6080 Regression loss 0.0229 Classification loss 0.5851 AP 1.0000 AR 0.0000
Epoch 128 batch 00003: Loss 0.5178 Regression loss 0.0186 Classification loss 0.4992 AP 0.6000 AR 0.2000
Epoch 128 batch 00004: Loss 0.5077 Regression loss 0.0221 Classification loss 0.4856 AP 0.8000 AR 0.0000
Epoch 128 batch 00005: Loss 0.5241 Regression loss 0.0276 Classification loss 0.4965 AP 1.0000 AR 0.0000
Epoch 128 batch 00006: Loss 0.4365 Regression loss 0.0193 Classification loss 0.4171 AP 0.8000 AR 0.0000
Epoch 128 batch 00007: Loss 0.4423 Regression loss 0.0241 Classification loss 0.4182 AP 1.0000 AR 0.2000
Epoch 128 batch 00008: Loss 0.5004 Regression loss 0.0188 Classification loss 0.4816 AP 1.0000 AR 0.1000
Epoch 128 batch 00009: Loss 0.4038 Regression loss 0.0216 Classification loss 0.3822 AP 0.6667 AR 0.0900
Epoch 128 batch 00010: Loss 0.5985 Regression loss 0.0227 Classification loss 0.5758 AP 1.0000 AR 0.0000
Epoch 129 batch 00001: Loss 0.4946 Regression loss 0.0246 Classification loss 0.4700 AP 0.8000 AR 0.2000
Epoch 129 batch 00002: Loss 0.4417 Regression loss 0.0244 Classification loss 0.4173 AP 1.0000 AR 0.0000
Epoch 129 batch 00003: Loss 0.4358 Regression loss 0.0194 Classification loss 0.4164 AP 0.8000 AR 0.0000
Epoch 129 batch 00004: Loss 0.4310 Regression loss 0.0230 Classification loss 0.4080 AP 1.0000 AR 0.0000
Epoch 129 batch 00005: Loss 0.5070 Regression loss 0.0219 Classification loss 0.4852 AP 1.0000 AR 0.0000
Epoch 129 batch 00006: Loss 0.5317 Regression loss 0.0209 Classification loss 0.5108 AP 0.8000 AR 0.0000
Epoch 129 batch 00007: Loss 0.3976 Regression loss 0.0206 Classification loss 0.3770 AP 0.4000 AR 0.2000
Epoch 129 batch 00008: Loss 0.6331 Regression loss 0.0291 Classification loss 0.6040 AP 1.0000 AR 0.0000
Epoch 129 batch 00009: Loss 0.4468 Regression loss 0.0240 Classification loss 0.4228 AP 0.6000 AR 0.0400
Epoch 129 batch 00010: Loss 0.5653 Regression loss 0.0224 Classification loss 0.5429 AP 0.8000 AR 0.0000
Epoch 130 batch 00001: Loss 0.4879 Regression loss 0.0203 Classification loss 0.4676 AP 0.8000 AR 0.2000
Epoch 130 batch 00002: Loss 0.4762 Regression loss 0.0213 Classification loss 0.4548 AP 1.0000 AR 0.0000
Epoch 130 batch 00003: Loss 0.4286 Regression loss 0.0205 Classification loss 0.4081 AP 1.0000 AR 0.0000
Epoch 130 batch 00004: Loss 0.4384 Regression loss 0.0241 Classification loss 0.4143 AP 0.8000 AR 0.0000
Epoch 130 batch 00005: Loss 0.3819 Regression loss 0.0228 Classification loss 0.3591 AP 0.6000 AR 0.0000
Epoch 130 batch 00006: Loss 0.4540 Regression loss 0.0256 Classification loss 0.4284 AP 1.0000 AR 0.1000
Epoch 130 batch 00007: Loss 0.5638 Regression loss 0.0200 Classification loss 0.5438 AP 0.4000 AR 0.0000
Epoch 130 batch 00008: Loss 0.5585 Regression loss 0.0231 Classification loss 0.5354 AP 0.8000 AR 0.2400
Epoch 130 batch 00009: Loss 0.5259 Regression loss 0.0247 Classification loss 0.5012 AP 1.0000 AR 0.0000
Epoch 130 batch 00010: Loss 0.5254 Regression loss 0.0197 Classification loss 0.5056 AP 1.0000 AR 0.0000
Epoch 131 batch 00001: Loss 0.6012 Regression loss 0.0164 Classification loss 0.5848 AP 1.0000 AR 0.2000
Epoch 131 batch 00002: Loss 0.4882 Regression loss 0.0213 Classification loss 0.4668 AP 1.0000 AR 0.2000
Epoch 131 batch 00003: Loss 0.4237 Regression loss 0.0225 Classification loss 0.4012 AP 1.0000 AR 0.0000
Epoch 131 batch 00004: Loss 0.3847 Regression loss 0.0199 Classification loss 0.3648 AP 1.0000 AR 0.0000
Epoch 131 batch 00005: Loss 0.4691 Regression loss 0.0217 Classification loss 0.4474 AP 0.8000 AR 0.1000
Epoch 131 batch 00006: Loss 0.4782 Regression loss 0.0238 Classification loss 0.4544 AP 1.0000 AR 0.0000
Epoch 131 batch 00007: Loss 0.4226 Regression loss 0.0252 Classification loss 0.3975 AP 0.8000 AR 0.0000
Epoch 131 batch 00008: Loss 0.4337 Regression loss 0.0217 Classification loss 0.4120 AP 0.6000 AR 0.0400
Epoch 131 batch 00009: Loss 0.5057 Regression loss 0.0247 Classification loss 0.4810 AP 0.7000 AR 0.0900
Epoch 131 batch 00010: Loss 0.4792 Regression loss 0.0224 Classification loss 0.4568 AP 1.0000 AR 0.0000
Epoch 132 batch 00001: Loss 0.4476 Regression loss 0.0197 Classification loss 0.4279 AP 0.8000 AR 0.0000
Epoch 132 batch 00002: Loss 0.4049 Regression loss 0.0226 Classification loss 0.3823 AP 0.6000 AR 0.0000
Epoch 132 batch 00003: Loss 0.4939 Regression loss 0.0245 Classification loss 0.4694 AP 0.6000 AR 0.0400
Epoch 132 batch 00004: Loss 0.4882 Regression loss 0.0239 Classification loss 0.4643 AP 1.0000 AR 0.0000
Epoch 132 batch 00005: Loss 0.6570 Regression loss 0.0222 Classification loss 0.6349 AP 1.0000 AR 0.0000
Epoch 132 batch 00006: Loss 0.5042 Regression loss 0.0219 Classification loss 0.4824 AP 0.8000 AR 0.0000
Epoch 132 batch 00007: Loss 0.5307 Regression loss 0.0180 Classification loss 0.5126 AP 1.0000 AR 0.0000
Epoch 132 batch 00008: Loss 0.3989 Regression loss 0.0218 Classification loss 0.3772 AP 0.8000 AR 0.2000
Epoch 132 batch 00009: Loss 0.3655 Regression loss 0.0205 Classification loss 0.3450 AP 0.8000 AR 0.2000
Epoch 132 batch 00010: Loss 0.4998 Regression loss 0.0241 Classification loss 0.4756 AP 1.0000 AR 0.1000
Epoch 133 batch 00001: Loss 0.5244 Regression loss 0.0269 Classification loss 0.4975 AP 1.0000 AR 0.0000
Epoch 133 batch 00002: Loss 0.4895 Regression loss 0.0209 Classification loss 0.4685 AP 0.8000 AR 0.0000
Epoch 133 batch 00003: Loss 0.4430 Regression loss 0.0234 Classification loss 0.4196 AP 0.6667 AR 0.0500
Epoch 133 batch 00004: Loss 0.3515 Regression loss 0.0234 Classification loss 0.3281 AP 0.4000 AR 0.0000
Epoch 133 batch 00005: Loss 0.3790 Regression loss 0.0208 Classification loss 0.3582 AP 0.6000 AR 0.0000
Epoch 133 batch 00006: Loss 0.4702 Regression loss 0.0180 Classification loss 0.4522 AP 0.8000 AR 0.0400
Epoch 133 batch 00007: Loss 0.5027 Regression loss 0.0251 Classification loss 0.4776 AP 1.0000 AR 0.1000
Epoch 133 batch 00008: Loss 0.3860 Regression loss 0.0196 Classification loss 0.3665 AP 1.0000 AR 0.4000
Epoch 133 batch 00009: Loss 0.5335 Regression loss 0.0227 Classification loss 0.5109 AP 0.8000 AR 0.0000
Epoch 133 batch 00010: Loss 0.5814 Regression loss 0.0227 Classification loss 0.5587 AP 1.0000 AR 0.0000
Epoch 134 batch 00001: Loss 0.4399 Regression loss 0.0238 Classification loss 0.4161 AP 0.6000 AR 0.2000
Epoch 134 batch 00002: Loss 0.4985 Regression loss 0.0232 Classification loss 0.4752 AP 0.6000 AR 0.0000
Epoch 134 batch 00003: Loss 0.3626 Regression loss 0.0241 Classification loss 0.3385 AP 0.8000 AR 0.0000
Epoch 134 batch 00004: Loss 0.5619 Regression loss 0.0285 Classification loss 0.5334 AP 1.0000 AR 0.0400
Epoch 134 batch 00005: Loss 0.4792 Regression loss 0.0228 Classification loss 0.4565 AP 1.0000 AR 0.0000
Epoch 134 batch 00006: Loss 0.4266 Regression loss 0.0215 Classification loss 0.4052 AP 1.0000 AR 0.0000
Epoch 134 batch 00007: Loss 0.3785 Regression loss 0.0188 Classification loss 0.3597 AP 0.8000 AR 0.0000
Epoch 134 batch 00008: Loss 0.4596 Regression loss 0.0219 Classification loss 0.4377 AP 0.8000 AR 0.0000
Epoch 134 batch 00009: Loss 0.4686 Regression loss 0.0181 Classification loss 0.4505 AP 0.8000 AR 0.0000
Epoch 134 batch 00010: Loss 0.5339 Regression loss 0.0164 Classification loss 0.5175 AP 0.8000 AR 0.0000
Epoch 135 batch 00001: Loss 0.4681 Regression loss 0.0216 Classification loss 0.4465 AP 0.4000 AR 0.0000
Epoch 135 batch 00002: Loss 0.5663 Regression loss 0.0231 Classification loss 0.5432 AP 1.0000 AR 0.0400
Epoch 135 batch 00003: Loss 0.5120 Regression loss 0.0235 Classification loss 0.4885 AP 0.8000 AR 0.0000
Epoch 135 batch 00004: Loss 0.5375 Regression loss 0.0249 Classification loss 0.5126 AP 0.8000 AR 0.0000
Epoch 135 batch 00005: Loss 0.4226 Regression loss 0.0217 Classification loss 0.4008 AP 1.0000 AR 0.0000
Epoch 135 batch 00006: Loss 0.4423 Regression loss 0.0218 Classification loss 0.4204 AP 0.4000 AR 0.0000
Epoch 135 batch 00007: Loss 0.4595 Regression loss 0.0230 Classification loss 0.4365 AP 1.0000 AR 0.1000
Epoch 135 batch 00008: Loss 0.4556 Regression loss 0.0193 Classification loss 0.4363 AP 1.0000 AR 0.2000
Epoch 135 batch 00009: Loss 0.3577 Regression loss 0.0220 Classification loss 0.3357 AP 1.0000 AR 0.0000
Epoch 135 batch 00010: Loss 0.4903 Regression loss 0.0200 Classification loss 0.4702 AP 0.6000 AR 0.0000
Epoch 136 batch 00001: Loss 0.4632 Regression loss 0.0195 Classification loss 0.4437 AP 0.8000 AR 0.0400
Epoch 136 batch 00002: Loss 0.5120 Regression loss 0.0211 Classification loss 0.4909 AP 0.8000 AR 0.0000
Epoch 136 batch 00003: Loss 0.5000 Regression loss 0.0240 Classification loss 0.4760 AP 1.0000 AR 0.0000
Epoch 136 batch 00004: Loss 0.4395 Regression loss 0.0202 Classification loss 0.4193 AP 0.6000 AR 0.0000
Epoch 136 batch 00005: Loss 0.3759 Regression loss 0.0239 Classification loss 0.3520 AP 0.8000 AR 0.0000
Epoch 136 batch 00006: Loss 0.5470 Regression loss 0.0248 Classification loss 0.5222 AP 1.0000 AR 0.0000
Epoch 136 batch 00007: Loss 0.4755 Regression loss 0.0251 Classification loss 0.4505 AP 1.0000 AR 0.0000
Epoch 136 batch 00008: Loss 0.4459 Regression loss 0.0202 Classification loss 0.4257 AP 0.6000 AR 0.1000
Epoch 136 batch 00009: Loss 0.6279 Regression loss 0.0169 Classification loss 0.6110 AP 0.8000 AR 0.2000
Epoch 136 batch 00010: Loss 0.4463 Regression loss 0.0233 Classification loss 0.4230 AP 0.8000 AR 0.0000
Epoch 137 batch 00001: Loss 0.3526 Regression loss 0.0136 Classification loss 0.3391 AP 1.0000 AR 0.0000
Epoch 137 batch 00002: Loss 0.6482 Regression loss 0.0266 Classification loss 0.6216 AP 1.0000 AR 0.4000
Epoch 137 batch 00003: Loss 0.4144 Regression loss 0.0184 Classification loss 0.3960 AP 1.0000 AR 0.0000
Epoch 137 batch 00004: Loss 0.5242 Regression loss 0.0256 Classification loss 0.4986 AP 1.0000 AR 0.0000
Epoch 137 batch 00005: Loss 0.4892 Regression loss 0.0224 Classification loss 0.4668 AP 0.8000 AR 0.0000
Epoch 137 batch 00006: Loss 0.5121 Regression loss 0.0212 Classification loss 0.4909 AP 1.0000 AR 0.0000
Epoch 137 batch 00007: Loss 0.4111 Regression loss 0.0202 Classification loss 0.3908 AP 0.4667 AR 0.0500
Epoch 137 batch 00008: Loss 0.4532 Regression loss 0.0247 Classification loss 0.4285 AP 0.5000 AR 0.0400
Epoch 137 batch 00009: Loss 0.4857 Regression loss 0.0271 Classification loss 0.4586 AP 0.9000 AR 0.1400
Epoch 137 batch 00010: Loss 0.4279 Regression loss 0.0218 Classification loss 0.4061 AP 0.4000 AR 0.0000
Epoch 138 batch 00001: Loss 0.5679 Regression loss 0.0205 Classification loss 0.5474 AP 1.0000 AR 0.0000
Epoch 138 batch 00002: Loss 0.3847 Regression loss 0.0222 Classification loss 0.3625 AP 1.0000 AR 0.0000
Epoch 138 batch 00003: Loss 0.4999 Regression loss 0.0270 Classification loss 0.4729 AP 1.0000 AR 0.0000
Epoch 138 batch 00004: Loss 0.4391 Regression loss 0.0205 Classification loss 0.4186 AP 0.8000 AR 0.0000
Epoch 138 batch 00005: Loss 0.4465 Regression loss 0.0215 Classification loss 0.4250 AP 0.4000 AR 0.0000
Epoch 138 batch 00006: Loss 0.3933 Regression loss 0.0261 Classification loss 0.3672 AP 1.0000 AR 0.0000
Epoch 138 batch 00007: Loss 0.5051 Regression loss 0.0202 Classification loss 0.4850 AP 0.8000 AR 0.1000
Epoch 138 batch 00008: Loss 0.7073 Regression loss 0.0222 Classification loss 0.6851 AP 0.8000 AR 0.2400
Epoch 138 batch 00009: Loss 0.3727 Regression loss 0.0211 Classification loss 0.3516 AP 0.5000 AR 0.0900
Epoch 138 batch 00010: Loss 0.4986 Regression loss 0.0184 Classification loss 0.4802 AP 0.8000 AR 0.0000
Epoch 139 batch 00001: Loss 0.5019 Regression loss 0.0252 Classification loss 0.4767 AP 0.8000 AR 0.0000
Epoch 139 batch 00002: Loss 0.5052 Regression loss 0.0228 Classification loss 0.4824 AP 0.8000 AR 0.0000
Epoch 139 batch 00003: Loss 0.4637 Regression loss 0.0185 Classification loss 0.4452 AP 1.0000 AR 0.2000
Epoch 139 batch 00004: Loss 0.5944 Regression loss 0.0181 Classification loss 0.5763 AP 1.0000 AR 0.2000
Epoch 139 batch 00005: Loss 0.4601 Regression loss 0.0160 Classification loss 0.4440 AP 0.8000 AR 0.0000
Epoch 139 batch 00006: Loss 0.4851 Regression loss 0.0221 Classification loss 0.4630 AP 1.0000 AR 0.0000
Epoch 139 batch 00007: Loss 0.4395 Regression loss 0.0229 Classification loss 0.4167 AP 0.8000 AR 0.1000
Epoch 139 batch 00008: Loss 0.3794 Regression loss 0.0218 Classification loss 0.3576 AP 0.6000 AR 0.0000
Epoch 139 batch 00009: Loss 0.3961 Regression loss 0.0250 Classification loss 0.3711 AP 0.8000 AR 0.0000
Epoch 139 batch 00010: Loss 0.4527 Regression loss 0.0233 Classification loss 0.4294 AP 1.0000 AR 0.0400
Epoch 140 batch 00001: Loss 0.5386 Regression loss 0.0229 Classification loss 0.5157 AP 0.6000 AR 0.0000
Epoch 140 batch 00002: Loss 0.3741 Regression loss 0.0218 Classification loss 0.3522 AP 0.6000 AR 0.0000
Epoch 140 batch 00003: Loss 0.4121 Regression loss 0.0221 Classification loss 0.3900 AP 0.8000 AR 0.1400
Epoch 140 batch 00004: Loss 0.5887 Regression loss 0.0244 Classification loss 0.5643 AP 1.0000 AR 0.2400
Epoch 140 batch 00005: Loss 0.4035 Regression loss 0.0202 Classification loss 0.3833 AP 0.8000 AR 0.0000
Epoch 140 batch 00006: Loss 0.3919 Regression loss 0.0202 Classification loss 0.3717 AP 1.0000 AR 0.0000
Epoch 140 batch 00007: Loss 0.4502 Regression loss 0.0236 Classification loss 0.4266 AP 0.8000 AR 0.0000
Epoch 140 batch 00008: Loss 0.5003 Regression loss 0.0234 Classification loss 0.4768 AP 0.5500 AR 0.2500
Epoch 140 batch 00009: Loss 0.4801 Regression loss 0.0203 Classification loss 0.4598 AP 0.6000 AR 0.0000
Epoch 140 batch 00010: Loss 0.5882 Regression loss 0.0204 Classification loss 0.5678 AP 0.8000 AR 0.0000
Epoch 141 batch 00001: Loss 0.3434 Regression loss 0.0182 Classification loss 0.3252 AP 1.0000 AR 0.0000
Epoch 141 batch 00002: Loss 0.3674 Regression loss 0.0199 Classification loss 0.3475 AP 1.0000 AR 0.0000
Epoch 141 batch 00003: Loss 0.4633 Regression loss 0.0211 Classification loss 0.4422 AP 1.0000 AR 0.2000
Epoch 141 batch 00004: Loss 0.5590 Regression loss 0.0254 Classification loss 0.5336 AP 0.8000 AR 0.3000
Epoch 141 batch 00005: Loss 0.6031 Regression loss 0.0212 Classification loss 0.5819 AP 0.8000 AR 0.0000
Epoch 141 batch 00006: Loss 0.3990 Regression loss 0.0220 Classification loss 0.3770 AP 0.9000 AR 0.0500
Epoch 141 batch 00007: Loss 0.4300 Regression loss 0.0207 Classification loss 0.4092 AP 0.5000 AR 0.0400
Epoch 141 batch 00008: Loss 0.4820 Regression loss 0.0230 Classification loss 0.4590 AP 0.2000 AR 0.0000
Epoch 141 batch 00009: Loss 0.4883 Regression loss 0.0239 Classification loss 0.4645 AP 0.8000 AR 0.0400
Epoch 141 batch 00010: Loss 0.4579 Regression loss 0.0214 Classification loss 0.4365 AP 1.0000 AR 0.0000
Epoch 142 batch 00001: Loss 0.4600 Regression loss 0.0228 Classification loss 0.4372 AP 1.0000 AR 0.0000
Epoch 142 batch 00002: Loss 0.5602 Regression loss 0.0261 Classification loss 0.5341 AP 1.0000 AR 0.0000
Epoch 142 batch 00003: Loss 0.3844 Regression loss 0.0183 Classification loss 0.3662 AP 1.0000 AR 0.0000
Epoch 142 batch 00004: Loss 0.5145 Regression loss 0.0174 Classification loss 0.4970 AP 0.8000 AR 0.0000
Epoch 142 batch 00005: Loss 0.4243 Regression loss 0.0208 Classification loss 0.4034 AP 0.8000 AR 0.0400
Epoch 142 batch 00006: Loss 0.4362 Regression loss 0.0204 Classification loss 0.4157 AP 0.6500 AR 0.4500
Epoch 142 batch 00007: Loss 0.4373 Regression loss 0.0235 Classification loss 0.4138 AP 1.0000 AR 0.0000
Epoch 142 batch 00008: Loss 0.3569 Regression loss 0.0188 Classification loss 0.3381 AP 0.6000 AR 0.0000
Epoch 142 batch 00009: Loss 0.4822 Regression loss 0.0264 Classification loss 0.4558 AP 0.8000 AR 0.0400
Epoch 142 batch 00010: Loss 0.5047 Regression loss 0.0221 Classification loss 0.4825 AP 0.6000 AR 0.1000
Epoch 143 batch 00001: Loss 0.4760 Regression loss 0.0240 Classification loss 0.4520 AP 0.8000 AR 0.0000
Epoch 143 batch 00002: Loss 0.3378 Regression loss 0.0215 Classification loss 0.3163 AP 0.2000 AR 0.2000
Epoch 143 batch 00003: Loss 0.4165 Regression loss 0.0224 Classification loss 0.3941 AP 0.4000 AR 0.0000
Epoch 143 batch 00004: Loss 0.4193 Regression loss 0.0215 Classification loss 0.3979 AP 0.6000 AR 0.0000
Epoch 143 batch 00005: Loss 0.5618 Regression loss 0.0215 Classification loss 0.5404 AP 0.8000 AR 0.0000
Epoch 143 batch 00006: Loss 0.5634 Regression loss 0.0244 Classification loss 0.5390 AP 0.8000 AR 0.0400
Epoch 143 batch 00007: Loss 0.5585 Regression loss 0.0208 Classification loss 0.5377 AP 0.8000 AR 0.0000
Epoch 143 batch 00008: Loss 0.4353 Regression loss 0.0221 Classification loss 0.4131 AP 1.0000 AR 0.0400
Epoch 143 batch 00009: Loss 0.3685 Regression loss 0.0175 Classification loss 0.3510 AP 1.0000 AR 0.1000
Epoch 143 batch 00010: Loss 0.4044 Regression loss 0.0186 Classification loss 0.3858 AP 0.8000 AR 0.2000
Epoch 144 batch 00001: Loss 0.4839 Regression loss 0.0221 Classification loss 0.4618 AP 0.8000 AR 0.2000
Epoch 144 batch 00002: Loss 0.5206 Regression loss 0.0283 Classification loss 0.4923 AP 1.0000 AR 0.0000
Epoch 144 batch 00003: Loss 0.3751 Regression loss 0.0167 Classification loss 0.3584 AP 0.8000 AR 0.0000
Epoch 144 batch 00004: Loss 0.4616 Regression loss 0.0248 Classification loss 0.4369 AP 0.8000 AR 0.0400
Epoch 144 batch 00005: Loss 0.3715 Regression loss 0.0232 Classification loss 0.3483 AP 0.8000 AR 0.0000
Epoch 144 batch 00006: Loss 0.6857 Regression loss 0.0186 Classification loss 0.6670 AP 1.0000 AR 0.0000
Epoch 144 batch 00007: Loss 0.5204 Regression loss 0.0208 Classification loss 0.4995 AP 0.8000 AR 0.0000
Epoch 144 batch 00008: Loss 0.4466 Regression loss 0.0226 Classification loss 0.4241 AP 1.0000 AR 0.2000
Epoch 144 batch 00009: Loss 0.4144 Regression loss 0.0235 Classification loss 0.3909 AP 0.6000 AR 0.0400
Epoch 144 batch 00010: Loss 0.4291 Regression loss 0.0176 Classification loss 0.4115 AP 0.6000 AR 0.1000
Epoch 145 batch 00001: Loss 0.5322 Regression loss 0.0225 Classification loss 0.5096 AP 1.0000 AR 0.2000
Epoch 145 batch 00002: Loss 0.4388 Regression loss 0.0218 Classification loss 0.4170 AP 1.0000 AR 0.0000
Epoch 145 batch 00003: Loss 0.4460 Regression loss 0.0200 Classification loss 0.4260 AP 0.4000 AR 0.0000
Epoch 145 batch 00004: Loss 0.3848 Regression loss 0.0201 Classification loss 0.3647 AP 0.8000 AR 0.0000
Epoch 145 batch 00005: Loss 0.3416 Regression loss 0.0177 Classification loss 0.3239 AP 0.8000 AR 0.2000
Epoch 145 batch 00006: Loss 0.4629 Regression loss 0.0255 Classification loss 0.4374 AP 0.6000 AR 0.0000
Epoch 145 batch 00007: Loss 0.6300 Regression loss 0.0198 Classification loss 0.6102 AP 0.8000 AR 0.0000
Epoch 145 batch 00008: Loss 0.4228 Regression loss 0.0250 Classification loss 0.3978 AP 0.9000 AR 0.0900
Epoch 145 batch 00009: Loss 0.4240 Regression loss 0.0176 Classification loss 0.4064 AP 0.6000 AR 0.1000
Epoch 145 batch 00010: Loss 0.4710 Regression loss 0.0246 Classification loss 0.4464 AP 0.5000 AR 0.0400
Epoch 146 batch 00001: Loss 0.4996 Regression loss 0.0254 Classification loss 0.4742 AP 0.8000 AR 0.0000
Epoch 146 batch 00002: Loss 0.5165 Regression loss 0.0257 Classification loss 0.4908 AP 0.8000 AR 0.0000
Epoch 146 batch 00003: Loss 0.4147 Regression loss 0.0224 Classification loss 0.3922 AP 0.9000 AR 0.2400
Epoch 146 batch 00004: Loss 0.4683 Regression loss 0.0220 Classification loss 0.4463 AP 0.6000 AR 0.0000
Epoch 146 batch 00005: Loss 0.4311 Regression loss 0.0182 Classification loss 0.4129 AP 0.2000 AR 0.0000
Epoch 146 batch 00006: Loss 0.3589 Regression loss 0.0197 Classification loss 0.3392 AP 1.0000 AR 0.0500
Epoch 146 batch 00007: Loss 0.6857 Regression loss 0.0178 Classification loss 0.6679 AP 1.0000 AR 0.3000
Epoch 146 batch 00008: Loss 0.3928 Regression loss 0.0185 Classification loss 0.3743 AP 0.8000 AR 0.0000
Epoch 146 batch 00009: Loss 0.3713 Regression loss 0.0212 Classification loss 0.3502 AP 0.8000 AR 0.0000
Epoch 146 batch 00010: Loss 0.4953 Regression loss 0.0251 Classification loss 0.4702 AP 0.6000 AR 0.0000
Epoch 147 batch 00001: Loss 0.3793 Regression loss 0.0183 Classification loss 0.3610 AP 0.8000 AR 0.0000
Epoch 147 batch 00002: Loss 0.4261 Regression loss 0.0240 Classification loss 0.4022 AP 0.6000 AR 0.0000
Epoch 147 batch 00003: Loss 0.4541 Regression loss 0.0244 Classification loss 0.4298 AP 1.0000 AR 0.0000
Epoch 147 batch 00004: Loss 0.3998 Regression loss 0.0228 Classification loss 0.3770 AP 0.7000 AR 0.0500
Epoch 147 batch 00005: Loss 0.4041 Regression loss 0.0239 Classification loss 0.3803 AP 0.6000 AR 0.0000
Epoch 147 batch 00006: Loss 0.3922 Regression loss 0.0220 Classification loss 0.3703 AP 0.8000 AR 0.1400
Epoch 147 batch 00007: Loss 0.5984 Regression loss 0.0189 Classification loss 0.5796 AP 0.8000 AR 0.0000
Epoch 147 batch 00008: Loss 0.6206 Regression loss 0.0211 Classification loss 0.5996 AP 0.8000 AR 0.0000
Epoch 147 batch 00009: Loss 0.4743 Regression loss 0.0174 Classification loss 0.4569 AP 0.6000 AR 0.0000
Epoch 147 batch 00010: Loss 0.4371 Regression loss 0.0182 Classification loss 0.4189 AP 0.8000 AR 0.4000
Epoch 148 batch 00001: Loss 0.4409 Regression loss 0.0193 Classification loss 0.4216 AP 1.0000 AR 0.0000
Epoch 148 batch 00002: Loss 0.5100 Regression loss 0.0241 Classification loss 0.4858 AP 1.0000 AR 0.1000
Epoch 148 batch 00003: Loss 0.5182 Regression loss 0.0192 Classification loss 0.4990 AP 0.8000 AR 0.0000
Epoch 148 batch 00004: Loss 0.4703 Regression loss 0.0186 Classification loss 0.4517 AP 1.0000 AR 0.1000
Epoch 148 batch 00005: Loss 0.3501 Regression loss 0.0202 Classification loss 0.3299 AP 0.6000 AR 0.0000
Epoch 148 batch 00006: Loss 0.5025 Regression loss 0.0254 Classification loss 0.4771 AP 0.8000 AR 0.0400
Epoch 148 batch 00007: Loss 0.4254 Regression loss 0.0180 Classification loss 0.4075 AP 0.4000 AR 0.0000
Epoch 148 batch 00008: Loss 0.4815 Regression loss 0.0213 Classification loss 0.4602 AP 0.9000 AR 0.2500
Epoch 148 batch 00009: Loss 0.4594 Regression loss 0.0226 Classification loss 0.4367 AP 0.2000 AR 0.0000
Epoch 148 batch 00010: Loss 0.4132 Regression loss 0.0235 Classification loss 0.3897 AP 0.8000 AR 0.0400
Epoch 149 batch 00001: Loss 0.4346 Regression loss 0.0217 Classification loss 0.4129 AP 0.6000 AR 0.2000
Epoch 149 batch 00002: Loss 0.4972 Regression loss 0.0233 Classification loss 0.4739 AP 0.8000 AR 0.0000
Epoch 149 batch 00003: Loss 0.4577 Regression loss 0.0181 Classification loss 0.4397 AP 0.6000 AR 0.0000
Epoch 149 batch 00004: Loss 0.5852 Regression loss 0.0220 Classification loss 0.5632 AP 0.8000 AR 0.0000
Epoch 149 batch 00005: Loss 0.5005 Regression loss 0.0230 Classification loss 0.4775 AP 1.0000 AR 0.0000
Epoch 149 batch 00006: Loss 0.4200 Regression loss 0.0217 Classification loss 0.3984 AP 0.8000 AR 0.0000
Epoch 149 batch 00007: Loss 0.4550 Regression loss 0.0184 Classification loss 0.4366 AP 0.6000 AR 0.2000
Epoch 149 batch 00008: Loss 0.4977 Regression loss 0.0253 Classification loss 0.4724 AP 0.6667 AR 0.0900
Epoch 149 batch 00009: Loss 0.3520 Regression loss 0.0222 Classification loss 0.3297 AP 0.7000 AR 0.0400
Epoch 149 batch 00010: Loss 0.3563 Regression loss 0.0232 Classification loss 0.3331 AP 0.6000 AR 0.0000
Epoch 150 batch 00001: Loss 0.4568 Regression loss 0.0222 Classification loss 0.4346 AP 0.6000 AR 0.0000
Epoch 150 batch 00002: Loss 0.4261 Regression loss 0.0212 Classification loss 0.4049 AP 1.0000 AR 0.0000
Epoch 150 batch 00003: Loss 0.5265 Regression loss 0.0173 Classification loss 0.5092 AP 0.8000 AR 0.2000
Epoch 150 batch 00004: Loss 0.4924 Regression loss 0.0177 Classification loss 0.4747 AP 0.8000 AR 0.0000
Epoch 150 batch 00005: Loss 0.4973 Regression loss 0.0223 Classification loss 0.4750 AP 0.8000 AR 0.0000
Epoch 150 batch 00006: Loss 0.3940 Regression loss 0.0199 Classification loss 0.3740 AP 0.6000 AR 0.0000
Epoch 150 batch 00007: Loss 0.4924 Regression loss 0.0249 Classification loss 0.4675 AP 0.8000 AR 0.0000
Epoch 150 batch 00008: Loss 0.3955 Regression loss 0.0247 Classification loss 0.3708 AP 0.2500 AR 0.0500
Epoch 150 batch 00009: Loss 0.5562 Regression loss 0.0229 Classification loss 0.5332 AP 0.6000 AR 0.2000
Epoch 150 batch 00010: Loss 0.4263 Regression loss 0.0220 Classification loss 0.4043 AP 1.0000 AR 0.1400
Epoch 151 batch 00001: Loss 0.4710 Regression loss 0.0176 Classification loss 0.4534 AP 1.0000 AR 0.0000
Epoch 151 batch 00002: Loss 0.5069 Regression loss 0.0199 Classification loss 0.4870 AP 0.8000 AR 0.0000
Epoch 151 batch 00003: Loss 0.5236 Regression loss 0.0248 Classification loss 0.4988 AP 1.0000 AR 0.2400
Epoch 151 batch 00004: Loss 0.4715 Regression loss 0.0181 Classification loss 0.4534 AP 0.8000 AR 0.0000
Epoch 151 batch 00005: Loss 0.4724 Regression loss 0.0220 Classification loss 0.4503 AP 0.6000 AR 0.0000
Epoch 151 batch 00006: Loss 0.4256 Regression loss 0.0177 Classification loss 0.4079 AP 0.6000 AR 0.0000
Epoch 151 batch 00007: Loss 0.4605 Regression loss 0.0204 Classification loss 0.4400 AP 0.8500 AR 0.3000
Epoch 151 batch 00008: Loss 0.4271 Regression loss 0.0263 Classification loss 0.4008 AP 0.8000 AR 0.1000
Epoch 151 batch 00009: Loss 0.4772 Regression loss 0.0233 Classification loss 0.4539 AP 0.6000 AR 0.0000
Epoch 151 batch 00010: Loss 0.3924 Regression loss 0.0194 Classification loss 0.3730 AP 1.0000 AR 0.0000
Epoch 152 batch 00001: Loss 0.4941 Regression loss 0.0249 Classification loss 0.4691 AP 1.0000 AR 0.0000
Epoch 152 batch 00002: Loss 0.3715 Regression loss 0.0150 Classification loss 0.3565 AP 0.8000 AR 0.1000
Epoch 152 batch 00003: Loss 0.4340 Regression loss 0.0208 Classification loss 0.4132 AP 0.8000 AR 0.0000
Epoch 152 batch 00004: Loss 0.3779 Regression loss 0.0220 Classification loss 0.3559 AP 0.2667 AR 0.0500
Epoch 152 batch 00005: Loss 0.4151 Regression loss 0.0215 Classification loss 0.3935 AP 0.6000 AR 0.0000
Epoch 152 batch 00006: Loss 0.4959 Regression loss 0.0238 Classification loss 0.4720 AP 0.4000 AR 0.2000
Epoch 152 batch 00007: Loss 0.4086 Regression loss 0.0190 Classification loss 0.3896 AP 0.6000 AR 0.0000
Epoch 152 batch 00008: Loss 0.4706 Regression loss 0.0211 Classification loss 0.4496 AP 0.6000 AR 0.0000
Epoch 152 batch 00009: Loss 0.5216 Regression loss 0.0233 Classification loss 0.4983 AP 1.0000 AR 0.0800
Epoch 152 batch 00010: Loss 0.5013 Regression loss 0.0212 Classification loss 0.4801 AP 0.6000 AR 0.0000
Epoch 153 batch 00001: Loss 0.3949 Regression loss 0.0217 Classification loss 0.3732 AP 0.8000 AR 0.0000
Epoch 153 batch 00002: Loss 0.4499 Regression loss 0.0236 Classification loss 0.4263 AP 0.4000 AR 0.0000
Epoch 153 batch 00003: Loss 0.4356 Regression loss 0.0185 Classification loss 0.4170 AP 0.2000 AR 0.0000
Epoch 153 batch 00004: Loss 0.4811 Regression loss 0.0216 Classification loss 0.4595 AP 0.9000 AR 0.0900
Epoch 153 batch 00005: Loss 0.4786 Regression loss 0.0220 Classification loss 0.4565 AP 1.0000 AR 0.0000
Epoch 153 batch 00006: Loss 0.3859 Regression loss 0.0224 Classification loss 0.3635 AP 0.8000 AR 0.0000
Epoch 153 batch 00007: Loss 0.5257 Regression loss 0.0248 Classification loss 0.5009 AP 0.8000 AR 0.2000
Epoch 153 batch 00008: Loss 0.3650 Regression loss 0.0194 Classification loss 0.3456 AP 0.8000 AR 0.0000
Epoch 153 batch 00009: Loss 0.5823 Regression loss 0.0197 Classification loss 0.5626 AP 0.8000 AR 0.3000
Epoch 153 batch 00010: Loss 0.4587 Regression loss 0.0189 Classification loss 0.4398 AP 0.8000 AR 0.0000
Epoch 154 batch 00001: Loss 0.5993 Regression loss 0.0229 Classification loss 0.5764 AP 1.0000 AR 0.0400
Epoch 154 batch 00002: Loss 0.4348 Regression loss 0.0251 Classification loss 0.4097 AP 0.6000 AR 0.0000
Epoch 154 batch 00003: Loss 0.3745 Regression loss 0.0189 Classification loss 0.3555 AP 0.6000 AR 0.0000
Epoch 154 batch 00004: Loss 0.4845 Regression loss 0.0214 Classification loss 0.4631 AP 0.6000 AR 0.0000
Epoch 154 batch 00005: Loss 0.3349 Regression loss 0.0210 Classification loss 0.3139 AP 0.2000 AR 0.0400
Epoch 154 batch 00006: Loss 0.4228 Regression loss 0.0158 Classification loss 0.4069 AP 0.4000 AR 0.0000
Epoch 154 batch 00007: Loss 0.4778 Regression loss 0.0247 Classification loss 0.4531 AP 1.0000 AR 0.0000
Epoch 154 batch 00008: Loss 0.4785 Regression loss 0.0282 Classification loss 0.4503 AP 1.0000 AR 0.1000
Epoch 154 batch 00009: Loss 0.4169 Regression loss 0.0162 Classification loss 0.4007 AP 0.8000 AR 0.4000
Epoch 154 batch 00010: Loss 0.5724 Regression loss 0.0209 Classification loss 0.5515 AP 0.8000 AR 0.0000
Epoch 155 batch 00001: Loss 0.4238 Regression loss 0.0188 Classification loss 0.4050 AP 0.6000 AR 0.0000
Epoch 155 batch 00002: Loss 0.5088 Regression loss 0.0259 Classification loss 0.4829 AP 0.8000 AR 0.0000
Epoch 155 batch 00003: Loss 0.4062 Regression loss 0.0215 Classification loss 0.3847 AP 1.0000 AR 0.0000
Epoch 155 batch 00004: Loss 0.4305 Regression loss 0.0246 Classification loss 0.4059 AP 0.8667 AR 0.0400
Epoch 155 batch 00005: Loss 0.5198 Regression loss 0.0232 Classification loss 0.4966 AP 0.8000 AR 0.0000
Epoch 155 batch 00006: Loss 0.3057 Regression loss 0.0189 Classification loss 0.2868 AP 0.5000 AR 0.2000
Epoch 155 batch 00007: Loss 0.4829 Regression loss 0.0219 Classification loss 0.4610 AP 0.6000 AR 0.0000
Epoch 155 batch 00008: Loss 0.5097 Regression loss 0.0237 Classification loss 0.4860 AP 0.8000 AR 0.1000
Epoch 155 batch 00009: Loss 0.4385 Regression loss 0.0202 Classification loss 0.4182 AP 0.6000 AR 0.2000
Epoch 155 batch 00010: Loss 0.4515 Regression loss 0.0217 Classification loss 0.4298 AP 0.6000 AR 0.0000
Epoch 156 batch 00001: Loss 0.3630 Regression loss 0.0225 Classification loss 0.3405 AP 0.6000 AR 0.2400
Epoch 156 batch 00002: Loss 0.3779 Regression loss 0.0213 Classification loss 0.3566 AP 1.0000 AR 0.2000
Epoch 156 batch 00003: Loss 0.6028 Regression loss 0.0230 Classification loss 0.5798 AP 1.0000 AR 0.0000
Epoch 156 batch 00004: Loss 0.4486 Regression loss 0.0208 Classification loss 0.4278 AP 0.6000 AR 0.0500
Epoch 156 batch 00005: Loss 0.5299 Regression loss 0.0210 Classification loss 0.5089 AP 0.8000 AR 0.0400
Epoch 156 batch 00006: Loss 0.3875 Regression loss 0.0202 Classification loss 0.3673 AP 0.4000 AR 0.0000
Epoch 156 batch 00007: Loss 0.5261 Regression loss 0.0194 Classification loss 0.5067 AP 0.4500 AR 0.0500
Epoch 156 batch 00008: Loss 0.4297 Regression loss 0.0229 Classification loss 0.4068 AP 0.8000 AR 0.0000
Epoch 156 batch 00009: Loss 0.4297 Regression loss 0.0252 Classification loss 0.4045 AP 0.6000 AR 0.0000
Epoch 156 batch 00010: Loss 0.4510 Regression loss 0.0179 Classification loss 0.4332 AP 0.8000 AR 0.0000
Epoch 157 batch 00001: Loss 0.3752 Regression loss 0.0205 Classification loss 0.3548 AP 1.0000 AR 0.0000
Epoch 157 batch 00002: Loss 0.4556 Regression loss 0.0207 Classification loss 0.4349 AP 1.0000 AR 0.2000
Epoch 157 batch 00003: Loss 0.5121 Regression loss 0.0176 Classification loss 0.4945 AP 0.8000 AR 0.0000
Epoch 157 batch 00004: Loss 0.4422 Regression loss 0.0207 Classification loss 0.4215 AP 0.6000 AR 0.0000
Epoch 157 batch 00005: Loss 0.3746 Regression loss 0.0214 Classification loss 0.3532 AP 0.2000 AR 0.0000
Epoch 157 batch 00006: Loss 0.6005 Regression loss 0.0204 Classification loss 0.5801 AP 0.8000 AR 0.1000
Epoch 157 batch 00007: Loss 0.5250 Regression loss 0.0233 Classification loss 0.5018 AP 0.8000 AR 0.2000
Epoch 157 batch 00008: Loss 0.5076 Regression loss 0.0221 Classification loss 0.4855 AP 1.0000 AR 0.0000
Epoch 157 batch 00009: Loss 0.6608 Regression loss 0.0231 Classification loss 0.6377 AP 1.0000 AR 0.0000
Epoch 157 batch 00010: Loss 0.5609 Regression loss 0.0210 Classification loss 0.5399 AP 1.0000 AR 0.0000
Epoch 158 batch 00001: Loss 0.4994 Regression loss 0.0213 Classification loss 0.4781 AP 0.6000 AR 0.0000
Epoch 158 batch 00002: Loss 0.6072 Regression loss 0.0263 Classification loss 0.5809 AP 1.0000 AR 0.0000
Epoch 158 batch 00003: Loss 0.4106 Regression loss 0.0220 Classification loss 0.3886 AP 0.2500 AR 0.0500
Epoch 158 batch 00004: Loss 0.5497 Regression loss 0.0219 Classification loss 0.5277 AP 0.1667 AR 0.3000
Epoch 158 batch 00005: Loss 0.4735 Regression loss 0.0188 Classification loss 0.4548 AP 0.5000 AR 0.0500
Epoch 158 batch 00006: Loss 0.4629 Regression loss 0.0157 Classification loss 0.4472 AP 0.6000 AR 0.2000
Epoch 158 batch 00007: Loss 0.4541 Regression loss 0.0216 Classification loss 0.4325 AP 1.0000 AR 0.0000
Epoch 158 batch 00008: Loss 0.4495 Regression loss 0.0186 Classification loss 0.4309 AP 0.8000 AR 0.0000
Epoch 158 batch 00009: Loss 0.3955 Regression loss 0.0260 Classification loss 0.3695 AP 1.0000 AR 0.0000
Epoch 158 batch 00010: Loss 0.5545 Regression loss 0.0230 Classification loss 0.5315 AP 1.0000 AR 0.0000
Epoch 159 batch 00001: Loss 0.4874 Regression loss 0.0216 Classification loss 0.4659 AP 0.6000 AR 0.2000
Epoch 159 batch 00002: Loss 0.4520 Regression loss 0.0223 Classification loss 0.4296 AP 0.4000 AR 0.0000
Epoch 159 batch 00003: Loss 0.6156 Regression loss 0.0184 Classification loss 0.5972 AP 0.2000 AR 0.0000
Epoch 159 batch 00004: Loss 0.6470 Regression loss 0.0195 Classification loss 0.6275 AP 0.8000 AR 0.0000
Epoch 159 batch 00005: Loss 0.3581 Regression loss 0.0168 Classification loss 0.3413 AP 0.8000 AR 0.0000
Epoch 159 batch 00006: Loss 0.5199 Regression loss 0.0271 Classification loss 0.4928 AP 0.8000 AR 0.0000
Epoch 159 batch 00007: Loss 0.4294 Regression loss 0.0240 Classification loss 0.4054 AP 1.0000 AR 0.0000
Epoch 159 batch 00008: Loss 0.5748 Regression loss 0.0241 Classification loss 0.5507 AP 1.0000 AR 0.0000
Epoch 159 batch 00009: Loss 0.5567 Regression loss 0.0266 Classification loss 0.5301 AP 0.8000 AR 0.0000
Epoch 159 batch 00010: Loss 0.3841 Regression loss 0.0217 Classification loss 0.3624 AP 0.8000 AR 0.0000
Epoch 160 batch 00001: Loss 0.4038 Regression loss 0.0237 Classification loss 0.3801 AP 1.0000 AR 0.0400
Epoch 160 batch 00002: Loss 0.5469 Regression loss 0.0248 Classification loss 0.5221 AP 0.9000 AR 0.0400
Epoch 160 batch 00003: Loss 0.4264 Regression loss 0.0194 Classification loss 0.4070 AP 0.2500 AR 0.1500
Epoch 160 batch 00004: Loss 0.6036 Regression loss 0.0260 Classification loss 0.5776 AP 0.9000 AR 0.4000
Epoch 160 batch 00005: Loss 0.3920 Regression loss 0.0224 Classification loss 0.3695 AP 0.8000 AR 0.0000
Epoch 160 batch 00006: Loss 0.6217 Regression loss 0.0195 Classification loss 0.6022 AP 0.8000 AR 0.0000
Epoch 160 batch 00007: Loss 0.4002 Regression loss 0.0250 Classification loss 0.3752 AP 1.0000 AR 0.0000
Epoch 160 batch 00008: Loss 0.6127 Regression loss 0.0217 Classification loss 0.5910 AP 1.0000 AR 0.0000
Epoch 160 batch 00009: Loss 0.5664 Regression loss 0.0218 Classification loss 0.5445 AP 0.6000 AR 0.0000
Epoch 160 batch 00010: Loss 0.4235 Regression loss 0.0202 Classification loss 0.4033 AP 0.6000 AR 0.0000
Epoch 161 batch 00001: Loss 0.5995 Regression loss 0.0167 Classification loss 0.5828 AP 0.6000 AR 0.0000
Epoch 161 batch 00002: Loss 0.4764 Regression loss 0.0242 Classification loss 0.4522 AP 0.4000 AR 0.0400
Epoch 161 batch 00003: Loss 0.4329 Regression loss 0.0220 Classification loss 0.4109 AP 0.3400 AR 0.2400
Epoch 161 batch 00004: Loss 0.4381 Regression loss 0.0234 Classification loss 0.4147 AP 0.6000 AR 0.0000
Epoch 161 batch 00005: Loss 0.4878 Regression loss 0.0239 Classification loss 0.4640 AP 0.6000 AR 0.0000
Epoch 161 batch 00006: Loss 0.4517 Regression loss 0.0202 Classification loss 0.4314 AP 1.0000 AR 0.2000
Epoch 161 batch 00007: Loss 0.4037 Regression loss 0.0194 Classification loss 0.3842 AP 1.0000 AR 0.0000
Epoch 161 batch 00008: Loss 0.3926 Regression loss 0.0169 Classification loss 0.3757 AP 0.8000 AR 0.0000
Epoch 161 batch 00009: Loss 0.4992 Regression loss 0.0200 Classification loss 0.4793 AP 0.8000 AR 0.0000
Epoch 161 batch 00010: Loss 0.5125 Regression loss 0.0259 Classification loss 0.4865 AP 1.0000 AR 0.1000
Epoch 162 batch 00001: Loss 0.4312 Regression loss 0.0211 Classification loss 0.4100 AP 0.9000 AR 0.2900
Epoch 162 batch 00002: Loss 0.5742 Regression loss 0.0239 Classification loss 0.5503 AP 0.8000 AR 0.0000
Epoch 162 batch 00003: Loss 0.4801 Regression loss 0.0234 Classification loss 0.4567 AP 0.3000 AR 0.0400
Epoch 162 batch 00004: Loss 0.4486 Regression loss 0.0204 Classification loss 0.4282 AP 0.4000 AR 0.0000
Epoch 162 batch 00005: Loss 0.5373 Regression loss 0.0242 Classification loss 0.5132 AP 0.6000 AR 0.2000
Epoch 162 batch 00006: Loss 0.3309 Regression loss 0.0201 Classification loss 0.3108 AP 0.2000 AR 0.0000
Epoch 162 batch 00007: Loss 0.3448 Regression loss 0.0236 Classification loss 0.3212 AP 0.8000 AR 0.0500
Epoch 162 batch 00008: Loss 0.5626 Regression loss 0.0237 Classification loss 0.5390 AP 1.0000 AR 0.0000
Epoch 162 batch 00009: Loss 0.4841 Regression loss 0.0179 Classification loss 0.4662 AP 1.0000 AR 0.0000
Epoch 162 batch 00010: Loss 0.4770 Regression loss 0.0179 Classification loss 0.4591 AP 0.8000 AR 0.0000
Epoch 163 batch 00001: Loss 0.3496 Regression loss 0.0205 Classification loss 0.3291 AP 0.2000 AR 0.0000
Epoch 163 batch 00002: Loss 0.4487 Regression loss 0.0220 Classification loss 0.4267 AP 0.6000 AR 0.2000
Epoch 163 batch 00003: Loss 0.4571 Regression loss 0.0163 Classification loss 0.4408 AP 0.5000 AR 0.3000
Epoch 163 batch 00004: Loss 0.3598 Regression loss 0.0202 Classification loss 0.3397 AP 0.2500 AR 0.0500
Epoch 163 batch 00005: Loss 0.4276 Regression loss 0.0219 Classification loss 0.4057 AP 0.6000 AR 0.0000
Epoch 163 batch 00006: Loss 0.5391 Regression loss 0.0206 Classification loss 0.5185 AP 0.8000 AR 0.0000
Epoch 163 batch 00007: Loss 0.5682 Regression loss 0.0260 Classification loss 0.5422 AP 0.8000 AR 0.0000
Epoch 163 batch 00008: Loss 0.4881 Regression loss 0.0281 Classification loss 0.4600 AP 1.0000 AR 0.0000
Epoch 163 batch 00009: Loss 0.4313 Regression loss 0.0229 Classification loss 0.4083 AP 0.6000 AR 0.0000
Epoch 163 batch 00010: Loss 0.5081 Regression loss 0.0215 Classification loss 0.4866 AP 0.8000 AR 0.0000
Epoch 164 batch 00001: Loss 0.5493 Regression loss 0.0157 Classification loss 0.5335 AP 0.8000 AR 0.0000
Epoch 164 batch 00002: Loss 0.4086 Regression loss 0.0213 Classification loss 0.3873 AP 0.5000 AR 0.2000
Epoch 164 batch 00003: Loss 0.4448 Regression loss 0.0220 Classification loss 0.4227 AP 0.6000 AR 0.0000
Epoch 164 batch 00004: Loss 0.5094 Regression loss 0.0243 Classification loss 0.4851 AP 0.8667 AR 0.0500
Epoch 164 batch 00005: Loss 0.4596 Regression loss 0.0211 Classification loss 0.4385 AP 0.3000 AR 0.1000
Epoch 164 batch 00006: Loss 0.6103 Regression loss 0.0334 Classification loss 0.5769 AP 0.8000 AR 0.0000
Epoch 164 batch 00007: Loss 0.4888 Regression loss 0.0236 Classification loss 0.4652 AP 0.8000 AR 0.0800
Epoch 164 batch 00008: Loss 0.2858 Regression loss 0.0200 Classification loss 0.2658 AP 0.6000 AR 0.2000
Epoch 164 batch 00009: Loss 0.3307 Regression loss 0.0176 Classification loss 0.3131 AP 0.8000 AR 0.0000
Epoch 164 batch 00010: Loss 0.4035 Regression loss 0.0177 Classification loss 0.3858 AP 0.8000 AR 0.0000
Epoch 165 batch 00001: Loss 0.4931 Regression loss 0.0242 Classification loss 0.4689 AP 1.0000 AR 0.0400
Epoch 165 batch 00002: Loss 0.3838 Regression loss 0.0213 Classification loss 0.3625 AP 0.8000 AR 0.2000
Epoch 165 batch 00003: Loss 0.4669 Regression loss 0.0248 Classification loss 0.4421 AP 0.6000 AR 0.0000
Epoch 165 batch 00004: Loss 0.4331 Regression loss 0.0184 Classification loss 0.4146 AP 0.6000 AR 0.1000
Epoch 165 batch 00005: Loss 0.5064 Regression loss 0.0155 Classification loss 0.4909 AP 0.6000 AR 0.0000
Epoch 165 batch 00006: Loss 0.4735 Regression loss 0.0246 Classification loss 0.4488 AP 0.8000 AR 0.0000
Epoch 165 batch 00007: Loss 0.3795 Regression loss 0.0192 Classification loss 0.3603 AP 1.0000 AR 0.0000
Epoch 165 batch 00008: Loss 0.4666 Regression loss 0.0247 Classification loss 0.4419 AP 0.8000 AR 0.2400
Epoch 165 batch 00009: Loss 0.4330 Regression loss 0.0218 Classification loss 0.4113 AP 0.8000 AR 0.0000
Epoch 165 batch 00010: Loss 0.4555 Regression loss 0.0176 Classification loss 0.4380 AP 0.6000 AR 0.0000
Epoch 166 batch 00001: Loss 0.4566 Regression loss 0.0237 Classification loss 0.4329 AP 0.7000 AR 0.1000
Epoch 166 batch 00002: Loss 0.4311 Regression loss 0.0178 Classification loss 0.4133 AP 0.6000 AR 0.2000
Epoch 166 batch 00003: Loss 0.3510 Regression loss 0.0198 Classification loss 0.3312 AP 0.3500 AR 0.2000
Epoch 166 batch 00004: Loss 0.5767 Regression loss 0.0230 Classification loss 0.5537 AP 1.0000 AR 0.0000
Epoch 166 batch 00005: Loss 0.3921 Regression loss 0.0233 Classification loss 0.3687 AP 0.6667 AR 0.2400
Epoch 166 batch 00006: Loss 0.5497 Regression loss 0.0162 Classification loss 0.5335 AP 0.9000 AR 0.1500
Epoch 166 batch 00007: Loss 0.3792 Regression loss 0.0212 Classification loss 0.3580 AP 0.6000 AR 0.0000
Epoch 166 batch 00008: Loss 0.4279 Regression loss 0.0161 Classification loss 0.4118 AP 0.6000 AR 0.0000
Epoch 166 batch 00009: Loss 0.5356 Regression loss 0.0251 Classification loss 0.5105 AP 0.8000 AR 0.0000
Epoch 166 batch 00010: Loss 0.4787 Regression loss 0.0233 Classification loss 0.4554 AP 0.8000 AR 0.0400
Epoch 167 batch 00001: Loss 0.3945 Regression loss 0.0192 Classification loss 0.3753 AP 0.9000 AR 0.1000
Epoch 167 batch 00002: Loss 0.3618 Regression loss 0.0213 Classification loss 0.3405 AP 0.4667 AR 0.0400
Epoch 167 batch 00003: Loss 0.3538 Regression loss 0.0163 Classification loss 0.3375 AP 0.6000 AR 0.0000
Epoch 167 batch 00004: Loss 0.5521 Regression loss 0.0212 Classification loss 0.5308 AP 1.0000 AR 0.2000
Epoch 167 batch 00005: Loss 0.4919 Regression loss 0.0237 Classification loss 0.4682 AP 0.8000 AR 0.0000
Epoch 167 batch 00006: Loss 0.5448 Regression loss 0.0194 Classification loss 0.5254 AP 0.6000 AR 0.0000
Epoch 167 batch 00007: Loss 0.4678 Regression loss 0.0250 Classification loss 0.4428 AP 1.0000 AR 0.2000
Epoch 167 batch 00008: Loss 0.4862 Regression loss 0.0226 Classification loss 0.4636 AP 0.6000 AR 0.1000
Epoch 167 batch 00009: Loss 0.3824 Regression loss 0.0217 Classification loss 0.3607 AP 0.9000 AR 0.0500
Epoch 167 batch 00010: Loss 0.4500 Regression loss 0.0242 Classification loss 0.4258 AP 0.8000 AR 0.0000
Epoch 168 batch 00001: Loss 0.4669 Regression loss 0.0230 Classification loss 0.4439 AP 0.8000 AR 0.0400
Epoch 168 batch 00002: Loss 0.5032 Regression loss 0.0235 Classification loss 0.4797 AP 0.6000 AR 0.0400
Epoch 168 batch 00003: Loss 0.4269 Regression loss 0.0230 Classification loss 0.4039 AP 0.4400 AR 0.0500
Epoch 168 batch 00004: Loss 0.4112 Regression loss 0.0202 Classification loss 0.3911 AP 0.6000 AR 0.0000
Epoch 168 batch 00005: Loss 0.3614 Regression loss 0.0161 Classification loss 0.3453 AP 0.7000 AR 0.1000
Epoch 168 batch 00006: Loss 0.5810 Regression loss 0.0234 Classification loss 0.5576 AP 1.0000 AR 0.0000
Epoch 168 batch 00007: Loss 0.5445 Regression loss 0.0209 Classification loss 0.5237 AP 0.8000 AR 0.4000
Epoch 168 batch 00008: Loss 0.4856 Regression loss 0.0218 Classification loss 0.4638 AP 0.6000 AR 0.0000
Epoch 168 batch 00009: Loss 0.2963 Regression loss 0.0189 Classification loss 0.2774 AP 0.6000 AR 0.0400
Epoch 168 batch 00010: Loss 0.4823 Regression loss 0.0216 Classification loss 0.4607 AP 0.8000 AR 0.1000
Epoch 169 batch 00001: Loss 0.3702 Regression loss 0.0172 Classification loss 0.3530 AP 0.2000 AR 0.0000
Epoch 169 batch 00002: Loss 0.4114 Regression loss 0.0236 Classification loss 0.3878 AP 0.6000 AR 0.4000
Epoch 169 batch 00003: Loss 0.3973 Regression loss 0.0236 Classification loss 0.3737 AP 0.8000 AR 0.0000
Epoch 169 batch 00004: Loss 0.4765 Regression loss 0.0239 Classification loss 0.4526 AP 0.6667 AR 0.0800
Epoch 169 batch 00005: Loss 0.5435 Regression loss 0.0182 Classification loss 0.5253 AP 0.6000 AR 0.1000
Epoch 169 batch 00006: Loss 0.4064 Regression loss 0.0189 Classification loss 0.3874 AP 0.4000 AR 0.0000
Epoch 169 batch 00007: Loss 0.4823 Regression loss 0.0252 Classification loss 0.4571 AP 0.8000 AR 0.0000
Epoch 169 batch 00008: Loss 0.6528 Regression loss 0.0172 Classification loss 0.6356 AP 1.0000 AR 0.0000
Epoch 169 batch 00009: Loss 0.4066 Regression loss 0.0247 Classification loss 0.3818 AP 0.7000 AR 0.0500
Epoch 169 batch 00010: Loss 0.4172 Regression loss 0.0203 Classification loss 0.3969 AP 0.6000 AR 0.0000
Epoch 170 batch 00001: Loss 0.3948 Regression loss 0.0218 Classification loss 0.3730 AP 0.6000 AR 0.0000
Epoch 170 batch 00002: Loss 0.6046 Regression loss 0.0222 Classification loss 0.5824 AP 1.0000 AR 0.2000
Epoch 170 batch 00003: Loss 0.4843 Regression loss 0.0186 Classification loss 0.4657 AP 0.4000 AR 0.0000
Epoch 170 batch 00004: Loss 0.4186 Regression loss 0.0195 Classification loss 0.3991 AP 0.7000 AR 0.1000
Epoch 170 batch 00005: Loss 0.4740 Regression loss 0.0202 Classification loss 0.4539 AP 0.6000 AR 0.0000
Epoch 170 batch 00006: Loss 0.3456 Regression loss 0.0209 Classification loss 0.3246 AP 0.9000 AR 0.1500
Epoch 170 batch 00007: Loss 0.3239 Regression loss 0.0197 Classification loss 0.3042 AP 0.5667 AR 0.1400
Epoch 170 batch 00008: Loss 0.4969 Regression loss 0.0196 Classification loss 0.4774 AP 0.2000 AR 0.0000
Epoch 170 batch 00009: Loss 0.4229 Regression loss 0.0252 Classification loss 0.3977 AP 0.6000 AR 0.2000
Epoch 170 batch 00010: Loss 0.4784 Regression loss 0.0225 Classification loss 0.4559 AP 0.6000 AR 0.0000
Epoch 171 batch 00001: Loss 0.4930 Regression loss 0.0227 Classification loss 0.4703 AP 0.8000 AR 0.0000
Epoch 171 batch 00002: Loss 0.4793 Regression loss 0.0238 Classification loss 0.4555 AP 1.0000 AR 0.1400
Epoch 171 batch 00003: Loss 0.4571 Regression loss 0.0193 Classification loss 0.4378 AP 0.8000 AR 0.0000
Epoch 171 batch 00004: Loss 0.3722 Regression loss 0.0217 Classification loss 0.3505 AP 0.7000 AR 0.0500
Epoch 171 batch 00005: Loss 0.5252 Regression loss 0.0186 Classification loss 0.5067 AP 0.8667 AR 0.0400
Epoch 171 batch 00006: Loss 0.3801 Regression loss 0.0208 Classification loss 0.3593 AP 0.6000 AR 0.0000
Epoch 171 batch 00007: Loss 0.4202 Regression loss 0.0216 Classification loss 0.3986 AP 0.2000 AR 0.0000
Epoch 171 batch 00008: Loss 0.3071 Regression loss 0.0205 Classification loss 0.2866 AP 0.4000 AR 0.0000
Epoch 171 batch 00009: Loss 0.6217 Regression loss 0.0227 Classification loss 0.5990 AP 1.0000 AR 0.4000
Epoch 171 batch 00010: Loss 0.5026 Regression loss 0.0193 Classification loss 0.4832 AP 0.6000 AR 0.0000
Epoch 172 batch 00001: Loss 0.3847 Regression loss 0.0212 Classification loss 0.3635 AP 0.6000 AR 0.0000
Epoch 172 batch 00002: Loss 0.4113 Regression loss 0.0172 Classification loss 0.3941 AP 0.8000 AR 0.2000
Epoch 172 batch 00003: Loss 0.4643 Regression loss 0.0192 Classification loss 0.4451 AP 0.4667 AR 0.1000
Epoch 172 batch 00004: Loss 0.5227 Regression loss 0.0252 Classification loss 0.4975 AP 0.8000 AR 0.2000
Epoch 172 batch 00005: Loss 0.4484 Regression loss 0.0226 Classification loss 0.4258 AP 0.8000 AR 0.0000
Epoch 172 batch 00006: Loss 0.4665 Regression loss 0.0187 Classification loss 0.4478 AP 0.8000 AR 0.0000
Epoch 172 batch 00007: Loss 0.4965 Regression loss 0.0220 Classification loss 0.4745 AP 0.6000 AR 0.0800
Epoch 172 batch 00008: Loss 0.4601 Regression loss 0.0180 Classification loss 0.4421 AP 0.6000 AR 0.0000
Epoch 172 batch 00009: Loss 0.4744 Regression loss 0.0226 Classification loss 0.4518 AP 1.0000 AR 0.1000
Epoch 172 batch 00010: Loss 0.4144 Regression loss 0.0181 Classification loss 0.3963 AP 0.6000 AR 0.0500
Epoch 173 batch 00001: Loss 0.3649 Regression loss 0.0162 Classification loss 0.3487 AP 0.6000 AR 0.0000
Epoch 173 batch 00002: Loss 0.3839 Regression loss 0.0150 Classification loss 0.3689 AP 0.4000 AR 0.3000
Epoch 173 batch 00003: Loss 0.4225 Regression loss 0.0207 Classification loss 0.4019 AP 0.4667 AR 0.1000
Epoch 173 batch 00004: Loss 0.5775 Regression loss 0.0250 Classification loss 0.5525 AP 0.8667 AR 0.0500
Epoch 173 batch 00005: Loss 0.4277 Regression loss 0.0220 Classification loss 0.4057 AP 0.4667 AR 0.0400
Epoch 173 batch 00006: Loss 0.3566 Regression loss 0.0225 Classification loss 0.3341 AP 1.0000 AR 0.0500
Epoch 173 batch 00007: Loss 0.4103 Regression loss 0.0230 Classification loss 0.3873 AP 0.6000 AR 0.0000
Epoch 173 batch 00008: Loss 0.4838 Regression loss 0.0200 Classification loss 0.4638 AP 0.8000 AR 0.0400
Epoch 173 batch 00009: Loss 0.5069 Regression loss 0.0196 Classification loss 0.4873 AP 0.6000 AR 0.2000
Epoch 173 batch 00010: Loss 0.4025 Regression loss 0.0216 Classification loss 0.3809 AP 0.6000 AR 0.0000
Epoch 174 batch 00001: Loss 0.5038 Regression loss 0.0215 Classification loss 0.4823 AP 1.0000 AR 0.0400
Epoch 174 batch 00002: Loss 0.4080 Regression loss 0.0199 Classification loss 0.3881 AP 0.8667 AR 0.0500
Epoch 174 batch 00003: Loss 0.3863 Regression loss 0.0246 Classification loss 0.3617 AP 0.6000 AR 0.0000
Epoch 174 batch 00004: Loss 0.3180 Regression loss 0.0163 Classification loss 0.3017 AP 0.4000 AR 0.0000
Epoch 174 batch 00005: Loss 0.5415 Regression loss 0.0209 Classification loss 0.5206 AP 0.6000 AR 0.0000
Epoch 174 batch 00006: Loss 0.3527 Regression loss 0.0188 Classification loss 0.3339 AP 0.8000 AR 0.0500
Epoch 174 batch 00007: Loss 0.4889 Regression loss 0.0199 Classification loss 0.4691 AP 0.6000 AR 0.0000
Epoch 174 batch 00008: Loss 0.5212 Regression loss 0.0184 Classification loss 0.5027 AP 0.8000 AR 0.2000
Epoch 174 batch 00009: Loss 0.4690 Regression loss 0.0191 Classification loss 0.4499 AP 0.8000 AR 0.3400
Epoch 174 batch 00010: Loss 0.3758 Regression loss 0.0247 Classification loss 0.3511 AP 0.6000 AR 0.0000
Epoch 175 batch 00001: Loss 0.4150 Regression loss 0.0214 Classification loss 0.3936 AP 0.4000 AR 0.0000
Epoch 175 batch 00002: Loss 0.4737 Regression loss 0.0243 Classification loss 0.4494 AP 0.8500 AR 0.1500
Epoch 175 batch 00003: Loss 0.7637 Regression loss 0.0211 Classification loss 0.7426 AP 0.8000 AR 0.0000
Epoch 175 batch 00004: Loss 0.3220 Regression loss 0.0139 Classification loss 0.3081 AP 0.6000 AR 0.2000
Epoch 175 batch 00005: Loss 0.5267 Regression loss 0.0183 Classification loss 0.5085 AP 0.4000 AR 0.2000
Epoch 175 batch 00006: Loss 0.5041 Regression loss 0.0184 Classification loss 0.4857 AP 0.8000 AR 0.0000
Epoch 175 batch 00007: Loss 0.4823 Regression loss 0.0223 Classification loss 0.4600 AP 0.8000 AR 0.0000
Epoch 175 batch 00008: Loss 0.3639 Regression loss 0.0199 Classification loss 0.3440 AP 0.8000 AR 0.0400
Epoch 175 batch 00009: Loss 0.5831 Regression loss 0.0206 Classification loss 0.5625 AP 0.8000 AR 0.0400
Epoch 175 batch 00010: Loss 0.4456 Regression loss 0.0235 Classification loss 0.4221 AP 0.6000 AR 0.0000
Epoch 176 batch 00001: Loss 0.7864 Regression loss 0.0222 Classification loss 0.7642 AP 0.8000 AR 0.0000
Epoch 176 batch 00002: Loss 0.3495 Regression loss 0.0169 Classification loss 0.3326 AP 0.4500 AR 0.1000
Epoch 176 batch 00003: Loss 0.4633 Regression loss 0.0221 Classification loss 0.4412 AP 1.0000 AR 0.1000
Epoch 176 batch 00004: Loss 0.4911 Regression loss 0.0189 Classification loss 0.4722 AP 0.6000 AR 0.2000
Epoch 176 batch 00005: Loss 0.4862 Regression loss 0.0192 Classification loss 0.4671 AP 0.8000 AR 0.2000
Epoch 176 batch 00006: Loss 0.5385 Regression loss 0.0240 Classification loss 0.5146 AP 0.8000 AR 0.0000
Epoch 176 batch 00007: Loss 0.4003 Regression loss 0.0232 Classification loss 0.3771 AP 0.6000 AR 0.0400
Epoch 176 batch 00008: Loss 0.5007 Regression loss 0.0201 Classification loss 0.4806 AP 0.8000 AR 0.0400
Epoch 176 batch 00009: Loss 0.4411 Regression loss 0.0237 Classification loss 0.4173 AP 0.4000 AR 0.0000
Epoch 176 batch 00010: Loss 0.4343 Regression loss 0.0171 Classification loss 0.4172 AP 0.0000 AR 0.0000
Epoch 177 batch 00001: Loss 0.4240 Regression loss 0.0162 Classification loss 0.4079 AP 0.2400 AR 0.0500
Epoch 177 batch 00002: Loss 0.4574 Regression loss 0.0241 Classification loss 0.4333 AP 1.0000 AR 0.2400
Epoch 177 batch 00003: Loss 0.5108 Regression loss 0.0202 Classification loss 0.4906 AP 1.0000 AR 0.2400
Epoch 177 batch 00004: Loss 0.3867 Regression loss 0.0263 Classification loss 0.3604 AP 0.6000 AR 0.0000
Epoch 177 batch 00005: Loss 0.3645 Regression loss 0.0184 Classification loss 0.3461 AP 0.8000 AR 0.0500
Epoch 177 batch 00006: Loss 0.4058 Regression loss 0.0179 Classification loss 0.3879 AP 0.4000 AR 0.0000
Epoch 177 batch 00007: Loss 0.5087 Regression loss 0.0176 Classification loss 0.4911 AP 0.8000 AR 0.0000
Epoch 177 batch 00008: Loss 0.4371 Regression loss 0.0238 Classification loss 0.4133 AP 0.7000 AR 0.1000
Epoch 177 batch 00009: Loss 0.4466 Regression loss 0.0189 Classification loss 0.4278 AP 0.4000 AR 0.0000
Epoch 177 batch 00010: Loss 0.4874 Regression loss 0.0213 Classification loss 0.4662 AP 0.6667 AR 0.1000
Epoch 178 batch 00001: Loss 0.3604 Regression loss 0.0198 Classification loss 0.3406 AP 0.5000 AR 0.3000
Epoch 178 batch 00002: Loss 0.3551 Regression loss 0.0215 Classification loss 0.3336 AP 0.8000 AR 0.0000
Epoch 178 batch 00003: Loss 0.4402 Regression loss 0.0175 Classification loss 0.4227 AP 0.4000 AR 0.0000
Epoch 178 batch 00004: Loss 0.4600 Regression loss 0.0176 Classification loss 0.4423 AP 0.6000 AR 0.1000
Epoch 178 batch 00005: Loss 0.3911 Regression loss 0.0207 Classification loss 0.3705 AP 0.8000 AR 0.0000
Epoch 178 batch 00006: Loss 0.5669 Regression loss 0.0170 Classification loss 0.5499 AP 0.6000 AR 0.0000
Epoch 178 batch 00007: Loss 0.4394 Regression loss 0.0186 Classification loss 0.4207 AP 0.6667 AR 0.0400
Epoch 178 batch 00008: Loss 0.6004 Regression loss 0.0299 Classification loss 0.5705 AP 0.8000 AR 0.0000
Epoch 178 batch 00009: Loss 0.4400 Regression loss 0.0239 Classification loss 0.4162 AP 0.6000 AR 0.2400
Epoch 178 batch 00010: Loss 0.3455 Regression loss 0.0219 Classification loss 0.3236 AP 0.7667 AR 0.1500
Epoch 179 batch 00001: Loss 0.6074 Regression loss 0.0182 Classification loss 0.5892 AP 0.8000 AR 0.0000
Epoch 179 batch 00002: Loss 0.3985 Regression loss 0.0202 Classification loss 0.3783 AP 0.6000 AR 0.2000
Epoch 179 batch 00003: Loss 0.3323 Regression loss 0.0182 Classification loss 0.3141 AP 0.5000 AR 0.1500
Epoch 179 batch 00004: Loss 0.4328 Regression loss 0.0211 Classification loss 0.4117 AP 0.4000 AR 0.0000
Epoch 179 batch 00005: Loss 0.3870 Regression loss 0.0208 Classification loss 0.3662 AP 0.5000 AR 0.1500
Epoch 179 batch 00006: Loss 0.4320 Regression loss 0.0205 Classification loss 0.4114 AP 0.6500 AR 0.0400
Epoch 179 batch 00007: Loss 0.4062 Regression loss 0.0193 Classification loss 0.3869 AP 0.3333 AR 0.3400
Epoch 179 batch 00008: Loss 0.6094 Regression loss 0.0181 Classification loss 0.5913 AP 0.6000 AR 0.0000
Epoch 179 batch 00009: Loss 0.3981 Regression loss 0.0249 Classification loss 0.3732 AP 0.8000 AR 0.0000
Epoch 179 batch 00010: Loss 0.4436 Regression loss 0.0247 Classification loss 0.4189 AP 1.0000 AR 0.0000
Epoch 180 batch 00001: Loss 0.5238 Regression loss 0.0207 Classification loss 0.5030 AP 0.6000 AR 0.1000
Epoch 180 batch 00002: Loss 0.4003 Regression loss 0.0165 Classification loss 0.3838 AP 0.9000 AR 0.1000
Epoch 180 batch 00003: Loss 0.5138 Regression loss 0.0181 Classification loss 0.4957 AP 0.8000 AR 0.0000
Epoch 180 batch 00004: Loss 0.4803 Regression loss 0.0176 Classification loss 0.4626 AP 0.8000 AR 0.0000
Epoch 180 batch 00005: Loss 0.5649 Regression loss 0.0219 Classification loss 0.5430 AP 0.6000 AR 0.0000
Epoch 180 batch 00006: Loss 0.3739 Regression loss 0.0216 Classification loss 0.3523 AP 0.3000 AR 0.0500
Epoch 180 batch 00007: Loss 0.4253 Regression loss 0.0237 Classification loss 0.4016 AP 0.8000 AR 0.2000
Epoch 180 batch 00008: Loss 0.3937 Regression loss 0.0205 Classification loss 0.3732 AP 0.5167 AR 0.1400
Epoch 180 batch 00009: Loss 0.3348 Regression loss 0.0195 Classification loss 0.3153 AP 0.4000 AR 0.0000
Epoch 180 batch 00010: Loss 0.5306 Regression loss 0.0256 Classification loss 0.5050 AP 1.0000 AR 0.2000
Epoch 181 batch 00001: Loss 0.4646 Regression loss 0.0271 Classification loss 0.4375 AP 0.8000 AR 0.2000
Epoch 181 batch 00002: Loss 0.3945 Regression loss 0.0206 Classification loss 0.3739 AP 0.6000 AR 0.0000
Epoch 181 batch 00003: Loss 0.4092 Regression loss 0.0160 Classification loss 0.3933 AP 0.4000 AR 0.0000
Epoch 181 batch 00004: Loss 0.4234 Regression loss 0.0224 Classification loss 0.4009 AP 0.8000 AR 0.0500
Epoch 181 batch 00005: Loss 0.4284 Regression loss 0.0207 Classification loss 0.4077 AP 0.3000 AR 0.0400
Epoch 181 batch 00006: Loss 0.5952 Regression loss 0.0225 Classification loss 0.5727 AP 0.8667 AR 0.1000
Epoch 181 batch 00007: Loss 0.4696 Regression loss 0.0238 Classification loss 0.4458 AP 0.4000 AR 0.0000
Epoch 181 batch 00008: Loss 0.5172 Regression loss 0.0199 Classification loss 0.4973 AP 0.8000 AR 0.1000
Epoch 181 batch 00009: Loss 0.3687 Regression loss 0.0166 Classification loss 0.3521 AP 0.6000 AR 0.0000
Epoch 181 batch 00010: Loss 0.3672 Regression loss 0.0188 Classification loss 0.3484 AP 0.8000 AR 0.2000
Epoch 182 batch 00001: Loss 0.5331 Regression loss 0.0240 Classification loss 0.5091 AP 1.0000 AR 0.1400
Epoch 182 batch 00002: Loss 0.5134 Regression loss 0.0147 Classification loss 0.4987 AP 1.0000 AR 0.0000
Epoch 182 batch 00003: Loss 0.4262 Regression loss 0.0202 Classification loss 0.4059 AP 0.4000 AR 0.0000
Epoch 182 batch 00004: Loss 0.5155 Regression loss 0.0216 Classification loss 0.4939 AP 0.8000 AR 0.4000
Epoch 182 batch 00005: Loss 0.4345 Regression loss 0.0235 Classification loss 0.4111 AP 0.6000 AR 0.0000
Epoch 182 batch 00006: Loss 0.3574 Regression loss 0.0211 Classification loss 0.3363 AP 0.3000 AR 0.0500
Epoch 182 batch 00007: Loss 0.3492 Regression loss 0.0203 Classification loss 0.3289 AP 0.4500 AR 0.0400
Epoch 182 batch 00008: Loss 0.5234 Regression loss 0.0179 Classification loss 0.5055 AP 0.6000 AR 0.0000
Epoch 182 batch 00009: Loss 0.3943 Regression loss 0.0227 Classification loss 0.3717 AP 0.6000 AR 0.0000
Epoch 182 batch 00010: Loss 0.4444 Regression loss 0.0207 Classification loss 0.4237 AP 0.6000 AR 0.0000
Epoch 183 batch 00001: Loss 0.5235 Regression loss 0.0173 Classification loss 0.5062 AP 1.0000 AR 0.1000
Epoch 183 batch 00002: Loss 0.4040 Regression loss 0.0193 Classification loss 0.3847 AP 0.6000 AR 0.0000
Epoch 183 batch 00003: Loss 0.4043 Regression loss 0.0230 Classification loss 0.3812 AP 0.6000 AR 0.0000
Epoch 183 batch 00004: Loss 0.3285 Regression loss 0.0206 Classification loss 0.3079 AP 0.2000 AR 0.0000
Epoch 183 batch 00005: Loss 0.5925 Regression loss 0.0190 Classification loss 0.5735 AP 0.8000 AR 0.0000
Epoch 183 batch 00006: Loss 0.4948 Regression loss 0.0221 Classification loss 0.4728 AP 0.4667 AR 0.1000
Epoch 183 batch 00007: Loss 0.3584 Regression loss 0.0165 Classification loss 0.3419 AP 0.6000 AR 0.2000
Epoch 183 batch 00008: Loss 0.4494 Regression loss 0.0221 Classification loss 0.4274 AP 1.0000 AR 0.2500
Epoch 183 batch 00009: Loss 0.4334 Regression loss 0.0211 Classification loss 0.4122 AP 0.8000 AR 0.0400
Epoch 183 batch 00010: Loss 0.5570 Regression loss 0.0209 Classification loss 0.5361 AP 0.6000 AR 0.0400
Epoch 184 batch 00001: Loss 0.4010 Regression loss 0.0178 Classification loss 0.3832 AP 0.6000 AR 0.0400
Epoch 184 batch 00002: Loss 0.4644 Regression loss 0.0247 Classification loss 0.4397 AP 0.8667 AR 0.1000
Epoch 184 batch 00003: Loss 0.4943 Regression loss 0.0263 Classification loss 0.4680 AP 0.8667 AR 0.0400
Epoch 184 batch 00004: Loss 0.4195 Regression loss 0.0189 Classification loss 0.4006 AP 0.8000 AR 0.0000
Epoch 184 batch 00005: Loss 0.4511 Regression loss 0.0195 Classification loss 0.4316 AP 0.4000 AR 0.2000
Epoch 184 batch 00006: Loss 0.5075 Regression loss 0.0202 Classification loss 0.4873 AP 0.8000 AR 0.1000
Epoch 184 batch 00007: Loss 0.3191 Regression loss 0.0147 Classification loss 0.3044 AP 1.0000 AR 0.2000
Epoch 184 batch 00008: Loss 0.4585 Regression loss 0.0219 Classification loss 0.4366 AP 0.4000 AR 0.0000
Epoch 184 batch 00009: Loss 0.4759 Regression loss 0.0196 Classification loss 0.4563 AP 0.8000 AR 0.0000
Epoch 184 batch 00010: Loss 0.3678 Regression loss 0.0184 Classification loss 0.3494 AP 0.6667 AR 0.1000
Epoch 185 batch 00001: Loss 0.5309 Regression loss 0.0214 Classification loss 0.5095 AP 0.8000 AR 0.0000
Epoch 185 batch 00002: Loss 0.4266 Regression loss 0.0158 Classification loss 0.4108 AP 0.6000 AR 0.2000
Epoch 185 batch 00003: Loss 0.3949 Regression loss 0.0216 Classification loss 0.3733 AP 0.8000 AR 0.0000
Epoch 185 batch 00004: Loss 0.4101 Regression loss 0.0196 Classification loss 0.3906 AP 0.1333 AR 0.1500
Epoch 185 batch 00005: Loss 0.4968 Regression loss 0.0220 Classification loss 0.4748 AP 0.6000 AR 0.0000
Epoch 185 batch 00006: Loss 0.4058 Regression loss 0.0192 Classification loss 0.3865 AP 0.6000 AR 0.0000
Epoch 185 batch 00007: Loss 0.5274 Regression loss 0.0216 Classification loss 0.5059 AP 1.0000 AR 0.3400
Epoch 185 batch 00008: Loss 0.4446 Regression loss 0.0210 Classification loss 0.4236 AP 0.8000 AR 0.0400
Epoch 185 batch 00009: Loss 0.3593 Regression loss 0.0215 Classification loss 0.3378 AP 0.7000 AR 0.0500
Epoch 185 batch 00010: Loss 0.4702 Regression loss 0.0202 Classification loss 0.4500 AP 0.4000 AR 0.0000
Epoch 186 batch 00001: Loss 0.5904 Regression loss 0.0253 Classification loss 0.5651 AP 1.0000 AR 0.2400
Epoch 186 batch 00002: Loss 0.4158 Regression loss 0.0190 Classification loss 0.3968 AP 0.5333 AR 0.3400
Epoch 186 batch 00003: Loss 0.4022 Regression loss 0.0243 Classification loss 0.3778 AP 0.6000 AR 0.0000
Epoch 186 batch 00004: Loss 0.4661 Regression loss 0.0184 Classification loss 0.4477 AP 0.6000 AR 0.0000
Epoch 186 batch 00005: Loss 0.4512 Regression loss 0.0253 Classification loss 0.4259 AP 0.8000 AR 0.0000
Epoch 186 batch 00006: Loss 0.4003 Regression loss 0.0205 Classification loss 0.3798 AP 0.8000 AR 0.0000
Epoch 186 batch 00007: Loss 0.5510 Regression loss 0.0177 Classification loss 0.5333 AP 0.8000 AR 0.0000
Epoch 186 batch 00008: Loss 0.3072 Regression loss 0.0166 Classification loss 0.2906 AP 0.6000 AR 0.0000
Epoch 186 batch 00009: Loss 0.4946 Regression loss 0.0178 Classification loss 0.4769 AP 0.6000 AR 0.0000
Epoch 186 batch 00010: Loss 0.3843 Regression loss 0.0207 Classification loss 0.3636 AP 0.5000 AR 0.0400
Epoch 187 batch 00001: Loss 0.4071 Regression loss 0.0169 Classification loss 0.3902 AP 0.8000 AR 0.2000
Epoch 187 batch 00002: Loss 0.3992 Regression loss 0.0194 Classification loss 0.3799 AP 0.8000 AR 0.0000
Epoch 187 batch 00003: Loss 0.4472 Regression loss 0.0263 Classification loss 0.4209 AP 0.4000 AR 0.0000
Epoch 187 batch 00004: Loss 0.5542 Regression loss 0.0173 Classification loss 0.5368 AP 0.6000 AR 0.0000
Epoch 187 batch 00005: Loss 0.5719 Regression loss 0.0182 Classification loss 0.5538 AP 0.8000 AR 0.0000
Epoch 187 batch 00006: Loss 0.3732 Regression loss 0.0169 Classification loss 0.3562 AP 0.4000 AR 0.0000
Epoch 187 batch 00007: Loss 0.3683 Regression loss 0.0205 Classification loss 0.3478 AP 0.7000 AR 0.2500
Epoch 187 batch 00008: Loss 0.4865 Regression loss 0.0240 Classification loss 0.4624 AP 0.8000 AR 0.0000
Epoch 187 batch 00009: Loss 0.4282 Regression loss 0.0233 Classification loss 0.4049 AP 0.7333 AR 0.2400
Epoch 187 batch 00010: Loss 0.3423 Regression loss 0.0197 Classification loss 0.3226 AP 0.6667 AR 0.1000
Epoch 188 batch 00001: Loss 0.3869 Regression loss 0.0232 Classification loss 0.3637 AP 0.2000 AR 0.0000
Epoch 188 batch 00002: Loss 0.4241 Regression loss 0.0217 Classification loss 0.4024 AP 0.4000 AR 0.0000
Epoch 188 batch 00003: Loss 0.4324 Regression loss 0.0197 Classification loss 0.4127 AP 0.6000 AR 0.0000
Epoch 188 batch 00004: Loss 0.3529 Regression loss 0.0179 Classification loss 0.3350 AP 0.7000 AR 0.4400
Epoch 188 batch 00005: Loss 0.3244 Regression loss 0.0189 Classification loss 0.3055 AP 0.7667 AR 0.1500
Epoch 188 batch 00006: Loss 0.4640 Regression loss 0.0195 Classification loss 0.4445 AP 0.8000 AR 0.0000
Epoch 188 batch 00007: Loss 0.4664 Regression loss 0.0212 Classification loss 0.4452 AP 0.2667 AR 0.1000
Epoch 188 batch 00008: Loss 0.3970 Regression loss 0.0201 Classification loss 0.3770 AP 0.8000 AR 0.0000
Epoch 188 batch 00009: Loss 0.6639 Regression loss 0.0225 Classification loss 0.6414 AP 1.0000 AR 0.0000
Epoch 188 batch 00010: Loss 0.5393 Regression loss 0.0208 Classification loss 0.5185 AP 0.6000 AR 0.1000
Epoch 189 batch 00001: Loss 0.4745 Regression loss 0.0187 Classification loss 0.4558 AP 0.6000 AR 0.1000
Epoch 189 batch 00002: Loss 0.3983 Regression loss 0.0162 Classification loss 0.3821 AP 0.2000 AR 0.0000
Epoch 189 batch 00003: Loss 0.3505 Regression loss 0.0232 Classification loss 0.3273 AP 0.4000 AR 0.0000
Epoch 189 batch 00004: Loss 0.4549 Regression loss 0.0263 Classification loss 0.4286 AP 0.8000 AR 0.4000
Epoch 189 batch 00005: Loss 0.4027 Regression loss 0.0192 Classification loss 0.3835 AP 0.4000 AR 0.0000
Epoch 189 batch 00006: Loss 0.4714 Regression loss 0.0201 Classification loss 0.4514 AP 0.6000 AR 0.0500
Epoch 189 batch 00007: Loss 0.4738 Regression loss 0.0249 Classification loss 0.4490 AP 1.0000 AR 0.0400
Epoch 189 batch 00008: Loss 0.5288 Regression loss 0.0147 Classification loss 0.5141 AP 0.8000 AR 0.0000
Epoch 189 batch 00009: Loss 0.5114 Regression loss 0.0218 Classification loss 0.4896 AP 0.8000 AR 0.0000
Epoch 189 batch 00010: Loss 0.4326 Regression loss 0.0196 Classification loss 0.4130 AP 0.6667 AR 0.3400
Epoch 190 batch 00001: Loss 0.3479 Regression loss 0.0190 Classification loss 0.3289 AP 0.4000 AR 0.0000
Epoch 190 batch 00002: Loss 0.5274 Regression loss 0.0171 Classification loss 0.5103 AP 0.6000 AR 0.2000
Epoch 190 batch 00003: Loss 0.3504 Regression loss 0.0217 Classification loss 0.3287 AP 0.6000 AR 0.0000
Epoch 190 batch 00004: Loss 0.6026 Regression loss 0.0207 Classification loss 0.5819 AP 0.6000 AR 0.0000
Epoch 190 batch 00005: Loss 0.4902 Regression loss 0.0202 Classification loss 0.4700 AP 0.6000 AR 0.0000
Epoch 190 batch 00006: Loss 0.4085 Regression loss 0.0200 Classification loss 0.3886 AP 0.7000 AR 0.2400
Epoch 190 batch 00007: Loss 0.3851 Regression loss 0.0214 Classification loss 0.3637 AP 0.3667 AR 0.1667
Epoch 190 batch 00008: Loss 0.4310 Regression loss 0.0234 Classification loss 0.4076 AP 0.5000 AR 0.1500
Epoch 190 batch 00009: Loss 0.3769 Regression loss 0.0235 Classification loss 0.3534 AP 0.2000 AR 0.0000
Epoch 190 batch 00010: Loss 0.5197 Regression loss 0.0221 Classification loss 0.4975 AP 1.0000 AR 0.0000
Epoch 191 batch 00001: Loss 0.4201 Regression loss 0.0253 Classification loss 0.3947 AP 0.6000 AR 0.0000
Epoch 191 batch 00002: Loss 0.4400 Regression loss 0.0229 Classification loss 0.4171 AP 0.8000 AR 0.0000
Epoch 191 batch 00003: Loss 0.6203 Regression loss 0.0196 Classification loss 0.6007 AP 1.0000 AR 0.2000
Epoch 191 batch 00004: Loss 0.4557 Regression loss 0.0189 Classification loss 0.4368 AP 0.5333 AR 0.1900
Epoch 191 batch 00005: Loss 0.3557 Regression loss 0.0210 Classification loss 0.3347 AP 0.6000 AR 0.0500
Epoch 191 batch 00006: Loss 0.3378 Regression loss 0.0196 Classification loss 0.3182 AP 0.5000 AR 0.0400
Epoch 191 batch 00007: Loss 0.4129 Regression loss 0.0199 Classification loss 0.3930 AP 0.4000 AR 0.0000
Epoch 191 batch 00008: Loss 0.4945 Regression loss 0.0181 Classification loss 0.4764 AP 0.2000 AR 0.1000
Epoch 191 batch 00009: Loss 0.3554 Regression loss 0.0191 Classification loss 0.3363 AP 0.5667 AR 0.3400
Epoch 191 batch 00010: Loss 0.5357 Regression loss 0.0226 Classification loss 0.5131 AP 0.8000 AR 0.0000
Epoch 192 batch 00001: Loss 0.3958 Regression loss 0.0174 Classification loss 0.3785 AP 0.4000 AR 0.0000
Epoch 192 batch 00002: Loss 0.4595 Regression loss 0.0259 Classification loss 0.4336 AP 0.7667 AR 0.1400
Epoch 192 batch 00003: Loss 0.4358 Regression loss 0.0176 Classification loss 0.4182 AP 0.8000 AR 0.0000
Epoch 192 batch 00004: Loss 0.4798 Regression loss 0.0207 Classification loss 0.4591 AP 0.4500 AR 0.0500
Epoch 192 batch 00005: Loss 0.5302 Regression loss 0.0198 Classification loss 0.5104 AP 0.8000 AR 0.1000
Epoch 192 batch 00006: Loss 0.3855 Regression loss 0.0224 Classification loss 0.3631 AP 0.9000 AR 0.0500
Epoch 192 batch 00007: Loss 0.4054 Regression loss 0.0156 Classification loss 0.3899 AP 0.6000 AR 0.2000
Epoch 192 batch 00008: Loss 0.4118 Regression loss 0.0132 Classification loss 0.3986 AP 0.7000 AR 0.0400
Epoch 192 batch 00009: Loss 0.3589 Regression loss 0.0212 Classification loss 0.3378 AP 0.2000 AR 0.2000
Epoch 192 batch 00010: Loss 0.4806 Regression loss 0.0217 Classification loss 0.4589 AP 0.7000 AR 0.1000
Epoch 193 batch 00001: Loss 0.3587 Regression loss 0.0202 Classification loss 0.3385 AP 0.6000 AR 0.0000
Epoch 193 batch 00002: Loss 0.3851 Regression loss 0.0161 Classification loss 0.3690 AP 0.4000 AR 0.0000
Epoch 193 batch 00003: Loss 0.3887 Regression loss 0.0146 Classification loss 0.3741 AP 0.8000 AR 0.2000
Epoch 193 batch 00004: Loss 0.4111 Regression loss 0.0230 Classification loss 0.3881 AP 1.0000 AR 0.0500
Epoch 193 batch 00005: Loss 0.3904 Regression loss 0.0223 Classification loss 0.3681 AP 0.6500 AR 0.0500
Epoch 193 batch 00006: Loss 0.4596 Regression loss 0.0177 Classification loss 0.4419 AP 0.6667 AR 0.0400
Epoch 193 batch 00007: Loss 0.4122 Regression loss 0.0168 Classification loss 0.3954 AP 0.6000 AR 0.1000
Epoch 193 batch 00008: Loss 0.5081 Regression loss 0.0251 Classification loss 0.4830 AP 0.8000 AR 0.2400
Epoch 193 batch 00009: Loss 0.4754 Regression loss 0.0195 Classification loss 0.4559 AP 0.4000 AR 0.0000
Epoch 193 batch 00010: Loss 0.4478 Regression loss 0.0219 Classification loss 0.4259 AP 0.8000 AR 0.0000
Epoch 194 batch 00001: Loss 0.3646 Regression loss 0.0191 Classification loss 0.3455 AP 0.5000 AR 0.0500
Epoch 194 batch 00002: Loss 0.3501 Regression loss 0.0207 Classification loss 0.3293 AP 0.6000 AR 0.0000
Epoch 194 batch 00003: Loss 0.4182 Regression loss 0.0190 Classification loss 0.3993 AP 0.6500 AR 0.0500
Epoch 194 batch 00004: Loss 0.4364 Regression loss 0.0193 Classification loss 0.4171 AP 0.6667 AR 0.1000
Epoch 194 batch 00005: Loss 0.4208 Regression loss 0.0192 Classification loss 0.4016 AP 0.2667 AR 0.1000
Epoch 194 batch 00006: Loss 0.4885 Regression loss 0.0223 Classification loss 0.4662 AP 0.8000 AR 0.1000
Epoch 194 batch 00007: Loss 0.4268 Regression loss 0.0212 Classification loss 0.4057 AP 0.6000 AR 0.0000
Epoch 194 batch 00008: Loss 0.3986 Regression loss 0.0193 Classification loss 0.3793 AP 0.4000 AR 0.2000
Epoch 194 batch 00009: Loss 0.5609 Regression loss 0.0187 Classification loss 0.5422 AP 1.0000 AR 0.2000
Epoch 194 batch 00010: Loss 0.3843 Regression loss 0.0219 Classification loss 0.3624 AP 0.8000 AR 0.0000
Epoch 195 batch 00001: Loss 0.4506 Regression loss 0.0194 Classification loss 0.4312 AP 1.0000 AR 0.0000
Epoch 195 batch 00002: Loss 0.3256 Regression loss 0.0185 Classification loss 0.3071 AP 0.8000 AR 0.0500
Epoch 195 batch 00003: Loss 0.4675 Regression loss 0.0166 Classification loss 0.4509 AP 0.4000 AR 0.0000
Epoch 195 batch 00004: Loss 0.4538 Regression loss 0.0151 Classification loss 0.4387 AP 0.6000 AR 0.0500
Epoch 195 batch 00005: Loss 0.3873 Regression loss 0.0219 Classification loss 0.3654 AP 0.6000 AR 0.2000
Epoch 195 batch 00006: Loss 0.4466 Regression loss 0.0179 Classification loss 0.4286 AP 0.4500 AR 0.0400
Epoch 195 batch 00007: Loss 0.3880 Regression loss 0.0172 Classification loss 0.3708 AP 0.6667 AR 0.1400
Epoch 195 batch 00008: Loss 0.4325 Regression loss 0.0251 Classification loss 0.4073 AP 0.8667 AR 0.1000
Epoch 195 batch 00009: Loss 0.3524 Regression loss 0.0218 Classification loss 0.3306 AP 0.6000 AR 0.2000
Epoch 195 batch 00010: Loss 0.5846 Regression loss 0.0234 Classification loss 0.5613 AP 1.0000 AR 0.0400
Epoch 196 batch 00001: Loss 0.4177 Regression loss 0.0198 Classification loss 0.3979 AP 0.6000 AR 0.1000
Epoch 196 batch 00002: Loss 0.4384 Regression loss 0.0219 Classification loss 0.4164 AP 0.6000 AR 0.0000
Epoch 196 batch 00003: Loss 0.5523 Regression loss 0.0230 Classification loss 0.5293 AP 0.8000 AR 0.0400
Epoch 196 batch 00004: Loss 0.3315 Regression loss 0.0137 Classification loss 0.3178 AP 0.7000 AR 0.0400
Epoch 196 batch 00005: Loss 0.3847 Regression loss 0.0215 Classification loss 0.3632 AP 0.4500 AR 0.0667
Epoch 196 batch 00006: Loss 0.3638 Regression loss 0.0183 Classification loss 0.3455 AP 0.7000 AR 0.2500
Epoch 196 batch 00007: Loss 0.4502 Regression loss 0.0177 Classification loss 0.4325 AP 0.6000 AR 0.0500
Epoch 196 batch 00008: Loss 0.4400 Regression loss 0.0216 Classification loss 0.4184 AP 0.6000 AR 0.0000
Epoch 196 batch 00009: Loss 0.4258 Regression loss 0.0202 Classification loss 0.4057 AP 0.6000 AR 0.2000
Epoch 196 batch 00010: Loss 0.5245 Regression loss 0.0193 Classification loss 0.5052 AP 0.8500 AR 0.0500
Epoch 197 batch 00001: Loss 0.3905 Regression loss 0.0205 Classification loss 0.3700 AP 0.4667 AR 0.1000
Epoch 197 batch 00002: Loss 0.5756 Regression loss 0.0211 Classification loss 0.5545 AP 1.0000 AR 0.2000
Epoch 197 batch 00003: Loss 0.3576 Regression loss 0.0191 Classification loss 0.3384 AP 0.2400 AR 0.0500
Epoch 197 batch 00004: Loss 0.4693 Regression loss 0.0192 Classification loss 0.4501 AP 0.4000 AR 0.0000
Epoch 197 batch 00005: Loss 0.3999 Regression loss 0.0186 Classification loss 0.3814 AP 0.9000 AR 0.0500
Epoch 197 batch 00006: Loss 0.3708 Regression loss 0.0190 Classification loss 0.3518 AP 0.6000 AR 0.0000
Epoch 197 batch 00007: Loss 0.4872 Regression loss 0.0183 Classification loss 0.4689 AP 0.8000 AR 0.0400
Epoch 197 batch 00008: Loss 0.4041 Regression loss 0.0216 Classification loss 0.3825 AP 0.4667 AR 0.0400
Epoch 197 batch 00009: Loss 0.4644 Regression loss 0.0209 Classification loss 0.4435 AP 0.6000 AR 0.1000
Epoch 197 batch 00010: Loss 0.4692 Regression loss 0.0209 Classification loss 0.4483 AP 0.6000 AR 0.2000
Epoch 198 batch 00001: Loss 0.3918 Regression loss 0.0211 Classification loss 0.3707 AP 0.4000 AR 0.0400
Epoch 198 batch 00002: Loss 0.5798 Regression loss 0.0208 Classification loss 0.5590 AP 0.8000 AR 0.0000
Epoch 198 batch 00003: Loss 0.3875 Regression loss 0.0210 Classification loss 0.3665 AP 0.4000 AR 0.0000
Epoch 198 batch 00004: Loss 0.4481 Regression loss 0.0192 Classification loss 0.4289 AP 0.6000 AR 0.2000
Epoch 198 batch 00005: Loss 0.4809 Regression loss 0.0215 Classification loss 0.4594 AP 1.0000 AR 0.2000
Epoch 198 batch 00006: Loss 0.5192 Regression loss 0.0247 Classification loss 0.4945 AP 0.8000 AR 0.1000
Epoch 198 batch 00007: Loss 0.4732 Regression loss 0.0242 Classification loss 0.4490 AP 0.7167 AR 0.1500
Epoch 198 batch 00008: Loss 0.3852 Regression loss 0.0162 Classification loss 0.3690 AP 0.5000 AR 0.0500
Epoch 198 batch 00009: Loss 0.4006 Regression loss 0.0177 Classification loss 0.3829 AP 0.2000 AR 0.0000
Epoch 198 batch 00010: Loss 0.2657 Regression loss 0.0146 Classification loss 0.2512 AP 0.4000 AR 0.0000
Epoch 199 batch 00001: Loss 0.4166 Regression loss 0.0167 Classification loss 0.3999 AP 0.4000 AR 0.0000
Epoch 199 batch 00002: Loss 0.4310 Regression loss 0.0218 Classification loss 0.4092 AP 0.4000 AR 0.0000
Epoch 199 batch 00003: Loss 0.2657 Regression loss 0.0164 Classification loss 0.2493 AP 0.8000 AR 0.0500
Epoch 199 batch 00004: Loss 0.4708 Regression loss 0.0226 Classification loss 0.4482 AP 0.8000 AR 0.0000
Epoch 199 batch 00005: Loss 0.4567 Regression loss 0.0219 Classification loss 0.4348 AP 0.7000 AR 0.2400
Epoch 199 batch 00006: Loss 0.4665 Regression loss 0.0224 Classification loss 0.4441 AP 0.8000 AR 0.0000
Epoch 199 batch 00007: Loss 0.5612 Regression loss 0.0148 Classification loss 0.5464 AP 0.4000 AR 0.2000
Epoch 199 batch 00008: Loss 0.3932 Regression loss 0.0209 Classification loss 0.3723 AP 0.2667 AR 0.1000
Epoch 199 batch 00009: Loss 0.4240 Regression loss 0.0186 Classification loss 0.4055 AP 0.8000 AR 0.1000
Epoch 199 batch 00010: Loss 0.5949 Regression loss 0.0258 Classification loss 0.5692 AP 1.0000 AR 0.0000
Epoch 200 batch 00001: Loss 0.4734 Regression loss 0.0209 Classification loss 0.4524 AP 0.6000 AR 0.0400
Epoch 200 batch 00002: Loss 0.5045 Regression loss 0.0168 Classification loss 0.4877 AP 0.4000 AR 0.0000
Epoch 200 batch 00003: Loss 0.4017 Regression loss 0.0176 Classification loss 0.3842 AP 0.8667 AR 0.3000
Epoch 200 batch 00004: Loss 0.3473 Regression loss 0.0185 Classification loss 0.3288 AP 0.6667 AR 0.3500
Epoch 200 batch 00005: Loss 0.4387 Regression loss 0.0252 Classification loss 0.4135 AP 0.8000 AR 0.0000
Epoch 200 batch 00006: Loss 0.3894 Regression loss 0.0149 Classification loss 0.3745 AP 0.4000 AR 0.0000
Epoch 200 batch 00007: Loss 0.4169 Regression loss 0.0191 Classification loss 0.3978 AP 0.7000 AR 0.0800
Epoch 200 batch 00008: Loss 0.3711 Regression loss 0.0177 Classification loss 0.3534 AP 0.6000 AR 0.1000
Epoch 200 batch 00009: Loss 0.4162 Regression loss 0.0229 Classification loss 0.3933 AP 0.6000 AR 0.0000
Epoch 200 batch 00010: Loss 0.4422 Regression loss 0.0228 Classification loss 0.4194 AP 0.6000 AR 0.0000
Epoch 201 batch 00001: Loss 0.3573 Regression loss 0.0210 Classification loss 0.3363 AP 0.6000 AR 0.0000
Epoch 201 batch 00002: Loss 0.3759 Regression loss 0.0210 Classification loss 0.3550 AP 0.9000 AR 0.1000
Epoch 201 batch 00003: Loss 0.4153 Regression loss 0.0194 Classification loss 0.3959 AP 0.4000 AR 0.0000
Epoch 201 batch 00004: Loss 0.3091 Regression loss 0.0187 Classification loss 0.2904 AP 0.2000 AR 0.0000
Epoch 201 batch 00005: Loss 0.6369 Regression loss 0.0233 Classification loss 0.6135 AP 1.0000 AR 0.2400
Epoch 201 batch 00006: Loss 0.4561 Regression loss 0.0196 Classification loss 0.4365 AP 0.4500 AR 0.0500
Epoch 201 batch 00007: Loss 0.4529 Regression loss 0.0225 Classification loss 0.4304 AP 0.4000 AR 0.0000
Epoch 201 batch 00008: Loss 0.5219 Regression loss 0.0246 Classification loss 0.4972 AP 0.6000 AR 0.0000
Epoch 201 batch 00009: Loss 0.3201 Regression loss 0.0208 Classification loss 0.2992 AP 0.4000 AR 0.0000
Epoch 201 batch 00010: Loss 0.4877 Regression loss 0.0148 Classification loss 0.4729 AP 0.6000 AR 0.2000
Epoch 202 batch 00001: Loss 0.5206 Regression loss 0.0172 Classification loss 0.5034 AP 1.0000 AR 0.2000
Epoch 202 batch 00002: Loss 0.4353 Regression loss 0.0198 Classification loss 0.4155 AP 0.6000 AR 0.0000
Epoch 202 batch 00003: Loss 0.4115 Regression loss 0.0235 Classification loss 0.3880 AP 0.6000 AR 0.0400
Epoch 202 batch 00004: Loss 0.3620 Regression loss 0.0189 Classification loss 0.3431 AP 0.8000 AR 0.0000
Epoch 202 batch 00005: Loss 0.3979 Regression loss 0.0204 Classification loss 0.3774 AP 0.3500 AR 0.1000
Epoch 202 batch 00006: Loss 0.4321 Regression loss 0.0239 Classification loss 0.4082 AP 0.8000 AR 0.0000
Epoch 202 batch 00007: Loss 0.4615 Regression loss 0.0206 Classification loss 0.4410 AP 0.6500 AR 0.0400
Epoch 202 batch 00008: Loss 0.5151 Regression loss 0.0169 Classification loss 0.4982 AP 0.4000 AR 0.1000
Epoch 202 batch 00009: Loss 0.5817 Regression loss 0.0152 Classification loss 0.5665 AP 1.0000 AR 0.2500
Epoch 202 batch 00010: Loss 0.2092 Regression loss 0.0154 Classification loss 0.1938 AP 0.4667 AR 0.1000
Epoch 203 batch 00001: Loss 0.3829 Regression loss 0.0183 Classification loss 0.3646 AP 0.6000 AR 0.0000
Epoch 203 batch 00002: Loss 0.5092 Regression loss 0.0172 Classification loss 0.4920 AP 0.8000 AR 0.0000
Epoch 203 batch 00003: Loss 0.2898 Regression loss 0.0174 Classification loss 0.2724 AP 0.6000 AR 0.2000
Epoch 203 batch 00004: Loss 0.4702 Regression loss 0.0210 Classification loss 0.4492 AP 0.6667 AR 0.2800
Epoch 203 batch 00005: Loss 0.4688 Regression loss 0.0216 Classification loss 0.4472 AP 0.6000 AR 0.1000
Epoch 203 batch 00006: Loss 0.4560 Regression loss 0.0217 Classification loss 0.4343 AP 0.6000 AR 0.0000
Epoch 203 batch 00007: Loss 0.6391 Regression loss 0.0184 Classification loss 0.6207 AP 0.4000 AR 0.0000
Epoch 203 batch 00008: Loss 0.4288 Regression loss 0.0220 Classification loss 0.4069 AP 0.8000 AR 0.0000
Epoch 203 batch 00009: Loss 0.4808 Regression loss 0.0180 Classification loss 0.4629 AP 0.6000 AR 0.0500
Epoch 203 batch 00010: Loss 0.4883 Regression loss 0.0206 Classification loss 0.4677 AP 0.7000 AR 0.1000
Epoch 204 batch 00001: Loss 0.3996 Regression loss 0.0216 Classification loss 0.3780 AP 1.0000 AR 0.0500
Epoch 204 batch 00002: Loss 0.5001 Regression loss 0.0172 Classification loss 0.4828 AP 0.4000 AR 0.0000
Epoch 204 batch 00003: Loss 0.3832 Regression loss 0.0169 Classification loss 0.3663 AP 0.4000 AR 0.0000
Epoch 204 batch 00004: Loss 0.5081 Regression loss 0.0243 Classification loss 0.4839 AP 0.8500 AR 0.0400
Epoch 204 batch 00005: Loss 0.3589 Regression loss 0.0205 Classification loss 0.3384 AP 0.6667 AR 0.2400
Epoch 204 batch 00006: Loss 0.3364 Regression loss 0.0217 Classification loss 0.3146 AP 0.5000 AR 0.0400
Epoch 204 batch 00007: Loss 0.6455 Regression loss 0.0195 Classification loss 0.6260 AP 0.8000 AR 0.2000
Epoch 204 batch 00008: Loss 0.4261 Regression loss 0.0188 Classification loss 0.4073 AP 0.6000 AR 0.1000
Epoch 204 batch 00009: Loss 0.5011 Regression loss 0.0157 Classification loss 0.4855 AP 0.4500 AR 0.0500
Epoch 204 batch 00010: Loss 0.3913 Regression loss 0.0207 Classification loss 0.3706 AP 0.6000 AR 0.0000
Epoch 205 batch 00001: Loss 0.3099 Regression loss 0.0140 Classification loss 0.2959 AP 0.6000 AR 0.1000
Epoch 205 batch 00002: Loss 0.5459 Regression loss 0.0155 Classification loss 0.5304 AP 0.8000 AR 0.2500
Epoch 205 batch 00003: Loss 0.2965 Regression loss 0.0162 Classification loss 0.2802 AP 0.1667 AR 0.1400
Epoch 205 batch 00004: Loss 0.4801 Regression loss 0.0239 Classification loss 0.4562 AP 0.6000 AR 0.0000
Epoch 205 batch 00005: Loss 0.4877 Regression loss 0.0213 Classification loss 0.4663 AP 0.6000 AR 0.1000
Epoch 205 batch 00006: Loss 0.3058 Regression loss 0.0200 Classification loss 0.2858 AP 0.7000 AR 0.0500
Epoch 205 batch 00007: Loss 0.4129 Regression loss 0.0221 Classification loss 0.3907 AP 0.6000 AR 0.2000
Epoch 205 batch 00008: Loss 0.4792 Regression loss 0.0206 Classification loss 0.4585 AP 0.6000 AR 0.0000
Epoch 205 batch 00009: Loss 0.4583 Regression loss 0.0211 Classification loss 0.4372 AP 0.4400 AR 0.0500
Epoch 205 batch 00010: Loss 0.5548 Regression loss 0.0211 Classification loss 0.5337 AP 0.8000 AR 0.0000
Epoch 206 batch 00001: Loss 0.4288 Regression loss 0.0139 Classification loss 0.4148 AP 0.5000 AR 0.0500
Epoch 206 batch 00002: Loss 0.4170 Regression loss 0.0197 Classification loss 0.3974 AP 0.6667 AR 0.1067
Epoch 206 batch 00003: Loss 0.3558 Regression loss 0.0221 Classification loss 0.3337 AP 0.0000 AR 0.0000
Epoch 206 batch 00004: Loss 0.4116 Regression loss 0.0203 Classification loss 0.3913 AP 0.4000 AR 0.0000
Epoch 206 batch 00005: Loss 0.5150 Regression loss 0.0187 Classification loss 0.4963 AP 0.7000 AR 0.1000
Epoch 206 batch 00006: Loss 0.3886 Regression loss 0.0217 Classification loss 0.3669 AP 0.6000 AR 0.0000
Epoch 206 batch 00007: Loss 0.5848 Regression loss 0.0246 Classification loss 0.5602 AP 1.0000 AR 0.2000
Epoch 206 batch 00008: Loss 0.2786 Regression loss 0.0159 Classification loss 0.2627 AP 0.8000 AR 0.2500
Epoch 206 batch 00009: Loss 0.4214 Regression loss 0.0204 Classification loss 0.4010 AP 0.4000 AR 0.0000
Epoch 206 batch 00010: Loss 0.5236 Regression loss 0.0218 Classification loss 0.5018 AP 0.8000 AR 0.0000
Epoch 207 batch 00001: Loss 0.4747 Regression loss 0.0197 Classification loss 0.4550 AP 0.2000 AR 0.0000
Epoch 207 batch 00002: Loss 0.4513 Regression loss 0.0219 Classification loss 0.4294 AP 0.6667 AR 0.0400
Epoch 207 batch 00003: Loss 0.4680 Regression loss 0.0197 Classification loss 0.4483 AP 0.6000 AR 0.0000
Epoch 207 batch 00004: Loss 0.5515 Regression loss 0.0211 Classification loss 0.5304 AP 0.8000 AR 0.0400
Epoch 207 batch 00005: Loss 0.2894 Regression loss 0.0155 Classification loss 0.2739 AP 0.7000 AR 0.1000
Epoch 207 batch 00006: Loss 0.3193 Regression loss 0.0233 Classification loss 0.2960 AP 0.8000 AR 0.2000
Epoch 207 batch 00007: Loss 0.3993 Regression loss 0.0192 Classification loss 0.3801 AP 0.6500 AR 0.2500
Epoch 207 batch 00008: Loss 0.4661 Regression loss 0.0269 Classification loss 0.4392 AP 0.8000 AR 0.1000
Epoch 207 batch 00009: Loss 0.4137 Regression loss 0.0188 Classification loss 0.3949 AP 0.3000 AR 0.0500
Epoch 207 batch 00010: Loss 0.3444 Regression loss 0.0158 Classification loss 0.3286 AP 0.5000 AR 0.0400
Epoch 208 batch 00001: Loss 0.3941 Regression loss 0.0186 Classification loss 0.3755 AP 0.2000 AR 0.0000
Epoch 208 batch 00002: Loss 0.4280 Regression loss 0.0205 Classification loss 0.4075 AP 0.7000 AR 0.1400
Epoch 208 batch 00003: Loss 0.4086 Regression loss 0.0145 Classification loss 0.3941 AP 0.6500 AR 0.0667
Epoch 208 batch 00004: Loss 0.4460 Regression loss 0.0214 Classification loss 0.4247 AP 0.7000 AR 0.0500
Epoch 208 batch 00005: Loss 0.3908 Regression loss 0.0188 Classification loss 0.3720 AP 0.6500 AR 0.0500
Epoch 208 batch 00006: Loss 0.5351 Regression loss 0.0266 Classification loss 0.5085 AP 0.6000 AR 0.0000
Epoch 208 batch 00007: Loss 0.3783 Regression loss 0.0219 Classification loss 0.3565 AP 0.6000 AR 0.0000
Epoch 208 batch 00008: Loss 0.4301 Regression loss 0.0237 Classification loss 0.4064 AP 0.9000 AR 0.0500
Epoch 208 batch 00009: Loss 0.4124 Regression loss 0.0180 Classification loss 0.3944 AP 0.5333 AR 0.2800
Epoch 208 batch 00010: Loss 0.3963 Regression loss 0.0185 Classification loss 0.3778 AP 0.4000 AR 0.2000
Epoch 209 batch 00001: Loss 0.4039 Regression loss 0.0183 Classification loss 0.3856 AP 0.4000 AR 0.0000
Epoch 209 batch 00002: Loss 0.4343 Regression loss 0.0231 Classification loss 0.4112 AP 0.6000 AR 0.0000
Epoch 209 batch 00003: Loss 0.4659 Regression loss 0.0137 Classification loss 0.4522 AP 0.7000 AR 0.0500
Epoch 209 batch 00004: Loss 0.4299 Regression loss 0.0186 Classification loss 0.4112 AP 0.4000 AR 0.0000
Epoch 209 batch 00005: Loss 0.4954 Regression loss 0.0196 Classification loss 0.4757 AP 0.8000 AR 0.0400
Epoch 209 batch 00006: Loss 0.3028 Regression loss 0.0162 Classification loss 0.2866 AP 0.2667 AR 0.2400
Epoch 209 batch 00007: Loss 0.3888 Regression loss 0.0240 Classification loss 0.3647 AP 0.8500 AR 0.1000
Epoch 209 batch 00008: Loss 0.3593 Regression loss 0.0195 Classification loss 0.3398 AP 0.8000 AR 0.0000
Epoch 209 batch 00009: Loss 0.5474 Regression loss 0.0202 Classification loss 0.5271 AP 0.7000 AR 0.1000
Epoch 209 batch 00010: Loss 0.3510 Regression loss 0.0210 Classification loss 0.3300 AP 0.6000 AR 0.2000
Epoch 210 batch 00001: Loss 0.4658 Regression loss 0.0189 Classification loss 0.4469 AP 0.6500 AR 0.0500
Epoch 210 batch 00002: Loss 0.3234 Regression loss 0.0161 Classification loss 0.3073 AP 0.4000 AR 0.0000
Epoch 210 batch 00003: Loss 0.3492 Regression loss 0.0175 Classification loss 0.3318 AP 0.6000 AR 0.1000
Epoch 210 batch 00004: Loss 0.5820 Regression loss 0.0208 Classification loss 0.5613 AP 0.6000 AR 0.2400
Epoch 210 batch 00005: Loss 0.4546 Regression loss 0.0189 Classification loss 0.4357 AP 0.6000 AR 0.2000
Epoch 210 batch 00006: Loss 0.5024 Regression loss 0.0238 Classification loss 0.4786 AP 0.6000 AR 0.0000
Epoch 210 batch 00007: Loss 0.3890 Regression loss 0.0217 Classification loss 0.3673 AP 0.4000 AR 0.0000
Epoch 210 batch 00008: Loss 0.3626 Regression loss 0.0216 Classification loss 0.3411 AP 0.5000 AR 0.0500
Epoch 210 batch 00009: Loss 0.5315 Regression loss 0.0218 Classification loss 0.5097 AP 0.6000 AR 0.0000
Epoch 210 batch 00010: Loss 0.3882 Regression loss 0.0164 Classification loss 0.3717 AP 0.5000 AR 0.0400
Epoch 211 batch 00001: Loss 0.5053 Regression loss 0.0197 Classification loss 0.4857 AP 0.4667 AR 0.0500
Epoch 211 batch 00002: Loss 0.4449 Regression loss 0.0213 Classification loss 0.4236 AP 0.6000 AR 0.1000
Epoch 211 batch 00003: Loss 0.3637 Regression loss 0.0189 Classification loss 0.3448 AP 0.2000 AR 0.0000
Epoch 211 batch 00004: Loss 0.4962 Regression loss 0.0206 Classification loss 0.4756 AP 0.8000 AR 0.0000
Epoch 211 batch 00005: Loss 0.5032 Regression loss 0.0231 Classification loss 0.4801 AP 0.6000 AR 0.0000
Epoch 211 batch 00006: Loss 0.2997 Regression loss 0.0192 Classification loss 0.2805 AP 0.2000 AR 0.0500
Epoch 211 batch 00007: Loss 0.3560 Regression loss 0.0196 Classification loss 0.3364 AP 0.6000 AR 0.0000
Epoch 211 batch 00008: Loss 0.4475 Regression loss 0.0222 Classification loss 0.4253 AP 0.8000 AR 0.2000
Epoch 211 batch 00009: Loss 0.4628 Regression loss 0.0217 Classification loss 0.4411 AP 0.6000 AR 0.0000
Epoch 211 batch 00010: Loss 0.5297 Regression loss 0.0136 Classification loss 0.5161 AP 0.7000 AR 0.2500
Epoch 212 batch 00001: Loss 0.4230 Regression loss 0.0184 Classification loss 0.4046 AP 0.4000 AR 0.0000
Epoch 212 batch 00002: Loss 0.4912 Regression loss 0.0201 Classification loss 0.4711 AP 0.8000 AR 0.0000
Epoch 212 batch 00003: Loss 0.3439 Regression loss 0.0202 Classification loss 0.3237 AP 0.4833 AR 0.1667
Epoch 212 batch 00004: Loss 0.4912 Regression loss 0.0236 Classification loss 0.4676 AP 0.6000 AR 0.0000
Epoch 212 batch 00005: Loss 0.3395 Regression loss 0.0174 Classification loss 0.3221 AP 0.8000 AR 0.0500
Epoch 212 batch 00006: Loss 0.4822 Regression loss 0.0221 Classification loss 0.4601 AP 0.7000 AR 0.2400
Epoch 212 batch 00007: Loss 0.4135 Regression loss 0.0153 Classification loss 0.3982 AP 0.6000 AR 0.1000
Epoch 212 batch 00008: Loss 0.4044 Regression loss 0.0155 Classification loss 0.3889 AP 0.6000 AR 0.2000
Epoch 212 batch 00009: Loss 0.3777 Regression loss 0.0199 Classification loss 0.3578 AP 0.4000 AR 0.0000
Epoch 212 batch 00010: Loss 0.4509 Regression loss 0.0192 Classification loss 0.4317 AP 0.7000 AR 0.1400
Epoch 213 batch 00001: Loss 0.4879 Regression loss 0.0166 Classification loss 0.4713 AP 0.6000 AR 0.0000
Epoch 213 batch 00002: Loss 0.3976 Regression loss 0.0208 Classification loss 0.3769 AP 0.4000 AR 0.0500
Epoch 213 batch 00003: Loss 0.4204 Regression loss 0.0137 Classification loss 0.4067 AP 0.5000 AR 0.1000
Epoch 213 batch 00004: Loss 0.4292 Regression loss 0.0191 Classification loss 0.4101 AP 0.6000 AR 0.1000
Epoch 213 batch 00005: Loss 0.4328 Regression loss 0.0194 Classification loss 0.4134 AP 0.6000 AR 0.2000
Epoch 213 batch 00006: Loss 0.4254 Regression loss 0.0215 Classification loss 0.4039 AP 0.4000 AR 0.0000
Epoch 213 batch 00007: Loss 0.3750 Regression loss 0.0184 Classification loss 0.3566 AP 0.6000 AR 0.2000
Epoch 213 batch 00008: Loss 0.4441 Regression loss 0.0234 Classification loss 0.4207 AP 0.8000 AR 0.0000
Epoch 213 batch 00009: Loss 0.3878 Regression loss 0.0133 Classification loss 0.3745 AP 0.7000 AR 0.1400
Epoch 213 batch 00010: Loss 0.4489 Regression loss 0.0227 Classification loss 0.4262 AP 0.8000 AR 0.0000
Epoch 214 batch 00001: Loss 0.3642 Regression loss 0.0178 Classification loss 0.3464 AP 0.4000 AR 0.2000
Epoch 214 batch 00002: Loss 0.5247 Regression loss 0.0183 Classification loss 0.5064 AP 0.5000 AR 0.0500
Epoch 214 batch 00003: Loss 0.3668 Regression loss 0.0170 Classification loss 0.3498 AP 0.5000 AR 0.0800
Epoch 214 batch 00004: Loss 0.4016 Regression loss 0.0179 Classification loss 0.3837 AP 0.6000 AR 0.0000
Epoch 214 batch 00005: Loss 0.4239 Regression loss 0.0193 Classification loss 0.4046 AP 0.6000 AR 0.0000
Epoch 214 batch 00006: Loss 0.5357 Regression loss 0.0245 Classification loss 0.5112 AP 1.0000 AR 0.3000
Epoch 214 batch 00007: Loss 0.5037 Regression loss 0.0219 Classification loss 0.4818 AP 0.4000 AR 0.0000
Epoch 214 batch 00008: Loss 0.3645 Regression loss 0.0212 Classification loss 0.3434 AP 0.4500 AR 0.0667
Epoch 214 batch 00009: Loss 0.3750 Regression loss 0.0214 Classification loss 0.3537 AP 0.7000 AR 0.0500
Epoch 214 batch 00010: Loss 0.3925 Regression loss 0.0174 Classification loss 0.3751 AP 0.2000 AR 0.0000
Epoch 215 batch 00001: Loss 0.4193 Regression loss 0.0245 Classification loss 0.3948 AP 0.6000 AR 0.0000
Epoch 215 batch 00002: Loss 0.3583 Regression loss 0.0186 Classification loss 0.3397 AP 0.3000 AR 0.0500
Epoch 215 batch 00003: Loss 0.4379 Regression loss 0.0222 Classification loss 0.4156 AP 0.4500 AR 0.0667
Epoch 215 batch 00004: Loss 0.5150 Regression loss 0.0236 Classification loss 0.4914 AP 1.0000 AR 0.0000
Epoch 215 batch 00005: Loss 0.4407 Regression loss 0.0185 Classification loss 0.4222 AP 0.6000 AR 0.0000
Epoch 215 batch 00006: Loss 0.4179 Regression loss 0.0176 Classification loss 0.4003 AP 0.5333 AR 0.1500
Epoch 215 batch 00007: Loss 0.2264 Regression loss 0.0138 Classification loss 0.2126 AP 1.0000 AR 0.0400
Epoch 215 batch 00008: Loss 0.4405 Regression loss 0.0182 Classification loss 0.4223 AP 0.4000 AR 0.1000
Epoch 215 batch 00009: Loss 0.4719 Regression loss 0.0150 Classification loss 0.4569 AP 0.5000 AR 0.2667
Epoch 215 batch 00010: Loss 0.3863 Regression loss 0.0204 Classification loss 0.3659 AP 0.6000 AR 0.2000
Epoch 216 batch 00001: Loss 0.4618 Regression loss 0.0165 Classification loss 0.4453 AP 0.4000 AR 0.0000
Epoch 216 batch 00002: Loss 0.5059 Regression loss 0.0176 Classification loss 0.4883 AP 0.6000 AR 0.0400
Epoch 216 batch 00003: Loss 0.2995 Regression loss 0.0192 Classification loss 0.2802 AP 0.5000 AR 0.0800
Epoch 216 batch 00004: Loss 0.4050 Regression loss 0.0200 Classification loss 0.3850 AP 0.4000 AR 0.0000
Epoch 216 batch 00005: Loss 0.4079 Regression loss 0.0194 Classification loss 0.3885 AP 0.5000 AR 0.1167
Epoch 216 batch 00006: Loss 0.4209 Regression loss 0.0213 Classification loss 0.3995 AP 0.6000 AR 0.0000
Epoch 216 batch 00007: Loss 0.3387 Regression loss 0.0197 Classification loss 0.3190 AP 0.5000 AR 0.0500
Epoch 216 batch 00008: Loss 0.5679 Regression loss 0.0239 Classification loss 0.5440 AP 1.0000 AR 0.3000
Epoch 216 batch 00009: Loss 0.4249 Regression loss 0.0199 Classification loss 0.4051 AP 0.4500 AR 0.1000
Epoch 216 batch 00010: Loss 0.3826 Regression loss 0.0184 Classification loss 0.3642 AP 0.6000 AR 0.2000
Epoch 217 batch 00001: Loss 0.4006 Regression loss 0.0215 Classification loss 0.3791 AP 0.4000 AR 0.1000
Epoch 217 batch 00002: Loss 0.3725 Regression loss 0.0198 Classification loss 0.3527 AP 0.6000 AR 0.0000
Epoch 217 batch 00003: Loss 0.4286 Regression loss 0.0180 Classification loss 0.4106 AP 0.2667 AR 0.0400
Epoch 217 batch 00004: Loss 0.4604 Regression loss 0.0196 Classification loss 0.4408 AP 0.8667 AR 0.1000
Epoch 217 batch 00005: Loss 0.4268 Regression loss 0.0189 Classification loss 0.4079 AP 0.8000 AR 0.0000
Epoch 217 batch 00006: Loss 0.5431 Regression loss 0.0183 Classification loss 0.5248 AP 0.8000 AR 0.0000
Epoch 217 batch 00007: Loss 0.5182 Regression loss 0.0218 Classification loss 0.4964 AP 0.8000 AR 0.2000
Epoch 217 batch 00008: Loss 0.3749 Regression loss 0.0122 Classification loss 0.3628 AP 0.5000 AR 0.0400
Epoch 217 batch 00009: Loss 0.3535 Regression loss 0.0219 Classification loss 0.3316 AP 0.4500 AR 0.0667
Epoch 217 batch 00010: Loss 0.4158 Regression loss 0.0225 Classification loss 0.3933 AP 0.8667 AR 0.2800
Epoch 218 batch 00001: Loss 0.4190 Regression loss 0.0202 Classification loss 0.3988 AP 0.7000 AR 0.0500
Epoch 218 batch 00002: Loss 0.5003 Regression loss 0.0200 Classification loss 0.4803 AP 0.6000 AR 0.0000
Epoch 218 batch 00003: Loss 0.3807 Regression loss 0.0241 Classification loss 0.3566 AP 0.5000 AR 0.0400
Epoch 218 batch 00004: Loss 0.5649 Regression loss 0.0175 Classification loss 0.5474 AP 1.0000 AR 0.0000
Epoch 218 batch 00005: Loss 0.4216 Regression loss 0.0220 Classification loss 0.3995 AP 0.5333 AR 0.1900
Epoch 218 batch 00006: Loss 0.4676 Regression loss 0.0185 Classification loss 0.4490 AP 0.4000 AR 0.0000
Epoch 218 batch 00007: Loss 0.3749 Regression loss 0.0205 Classification loss 0.3544 AP 0.5000 AR 0.0400
Epoch 218 batch 00008: Loss 0.3697 Regression loss 0.0165 Classification loss 0.3532 AP 0.2000 AR 0.0000
Epoch 218 batch 00009: Loss 0.3269 Regression loss 0.0135 Classification loss 0.3135 AP 0.1000 AR 0.0800
Epoch 218 batch 00010: Loss 0.5216 Regression loss 0.0206 Classification loss 0.5010 AP 0.8000 AR 0.4000
Epoch 219 batch 00001: Loss 0.5141 Regression loss 0.0164 Classification loss 0.4977 AP 0.8000 AR 0.1000
Epoch 219 batch 00002: Loss 0.5289 Regression loss 0.0209 Classification loss 0.5079 AP 0.6000 AR 0.0000
Epoch 219 batch 00003: Loss 0.4617 Regression loss 0.0169 Classification loss 0.4448 AP 0.4000 AR 0.0000
Epoch 219 batch 00004: Loss 0.3256 Regression loss 0.0193 Classification loss 0.3063 AP 0.6000 AR 0.0000
Epoch 219 batch 00005: Loss 0.5208 Regression loss 0.0175 Classification loss 0.5033 AP 0.6333 AR 0.0500
Epoch 219 batch 00006: Loss 0.5087 Regression loss 0.0243 Classification loss 0.4843 AP 0.4667 AR 0.0400
Epoch 219 batch 00007: Loss 0.5146 Regression loss 0.0211 Classification loss 0.4935 AP 0.4333 AR 0.2400
Epoch 219 batch 00008: Loss 0.1986 Regression loss 0.0165 Classification loss 0.1822 AP 0.4000 AR 0.3300
Epoch 219 batch 00009: Loss 0.4504 Regression loss 0.0166 Classification loss 0.4338 AP 0.7000 AR 0.0500
Epoch 219 batch 00010: Loss 0.5899 Regression loss 0.0274 Classification loss 0.5625 AP 0.8000 AR 0.0000
Epoch 220 batch 00001: Loss 0.4968 Regression loss 0.0224 Classification loss 0.4744 AP 0.8000 AR 0.0000
Epoch 220 batch 00002: Loss 0.4030 Regression loss 0.0231 Classification loss 0.3799 AP 0.8000 AR 0.2000
Epoch 220 batch 00003: Loss 0.4250 Regression loss 0.0200 Classification loss 0.4051 AP 0.2000 AR 0.0800
Epoch 220 batch 00004: Loss 0.5275 Regression loss 0.0224 Classification loss 0.5051 AP 0.8000 AR 0.0000
Epoch 220 batch 00005: Loss 0.6391 Regression loss 0.0188 Classification loss 0.6203 AP 0.8000 AR 0.0000
Epoch 220 batch 00006: Loss 0.4135 Regression loss 0.0143 Classification loss 0.3992 AP 0.4000 AR 0.0000
Epoch 220 batch 00007: Loss 0.4927 Regression loss 0.0237 Classification loss 0.4690 AP 0.9000 AR 0.1000
Epoch 220 batch 00008: Loss 0.4115 Regression loss 0.0202 Classification loss 0.3914 AP 0.2000 AR 0.0000
Epoch 220 batch 00009: Loss 0.4659 Regression loss 0.0258 Classification loss 0.4402 AP 1.0000 AR 0.0000
Epoch 220 batch 00010: Loss 0.3667 Regression loss 0.0173 Classification loss 0.3493 AP 0.6000 AR 0.1000
Epoch 221 batch 00001: Loss 0.4357 Regression loss 0.0228 Classification loss 0.4129 AP 0.4400 AR 0.0500
Epoch 221 batch 00002: Loss 0.2988 Regression loss 0.0148 Classification loss 0.2840 AP 0.4667 AR 0.0400
Epoch 221 batch 00003: Loss 0.3319 Regression loss 0.0171 Classification loss 0.3148 AP 0.4000 AR 0.2000
Epoch 221 batch 00004: Loss 0.3506 Regression loss 0.0175 Classification loss 0.3331 AP 0.0000 AR 0.0000
Epoch 221 batch 00005: Loss 0.4668 Regression loss 0.0201 Classification loss 0.4467 AP 0.6000 AR 0.0500
Epoch 221 batch 00006: Loss 0.3793 Regression loss 0.0200 Classification loss 0.3592 AP 0.7000 AR 0.2400
Epoch 221 batch 00007: Loss 0.5772 Regression loss 0.0232 Classification loss 0.5541 AP 0.6000 AR 0.0000
Epoch 221 batch 00008: Loss 0.4892 Regression loss 0.0229 Classification loss 0.4663 AP 0.4000 AR 0.0000
Epoch 221 batch 00009: Loss 0.4399 Regression loss 0.0222 Classification loss 0.4178 AP 0.4667 AR 0.1000
Epoch 221 batch 00010: Loss 0.5203 Regression loss 0.0213 Classification loss 0.4990 AP 0.8000 AR 0.0400
Epoch 222 batch 00001: Loss 0.3459 Regression loss 0.0179 Classification loss 0.3280 AP 0.8000 AR 0.1300
Epoch 222 batch 00002: Loss 0.4590 Regression loss 0.0164 Classification loss 0.4427 AP 0.6000 AR 0.0000
Epoch 222 batch 00003: Loss 0.3925 Regression loss 0.0192 Classification loss 0.3734 AP 0.6000 AR 0.4000
Epoch 222 batch 00004: Loss 0.5618 Regression loss 0.0203 Classification loss 0.5415 AP 1.0000 AR 0.0000
Epoch 222 batch 00005: Loss 0.4163 Regression loss 0.0192 Classification loss 0.3971 AP 0.8000 AR 0.0000
Epoch 222 batch 00006: Loss 0.4748 Regression loss 0.0205 Classification loss 0.4543 AP 0.4000 AR 0.0000
Epoch 222 batch 00007: Loss 0.4654 Regression loss 0.0168 Classification loss 0.4487 AP 0.4000 AR 0.0000
Epoch 222 batch 00008: Loss 0.3835 Regression loss 0.0200 Classification loss 0.3635 AP 0.6000 AR 0.0500
Epoch 222 batch 00009: Loss 0.4907 Regression loss 0.0243 Classification loss 0.4664 AP 0.5000 AR 0.0400
Epoch 222 batch 00010: Loss 0.4505 Regression loss 0.0198 Classification loss 0.4306 AP 0.6722 AR 0.0900
Epoch 223 batch 00001: Loss 0.3785 Regression loss 0.0174 Classification loss 0.3612 AP 0.6800 AR 0.3000
Epoch 223 batch 00002: Loss 0.4421 Regression loss 0.0255 Classification loss 0.4166 AP 0.8000 AR 0.3000
Epoch 223 batch 00003: Loss 0.4856 Regression loss 0.0181 Classification loss 0.4676 AP 0.7000 AR 0.1000
Epoch 223 batch 00004: Loss 0.4527 Regression loss 0.0180 Classification loss 0.4347 AP 0.6000 AR 0.0400
Epoch 223 batch 00005: Loss 0.3813 Regression loss 0.0188 Classification loss 0.3625 AP 0.7000 AR 0.0500
Epoch 223 batch 00006: Loss 0.4500 Regression loss 0.0178 Classification loss 0.4323 AP 0.4000 AR 0.0000
Epoch 223 batch 00007: Loss 0.3779 Regression loss 0.0171 Classification loss 0.3609 AP 0.3000 AR 0.0400
Epoch 223 batch 00008: Loss 0.4386 Regression loss 0.0201 Classification loss 0.4185 AP 0.6286 AR 0.0500
Epoch 223 batch 00009: Loss 0.5482 Regression loss 0.0259 Classification loss 0.5223 AP 0.6000 AR 0.0000
Epoch 223 batch 00010: Loss 0.3529 Regression loss 0.0170 Classification loss 0.3360 AP 0.0000 AR 0.0000
Epoch 224 batch 00001: Loss 0.4540 Regression loss 0.0148 Classification loss 0.4392 AP 0.7000 AR 0.2500
Epoch 224 batch 00002: Loss 0.4264 Regression loss 0.0187 Classification loss 0.4076 AP 0.6000 AR 0.0000
Epoch 224 batch 00003: Loss 0.4358 Regression loss 0.0243 Classification loss 0.4114 AP 0.6000 AR 0.0000
Epoch 224 batch 00004: Loss 0.5333 Regression loss 0.0165 Classification loss 0.5168 AP 0.6000 AR 0.0000
Epoch 224 batch 00005: Loss 0.3486 Regression loss 0.0186 Classification loss 0.3299 AP 0.5500 AR 0.1167
Epoch 224 batch 00006: Loss 0.5008 Regression loss 0.0290 Classification loss 0.4718 AP 1.0000 AR 0.2000
Epoch 224 batch 00007: Loss 0.3628 Regression loss 0.0186 Classification loss 0.3442 AP 0.2000 AR 0.0000
Epoch 224 batch 00008: Loss 0.4742 Regression loss 0.0173 Classification loss 0.4568 AP 0.2800 AR 0.0800
Epoch 224 batch 00009: Loss 0.4501 Regression loss 0.0176 Classification loss 0.4325 AP 0.2250 AR 0.0500
Epoch 224 batch 00010: Loss 0.4210 Regression loss 0.0187 Classification loss 0.4023 AP 0.7000 AR 0.1000
Epoch 225 batch 00001: Loss 0.5248 Regression loss 0.0212 Classification loss 0.5036 AP 1.0000 AR 0.0000
Epoch 225 batch 00002: Loss 0.5103 Regression loss 0.0180 Classification loss 0.4924 AP 0.6000 AR 0.0000
Epoch 225 batch 00003: Loss 0.5810 Regression loss 0.0247 Classification loss 0.5563 AP 0.8000 AR 0.0000
Epoch 225 batch 00004: Loss 0.3607 Regression loss 0.0183 Classification loss 0.3424 AP 0.7000 AR 0.1000
Epoch 225 batch 00005: Loss 0.4228 Regression loss 0.0213 Classification loss 0.4016 AP 0.8000 AR 0.2000
Epoch 225 batch 00006: Loss 0.3599 Regression loss 0.0148 Classification loss 0.3451 AP 0.6000 AR 0.1400
Epoch 225 batch 00007: Loss 0.4477 Regression loss 0.0173 Classification loss 0.4304 AP 0.2000 AR 0.0000
Epoch 225 batch 00008: Loss 0.3554 Regression loss 0.0185 Classification loss 0.3369 AP 0.6000 AR 0.0500
Epoch 225 batch 00009: Loss 0.3572 Regression loss 0.0156 Classification loss 0.3416 AP 0.4000 AR 0.2000
Epoch 225 batch 00010: Loss 0.4611 Regression loss 0.0206 Classification loss 0.4406 AP 0.6000 AR 0.0000
Epoch 226 batch 00001: Loss 0.6088 Regression loss 0.0217 Classification loss 0.5871 AP 0.8000 AR 0.0000
Epoch 226 batch 00002: Loss 0.7065 Regression loss 0.0203 Classification loss 0.6862 AP 0.8000 AR 0.2000
Epoch 226 batch 00003: Loss 0.4074 Regression loss 0.0142 Classification loss 0.3932 AP 0.6286 AR 0.0500
Epoch 226 batch 00004: Loss 0.3424 Regression loss 0.0193 Classification loss 0.3230 AP 0.5000 AR 0.1000
Epoch 226 batch 00005: Loss 0.3484 Regression loss 0.0205 Classification loss 0.3279 AP 0.2667 AR 0.0500
Epoch 226 batch 00006: Loss 0.3802 Regression loss 0.0182 Classification loss 0.3620 AP 0.5167 AR 0.0800
Epoch 226 batch 00007: Loss 0.3170 Regression loss 0.0159 Classification loss 0.3011 AP 0.3167 AR 0.1067
Epoch 226 batch 00008: Loss 0.4452 Regression loss 0.0183 Classification loss 0.4269 AP 0.5000 AR 0.1667
Epoch 226 batch 00009: Loss 0.3062 Regression loss 0.0211 Classification loss 0.2850 AP 0.8000 AR 0.2000
Epoch 226 batch 00010: Loss 0.5164 Regression loss 0.0199 Classification loss 0.4965 AP 0.7000 AR 0.0900
Epoch 227 batch 00001: Loss 0.4769 Regression loss 0.0193 Classification loss 0.4576 AP 0.8000 AR 0.0400
Epoch 227 batch 00002: Loss 0.4461 Regression loss 0.0231 Classification loss 0.4230 AP 0.6000 AR 0.0000
Epoch 227 batch 00003: Loss 0.3739 Regression loss 0.0154 Classification loss 0.3585 AP 0.6000 AR 0.1000
Epoch 227 batch 00004: Loss 0.4252 Regression loss 0.0201 Classification loss 0.4051 AP 0.2667 AR 0.0500
Epoch 227 batch 00005: Loss 0.4021 Regression loss 0.0210 Classification loss 0.3811 AP 0.8000 AR 0.1000
Epoch 227 batch 00006: Loss 0.3711 Regression loss 0.0218 Classification loss 0.3493 AP 0.4667 AR 0.0667
Epoch 227 batch 00007: Loss 0.3736 Regression loss 0.0210 Classification loss 0.3526 AP 0.4000 AR 0.2000
Epoch 227 batch 00008: Loss 0.4691 Regression loss 0.0187 Classification loss 0.4504 AP 0.4000 AR 0.0000
Epoch 227 batch 00009: Loss 0.3946 Regression loss 0.0155 Classification loss 0.3791 AP 0.4667 AR 0.3000
Epoch 227 batch 00010: Loss 0.3971 Regression loss 0.0138 Classification loss 0.3833 AP 0.7667 AR 0.1067
Epoch 228 batch 00001: Loss 0.4167 Regression loss 0.0173 Classification loss 0.3995 AP 0.6000 AR 0.1000
Epoch 228 batch 00002: Loss 0.3703 Regression loss 0.0210 Classification loss 0.3493 AP 0.6000 AR 0.3000
Epoch 228 batch 00003: Loss 0.4661 Regression loss 0.0175 Classification loss 0.4485 AP 0.5000 AR 0.0400
Epoch 228 batch 00004: Loss 0.4986 Regression loss 0.0150 Classification loss 0.4836 AP 0.4286 AR 0.0500
Epoch 228 batch 00005: Loss 0.4716 Regression loss 0.0198 Classification loss 0.4518 AP 0.7000 AR 0.0900
Epoch 228 batch 00006: Loss 0.3870 Regression loss 0.0201 Classification loss 0.3669 AP 0.8000 AR 0.0500
Epoch 228 batch 00007: Loss 0.3641 Regression loss 0.0216 Classification loss 0.3425 AP 0.9000 AR 0.1500
Epoch 228 batch 00008: Loss 0.3370 Regression loss 0.0167 Classification loss 0.3202 AP 0.8000 AR 0.2400
Epoch 228 batch 00009: Loss 0.3100 Regression loss 0.0165 Classification loss 0.2935 AP 0.6000 AR 0.0000
Epoch 228 batch 00010: Loss 0.4339 Regression loss 0.0223 Classification loss 0.4117 AP 0.6000 AR 0.0000
Epoch 229 batch 00001: Loss 0.4014 Regression loss 0.0162 Classification loss 0.3851 AP 0.6000 AR 0.0000
Epoch 229 batch 00002: Loss 0.5899 Regression loss 0.0150 Classification loss 0.5750 AP 0.9000 AR 0.0500
Epoch 229 batch 00003: Loss 0.4530 Regression loss 0.0223 Classification loss 0.4306 AP 0.6667 AR 0.0500
Epoch 229 batch 00004: Loss 0.3653 Regression loss 0.0219 Classification loss 0.3434 AP 0.7000 AR 0.1200
Epoch 229 batch 00005: Loss 0.4817 Regression loss 0.0227 Classification loss 0.4590 AP 0.4000 AR 0.0000
Epoch 229 batch 00006: Loss 0.4732 Regression loss 0.0233 Classification loss 0.4499 AP 0.4667 AR 0.0400
Epoch 229 batch 00007: Loss 0.5225 Regression loss 0.0154 Classification loss 0.5071 AP 0.4000 AR 0.2000
Epoch 229 batch 00008: Loss 0.3519 Regression loss 0.0182 Classification loss 0.3337 AP 0.7000 AR 0.3000
Epoch 229 batch 00009: Loss 0.4331 Regression loss 0.0191 Classification loss 0.4140 AP 0.6000 AR 0.0000
Epoch 229 batch 00010: Loss 0.3559 Regression loss 0.0162 Classification loss 0.3396 AP 0.2000 AR 0.0000
Epoch 230 batch 00001: Loss 0.4239 Regression loss 0.0192 Classification loss 0.4047 AP 0.6000 AR 0.0000
Epoch 230 batch 00002: Loss 0.5254 Regression loss 0.0128 Classification loss 0.5126 AP 0.8000 AR 0.0000
Epoch 230 batch 00003: Loss 0.3415 Regression loss 0.0203 Classification loss 0.3212 AP 0.4000 AR 0.0000
Epoch 230 batch 00004: Loss 0.3679 Regression loss 0.0203 Classification loss 0.3477 AP 0.6500 AR 0.2667
Epoch 230 batch 00005: Loss 0.4392 Regression loss 0.0191 Classification loss 0.4201 AP 0.6000 AR 0.0500
Epoch 230 batch 00006: Loss 0.5531 Regression loss 0.0189 Classification loss 0.5342 AP 0.8000 AR 0.0400
Epoch 230 batch 00007: Loss 0.3563 Regression loss 0.0188 Classification loss 0.3375 AP 0.6000 AR 0.2500
Epoch 230 batch 00008: Loss 0.3429 Regression loss 0.0136 Classification loss 0.3293 AP 0.4000 AR 0.1500
Epoch 230 batch 00009: Loss 0.4067 Regression loss 0.0203 Classification loss 0.3864 AP 0.6000 AR 0.0000
Epoch 230 batch 00010: Loss 0.4509 Regression loss 0.0216 Classification loss 0.4293 AP 0.2286 AR 0.0500
Epoch 231 batch 00001: Loss 0.4152 Regression loss 0.0258 Classification loss 0.3895 AP 0.6667 AR 0.0500
Epoch 231 batch 00002: Loss 0.5600 Regression loss 0.0252 Classification loss 0.5348 AP 0.4000 AR 0.0000
Epoch 231 batch 00003: Loss 0.4902 Regression loss 0.0184 Classification loss 0.4718 AP 0.7000 AR 0.2000
Epoch 231 batch 00004: Loss 0.4125 Regression loss 0.0177 Classification loss 0.3948 AP 0.2000 AR 0.0000
Epoch 231 batch 00005: Loss 0.4819 Regression loss 0.0166 Classification loss 0.4654 AP 0.6000 AR 0.0000
Epoch 231 batch 00006: Loss 0.4648 Regression loss 0.0201 Classification loss 0.4447 AP 0.6000 AR 0.2000
Epoch 231 batch 00007: Loss 0.4484 Regression loss 0.0166 Classification loss 0.4318 AP 0.6000 AR 0.0000
Epoch 231 batch 00008: Loss 0.3885 Regression loss 0.0187 Classification loss 0.3698 AP 0.2000 AR 0.0000
Epoch 231 batch 00009: Loss 0.3700 Regression loss 0.0162 Classification loss 0.3537 AP 0.5667 AR 0.1300
Epoch 231 batch 00010: Loss 0.3703 Regression loss 0.0158 Classification loss 0.3545 AP 0.6000 AR 0.2000
Epoch 232 batch 00001: Loss 0.4820 Regression loss 0.0180 Classification loss 0.4641 AP 0.7000 AR 0.1000
Epoch 232 batch 00002: Loss 0.4677 Regression loss 0.0208 Classification loss 0.4470 AP 0.5000 AR 0.0500
Epoch 232 batch 00003: Loss 0.4790 Regression loss 0.0223 Classification loss 0.4567 AP 0.7000 AR 0.0500
Epoch 232 batch 00004: Loss 0.3700 Regression loss 0.0132 Classification loss 0.3567 AP 0.2500 AR 0.0667
Epoch 232 batch 00005: Loss 0.3097 Regression loss 0.0135 Classification loss 0.2961 AP 0.3619 AR 0.1300
Epoch 232 batch 00006: Loss 0.5038 Regression loss 0.0244 Classification loss 0.4794 AP 1.0000 AR 0.0000
Epoch 232 batch 00007: Loss 0.4288 Regression loss 0.0183 Classification loss 0.4105 AP 0.3000 AR 0.0500
Epoch 232 batch 00008: Loss 0.4380 Regression loss 0.0197 Classification loss 0.4184 AP 0.6000 AR 0.4000
Epoch 232 batch 00009: Loss 0.3320 Regression loss 0.0205 Classification loss 0.3115 AP 0.4500 AR 0.1400
Epoch 232 batch 00010: Loss 0.4342 Regression loss 0.0190 Classification loss 0.4152 AP 0.6000 AR 0.0000
Epoch 233 batch 00001: Loss 0.3998 Regression loss 0.0203 Classification loss 0.3794 AP 0.6000 AR 0.0000
Epoch 233 batch 00002: Loss 0.3410 Regression loss 0.0188 Classification loss 0.3222 AP 0.8000 AR 0.0500
Epoch 233 batch 00003: Loss 0.4164 Regression loss 0.0188 Classification loss 0.3976 AP 0.7067 AR 0.0900
Epoch 233 batch 00004: Loss 0.4387 Regression loss 0.0179 Classification loss 0.4208 AP 0.7000 AR 0.2500
Epoch 233 batch 00005: Loss 0.4909 Regression loss 0.0177 Classification loss 0.4732 AP 1.0000 AR 0.2400
Epoch 233 batch 00006: Loss 0.5287 Regression loss 0.0176 Classification loss 0.5111 AP 0.4000 AR 0.0000
Epoch 233 batch 00007: Loss 0.3085 Regression loss 0.0149 Classification loss 0.2936 AP 0.4000 AR 0.1400
Epoch 233 batch 00008: Loss 0.4469 Regression loss 0.0228 Classification loss 0.4241 AP 0.4000 AR 0.0000
Epoch 233 batch 00009: Loss 0.4013 Regression loss 0.0197 Classification loss 0.3816 AP 0.2000 AR 0.0000
Epoch 233 batch 00010: Loss 0.3495 Regression loss 0.0196 Classification loss 0.3299 AP 0.2500 AR 0.0667
Epoch 234 batch 00001: Loss 0.4601 Regression loss 0.0201 Classification loss 0.4400 AP 0.6000 AR 0.3000
Epoch 234 batch 00002: Loss 0.4675 Regression loss 0.0159 Classification loss 0.4517 AP 0.7000 AR 0.2500
Epoch 234 batch 00003: Loss 0.3152 Regression loss 0.0142 Classification loss 0.3010 AP 0.3000 AR 0.1000
Epoch 234 batch 00004: Loss 0.3991 Regression loss 0.0180 Classification loss 0.3811 AP 0.6667 AR 0.0500
Epoch 234 batch 00005: Loss 0.3446 Regression loss 0.0185 Classification loss 0.3262 AP 0.3667 AR 0.1400
Epoch 234 batch 00006: Loss 0.4061 Regression loss 0.0191 Classification loss 0.3870 AP 0.4000 AR 0.0000
Epoch 234 batch 00007: Loss 0.4984 Regression loss 0.0194 Classification loss 0.4789 AP 0.4286 AR 0.0500
Epoch 234 batch 00008: Loss 0.3440 Regression loss 0.0194 Classification loss 0.3246 AP 0.7167 AR 0.1067
Epoch 234 batch 00009: Loss 0.4243 Regression loss 0.0212 Classification loss 0.4031 AP 0.6000 AR 0.0000
Epoch 234 batch 00010: Loss 0.5729 Regression loss 0.0254 Classification loss 0.5475 AP 0.6000 AR 0.0000
Epoch 235 batch 00001: Loss 0.3309 Regression loss 0.0203 Classification loss 0.3107 AP 0.5167 AR 0.1167
Epoch 235 batch 00002: Loss 0.4623 Regression loss 0.0185 Classification loss 0.4438 AP 0.8000 AR 0.1000
Epoch 235 batch 00003: Loss 0.3596 Regression loss 0.0214 Classification loss 0.3382 AP 0.4000 AR 0.0000
Epoch 235 batch 00004: Loss 0.5927 Regression loss 0.0166 Classification loss 0.5761 AP 0.5000 AR 0.0500
Epoch 235 batch 00005: Loss 0.3820 Regression loss 0.0165 Classification loss 0.3656 AP 0.5333 AR 0.0800
Epoch 235 batch 00006: Loss 0.3621 Regression loss 0.0167 Classification loss 0.3454 AP 0.5000 AR 0.3000
Epoch 235 batch 00007: Loss 0.4404 Regression loss 0.0171 Classification loss 0.4234 AP 0.4333 AR 0.0500
Epoch 235 batch 00008: Loss 0.3803 Regression loss 0.0209 Classification loss 0.3593 AP 0.8000 AR 0.0000
Epoch 235 batch 00009: Loss 0.4937 Regression loss 0.0189 Classification loss 0.4747 AP 0.2667 AR 0.0400
Epoch 235 batch 00010: Loss 0.4361 Regression loss 0.0197 Classification loss 0.4164 AP 0.8000 AR 0.2000
Epoch 236 batch 00001: Loss 0.4838 Regression loss 0.0200 Classification loss 0.4638 AP 0.2667 AR 0.0400
Epoch 236 batch 00002: Loss 0.4139 Regression loss 0.0192 Classification loss 0.3946 AP 0.6000 AR 0.1000
Epoch 236 batch 00003: Loss 0.4814 Regression loss 0.0175 Classification loss 0.4639 AP 0.4667 AR 0.2500
Epoch 236 batch 00004: Loss 0.1881 Regression loss 0.0130 Classification loss 0.1751 AP 0.5667 AR 0.3400
Epoch 236 batch 00005: Loss 0.4861 Regression loss 0.0187 Classification loss 0.4674 AP 0.8000 AR 0.0400
Epoch 236 batch 00006: Loss 0.4173 Regression loss 0.0170 Classification loss 0.4004 AP 0.4333 AR 0.0500
Epoch 236 batch 00007: Loss 0.4912 Regression loss 0.0193 Classification loss 0.4719 AP 0.6000 AR 0.0400
Epoch 236 batch 00008: Loss 0.2722 Regression loss 0.0195 Classification loss 0.2526 AP 0.4000 AR 0.0000
Epoch 236 batch 00009: Loss 0.4666 Regression loss 0.0186 Classification loss 0.4480 AP 0.5000 AR 0.0400
Epoch 236 batch 00010: Loss 0.5462 Regression loss 0.0210 Classification loss 0.5252 AP 0.4000 AR 0.0000
Epoch 237 batch 00001: Loss 0.3922 Regression loss 0.0228 Classification loss 0.3694 AP 0.2500 AR 0.0667
Epoch 237 batch 00002: Loss 0.5035 Regression loss 0.0149 Classification loss 0.4885 AP 0.6000 AR 0.0000
Epoch 237 batch 00003: Loss 0.5084 Regression loss 0.0236 Classification loss 0.4847 AP 0.4000 AR 0.0000
Epoch 237 batch 00004: Loss 0.3578 Regression loss 0.0181 Classification loss 0.3398 AP 0.6000 AR 0.2000
Epoch 237 batch 00005: Loss 0.3946 Regression loss 0.0173 Classification loss 0.3773 AP 0.8000 AR 0.0000
Epoch 237 batch 00006: Loss 0.4489 Regression loss 0.0200 Classification loss 0.4289 AP 0.2000 AR 0.2000
Epoch 237 batch 00007: Loss 0.5140 Regression loss 0.0144 Classification loss 0.4996 AP 0.3000 AR 0.0500
Epoch 237 batch 00008: Loss 0.4936 Regression loss 0.0177 Classification loss 0.4759 AP 0.8000 AR 0.1000
Epoch 237 batch 00009: Loss 0.3871 Regression loss 0.0210 Classification loss 0.3661 AP 0.5667 AR 0.0900
Epoch 237 batch 00010: Loss 0.3423 Regression loss 0.0161 Classification loss 0.3262 AP 0.5167 AR 0.0800
Epoch 238 batch 00001: Loss 0.4533 Regression loss 0.0123 Classification loss 0.4410 AP 0.4000 AR 0.1500
Epoch 238 batch 00002: Loss 0.3135 Regression loss 0.0163 Classification loss 0.2971 AP 0.6000 AR 0.1000
Epoch 238 batch 00003: Loss 0.4953 Regression loss 0.0206 Classification loss 0.4747 AP 0.9333 AR 0.0800
Epoch 238 batch 00004: Loss 0.4692 Regression loss 0.0174 Classification loss 0.4518 AP 0.6333 AR 0.0500
Epoch 238 batch 00005: Loss 0.4513 Regression loss 0.0191 Classification loss 0.4321 AP 0.3000 AR 0.0500
Epoch 238 batch 00006: Loss 0.4074 Regression loss 0.0205 Classification loss 0.3870 AP 0.8000 AR 0.2000
Epoch 238 batch 00007: Loss 0.4532 Regression loss 0.0180 Classification loss 0.4352 AP 0.2500 AR 0.0667
Epoch 238 batch 00008: Loss 0.5574 Regression loss 0.0162 Classification loss 0.5412 AP 0.8000 AR 0.2000
Epoch 238 batch 00009: Loss 0.4093 Regression loss 0.0249 Classification loss 0.3844 AP 0.4667 AR 0.1000
Epoch 238 batch 00010: Loss 0.3811 Regression loss 0.0184 Classification loss 0.3627 AP 0.4500 AR 0.0400
Epoch 239 batch 00001: Loss 0.5766 Regression loss 0.0212 Classification loss 0.5554 AP 0.7000 AR 0.0500
Epoch 239 batch 00002: Loss 0.3950 Regression loss 0.0166 Classification loss 0.3784 AP 0.4400 AR 0.0500
Epoch 239 batch 00003: Loss 0.4744 Regression loss 0.0166 Classification loss 0.4578 AP 0.8000 AR 0.0000
Epoch 239 batch 00004: Loss 0.4697 Regression loss 0.0210 Classification loss 0.4487 AP 0.8000 AR 0.0400
Epoch 239 batch 00005: Loss 0.4656 Regression loss 0.0135 Classification loss 0.4520 AP 0.6000 AR 0.2000
Epoch 239 batch 00006: Loss 0.3997 Regression loss 0.0152 Classification loss 0.3845 AP 0.6500 AR 0.2667
Epoch 239 batch 00007: Loss 0.4568 Regression loss 0.0209 Classification loss 0.4359 AP 0.4000 AR 0.0000
Epoch 239 batch 00008: Loss 0.5194 Regression loss 0.0221 Classification loss 0.4974 AP 0.5000 AR 0.1000
Epoch 239 batch 00009: Loss 0.3379 Regression loss 0.0209 Classification loss 0.3170 AP 0.4667 AR 0.1000
Epoch 239 batch 00010: Loss 0.2590 Regression loss 0.0184 Classification loss 0.2407 AP 0.5000 AR 0.0800
Epoch 240 batch 00001: Loss 0.2924 Regression loss 0.0187 Classification loss 0.2737 AP 0.6333 AR 0.2300
Epoch 240 batch 00002: Loss 0.3128 Regression loss 0.0155 Classification loss 0.2973 AP 0.1833 AR 0.2167
Epoch 240 batch 00003: Loss 0.5249 Regression loss 0.0214 Classification loss 0.5035 AP 1.0000 AR 0.0400
Epoch 240 batch 00004: Loss 0.4009 Regression loss 0.0167 Classification loss 0.3843 AP 0.5000 AR 0.0667
Epoch 240 batch 00005: Loss 0.4568 Regression loss 0.0146 Classification loss 0.4422 AP 0.4000 AR 0.2000
Epoch 240 batch 00006: Loss 0.4472 Regression loss 0.0204 Classification loss 0.4268 AP 0.7000 AR 0.0500
Epoch 240 batch 00007: Loss 0.4453 Regression loss 0.0155 Classification loss 0.4298 AP 0.6667 AR 0.3000
Epoch 240 batch 00008: Loss 0.5450 Regression loss 0.0207 Classification loss 0.5243 AP 0.7000 AR 0.0400
Epoch 240 batch 00009: Loss 0.4473 Regression loss 0.0164 Classification loss 0.4308 AP 0.4000 AR 0.0000
Epoch 240 batch 00010: Loss 0.4536 Regression loss 0.0213 Classification loss 0.4323 AP 0.7000 AR 0.0500
Epoch 241 batch 00001: Loss 0.3533 Regression loss 0.0149 Classification loss 0.3384 AP 0.2000 AR 0.0000
Epoch 241 batch 00002: Loss 0.4133 Regression loss 0.0196 Classification loss 0.3937 AP 0.6667 AR 0.0500
Epoch 241 batch 00003: Loss 0.5263 Regression loss 0.0185 Classification loss 0.5078 AP 0.4000 AR 0.0000
Epoch 241 batch 00004: Loss 0.3628 Regression loss 0.0174 Classification loss 0.3454 AP 0.7333 AR 0.1500
Epoch 241 batch 00005: Loss 0.3657 Regression loss 0.0165 Classification loss 0.3492 AP 0.6000 AR 0.0900
Epoch 241 batch 00006: Loss 0.5811 Regression loss 0.0181 Classification loss 0.5630 AP 0.8000 AR 0.3000
Epoch 241 batch 00007: Loss 0.4168 Regression loss 0.0160 Classification loss 0.4008 AP 0.6667 AR 0.2667
Epoch 241 batch 00008: Loss 0.2921 Regression loss 0.0189 Classification loss 0.2733 AP 0.3333 AR 0.1300
Epoch 241 batch 00009: Loss 0.4218 Regression loss 0.0210 Classification loss 0.4008 AP 0.4000 AR 0.0000
Epoch 241 batch 00010: Loss 0.5699 Regression loss 0.0244 Classification loss 0.5455 AP 0.9000 AR 0.0400
Epoch 242 batch 00001: Loss 0.3898 Regression loss 0.0190 Classification loss 0.3708 AP 0.4000 AR 0.0000
Epoch 242 batch 00002: Loss 0.3796 Regression loss 0.0161 Classification loss 0.3634 AP 0.2000 AR 0.0000
Epoch 242 batch 00003: Loss 0.4289 Regression loss 0.0132 Classification loss 0.4157 AP 0.4000 AR 0.0000
Epoch 242 batch 00004: Loss 0.3679 Regression loss 0.0201 Classification loss 0.3478 AP 0.4000 AR 0.0000
Epoch 242 batch 00005: Loss 0.4823 Regression loss 0.0201 Classification loss 0.4621 AP 0.8000 AR 0.2400
Epoch 242 batch 00006: Loss 0.4122 Regression loss 0.0216 Classification loss 0.3907 AP 0.8000 AR 0.0000
Epoch 242 batch 00007: Loss 0.3747 Regression loss 0.0159 Classification loss 0.3588 AP 0.4000 AR 0.2000
Epoch 242 batch 00008: Loss 0.4288 Regression loss 0.0198 Classification loss 0.4091 AP 0.6667 AR 0.0500
Epoch 242 batch 00009: Loss 0.5742 Regression loss 0.0198 Classification loss 0.5543 AP 0.2667 AR 0.0500
Epoch 242 batch 00010: Loss 0.4133 Regression loss 0.0221 Classification loss 0.3913 AP 0.6000 AR 0.0000
Epoch 243 batch 00001: Loss 0.4168 Regression loss 0.0170 Classification loss 0.3997 AP 0.2000 AR 0.0000
Epoch 243 batch 00002: Loss 0.3803 Regression loss 0.0205 Classification loss 0.3598 AP 0.7000 AR 0.0400
Epoch 243 batch 00003: Loss 0.5271 Regression loss 0.0176 Classification loss 0.5095 AP 0.6000 AR 0.1000
Epoch 243 batch 00004: Loss 0.4170 Regression loss 0.0150 Classification loss 0.4020 AP 0.8000 AR 0.0000
Epoch 243 batch 00005: Loss 0.4279 Regression loss 0.0158 Classification loss 0.4121 AP 0.8000 AR 0.2000
Epoch 243 batch 00006: Loss 0.4279 Regression loss 0.0215 Classification loss 0.4063 AP 0.5000 AR 0.0500
Epoch 243 batch 00007: Loss 0.4842 Regression loss 0.0181 Classification loss 0.4661 AP 0.6000 AR 0.0000
Epoch 243 batch 00008: Loss 0.4769 Regression loss 0.0213 Classification loss 0.4555 AP 0.8250 AR 0.0900
Epoch 243 batch 00009: Loss 0.3613 Regression loss 0.0186 Classification loss 0.3428 AP 0.1000 AR 0.1000
Epoch 243 batch 00010: Loss 0.3945 Regression loss 0.0155 Classification loss 0.3790 AP 0.4500 AR 0.2500
Epoch 244 batch 00001: Loss 0.4787 Regression loss 0.0171 Classification loss 0.4615 AP 0.5000 AR 0.1500
Epoch 244 batch 00002: Loss 0.3729 Regression loss 0.0204 Classification loss 0.3524 AP 0.4286 AR 0.0500
Epoch 244 batch 00003: Loss 0.3326 Regression loss 0.0184 Classification loss 0.3142 AP 0.7000 AR 0.4400
Epoch 244 batch 00004: Loss 0.5961 Regression loss 0.0154 Classification loss 0.5807 AP 0.7000 AR 0.0667
Epoch 244 batch 00005: Loss 0.4709 Regression loss 0.0187 Classification loss 0.4522 AP 0.2667 AR 0.1000
Epoch 244 batch 00006: Loss 0.2472 Regression loss 0.0119 Classification loss 0.2353 AP 0.4500 AR 0.0400
Epoch 244 batch 00007: Loss 0.5481 Regression loss 0.0194 Classification loss 0.5287 AP 1.0000 AR 0.0000
Epoch 244 batch 00008: Loss 0.3739 Regression loss 0.0214 Classification loss 0.3525 AP 0.8000 AR 0.0500
Epoch 244 batch 00009: Loss 0.4873 Regression loss 0.0211 Classification loss 0.4662 AP 0.6000 AR 0.0000
Epoch 244 batch 00010: Loss 0.3014 Regression loss 0.0184 Classification loss 0.2831 AP 0.3333 AR 0.0900
Epoch 245 batch 00001: Loss 0.4898 Regression loss 0.0162 Classification loss 0.4736 AP 0.7000 AR 0.0500
Epoch 245 batch 00002: Loss 0.4767 Regression loss 0.0189 Classification loss 0.4578 AP 0.5333 AR 0.1000
Epoch 245 batch 00003: Loss 0.4953 Regression loss 0.0136 Classification loss 0.4817 AP 0.6000 AR 0.2000
Epoch 245 batch 00004: Loss 0.5919 Regression loss 0.0218 Classification loss 0.5700 AP 0.8000 AR 0.0000
Epoch 245 batch 00005: Loss 0.3743 Regression loss 0.0170 Classification loss 0.3574 AP 0.5667 AR 0.2400
Epoch 245 batch 00006: Loss 0.3629 Regression loss 0.0163 Classification loss 0.3467 AP 0.2667 AR 0.0400
Epoch 245 batch 00007: Loss 0.3525 Regression loss 0.0153 Classification loss 0.3372 AP 0.5667 AR 0.1300
Epoch 245 batch 00008: Loss 0.2847 Regression loss 0.0186 Classification loss 0.2661 AP 0.2000 AR 0.0000
Epoch 245 batch 00009: Loss 0.3616 Regression loss 0.0249 Classification loss 0.3368 AP 0.8000 AR 0.2000
Epoch 245 batch 00010: Loss 0.4374 Regression loss 0.0219 Classification loss 0.4155 AP 0.2500 AR 0.0667
Epoch 246 batch 00001: Loss 0.4417 Regression loss 0.0194 Classification loss 0.4223 AP 0.1667 AR 0.0900
Epoch 246 batch 00002: Loss 0.4628 Regression loss 0.0205 Classification loss 0.4423 AP 0.4000 AR 0.0000
Epoch 246 batch 00003: Loss 0.6167 Regression loss 0.0146 Classification loss 0.6020 AP 0.5000 AR 0.0667
Epoch 246 batch 00004: Loss 0.4086 Regression loss 0.0218 Classification loss 0.3867 AP 0.8667 AR 0.2800
Epoch 246 batch 00005: Loss 0.4554 Regression loss 0.0194 Classification loss 0.4360 AP 0.8000 AR 0.0500
Epoch 246 batch 00006: Loss 0.4636 Regression loss 0.0187 Classification loss 0.4449 AP 0.6000 AR 0.0000
Epoch 246 batch 00007: Loss 0.4138 Regression loss 0.0163 Classification loss 0.3975 AP 0.5667 AR 0.2000
Epoch 246 batch 00008: Loss 0.4515 Regression loss 0.0191 Classification loss 0.4324 AP 0.6000 AR 0.0000
Epoch 246 batch 00009: Loss 0.2638 Regression loss 0.0172 Classification loss 0.2466 AP 0.5000 AR 0.0900
Epoch 246 batch 00010: Loss 0.2993 Regression loss 0.0166 Classification loss 0.2827 AP 0.6000 AR 0.2000
Epoch 247 batch 00001: Loss 0.3658 Regression loss 0.0149 Classification loss 0.3510 AP 0.6000 AR 0.0000
Epoch 247 batch 00002: Loss 0.3306 Regression loss 0.0171 Classification loss 0.3135 AP 0.6119 AR 0.1967
Epoch 247 batch 00003: Loss 0.4303 Regression loss 0.0187 Classification loss 0.4117 AP 0.2000 AR 0.0000
Epoch 247 batch 00004: Loss 0.5104 Regression loss 0.0202 Classification loss 0.4903 AP 0.8000 AR 0.0000
Epoch 247 batch 00005: Loss 0.4644 Regression loss 0.0206 Classification loss 0.4439 AP 0.4000 AR 0.0000
Epoch 247 batch 00006: Loss 0.4606 Regression loss 0.0161 Classification loss 0.4445 AP 0.4500 AR 0.2500
Epoch 247 batch 00007: Loss 0.4196 Regression loss 0.0183 Classification loss 0.4013 AP 0.6000 AR 0.1000
Epoch 247 batch 00008: Loss 0.3500 Regression loss 0.0192 Classification loss 0.3308 AP 0.6000 AR 0.2000
Epoch 247 batch 00009: Loss 0.5204 Regression loss 0.0213 Classification loss 0.4991 AP 0.7333 AR 0.1500
Epoch 247 batch 00010: Loss 0.3663 Regression loss 0.0187 Classification loss 0.3476 AP 0.4667 AR 0.1800
Epoch 248 batch 00001: Loss 0.3639 Regression loss 0.0183 Classification loss 0.3456 AP 0.6000 AR 0.0000
Epoch 248 batch 00002: Loss 0.4678 Regression loss 0.0178 Classification loss 0.4500 AP 0.4000 AR 0.0000
Epoch 248 batch 00003: Loss 0.4227 Regression loss 0.0157 Classification loss 0.4071 AP 0.7000 AR 0.4500
Epoch 248 batch 00004: Loss 0.4972 Regression loss 0.0183 Classification loss 0.4789 AP 0.7667 AR 0.1800
Epoch 248 batch 00005: Loss 0.3337 Regression loss 0.0157 Classification loss 0.3180 AP 0.6500 AR 0.0667
Epoch 248 batch 00006: Loss 0.4837 Regression loss 0.0175 Classification loss 0.4662 AP 0.6000 AR 0.0000
Epoch 248 batch 00007: Loss 0.3732 Regression loss 0.0229 Classification loss 0.3503 AP 0.7000 AR 0.0800
Epoch 248 batch 00008: Loss 0.4623 Regression loss 0.0160 Classification loss 0.4463 AP 0.7000 AR 0.3400
Epoch 248 batch 00009: Loss 0.4352 Regression loss 0.0196 Classification loss 0.4156 AP 0.5667 AR 0.1500
Epoch 248 batch 00010: Loss 0.3698 Regression loss 0.0186 Classification loss 0.3511 AP 0.2000 AR 0.0000
Epoch 249 batch 00001: Loss 0.5430 Regression loss 0.0231 Classification loss 0.5199 AP 0.8000 AR 0.0000
Epoch 249 batch 00002: Loss 0.5130 Regression loss 0.0220 Classification loss 0.4910 AP 0.4000 AR 0.0000
Epoch 249 batch 00003: Loss 0.4429 Regression loss 0.0144 Classification loss 0.4284 AP 0.4667 AR 0.2667
Epoch 249 batch 00004: Loss 0.3429 Regression loss 0.0191 Classification loss 0.3238 AP 0.3000 AR 0.0400
Epoch 249 batch 00005: Loss 0.3291 Regression loss 0.0176 Classification loss 0.3115 AP 0.5667 AR 0.2167
Epoch 249 batch 00006: Loss 0.5163 Regression loss 0.0187 Classification loss 0.4976 AP 0.6000 AR 0.0000
Epoch 249 batch 00007: Loss 0.4529 Regression loss 0.0126 Classification loss 0.4403 AP 0.6000 AR 0.2000
Epoch 249 batch 00008: Loss 0.4296 Regression loss 0.0190 Classification loss 0.4106 AP 0.6000 AR 0.2900
Epoch 249 batch 00009: Loss 0.5105 Regression loss 0.0173 Classification loss 0.4932 AP 0.6667 AR 0.1000
Epoch 249 batch 00010: Loss 0.3085 Regression loss 0.0188 Classification loss 0.2896 AP 0.4667 AR 0.0400
Epoch 250 batch 00001: Loss 0.3710 Regression loss 0.0147 Classification loss 0.3563 AP 0.4000 AR 0.2500
Epoch 250 batch 00002: Loss 0.4327 Regression loss 0.0152 Classification loss 0.4175 AP 0.3667 AR 0.0900
Epoch 250 batch 00003: Loss 0.4103 Regression loss 0.0249 Classification loss 0.3855 AP 0.6000 AR 0.0000
Epoch 250 batch 00004: Loss 0.3126 Regression loss 0.0158 Classification loss 0.2968 AP 0.4000 AR 0.0000
Epoch 250 batch 00005: Loss 0.5010 Regression loss 0.0212 Classification loss 0.4798 AP 0.4500 AR 0.0800
Epoch 250 batch 00006: Loss 0.5550 Regression loss 0.0244 Classification loss 0.5306 AP 1.0000 AR 0.0000
Epoch 250 batch 00007: Loss 0.2840 Regression loss 0.0172 Classification loss 0.2668 AP 0.5400 AR 0.3667
Epoch 250 batch 00008: Loss 0.3287 Regression loss 0.0150 Classification loss 0.3137 AP 0.5667 AR 0.1300
Epoch 250 batch 00009: Loss 0.4861 Regression loss 0.0206 Classification loss 0.4655 AP 0.6000 AR 0.0000
Epoch 250 batch 00010: Loss 0.3669 Regression loss 0.0146 Classification loss 0.3523 AP 0.4000 AR 0.1000
Epoch 251 batch 00001: Loss 0.4181 Regression loss 0.0174 Classification loss 0.4008 AP 0.4667 AR 0.3000
Epoch 251 batch 00002: Loss 0.4064 Regression loss 0.0181 Classification loss 0.3883 AP 0.3000 AR 0.1000
Epoch 251 batch 00003: Loss 0.2942 Regression loss 0.0182 Classification loss 0.2761 AP 0.4667 AR 0.1733
Epoch 251 batch 00004: Loss 0.4842 Regression loss 0.0212 Classification loss 0.4630 AP 0.5000 AR 0.2500
Epoch 251 batch 00005: Loss 0.4197 Regression loss 0.0143 Classification loss 0.4054 AP 0.4333 AR 0.0500
Epoch 251 batch 00006: Loss 0.4327 Regression loss 0.0209 Classification loss 0.4117 AP 0.8667 AR 0.0500
Epoch 251 batch 00007: Loss 0.3823 Regression loss 0.0175 Classification loss 0.3648 AP 0.9333 AR 0.2200
Epoch 251 batch 00008: Loss 0.4194 Regression loss 0.0221 Classification loss 0.3972 AP 0.4000 AR 0.0000
Epoch 251 batch 00009: Loss 0.4386 Regression loss 0.0184 Classification loss 0.4202 AP 0.4000 AR 0.0000
Epoch 251 batch 00010: Loss 0.4846 Regression loss 0.0181 Classification loss 0.4665 AP 0.6000 AR 0.0900
Epoch 252 batch 00001: Loss 0.4498 Regression loss 0.0173 Classification loss 0.4324 AP 0.4667 AR 0.0500
Epoch 252 batch 00002: Loss 0.4638 Regression loss 0.0200 Classification loss 0.4438 AP 0.7000 AR 0.0400
Epoch 252 batch 00003: Loss 0.4513 Regression loss 0.0192 Classification loss 0.4321 AP 0.5000 AR 0.1000
Epoch 252 batch 00004: Loss 0.3907 Regression loss 0.0189 Classification loss 0.3718 AP 0.4667 AR 0.0667
Epoch 252 batch 00005: Loss 0.3254 Regression loss 0.0222 Classification loss 0.3032 AP 0.8000 AR 0.0000
Epoch 252 batch 00006: Loss 0.4031 Regression loss 0.0160 Classification loss 0.3870 AP 0.6000 AR 0.0000
Epoch 252 batch 00007: Loss 0.3387 Regression loss 0.0137 Classification loss 0.3250 AP 0.2000 AR 0.0000
Epoch 252 batch 00008: Loss 0.4160 Regression loss 0.0166 Classification loss 0.3994 AP 0.3000 AR 0.1400
Epoch 252 batch 00009: Loss 0.3446 Regression loss 0.0199 Classification loss 0.3247 AP 0.6000 AR 0.4000
Epoch 252 batch 00010: Loss 0.5025 Regression loss 0.0175 Classification loss 0.4850 AP 0.8000 AR 0.0000
Epoch 253 batch 00001: Loss 0.4051 Regression loss 0.0197 Classification loss 0.3854 AP 0.8000 AR 0.0000
Epoch 253 batch 00002: Loss 0.3970 Regression loss 0.0120 Classification loss 0.3849 AP 0.4500 AR 0.0667
Epoch 253 batch 00003: Loss 0.3337 Regression loss 0.0171 Classification loss 0.3167 AP 0.0667 AR 0.0500
Epoch 253 batch 00004: Loss 0.3561 Regression loss 0.0187 Classification loss 0.3374 AP 0.7000 AR 0.0400
Epoch 253 batch 00005: Loss 0.5191 Regression loss 0.0159 Classification loss 0.5032 AP 0.4000 AR 0.0000
Epoch 253 batch 00006: Loss 0.3847 Regression loss 0.0157 Classification loss 0.3689 AP 0.4000 AR 0.1000
Epoch 253 batch 00007: Loss 0.4298 Regression loss 0.0220 Classification loss 0.4079 AP 0.6000 AR 0.0000
Epoch 253 batch 00008: Loss 0.4622 Regression loss 0.0223 Classification loss 0.4399 AP 0.6667 AR 0.2800
Epoch 253 batch 00009: Loss 0.3886 Regression loss 0.0172 Classification loss 0.3713 AP 0.4952 AR 0.1900
Epoch 253 batch 00010: Loss 0.4198 Regression loss 0.0173 Classification loss 0.4025 AP 0.8000 AR 0.4000
Epoch 254 batch 00001: Loss 0.4008 Regression loss 0.0165 Classification loss 0.3843 AP 0.6000 AR 0.0500
Epoch 254 batch 00002: Loss 0.4539 Regression loss 0.0177 Classification loss 0.4362 AP 0.4667 AR 0.0800
Epoch 254 batch 00003: Loss 0.3386 Regression loss 0.0147 Classification loss 0.3239 AP 0.3000 AR 0.1000
Epoch 254 batch 00004: Loss 0.4380 Regression loss 0.0147 Classification loss 0.4233 AP 0.6000 AR 0.3000
Epoch 254 batch 00005: Loss 0.3121 Regression loss 0.0168 Classification loss 0.2953 AP 0.5000 AR 0.2400
Epoch 254 batch 00006: Loss 0.5290 Regression loss 0.0241 Classification loss 0.5050 AP 0.6000 AR 0.0000
Epoch 254 batch 00007: Loss 0.5201 Regression loss 0.0166 Classification loss 0.5035 AP 0.5000 AR 0.0500
Epoch 254 batch 00008: Loss 0.4629 Regression loss 0.0176 Classification loss 0.4453 AP 0.6667 AR 0.1000
Epoch 254 batch 00009: Loss 0.2720 Regression loss 0.0186 Classification loss 0.2535 AP 0.7000 AR 0.0800
Epoch 254 batch 00010: Loss 0.4549 Regression loss 0.0227 Classification loss 0.4322 AP 0.6000 AR 0.0000
Epoch 255 batch 00001: Loss 0.3106 Regression loss 0.0169 Classification loss 0.2938 AP 0.9333 AR 0.2800
Epoch 255 batch 00002: Loss 0.4961 Regression loss 0.0185 Classification loss 0.4776 AP 0.2000 AR 0.0000
Epoch 255 batch 00003: Loss 0.4078 Regression loss 0.0157 Classification loss 0.3921 AP 0.4000 AR 0.0000
Epoch 255 batch 00004: Loss 0.5061 Regression loss 0.0204 Classification loss 0.4858 AP 0.6667 AR 0.3000
Epoch 255 batch 00005: Loss 0.3706 Regression loss 0.0178 Classification loss 0.3528 AP 0.9000 AR 0.0800
Epoch 255 batch 00006: Loss 0.4871 Regression loss 0.0236 Classification loss 0.4635 AP 0.8000 AR 0.0000
Epoch 255 batch 00007: Loss 0.5262 Regression loss 0.0177 Classification loss 0.5085 AP 0.8000 AR 0.0000
Epoch 255 batch 00008: Loss 0.4634 Regression loss 0.0168 Classification loss 0.4466 AP 0.2286 AR 0.0500
Epoch 255 batch 00009: Loss 0.3179 Regression loss 0.0213 Classification loss 0.2965 AP 0.2000 AR 0.0000
Epoch 255 batch 00010: Loss 0.3392 Regression loss 0.0146 Classification loss 0.3246 AP 0.2167 AR 0.2000
Epoch 256 batch 00001: Loss 0.2650 Regression loss 0.0169 Classification loss 0.2482 AP 0.4167 AR 0.2167
Epoch 256 batch 00002: Loss 0.3786 Regression loss 0.0160 Classification loss 0.3626 AP 0.4667 AR 0.0400
Epoch 256 batch 00003: Loss 0.5377 Regression loss 0.0181 Classification loss 0.5195 AP 0.5000 AR 0.0500
Epoch 256 batch 00004: Loss 0.5696 Regression loss 0.0184 Classification loss 0.5512 AP 0.6667 AR 0.1000
Epoch 256 batch 00005: Loss 0.4827 Regression loss 0.0211 Classification loss 0.4617 AP 1.0000 AR 0.3000
Epoch 256 batch 00006: Loss 0.4687 Regression loss 0.0170 Classification loss 0.4517 AP 0.5000 AR 0.0400
Epoch 256 batch 00007: Loss 0.5439 Regression loss 0.0191 Classification loss 0.5248 AP 0.4000 AR 0.0000
Epoch 256 batch 00008: Loss 0.3981 Regression loss 0.0191 Classification loss 0.3790 AP 0.3000 AR 0.0400
Epoch 256 batch 00009: Loss 0.2589 Regression loss 0.0205 Classification loss 0.2385 AP 0.5333 AR 0.2800
Epoch 256 batch 00010: Loss 0.3768 Regression loss 0.0187 Classification loss 0.3581 AP 0.8000 AR 0.2000
Epoch 257 batch 00001: Loss 0.3817 Regression loss 0.0203 Classification loss 0.3613 AP 0.6000 AR 0.0000
Epoch 257 batch 00002: Loss 0.4002 Regression loss 0.0162 Classification loss 0.3840 AP 0.6000 AR 0.0000
Epoch 257 batch 00003: Loss 0.4459 Regression loss 0.0165 Classification loss 0.4294 AP 0.4000 AR 0.2000
Epoch 257 batch 00004: Loss 0.4386 Regression loss 0.0199 Classification loss 0.4188 AP 0.2000 AR 0.2000
Epoch 257 batch 00005: Loss 0.3408 Regression loss 0.0160 Classification loss 0.3248 AP 0.0400 AR 0.0667
Epoch 257 batch 00006: Loss 0.4562 Regression loss 0.0145 Classification loss 0.4417 AP 0.6250 AR 0.0500
Epoch 257 batch 00007: Loss 0.4701 Regression loss 0.0208 Classification loss 0.4493 AP 0.6667 AR 0.0500
Epoch 257 batch 00008: Loss 0.3923 Regression loss 0.0169 Classification loss 0.3754 AP 0.6000 AR 0.0000
Epoch 257 batch 00009: Loss 0.6350 Regression loss 0.0232 Classification loss 0.6119 AP 0.9000 AR 0.0500
Epoch 257 batch 00010: Loss 0.3866 Regression loss 0.0191 Classification loss 0.3675 AP 0.2000 AR 0.1400
Epoch 258 batch 00001: Loss 0.4946 Regression loss 0.0199 Classification loss 0.4748 AP 0.6000 AR 0.0500
Epoch 258 batch 00002: Loss 0.3658 Regression loss 0.0192 Classification loss 0.3466 AP 0.5333 AR 0.1400
Epoch 258 batch 00003: Loss 0.4968 Regression loss 0.0248 Classification loss 0.4720 AP 0.9000 AR 0.0400
Epoch 258 batch 00004: Loss 0.3987 Regression loss 0.0167 Classification loss 0.3820 AP 0.7167 AR 0.3667
Epoch 258 batch 00005: Loss 0.5145 Regression loss 0.0139 Classification loss 0.5006 AP 0.7000 AR 0.0500
Epoch 258 batch 00006: Loss 0.2850 Regression loss 0.0135 Classification loss 0.2715 AP 0.6400 AR 0.2900
Epoch 258 batch 00007: Loss 0.4391 Regression loss 0.0207 Classification loss 0.4185 AP 0.5000 AR 0.1000
Epoch 258 batch 00008: Loss 0.3866 Regression loss 0.0168 Classification loss 0.3698 AP 0.4000 AR 0.2000
Epoch 258 batch 00009: Loss 0.5963 Regression loss 0.0177 Classification loss 0.5786 AP 0.8000 AR 0.0000
Epoch 258 batch 00010: Loss 0.4269 Regression loss 0.0214 Classification loss 0.4055 AP 0.6000 AR 0.0000
Epoch 259 batch 00001: Loss 0.4605 Regression loss 0.0133 Classification loss 0.4472 AP 0.6667 AR 0.0500
Epoch 259 batch 00002: Loss 0.3228 Regression loss 0.0134 Classification loss 0.3093 AP 0.8500 AR 0.3400
Epoch 259 batch 00003: Loss 0.3046 Regression loss 0.0176 Classification loss 0.2871 AP 0.4000 AR 0.0500
Epoch 259 batch 00004: Loss 0.3869 Regression loss 0.0205 Classification loss 0.3664 AP 0.7000 AR 0.2667
Epoch 259 batch 00005: Loss 0.4844 Regression loss 0.0203 Classification loss 0.4642 AP 0.6500 AR 0.0667
Epoch 259 batch 00006: Loss 0.5584 Regression loss 0.0189 Classification loss 0.5396 AP 0.6000 AR 0.0000
Epoch 259 batch 00007: Loss 0.4539 Regression loss 0.0165 Classification loss 0.4374 AP 0.5000 AR 0.1000
Epoch 259 batch 00008: Loss 0.4458 Regression loss 0.0206 Classification loss 0.4252 AP 0.2286 AR 0.0500
Epoch 259 batch 00009: Loss 0.3380 Regression loss 0.0176 Classification loss 0.3204 AP 0.6667 AR 0.1400
Epoch 259 batch 00010: Loss 0.5358 Regression loss 0.0232 Classification loss 0.5126 AP 0.3667 AR 0.0900
Epoch 260 batch 00001: Loss 0.3369 Regression loss 0.0155 Classification loss 0.3214 AP 0.6000 AR 0.2000
Epoch 260 batch 00002: Loss 0.3194 Regression loss 0.0159 Classification loss 0.3035 AP 0.3333 AR 0.0800
Epoch 260 batch 00003: Loss 0.5865 Regression loss 0.0188 Classification loss 0.5678 AP 0.6000 AR 0.0000
Epoch 260 batch 00004: Loss 0.4813 Regression loss 0.0199 Classification loss 0.4614 AP 0.3000 AR 0.0500
Epoch 260 batch 00005: Loss 0.4800 Regression loss 0.0181 Classification loss 0.4619 AP 0.2000 AR 0.0000
Epoch 260 batch 00006: Loss 0.4209 Regression loss 0.0218 Classification loss 0.3991 AP 0.8000 AR 0.0000
Epoch 260 batch 00007: Loss 0.3361 Regression loss 0.0212 Classification loss 0.3149 AP 0.5000 AR 0.0400
Epoch 260 batch 00008: Loss 0.4106 Regression loss 0.0185 Classification loss 0.3921 AP 0.5667 AR 0.2000
Epoch 260 batch 00009: Loss 0.4794 Regression loss 0.0209 Classification loss 0.4585 AP 0.8000 AR 0.0000
Epoch 260 batch 00010: Loss 0.4216 Regression loss 0.0151 Classification loss 0.4064 AP 0.4833 AR 0.1167
Epoch 261 batch 00001: Loss 0.4319 Regression loss 0.0159 Classification loss 0.4160 AP 0.4667 AR 0.0667
Epoch 261 batch 00002: Loss 0.4905 Regression loss 0.0209 Classification loss 0.4696 AP 0.6000 AR 0.0000
Epoch 261 batch 00003: Loss 0.5059 Regression loss 0.0183 Classification loss 0.4877 AP 0.4000 AR 0.0000
Epoch 261 batch 00004: Loss 0.4880 Regression loss 0.0204 Classification loss 0.4676 AP 0.9000 AR 0.0800
Epoch 261 batch 00005: Loss 0.2859 Regression loss 0.0170 Classification loss 0.2689 AP 0.2000 AR 0.0000
Epoch 261 batch 00006: Loss 0.4165 Regression loss 0.0178 Classification loss 0.3987 AP 0.4250 AR 0.0500
Epoch 261 batch 00007: Loss 0.6449 Regression loss 0.0212 Classification loss 0.6237 AP 0.8000 AR 0.0000
Epoch 261 batch 00008: Loss 0.3525 Regression loss 0.0152 Classification loss 0.3373 AP 0.2000 AR 0.2000
Epoch 261 batch 00009: Loss 0.3837 Regression loss 0.0217 Classification loss 0.3619 AP 0.6000 AR 0.2000
Epoch 261 batch 00010: Loss 0.4810 Regression loss 0.0194 Classification loss 0.4616 AP 0.8000 AR 0.0000
Epoch 262 batch 00001: Loss 0.5662 Regression loss 0.0238 Classification loss 0.5425 AP 0.8000 AR 0.2000
Epoch 262 batch 00002: Loss 0.3873 Regression loss 0.0184 Classification loss 0.3690 AP 0.6000 AR 0.0500
Epoch 262 batch 00003: Loss 0.4708 Regression loss 0.0187 Classification loss 0.4522 AP 0.6000 AR 0.0000
Epoch 262 batch 00004: Loss 0.4509 Regression loss 0.0180 Classification loss 0.4329 AP 0.5000 AR 0.2000
Epoch 262 batch 00005: Loss 0.4435 Regression loss 0.0192 Classification loss 0.4243 AP 0.4667 AR 0.1400
Epoch 262 batch 00006: Loss 0.4032 Regression loss 0.0170 Classification loss 0.3862 AP 0.3833 AR 0.2167
Epoch 262 batch 00007: Loss 0.4378 Regression loss 0.0164 Classification loss 0.4214 AP 0.4000 AR 0.0000
Epoch 262 batch 00008: Loss 0.4144 Regression loss 0.0173 Classification loss 0.3972 AP 0.4000 AR 0.0000
Epoch 262 batch 00009: Loss 0.3327 Regression loss 0.0176 Classification loss 0.3151 AP 0.7000 AR 0.2700
Epoch 262 batch 00010: Loss 0.6365 Regression loss 0.0203 Classification loss 0.6162 AP 0.6000 AR 0.0000
Epoch 263 batch 00001: Loss 0.4232 Regression loss 0.0168 Classification loss 0.4064 AP 0.3333 AR 0.1500
Epoch 263 batch 00002: Loss 0.6861 Regression loss 0.0185 Classification loss 0.6676 AP 0.8000 AR 0.0000
Epoch 263 batch 00003: Loss 0.3473 Regression loss 0.0206 Classification loss 0.3267 AP 0.0000 AR 0.0000
Epoch 263 batch 00004: Loss 0.4088 Regression loss 0.0231 Classification loss 0.3857 AP 0.2000 AR 0.0000
Epoch 263 batch 00005: Loss 0.3996 Regression loss 0.0196 Classification loss 0.3800 AP 0.2000 AR 0.0000
Epoch 263 batch 00006: Loss 0.4103 Regression loss 0.0182 Classification loss 0.3921 AP 0.8000 AR 0.0500
Epoch 263 batch 00007: Loss 0.3963 Regression loss 0.0192 Classification loss 0.3771 AP 0.7000 AR 0.0500
Epoch 263 batch 00008: Loss 0.3965 Regression loss 0.0137 Classification loss 0.3828 AP 0.4000 AR 0.0000
Epoch 263 batch 00009: Loss 0.5100 Regression loss 0.0180 Classification loss 0.4919 AP 0.5000 AR 0.0500
Epoch 263 batch 00010: Loss 0.4658 Regression loss 0.0197 Classification loss 0.4461 AP 0.8000 AR 0.2400
Epoch 264 batch 00001: Loss 0.5456 Regression loss 0.0200 Classification loss 0.5257 AP 0.4000 AR 0.0000
Epoch 264 batch 00002: Loss 0.5607 Regression loss 0.0308 Classification loss 0.5299 AP 0.6000 AR 0.0000
Epoch 264 batch 00003: Loss 0.4570 Regression loss 0.0136 Classification loss 0.4434 AP 0.7000 AR 0.0500
Epoch 264 batch 00004: Loss 0.3683 Regression loss 0.0156 Classification loss 0.3526 AP 0.6000 AR 0.4000
Epoch 264 batch 00005: Loss 0.4598 Regression loss 0.0154 Classification loss 0.4444 AP 0.8000 AR 0.1400
Epoch 264 batch 00006: Loss 0.4194 Regression loss 0.0168 Classification loss 0.4025 AP 0.4500 AR 0.0667
Epoch 264 batch 00007: Loss 0.3157 Regression loss 0.0168 Classification loss 0.2989 AP 0.7067 AR 0.0900
Epoch 264 batch 00008: Loss 0.3409 Regression loss 0.0194 Classification loss 0.3215 AP 0.0000 AR 0.0000
Epoch 264 batch 00009: Loss 0.4501 Regression loss 0.0191 Classification loss 0.4310 AP 0.4000 AR 0.0000
Epoch 264 batch 00010: Loss 0.5054 Regression loss 0.0191 Classification loss 0.4863 AP 0.5667 AR 0.0900
Epoch 265 batch 00001: Loss 0.5219 Regression loss 0.0190 Classification loss 0.5029 AP 0.4667 AR 0.2500
Epoch 265 batch 00002: Loss 0.4513 Regression loss 0.0192 Classification loss 0.4321 AP 0.6000 AR 0.2000
Epoch 265 batch 00003: Loss 0.4691 Regression loss 0.0214 Classification loss 0.4476 AP 0.6000 AR 0.0000
Epoch 265 batch 00004: Loss 0.4062 Regression loss 0.0159 Classification loss 0.3903 AP 0.3500 AR 0.1167
Epoch 265 batch 00005: Loss 0.4184 Regression loss 0.0208 Classification loss 0.3976 AP 0.2500 AR 0.0400
Epoch 265 batch 00006: Loss 0.3709 Regression loss 0.0180 Classification loss 0.3529 AP 0.5667 AR 0.0900
Epoch 265 batch 00007: Loss 0.4858 Regression loss 0.0200 Classification loss 0.4658 AP 0.4667 AR 0.0900
Epoch 265 batch 00008: Loss 0.3840 Regression loss 0.0156 Classification loss 0.3685 AP 0.6000 AR 0.0000
Epoch 265 batch 00009: Loss 0.3361 Regression loss 0.0192 Classification loss 0.3169 AP 0.5000 AR 0.0800
Epoch 265 batch 00010: Loss 0.5026 Regression loss 0.0154 Classification loss 0.4872 AP 0.6000 AR 0.0000
Epoch 266 batch 00001: Loss 0.3883 Regression loss 0.0169 Classification loss 0.3714 AP 0.4667 AR 0.0400
Epoch 266 batch 00002: Loss 0.3572 Regression loss 0.0149 Classification loss 0.3423 AP 0.4167 AR 0.2667
Epoch 266 batch 00003: Loss 0.4585 Regression loss 0.0195 Classification loss 0.4391 AP 0.8000 AR 0.0000
Epoch 266 batch 00004: Loss 0.3861 Regression loss 0.0212 Classification loss 0.3649 AP 0.7000 AR 0.0400
Epoch 266 batch 00005: Loss 0.4807 Regression loss 0.0174 Classification loss 0.4633 AP 0.4667 AR 0.2500
Epoch 266 batch 00006: Loss 0.4449 Regression loss 0.0188 Classification loss 0.4261 AP 0.2000 AR 0.0000
Epoch 266 batch 00007: Loss 0.3235 Regression loss 0.0176 Classification loss 0.3059 AP 0.6833 AR 0.1900
Epoch 266 batch 00008: Loss 0.4024 Regression loss 0.0172 Classification loss 0.3852 AP 0.6000 AR 0.2500
Epoch 266 batch 00009: Loss 0.4287 Regression loss 0.0165 Classification loss 0.4121 AP 0.5000 AR 0.0500
Epoch 266 batch 00010: Loss 0.4258 Regression loss 0.0188 Classification loss 0.4070 AP 0.7667 AR 0.0900
Epoch 267 batch 00001: Loss 0.3923 Regression loss 0.0156 Classification loss 0.3767 AP 0.4833 AR 0.3000
Epoch 267 batch 00002: Loss 0.3489 Regression loss 0.0170 Classification loss 0.3319 AP 0.8333 AR 0.3600
Epoch 267 batch 00003: Loss 0.4783 Regression loss 0.0227 Classification loss 0.4556 AP 0.6000 AR 0.0000
Epoch 267 batch 00004: Loss 0.3392 Regression loss 0.0169 Classification loss 0.3224 AP 0.4500 AR 0.2667
Epoch 267 batch 00005: Loss 0.4355 Regression loss 0.0183 Classification loss 0.4172 AP 0.6000 AR 0.1000
Epoch 267 batch 00006: Loss 0.3299 Regression loss 0.0162 Classification loss 0.3137 AP 0.6000 AR 0.0000
Epoch 267 batch 00007: Loss 0.4583 Regression loss 0.0140 Classification loss 0.4443 AP 0.7000 AR 0.0500
Epoch 267 batch 00008: Loss 0.4148 Regression loss 0.0152 Classification loss 0.3996 AP 0.2400 AR 0.0500
Epoch 267 batch 00009: Loss 0.4396 Regression loss 0.0197 Classification loss 0.4199 AP 0.6000 AR 0.0500
Epoch 267 batch 00010: Loss 0.5236 Regression loss 0.0254 Classification loss 0.4982 AP 0.8000 AR 0.1000
Epoch 268 batch 00001: Loss 0.3953 Regression loss 0.0177 Classification loss 0.3775 AP 0.2667 AR 0.1000
Epoch 268 batch 00002: Loss 0.4612 Regression loss 0.0191 Classification loss 0.4422 AP 0.6667 AR 0.0400
Epoch 268 batch 00003: Loss 0.4903 Regression loss 0.0206 Classification loss 0.4697 AP 0.6000 AR 0.0000
Epoch 268 batch 00004: Loss 0.3329 Regression loss 0.0163 Classification loss 0.3166 AP 0.5000 AR 0.1500
Epoch 268 batch 00005: Loss 0.4329 Regression loss 0.0168 Classification loss 0.4161 AP 0.8667 AR 0.3500
Epoch 268 batch 00006: Loss 0.3240 Regression loss 0.0149 Classification loss 0.3091 AP 0.6500 AR 0.1867
Epoch 268 batch 00007: Loss 0.4231 Regression loss 0.0161 Classification loss 0.4070 AP 0.7667 AR 0.1400
Epoch 268 batch 00008: Loss 0.5257 Regression loss 0.0174 Classification loss 0.5082 AP 0.4000 AR 0.2000
Epoch 268 batch 00009: Loss 0.4501 Regression loss 0.0192 Classification loss 0.4308 AP 0.6000 AR 0.0000
Epoch 268 batch 00010: Loss 0.3747 Regression loss 0.0172 Classification loss 0.3575 AP 0.2000 AR 0.2000
Epoch 269 batch 00001: Loss 0.3421 Regression loss 0.0182 Classification loss 0.3239 AP 0.5167 AR 0.3067
Epoch 269 batch 00002: Loss 0.4504 Regression loss 0.0168 Classification loss 0.4337 AP 0.6667 AR 0.1000
Epoch 269 batch 00003: Loss 0.5002 Regression loss 0.0170 Classification loss 0.4832 AP 0.8000 AR 0.1000
Epoch 269 batch 00004: Loss 0.3621 Regression loss 0.0192 Classification loss 0.3429 AP 0.4000 AR 0.0000
Epoch 269 batch 00005: Loss 0.5433 Regression loss 0.0203 Classification loss 0.5230 AP 0.6667 AR 0.0500
Epoch 269 batch 00006: Loss 0.3580 Regression loss 0.0155 Classification loss 0.3425 AP 0.2667 AR 0.0500
Epoch 269 batch 00007: Loss 0.3343 Regression loss 0.0180 Classification loss 0.3163 AP 0.7000 AR 0.0400
Epoch 269 batch 00008: Loss 0.3165 Regression loss 0.0122 Classification loss 0.3042 AP 0.5333 AR 0.3300
Epoch 269 batch 00009: Loss 0.3940 Regression loss 0.0122 Classification loss 0.3818 AP 0.5000 AR 0.1000
Epoch 269 batch 00010: Loss 0.5395 Regression loss 0.0172 Classification loss 0.5223 AP 0.2000 AR 0.0000
Epoch 270 batch 00001: Loss 0.3431 Regression loss 0.0172 Classification loss 0.3259 AP 0.7333 AR 0.0800
Epoch 270 batch 00002: Loss 0.4219 Regression loss 0.0179 Classification loss 0.4040 AP 0.2000 AR 0.0000
Epoch 270 batch 00003: Loss 0.5133 Regression loss 0.0171 Classification loss 0.4962 AP 0.9000 AR 0.4067
Epoch 270 batch 00004: Loss 0.4734 Regression loss 0.0162 Classification loss 0.4572 AP 0.8000 AR 0.2000
Epoch 270 batch 00005: Loss 0.6176 Regression loss 0.0167 Classification loss 0.6008 AP 0.5667 AR 0.1500
Epoch 270 batch 00006: Loss 0.3448 Regression loss 0.0188 Classification loss 0.3260 AP 0.7500 AR 0.1500
Epoch 270 batch 00007: Loss 0.2840 Regression loss 0.0144 Classification loss 0.2696 AP 0.4500 AR 0.0667
Epoch 270 batch 00008: Loss 0.4043 Regression loss 0.0166 Classification loss 0.3877 AP 0.7333 AR 0.3400
Epoch 270 batch 00009: Loss 0.5493 Regression loss 0.0181 Classification loss 0.5312 AP 0.2000 AR 0.0000
Epoch 270 batch 00010: Loss 0.3964 Regression loss 0.0164 Classification loss 0.3800 AP 0.3333 AR 0.0900
Epoch 271 batch 00001: Loss 0.4490 Regression loss 0.0243 Classification loss 0.4247 AP 0.8000 AR 0.0000
Epoch 271 batch 00002: Loss 0.3080 Regression loss 0.0123 Classification loss 0.2958 AP 0.3800 AR 0.1300
Epoch 271 batch 00003: Loss 0.3524 Regression loss 0.0158 Classification loss 0.3365 AP 0.5667 AR 0.1500
Epoch 271 batch 00004: Loss 0.4813 Regression loss 0.0186 Classification loss 0.4628 AP 0.4667 AR 0.1000
Epoch 271 batch 00005: Loss 0.4894 Regression loss 0.0123 Classification loss 0.4771 AP 0.6000 AR 0.0000
Epoch 271 batch 00006: Loss 0.4113 Regression loss 0.0168 Classification loss 0.3945 AP 0.4333 AR 0.0500
Epoch 271 batch 00007: Loss 0.3568 Regression loss 0.0173 Classification loss 0.3395 AP 0.5167 AR 0.3067
Epoch 271 batch 00008: Loss 0.4239 Regression loss 0.0169 Classification loss 0.4070 AP 0.4000 AR 0.0000
Epoch 271 batch 00009: Loss 0.4036 Regression loss 0.0176 Classification loss 0.3860 AP 0.2667 AR 0.3000
Epoch 271 batch 00010: Loss 0.5067 Regression loss 0.0174 Classification loss 0.4893 AP 0.7000 AR 0.2400
Epoch 272 batch 00001: Loss 0.4092 Regression loss 0.0156 Classification loss 0.3936 AP 0.6000 AR 0.3500
Epoch 272 batch 00002: Loss 0.2949 Regression loss 0.0177 Classification loss 0.2772 AP 0.5000 AR 0.3167
Epoch 272 batch 00003: Loss 0.3673 Regression loss 0.0166 Classification loss 0.3507 AP 0.0667 AR 0.0400
Epoch 272 batch 00004: Loss 0.4772 Regression loss 0.0146 Classification loss 0.4626 AP 0.7000 AR 0.1000
Epoch 272 batch 00005: Loss 0.4435 Regression loss 0.0155 Classification loss 0.4280 AP 0.8000 AR 0.2400
Epoch 272 batch 00006: Loss 0.4885 Regression loss 0.0180 Classification loss 0.4705 AP 0.4000 AR 0.0000
Epoch 272 batch 00007: Loss 0.5299 Regression loss 0.0185 Classification loss 0.5114 AP 0.5000 AR 0.0400
Epoch 272 batch 00008: Loss 0.3317 Regression loss 0.0166 Classification loss 0.3151 AP 0.7333 AR 0.0800
Epoch 272 batch 00009: Loss 0.4281 Regression loss 0.0178 Classification loss 0.4103 AP 0.8667 AR 0.2000
Epoch 272 batch 00010: Loss 0.3963 Regression loss 0.0219 Classification loss 0.3744 AP 0.6000 AR 0.0000
Epoch 273 batch 00001: Loss 0.3353 Regression loss 0.0158 Classification loss 0.3195 AP 0.5133 AR 0.1300
Epoch 273 batch 00002: Loss 0.5064 Regression loss 0.0210 Classification loss 0.4853 AP 0.6000 AR 0.0000
Epoch 273 batch 00003: Loss 0.3303 Regression loss 0.0155 Classification loss 0.3148 AP 0.6000 AR 0.2500
Epoch 273 batch 00004: Loss 0.3898 Regression loss 0.0154 Classification loss 0.3745 AP 0.8000 AR 0.2000
Epoch 273 batch 00005: Loss 0.2703 Regression loss 0.0154 Classification loss 0.2550 AP 0.8667 AR 0.1000
Epoch 273 batch 00006: Loss 0.4169 Regression loss 0.0168 Classification loss 0.4000 AP 0.4000 AR 0.1000
Epoch 273 batch 00007: Loss 0.6135 Regression loss 0.0179 Classification loss 0.5956 AP 0.5000 AR 0.0500
Epoch 273 batch 00008: Loss 0.4878 Regression loss 0.0179 Classification loss 0.4699 AP 0.4000 AR 0.1567
Epoch 273 batch 00009: Loss 0.6073 Regression loss 0.0271 Classification loss 0.5802 AP 0.6667 AR 0.1000
Epoch 273 batch 00010: Loss 0.4170 Regression loss 0.0183 Classification loss 0.3986 AP 0.4286 AR 0.0400
Epoch 274 batch 00001: Loss 0.5085 Regression loss 0.0182 Classification loss 0.4902 AP 0.6000 AR 0.0000
Epoch 274 batch 00002: Loss 0.4136 Regression loss 0.0193 Classification loss 0.3943 AP 0.2167 AR 0.1400
Epoch 274 batch 00003: Loss 0.5079 Regression loss 0.0178 Classification loss 0.4901 AP 0.4000 AR 0.0000
Epoch 274 batch 00004: Loss 0.4670 Regression loss 0.0185 Classification loss 0.4485 AP 0.6000 AR 0.0000
Epoch 274 batch 00005: Loss 0.3669 Regression loss 0.0197 Classification loss 0.3472 AP 0.4000 AR 0.0000
Epoch 274 batch 00006: Loss 0.4999 Regression loss 0.0172 Classification loss 0.4827 AP 0.7000 AR 0.0400
Epoch 274 batch 00007: Loss 0.4190 Regression loss 0.0180 Classification loss 0.4010 AP 0.4400 AR 0.0500
Epoch 274 batch 00008: Loss 0.3649 Regression loss 0.0225 Classification loss 0.3424 AP 0.5000 AR 0.0400
Epoch 274 batch 00009: Loss 0.6372 Regression loss 0.0159 Classification loss 0.6213 AP 0.8667 AR 0.2000
Epoch 274 batch 00010: Loss 0.3566 Regression loss 0.0167 Classification loss 0.3399 AP 0.4000 AR 0.4000
Epoch 275 batch 00001: Loss 0.4680 Regression loss 0.0263 Classification loss 0.4417 AP 0.6667 AR 0.2400
Epoch 275 batch 00002: Loss 0.4797 Regression loss 0.0182 Classification loss 0.4615 AP 0.7000 AR 0.0400
Epoch 275 batch 00003: Loss 0.4818 Regression loss 0.0214 Classification loss 0.4605 AP 0.6000 AR 0.0000
Epoch 275 batch 00004: Loss 0.3874 Regression loss 0.0127 Classification loss 0.3746 AP 0.4000 AR 0.0000
Epoch 275 batch 00005: Loss 0.5120 Regression loss 0.0170 Classification loss 0.4950 AP 0.4000 AR 0.0000
Epoch 275 batch 00006: Loss 0.4729 Regression loss 0.0169 Classification loss 0.4560 AP 0.4000 AR 0.0000
Epoch 275 batch 00007: Loss 0.3043 Regression loss 0.0163 Classification loss 0.2880 AP 0.3467 AR 0.1800
Epoch 275 batch 00008: Loss 0.6850 Regression loss 0.0166 Classification loss 0.6684 AP 0.4000 AR 0.0000
Epoch 275 batch 00009: Loss 0.3990 Regression loss 0.0189 Classification loss 0.3801 AP 0.6000 AR 0.0000
Epoch 275 batch 00010: Loss 0.4943 Regression loss 0.0190 Classification loss 0.4753 AP 0.4000 AR 0.2000
Epoch 276 batch 00001: Loss 0.4087 Regression loss 0.0167 Classification loss 0.3920 AP 0.3333 AR 0.0800
Epoch 276 batch 00002: Loss 0.4950 Regression loss 0.0176 Classification loss 0.4774 AP 0.4500 AR 0.0667
Epoch 276 batch 00003: Loss 0.3820 Regression loss 0.0195 Classification loss 0.3626 AP 0.4000 AR 0.2000
Epoch 276 batch 00004: Loss 0.3947 Regression loss 0.0145 Classification loss 0.3802 AP 0.2000 AR 0.0000
Epoch 276 batch 00005: Loss 0.5342 Regression loss 0.0208 Classification loss 0.5134 AP 0.6000 AR 0.1000
Epoch 276 batch 00006: Loss 0.4602 Regression loss 0.0172 Classification loss 0.4430 AP 0.6667 AR 0.0400
Epoch 276 batch 00007: Loss 0.5457 Regression loss 0.0219 Classification loss 0.5238 AP 0.7000 AR 0.0500
Epoch 276 batch 00008: Loss 0.4902 Regression loss 0.0134 Classification loss 0.4768 AP 0.6000 AR 0.2000
Epoch 276 batch 00009: Loss 0.3032 Regression loss 0.0161 Classification loss 0.2871 AP 0.3000 AR 0.1000
Epoch 276 batch 00010: Loss 0.5147 Regression loss 0.0206 Classification loss 0.4941 AP 0.6667 AR 0.0500
Epoch 277 batch 00001: Loss 0.4241 Regression loss 0.0169 Classification loss 0.4071 AP 0.4667 AR 0.2500
Epoch 277 batch 00002: Loss 0.3258 Regression loss 0.0174 Classification loss 0.3085 AP 0.6000 AR 0.2800
Epoch 277 batch 00003: Loss 0.3144 Regression loss 0.0148 Classification loss 0.2996 AP 0.8667 AR 0.0500
Epoch 277 batch 00004: Loss 0.3755 Regression loss 0.0180 Classification loss 0.3575 AP 0.2333 AR 0.0500
Epoch 277 batch 00005: Loss 0.3591 Regression loss 0.0172 Classification loss 0.3420 AP 0.4000 AR 0.0000
Epoch 277 batch 00006: Loss 0.5424 Regression loss 0.0199 Classification loss 0.5224 AP 0.8000 AR 0.0000
Epoch 277 batch 00007: Loss 0.4014 Regression loss 0.0197 Classification loss 0.3818 AP 0.7000 AR 0.0400
Epoch 277 batch 00008: Loss 0.4599 Regression loss 0.0234 Classification loss 0.4365 AP 0.4667 AR 0.1000
Epoch 277 batch 00009: Loss 0.4774 Regression loss 0.0171 Classification loss 0.4603 AP 0.2000 AR 0.0000
Epoch 277 batch 00010: Loss 0.5576 Regression loss 0.0180 Classification loss 0.5395 AP 0.5000 AR 0.1500
Epoch 278 batch 00001: Loss 0.3677 Regression loss 0.0163 Classification loss 0.3514 AP 0.3667 AR 0.2000
Epoch 278 batch 00002: Loss 0.5668 Regression loss 0.0200 Classification loss 0.5468 AP 0.7000 AR 0.0400
Epoch 278 batch 00003: Loss 0.3855 Regression loss 0.0202 Classification loss 0.3653 AP 0.6667 AR 0.3000
Epoch 278 batch 00004: Loss 0.2875 Regression loss 0.0171 Classification loss 0.2704 AP 0.7000 AR 0.1000
Epoch 278 batch 00005: Loss 0.5139 Regression loss 0.0180 Classification loss 0.4959 AP 0.4000 AR 0.0400
Epoch 278 batch 00006: Loss 0.4169 Regression loss 0.0203 Classification loss 0.3966 AP 0.8000 AR 0.2000
Epoch 278 batch 00007: Loss 0.4526 Regression loss 0.0156 Classification loss 0.4370 AP 0.8000 AR 0.1000
Epoch 278 batch 00008: Loss 0.4412 Regression loss 0.0215 Classification loss 0.4197 AP 0.6000 AR 0.0400
Epoch 278 batch 00009: Loss 0.5097 Regression loss 0.0217 Classification loss 0.4880 AP 0.6667 AR 0.0500
Epoch 278 batch 00010: Loss 0.3168 Regression loss 0.0164 Classification loss 0.3004 AP 0.2686 AR 0.1167
Epoch 279 batch 00001: Loss 0.3690 Regression loss 0.0186 Classification loss 0.3504 AP 0.6500 AR 0.0400
Epoch 279 batch 00002: Loss 0.4177 Regression loss 0.0184 Classification loss 0.3994 AP 0.5400 AR 0.1500
Epoch 279 batch 00003: Loss 0.3894 Regression loss 0.0118 Classification loss 0.3776 AP 0.1286 AR 0.1500
Epoch 279 batch 00004: Loss 0.3444 Regression loss 0.0161 Classification loss 0.3283 AP 0.4000 AR 0.2000
Epoch 279 batch 00005: Loss 0.5246 Regression loss 0.0162 Classification loss 0.5084 AP 0.4000 AR 0.1000
Epoch 279 batch 00006: Loss 0.4236 Regression loss 0.0182 Classification loss 0.4054 AP 0.7500 AR 0.1467
Epoch 279 batch 00007: Loss 0.4942 Regression loss 0.0185 Classification loss 0.4758 AP 0.6667 AR 0.1000
Epoch 279 batch 00008: Loss 0.3992 Regression loss 0.0195 Classification loss 0.3797 AP 0.8000 AR 0.0000
Epoch 279 batch 00009: Loss 0.4509 Regression loss 0.0222 Classification loss 0.4287 AP 0.6000 AR 0.2000
Epoch 279 batch 00010: Loss 0.4209 Regression loss 0.0197 Classification loss 0.4013 AP 0.5000 AR 0.0400
Epoch 280 batch 00001: Loss 0.3978 Regression loss 0.0175 Classification loss 0.3802 AP 0.4400 AR 0.0667
Epoch 280 batch 00002: Loss 0.4456 Regression loss 0.0200 Classification loss 0.4257 AP 0.8000 AR 0.1000
Epoch 280 batch 00003: Loss 0.5313 Regression loss 0.0166 Classification loss 0.5148 AP 0.5000 AR 0.0500
Epoch 280 batch 00004: Loss 0.3053 Regression loss 0.0169 Classification loss 0.2884 AP 0.8000 AR 0.2500
Epoch 280 batch 00005: Loss 0.3822 Regression loss 0.0185 Classification loss 0.3637 AP 0.6400 AR 0.2500
Epoch 280 batch 00006: Loss 0.4327 Regression loss 0.0116 Classification loss 0.4211 AP 0.3333 AR 0.2000
Epoch 280 batch 00007: Loss 0.4429 Regression loss 0.0176 Classification loss 0.4253 AP 0.3000 AR 0.0400
Epoch 280 batch 00008: Loss 0.5429 Regression loss 0.0223 Classification loss 0.5207 AP 0.6000 AR 0.0000
Epoch 280 batch 00009: Loss 0.4421 Regression loss 0.0176 Classification loss 0.4245 AP 0.7333 AR 0.0800
Epoch 280 batch 00010: Loss 0.3838 Regression loss 0.0179 Classification loss 0.3659 AP 0.4667 AR 0.0500
Epoch 281 batch 00001: Loss 0.2981 Regression loss 0.0157 Classification loss 0.2824 AP 0.5333 AR 0.0800
Epoch 281 batch 00002: Loss 0.3616 Regression loss 0.0184 Classification loss 0.3432 AP 0.4000 AR 0.0000
Epoch 281 batch 00003: Loss 0.3662 Regression loss 0.0182 Classification loss 0.3480 AP 0.4500 AR 0.0667
Epoch 281 batch 00004: Loss 0.3715 Regression loss 0.0179 Classification loss 0.3536 AP 0.4000 AR 0.1400
Epoch 281 batch 00005: Loss 0.4596 Regression loss 0.0168 Classification loss 0.4428 AP 0.5000 AR 0.1000
Epoch 281 batch 00006: Loss 0.5264 Regression loss 0.0207 Classification loss 0.5057 AP 0.6000 AR 0.0000
Epoch 281 batch 00007: Loss 0.5284 Regression loss 0.0202 Classification loss 0.5082 AP 0.6000 AR 0.0000
Epoch 281 batch 00008: Loss 0.3364 Regression loss 0.0179 Classification loss 0.3185 AP 0.6667 AR 0.3500
Epoch 281 batch 00009: Loss 0.5708 Regression loss 0.0177 Classification loss 0.5531 AP 0.4000 AR 0.0000
Epoch 281 batch 00010: Loss 0.5361 Regression loss 0.0183 Classification loss 0.5178 AP 0.4500 AR 0.0500
Epoch 282 batch 00001: Loss 0.3170 Regression loss 0.0135 Classification loss 0.3035 AP 0.6000 AR 0.2000
Epoch 282 batch 00002: Loss 0.4590 Regression loss 0.0182 Classification loss 0.4408 AP 0.6000 AR 0.0000
Epoch 282 batch 00003: Loss 0.3839 Regression loss 0.0172 Classification loss 0.3667 AP 0.3167 AR 0.2167
Epoch 282 batch 00004: Loss 0.2968 Regression loss 0.0179 Classification loss 0.2789 AP 0.9000 AR 0.2900
Epoch 282 batch 00005: Loss 0.5056 Regression loss 0.0197 Classification loss 0.4860 AP 0.6667 AR 0.1500
Epoch 282 batch 00006: Loss 0.4693 Regression loss 0.0164 Classification loss 0.4529 AP 0.2400 AR 0.0500
Epoch 282 batch 00007: Loss 0.5346 Regression loss 0.0111 Classification loss 0.5235 AP 0.6000 AR 0.0000
Epoch 282 batch 00008: Loss 0.4123 Regression loss 0.0184 Classification loss 0.3939 AP 0.4167 AR 0.3400
Epoch 282 batch 00009: Loss 0.3981 Regression loss 0.0180 Classification loss 0.3801 AP 0.6000 AR 0.0000
Epoch 282 batch 00010: Loss 0.4164 Regression loss 0.0165 Classification loss 0.3999 AP 0.5000 AR 0.1000
Epoch 283 batch 00001: Loss 0.4310 Regression loss 0.0166 Classification loss 0.4144 AP 0.2000 AR 0.0000
Epoch 283 batch 00002: Loss 0.3843 Regression loss 0.0222 Classification loss 0.3621 AP 0.6000 AR 0.0500
Epoch 283 batch 00003: Loss 0.3979 Regression loss 0.0120 Classification loss 0.3859 AP 0.6000 AR 0.0000
Epoch 283 batch 00004: Loss 0.3389 Regression loss 0.0191 Classification loss 0.3198 AP 0.7167 AR 0.1067
Epoch 283 batch 00005: Loss 0.4947 Regression loss 0.0161 Classification loss 0.4786 AP 0.8000 AR 0.0000
Epoch 283 batch 00006: Loss 0.3633 Regression loss 0.0198 Classification loss 0.3435 AP 0.5500 AR 0.2900
Epoch 283 batch 00007: Loss 0.3467 Regression loss 0.0133 Classification loss 0.3334 AP 0.5333 AR 0.1400
Epoch 283 batch 00008: Loss 0.5518 Regression loss 0.0227 Classification loss 0.5291 AP 1.0000 AR 0.2400
Epoch 283 batch 00009: Loss 0.4353 Regression loss 0.0157 Classification loss 0.4196 AP 0.2500 AR 0.0500
Epoch 283 batch 00010: Loss 0.5422 Regression loss 0.0124 Classification loss 0.5298 AP 0.5000 AR 0.2000
Epoch 284 batch 00001: Loss 0.4620 Regression loss 0.0171 Classification loss 0.4450 AP 0.5167 AR 0.0900
Epoch 284 batch 00002: Loss 0.3108 Regression loss 0.0128 Classification loss 0.2980 AP 0.1000 AR 0.0500
Epoch 284 batch 00003: Loss 0.3695 Regression loss 0.0204 Classification loss 0.3491 AP 0.8000 AR 0.0500
Epoch 284 batch 00004: Loss 0.3921 Regression loss 0.0157 Classification loss 0.3765 AP 0.4000 AR 0.1000
Epoch 284 batch 00005: Loss 0.4080 Regression loss 0.0162 Classification loss 0.3918 AP 0.6500 AR 0.0667
Epoch 284 batch 00006: Loss 0.3394 Regression loss 0.0140 Classification loss 0.3253 AP 0.7000 AR 0.2400
Epoch 284 batch 00007: Loss 0.3729 Regression loss 0.0151 Classification loss 0.3579 AP 0.5333 AR 0.0900
Epoch 284 batch 00008: Loss 0.5239 Regression loss 0.0178 Classification loss 0.5061 AP 0.5000 AR 0.0400
Epoch 284 batch 00009: Loss 0.4905 Regression loss 0.0184 Classification loss 0.4721 AP 0.6000 AR 0.2000
Epoch 284 batch 00010: Loss 0.4709 Regression loss 0.0202 Classification loss 0.4508 AP 0.4500 AR 0.2500
Epoch 285 batch 00001: Loss 0.3770 Regression loss 0.0188 Classification loss 0.3583 AP 0.8667 AR 0.2900
Epoch 285 batch 00002: Loss 0.3959 Regression loss 0.0129 Classification loss 0.3830 AP 0.3500 AR 0.1167
Epoch 285 batch 00003: Loss 0.3472 Regression loss 0.0161 Classification loss 0.3311 AP 0.7000 AR 0.2400
Epoch 285 batch 00004: Loss 0.3184 Regression loss 0.0193 Classification loss 0.2991 AP 0.7000 AR 0.0800
Epoch 285 batch 00005: Loss 0.4011 Regression loss 0.0199 Classification loss 0.3812 AP 0.4667 AR 0.0500
Epoch 285 batch 00006: Loss 0.4522 Regression loss 0.0157 Classification loss 0.4365 AP 0.5000 AR 0.1500
Epoch 285 batch 00007: Loss 0.4529 Regression loss 0.0220 Classification loss 0.4309 AP 0.6000 AR 0.0000
Epoch 285 batch 00008: Loss 0.4336 Regression loss 0.0140 Classification loss 0.4196 AP 0.6667 AR 0.3000
Epoch 285 batch 00009: Loss 0.5680 Regression loss 0.0097 Classification loss 0.5583 AP 0.4000 AR 0.0000
Epoch 285 batch 00010: Loss 0.4451 Regression loss 0.0181 Classification loss 0.4270 AP 0.4333 AR 0.1500
Epoch 286 batch 00001: Loss 0.4879 Regression loss 0.0203 Classification loss 0.4676 AP 0.8000 AR 0.1000
Epoch 286 batch 00002: Loss 0.4511 Regression loss 0.0150 Classification loss 0.4361 AP 0.6667 AR 0.2400
Epoch 286 batch 00003: Loss 0.4431 Regression loss 0.0167 Classification loss 0.4264 AP 0.2000 AR 0.0000
Epoch 286 batch 00004: Loss 0.5942 Regression loss 0.0206 Classification loss 0.5736 AP 1.0000 AR 0.2400
Epoch 286 batch 00005: Loss 0.4073 Regression loss 0.0159 Classification loss 0.3914 AP 0.3667 AR 0.0800
Epoch 286 batch 00006: Loss 0.3214 Regression loss 0.0187 Classification loss 0.3027 AP 0.6667 AR 0.0500
Epoch 286 batch 00007: Loss 0.2915 Regression loss 0.0167 Classification loss 0.2748 AP 0.4500 AR 0.0667
Epoch 286 batch 00008: Loss 0.4961 Regression loss 0.0167 Classification loss 0.4794 AP 0.5000 AR 0.1500
Epoch 286 batch 00009: Loss 0.3265 Regression loss 0.0153 Classification loss 0.3112 AP 0.5000 AR 0.0900
Epoch 286 batch 00010: Loss 0.3527 Regression loss 0.0167 Classification loss 0.3360 AP 0.6000 AR 0.0500
Epoch 287 batch 00001: Loss 0.4970 Regression loss 0.0179 Classification loss 0.4791 AP 0.6333 AR 0.1400
Epoch 287 batch 00002: Loss 0.5155 Regression loss 0.0161 Classification loss 0.4994 AP 0.8500 AR 0.0667
Epoch 287 batch 00003: Loss 0.3365 Regression loss 0.0197 Classification loss 0.3168 AP 0.6000 AR 0.0500
Epoch 287 batch 00004: Loss 0.4412 Regression loss 0.0201 Classification loss 0.4210 AP 0.7000 AR 0.3000
Epoch 287 batch 00005: Loss 0.5059 Regression loss 0.0163 Classification loss 0.4896 AP 0.2000 AR 0.0000
Epoch 287 batch 00006: Loss 0.4521 Regression loss 0.0156 Classification loss 0.4366 AP 0.2000 AR 0.0000
Epoch 287 batch 00007: Loss 0.2018 Regression loss 0.0096 Classification loss 0.1922 AP 0.8000 AR 0.3000
Epoch 287 batch 00008: Loss 0.2217 Regression loss 0.0144 Classification loss 0.2074 AP 0.3667 AR 0.1400
Epoch 287 batch 00009: Loss 0.4656 Regression loss 0.0212 Classification loss 0.4444 AP 1.0000 AR 0.1400
Epoch 287 batch 00010: Loss 0.3760 Regression loss 0.0220 Classification loss 0.3540 AP 0.6667 AR 0.2500
Epoch 288 batch 00001: Loss 0.3886 Regression loss 0.0195 Classification loss 0.3691 AP 0.4667 AR 0.2500
Epoch 288 batch 00002: Loss 0.3214 Regression loss 0.0152 Classification loss 0.3062 AP 0.6000 AR 0.2000
Epoch 288 batch 00003: Loss 0.3687 Regression loss 0.0192 Classification loss 0.3494 AP 0.2400 AR 0.0500
Epoch 288 batch 00004: Loss 0.4923 Regression loss 0.0196 Classification loss 0.4728 AP 0.8000 AR 0.0000
Epoch 288 batch 00005: Loss 0.4316 Regression loss 0.0185 Classification loss 0.4131 AP 0.4500 AR 0.0667
Epoch 288 batch 00006: Loss 0.3938 Regression loss 0.0156 Classification loss 0.3782 AP 0.3000 AR 0.1000
Epoch 288 batch 00007: Loss 0.4717 Regression loss 0.0213 Classification loss 0.4504 AP 0.8000 AR 0.0900
Epoch 288 batch 00008: Loss 0.4700 Regression loss 0.0147 Classification loss 0.4554 AP 0.4667 AR 0.2000
Epoch 288 batch 00009: Loss 0.3839 Regression loss 0.0166 Classification loss 0.3673 AP 0.7000 AR 0.0400
Epoch 288 batch 00010: Loss 0.5282 Regression loss 0.0119 Classification loss 0.5163 AP 0.6000 AR 0.2000
Epoch 289 batch 00001: Loss 0.3547 Regression loss 0.0132 Classification loss 0.3414 AP 0.6500 AR 0.0667
Epoch 289 batch 00002: Loss 0.3847 Regression loss 0.0172 Classification loss 0.3674 AP 0.7000 AR 0.2000
Epoch 289 batch 00003: Loss 0.4780 Regression loss 0.0151 Classification loss 0.4629 AP 0.6000 AR 0.0000
Epoch 289 batch 00004: Loss 0.3291 Regression loss 0.0180 Classification loss 0.3110 AP 0.1000 AR 0.0800
Epoch 289 batch 00005: Loss 0.4282 Regression loss 0.0189 Classification loss 0.4093 AP 0.4333 AR 0.0500
Epoch 289 batch 00006: Loss 0.4125 Regression loss 0.0127 Classification loss 0.3997 AP 0.3667 AR 0.2500
Epoch 289 batch 00007: Loss 0.5910 Regression loss 0.0179 Classification loss 0.5731 AP 0.7000 AR 0.1500
Epoch 289 batch 00008: Loss 0.4481 Regression loss 0.0200 Classification loss 0.4282 AP 0.8500 AR 0.2500
Epoch 289 batch 00009: Loss 0.3706 Regression loss 0.0174 Classification loss 0.3531 AP 0.4667 AR 0.2667
Epoch 289 batch 00010: Loss 0.4041 Regression loss 0.0189 Classification loss 0.3852 AP 0.5667 AR 0.1400
Epoch 290 batch 00001: Loss 0.2390 Regression loss 0.0177 Classification loss 0.2213 AP 0.9000 AR 0.2800
Epoch 290 batch 00002: Loss 0.5047 Regression loss 0.0168 Classification loss 0.4879 AP 0.8000 AR 0.0000
Epoch 290 batch 00003: Loss 0.5174 Regression loss 0.0238 Classification loss 0.4935 AP 0.4000 AR 0.0000
Epoch 290 batch 00004: Loss 0.3369 Regression loss 0.0165 Classification loss 0.3205 AP 0.5000 AR 0.0400
Epoch 290 batch 00005: Loss 0.6150 Regression loss 0.0187 Classification loss 0.5963 AP 1.0000 AR 0.1000
Epoch 290 batch 00006: Loss 0.4553 Regression loss 0.0166 Classification loss 0.4387 AP 0.4500 AR 0.0400
Epoch 290 batch 00007: Loss 0.3826 Regression loss 0.0165 Classification loss 0.3662 AP 0.1500 AR 0.1667
Epoch 290 batch 00008: Loss 0.4869 Regression loss 0.0209 Classification loss 0.4660 AP 0.7000 AR 0.3400
Epoch 290 batch 00009: Loss 0.3302 Regression loss 0.0177 Classification loss 0.3125 AP 0.6667 AR 0.2500
Epoch 290 batch 00010: Loss 0.4227 Regression loss 0.0153 Classification loss 0.4073 AP 0.5000 AR 0.1500
Epoch 291 batch 00001: Loss 0.4178 Regression loss 0.0159 Classification loss 0.4019 AP 0.6667 AR 0.0400
Epoch 291 batch 00002: Loss 0.4301 Regression loss 0.0146 Classification loss 0.4155 AP 0.2667 AR 0.0900
Epoch 291 batch 00003: Loss 0.3500 Regression loss 0.0141 Classification loss 0.3359 AP 0.4000 AR 0.1400
Epoch 291 batch 00004: Loss 0.3494 Regression loss 0.0132 Classification loss 0.3362 AP 0.6000 AR 0.0000
Epoch 291 batch 00005: Loss 0.4310 Regression loss 0.0208 Classification loss 0.4102 AP 0.7000 AR 0.0500
Epoch 291 batch 00006: Loss 0.4894 Regression loss 0.0172 Classification loss 0.4722 AP 0.5000 AR 0.2500
Epoch 291 batch 00007: Loss 0.4218 Regression loss 0.0215 Classification loss 0.4003 AP 0.4000 AR 0.3000
Epoch 291 batch 00008: Loss 0.4286 Regression loss 0.0160 Classification loss 0.4126 AP 0.8000 AR 0.1000
Epoch 291 batch 00009: Loss 0.4851 Regression loss 0.0154 Classification loss 0.4697 AP 0.8000 AR 0.0000
Epoch 291 batch 00010: Loss 0.3351 Regression loss 0.0184 Classification loss 0.3167 AP 0.4500 AR 0.1167
Epoch 292 batch 00001: Loss 0.3132 Regression loss 0.0171 Classification loss 0.2961 AP 0.5000 AR 0.0900
Epoch 292 batch 00002: Loss 0.3892 Regression loss 0.0179 Classification loss 0.3713 AP 0.4333 AR 0.1400
Epoch 292 batch 00003: Loss 0.4418 Regression loss 0.0150 Classification loss 0.4267 AP 0.6000 AR 0.0000
Epoch 292 batch 00004: Loss 0.4327 Regression loss 0.0160 Classification loss 0.4167 AP 0.8000 AR 0.2000
Epoch 292 batch 00005: Loss 0.4197 Regression loss 0.0142 Classification loss 0.4055 AP 0.4400 AR 0.1667
Epoch 292 batch 00006: Loss 0.5650 Regression loss 0.0171 Classification loss 0.5480 AP 0.6000 AR 0.1000
Epoch 292 batch 00007: Loss 0.5271 Regression loss 0.0189 Classification loss 0.5082 AP 0.8000 AR 0.0800
Epoch 292 batch 00008: Loss 0.3718 Regression loss 0.0167 Classification loss 0.3551 AP 0.6000 AR 0.2000
Epoch 292 batch 00009: Loss 0.3529 Regression loss 0.0162 Classification loss 0.3367 AP 0.5333 AR 0.0900
Epoch 292 batch 00010: Loss 0.3602 Regression loss 0.0132 Classification loss 0.3470 AP 0.3667 AR 0.1500
Epoch 293 batch 00001: Loss 0.4839 Regression loss 0.0162 Classification loss 0.4677 AP 0.7000 AR 0.1500
Epoch 293 batch 00002: Loss 0.4318 Regression loss 0.0145 Classification loss 0.4172 AP 0.5000 AR 0.3000
Epoch 293 batch 00003: Loss 0.4077 Regression loss 0.0169 Classification loss 0.3907 AP 0.4667 AR 0.1500
Epoch 293 batch 00004: Loss 0.2090 Regression loss 0.0156 Classification loss 0.1934 AP 0.8000 AR 0.1300
Epoch 293 batch 00005: Loss 0.4399 Regression loss 0.0157 Classification loss 0.4242 AP 0.4667 AR 0.1300
Epoch 293 batch 00006: Loss 0.4805 Regression loss 0.0164 Classification loss 0.4641 AP 0.4667 AR 0.1000
Epoch 293 batch 00007: Loss 0.3275 Regression loss 0.0198 Classification loss 0.3077 AP 0.4667 AR 0.0400
Epoch 293 batch 00008: Loss 0.3984 Regression loss 0.0179 Classification loss 0.3804 AP 0.6500 AR 0.0667
Epoch 293 batch 00009: Loss 0.5765 Regression loss 0.0151 Classification loss 0.5614 AP 0.6000 AR 0.0000
Epoch 293 batch 00010: Loss 0.4548 Regression loss 0.0161 Classification loss 0.4387 AP 0.6333 AR 0.2500
Epoch 294 batch 00001: Loss 0.4250 Regression loss 0.0181 Classification loss 0.4069 AP 0.6000 AR 0.1500
Epoch 294 batch 00002: Loss 0.5231 Regression loss 0.0121 Classification loss 0.5110 AP 0.3000 AR 0.0500
Epoch 294 batch 00003: Loss 0.4393 Regression loss 0.0164 Classification loss 0.4229 AP 0.6000 AR 0.2000
Epoch 294 batch 00004: Loss 0.5007 Regression loss 0.0182 Classification loss 0.4825 AP 0.9000 AR 0.0400
Epoch 294 batch 00005: Loss 0.4845 Regression loss 0.0211 Classification loss 0.4634 AP 0.8667 AR 0.1000
Epoch 294 batch 00006: Loss 0.2183 Regression loss 0.0146 Classification loss 0.2037 AP 0.5500 AR 0.3467
Epoch 294 batch 00007: Loss 0.3097 Regression loss 0.0099 Classification loss 0.2998 AP 0.5333 AR 0.1500
Epoch 294 batch 00008: Loss 0.3911 Regression loss 0.0182 Classification loss 0.3729 AP 0.7000 AR 0.0800
Epoch 294 batch 00009: Loss 0.5746 Regression loss 0.0170 Classification loss 0.5576 AP 0.1000 AR 0.0500
Epoch 294 batch 00010: Loss 0.4097 Regression loss 0.0203 Classification loss 0.3894 AP 0.4667 AR 0.0500
Epoch 295 batch 00001: Loss 0.4747 Regression loss 0.0206 Classification loss 0.4541 AP 0.5333 AR 0.1400
Epoch 295 batch 00002: Loss 0.4455 Regression loss 0.0144 Classification loss 0.4311 AP 0.6000 AR 0.0000
Epoch 295 batch 00003: Loss 0.3240 Regression loss 0.0180 Classification loss 0.3060 AP 0.5000 AR 0.0900
Epoch 295 batch 00004: Loss 0.4205 Regression loss 0.0172 Classification loss 0.4033 AP 0.6000 AR 0.0000
Epoch 295 batch 00005: Loss 0.3513 Regression loss 0.0161 Classification loss 0.3352 AP 0.2833 AR 0.2900
Epoch 295 batch 00006: Loss 0.4329 Regression loss 0.0163 Classification loss 0.4166 AP 0.8000 AR 0.3800
Epoch 295 batch 00007: Loss 0.4829 Regression loss 0.0156 Classification loss 0.4674 AP 0.1000 AR 0.0500
Epoch 295 batch 00008: Loss 0.5792 Regression loss 0.0183 Classification loss 0.5608 AP 0.6667 AR 0.0500
Epoch 295 batch 00009: Loss 0.2823 Regression loss 0.0130 Classification loss 0.2694 AP 0.7500 AR 0.2667
Epoch 295 batch 00010: Loss 0.3895 Regression loss 0.0174 Classification loss 0.3721 AP 0.6000 AR 0.0500
Epoch 296 batch 00001: Loss 0.5534 Regression loss 0.0184 Classification loss 0.5350 AP 0.5000 AR 0.0400
Epoch 296 batch 00002: Loss 0.4042 Regression loss 0.0199 Classification loss 0.3842 AP 0.7000 AR 0.3000
Epoch 296 batch 00003: Loss 0.2860 Regression loss 0.0154 Classification loss 0.2706 AP 0.5000 AR 0.2700
Epoch 296 batch 00004: Loss 0.3156 Regression loss 0.0192 Classification loss 0.2964 AP 0.6667 AR 0.0500
Epoch 296 batch 00005: Loss 0.4374 Regression loss 0.0141 Classification loss 0.4233 AP 0.7333 AR 0.1500
Epoch 296 batch 00006: Loss 0.5310 Regression loss 0.0152 Classification loss 0.5159 AP 0.6000 AR 0.0000
Epoch 296 batch 00007: Loss 0.4341 Regression loss 0.0199 Classification loss 0.4141 AP 0.8000 AR 0.3000
Epoch 296 batch 00008: Loss 0.3429 Regression loss 0.0155 Classification loss 0.3274 AP 0.2400 AR 0.0667
Epoch 296 batch 00009: Loss 0.4336 Regression loss 0.0150 Classification loss 0.4186 AP 0.0400 AR 0.0500
Epoch 296 batch 00010: Loss 0.4857 Regression loss 0.0213 Classification loss 0.4644 AP 0.4000 AR 0.0000
Epoch 297 batch 00001: Loss 0.5404 Regression loss 0.0147 Classification loss 0.5257 AP 0.4500 AR 0.0400
Epoch 297 batch 00002: Loss 0.5287 Regression loss 0.0273 Classification loss 0.5014 AP 0.6000 AR 0.0000
Epoch 297 batch 00003: Loss 0.4422 Regression loss 0.0171 Classification loss 0.4251 AP 0.8000 AR 0.2000
Epoch 297 batch 00004: Loss 0.5482 Regression loss 0.0138 Classification loss 0.5344 AP 0.6000 AR 0.0000
Epoch 297 batch 00005: Loss 0.4885 Regression loss 0.0170 Classification loss 0.4715 AP 0.7000 AR 0.0667
Epoch 297 batch 00006: Loss 0.4407 Regression loss 0.0164 Classification loss 0.4243 AP 0.5333 AR 0.3000
Epoch 297 batch 00007: Loss 0.4000 Regression loss 0.0165 Classification loss 0.3835 AP 0.5000 AR 0.2000
Epoch 297 batch 00008: Loss 0.3999 Regression loss 0.0162 Classification loss 0.3837 AP 0.3000 AR 0.0800
Epoch 297 batch 00009: Loss 0.3075 Regression loss 0.0160 Classification loss 0.2915 AP 0.4500 AR 0.1667
Epoch 297 batch 00010: Loss 0.3613 Regression loss 0.0188 Classification loss 0.3425 AP 0.3333 AR 0.0800
Epoch 298 batch 00001: Loss 0.3814 Regression loss 0.0139 Classification loss 0.3675 AP 0.2400 AR 0.0667
Epoch 298 batch 00002: Loss 0.3872 Regression loss 0.0156 Classification loss 0.3716 AP 0.6000 AR 0.3000
Epoch 298 batch 00003: Loss 0.4550 Regression loss 0.0203 Classification loss 0.4347 AP 0.9000 AR 0.1000
Epoch 298 batch 00004: Loss 0.4187 Regression loss 0.0167 Classification loss 0.4021 AP 0.5000 AR 0.0400
Epoch 298 batch 00005: Loss 0.5057 Regression loss 0.0191 Classification loss 0.4866 AP 0.6000 AR 0.0000
Epoch 298 batch 00006: Loss 0.4242 Regression loss 0.0160 Classification loss 0.4082 AP 0.5000 AR 0.1000
Epoch 298 batch 00007: Loss 0.2995 Regression loss 0.0143 Classification loss 0.2853 AP 0.2667 AR 0.0500
Epoch 298 batch 00008: Loss 0.3793 Regression loss 0.0178 Classification loss 0.3615 AP 0.6333 AR 0.3200
Epoch 298 batch 00009: Loss 0.5351 Regression loss 0.0153 Classification loss 0.5197 AP 0.6000 AR 0.1000
Epoch 298 batch 00010: Loss 0.4846 Regression loss 0.0220 Classification loss 0.4625 AP 0.8000 AR 0.0000
Epoch 299 batch 00001: Loss 0.3104 Regression loss 0.0185 Classification loss 0.2920 AP 0.3333 AR 0.0800
Epoch 299 batch 00002: Loss 0.4320 Regression loss 0.0167 Classification loss 0.4153 AP 0.3333 AR 0.3400
Epoch 299 batch 00003: Loss 0.3696 Regression loss 0.0158 Classification loss 0.3538 AP 0.2400 AR 0.0667
Epoch 299 batch 00004: Loss 0.3821 Regression loss 0.0196 Classification loss 0.3625 AP 0.6000 AR 0.0000
Epoch 299 batch 00005: Loss 0.4203 Regression loss 0.0159 Classification loss 0.4044 AP 0.4400 AR 0.0500
Epoch 299 batch 00006: Loss 0.4434 Regression loss 0.0165 Classification loss 0.4268 AP 0.4667 AR 0.0500
Epoch 299 batch 00007: Loss 0.4741 Regression loss 0.0157 Classification loss 0.4584 AP 0.5000 AR 0.3000
Epoch 299 batch 00008: Loss 0.4286 Regression loss 0.0178 Classification loss 0.4108 AP 0.8000 AR 0.0000
Epoch 299 batch 00009: Loss 0.4978 Regression loss 0.0131 Classification loss 0.4847 AP 0.8000 AR 0.0000
Epoch 299 batch 00010: Loss 0.4629 Regression loss 0.0175 Classification loss 0.4455 AP 0.3333 AR 0.0900
Epoch 300 batch 00001: Loss 0.3712 Regression loss 0.0146 Classification loss 0.3566 AP 0.4667 AR 0.0500
Epoch 300 batch 00002: Loss 0.4392 Regression loss 0.0175 Classification loss 0.4217 AP 0.7000 AR 0.2500
Epoch 300 batch 00003: Loss 0.4462 Regression loss 0.0169 Classification loss 0.4293 AP 0.2333 AR 0.0500
Epoch 300 batch 00004: Loss 0.3575 Regression loss 0.0169 Classification loss 0.3406 AP 0.6000 AR 0.0000
Epoch 300 batch 00005: Loss 0.4584 Regression loss 0.0167 Classification loss 0.4417 AP 0.4000 AR 0.0000
Epoch 300 batch 00006: Loss 0.2938 Regression loss 0.0161 Classification loss 0.2777 AP 0.2667 AR 0.0400
Epoch 300 batch 00007: Loss 0.3116 Regression loss 0.0169 Classification loss 0.2947 AP 0.7000 AR 0.3000
Epoch 300 batch 00008: Loss 0.5495 Regression loss 0.0194 Classification loss 0.5300 AP 0.6667 AR 0.2900
Epoch 300 batch 00009: Loss 0.6088 Regression loss 0.0139 Classification loss 0.5949 AP 0.8667 AR 0.2000
Epoch 300 batch 00010: Loss 0.3528 Regression loss 0.0188 Classification loss 0.3340 AP 0.9000 AR 0.1400
Epoch 301 batch 00001: Loss 0.3817 Regression loss 0.0146 Classification loss 0.3671 AP 0.5000 AR 0.2000
Epoch 301 batch 00002: Loss 0.3619 Regression loss 0.0148 Classification loss 0.3471 AP 0.5667 AR 0.1167
Epoch 301 batch 00003: Loss 0.5915 Regression loss 0.0256 Classification loss 0.5659 AP 1.0000 AR 0.0000
Epoch 301 batch 00004: Loss 0.5211 Regression loss 0.0197 Classification loss 0.5014 AP 0.7000 AR 0.3000
Epoch 301 batch 00005: Loss 0.3435 Regression loss 0.0134 Classification loss 0.3301 AP 0.2667 AR 0.3000
Epoch 301 batch 00006: Loss 0.4583 Regression loss 0.0151 Classification loss 0.4432 AP 0.5333 AR 0.0900
Epoch 301 batch 00007: Loss 0.5066 Regression loss 0.0167 Classification loss 0.4900 AP 0.6000 AR 0.0000
Epoch 301 batch 00008: Loss 0.6255 Regression loss 0.0166 Classification loss 0.6089 AP 0.7667 AR 0.0900
Epoch 301 batch 00009: Loss 0.2429 Regression loss 0.0147 Classification loss 0.2282 AP 0.6500 AR 0.1467
Epoch 301 batch 00010: Loss 0.5120 Regression loss 0.0179 Classification loss 0.4941 AP 0.5000 AR 0.0400
Epoch 302 batch 00001: Loss 0.3685 Regression loss 0.0195 Classification loss 0.3490 AP 0.2333 AR 0.0400
Epoch 302 batch 00002: Loss 0.4544 Regression loss 0.0230 Classification loss 0.4313 AP 0.6000 AR 0.0000
Epoch 302 batch 00003: Loss 0.3777 Regression loss 0.0187 Classification loss 0.3590 AP 0.6000 AR 0.0500
Epoch 302 batch 00004: Loss 0.3475 Regression loss 0.0128 Classification loss 0.3347 AP 0.7067 AR 0.4667
Epoch 302 batch 00005: Loss 0.4231 Regression loss 0.0158 Classification loss 0.4073 AP 0.6000 AR 0.0400
Epoch 302 batch 00006: Loss 0.5055 Regression loss 0.0153 Classification loss 0.4902 AP 0.4667 AR 0.0500
Epoch 302 batch 00007: Loss 0.4655 Regression loss 0.0183 Classification loss 0.4472 AP 1.0000 AR 0.1200
Epoch 302 batch 00008: Loss 0.3492 Regression loss 0.0145 Classification loss 0.3347 AP 0.2333 AR 0.0500
Epoch 302 batch 00009: Loss 0.5212 Regression loss 0.0174 Classification loss 0.5038 AP 0.5000 AR 0.0500
Epoch 302 batch 00010: Loss 0.5239 Regression loss 0.0146 Classification loss 0.5093 AP 0.9000 AR 0.4000
Epoch 303 batch 00001: Loss 0.4902 Regression loss 0.0168 Classification loss 0.4734 AP 0.5333 AR 0.1000
Epoch 303 batch 00002: Loss 0.4551 Regression loss 0.0177 Classification loss 0.4374 AP 0.4000 AR 0.0000
Epoch 303 batch 00003: Loss 0.3972 Regression loss 0.0170 Classification loss 0.3802 AP 0.6000 AR 0.3500
Epoch 303 batch 00004: Loss 0.3353 Regression loss 0.0137 Classification loss 0.3216 AP 0.4000 AR 0.1400
Epoch 303 batch 00005: Loss 0.4768 Regression loss 0.0177 Classification loss 0.4591 AP 0.4000 AR 0.0000
Epoch 303 batch 00006: Loss 0.4944 Regression loss 0.0186 Classification loss 0.4758 AP 0.7667 AR 0.1400
Epoch 303 batch 00007: Loss 0.2923 Regression loss 0.0136 Classification loss 0.2786 AP 0.5000 AR 0.2000
Epoch 303 batch 00008: Loss 0.5277 Regression loss 0.0173 Classification loss 0.5103 AP 0.6000 AR 0.2000
Epoch 303 batch 00009: Loss 0.3905 Regression loss 0.0174 Classification loss 0.3730 AP 0.4500 AR 0.0667
Epoch 303 batch 00010: Loss 0.3046 Regression loss 0.0179 Classification loss 0.2867 AP 0.6400 AR 0.0400
Epoch 304 batch 00001: Loss 0.4050 Regression loss 0.0153 Classification loss 0.3897 AP 0.5000 AR 0.1000
Epoch 304 batch 00002: Loss 0.4276 Regression loss 0.0208 Classification loss 0.4068 AP 0.4000 AR 0.0000
Epoch 304 batch 00003: Loss 0.3862 Regression loss 0.0191 Classification loss 0.3671 AP 0.5000 AR 0.0667
Epoch 304 batch 00004: Loss 0.3407 Regression loss 0.0149 Classification loss 0.3258 AP 0.3667 AR 0.2067
Epoch 304 batch 00005: Loss 0.4855 Regression loss 0.0173 Classification loss 0.4681 AP 0.8667 AR 0.2500
Epoch 304 batch 00006: Loss 0.4133 Regression loss 0.0167 Classification loss 0.3966 AP 0.6000 AR 0.1400
Epoch 304 batch 00007: Loss 0.4435 Regression loss 0.0184 Classification loss 0.4251 AP 0.6000 AR 0.1000
Epoch 304 batch 00008: Loss 0.4153 Regression loss 0.0124 Classification loss 0.4029 AP 0.6000 AR 0.2000
Epoch 304 batch 00009: Loss 0.3986 Regression loss 0.0145 Classification loss 0.3841 AP 0.1500 AR 0.1400
Epoch 304 batch 00010: Loss 0.5677 Regression loss 0.0156 Classification loss 0.5522 AP 0.6000 AR 0.0000
Epoch 305 batch 00001: Loss 0.4739 Regression loss 0.0142 Classification loss 0.4598 AP 0.5000 AR 0.2400
Epoch 305 batch 00002: Loss 0.3577 Regression loss 0.0116 Classification loss 0.3461 AP 0.3833 AR 0.1667
Epoch 305 batch 00003: Loss 0.4626 Regression loss 0.0171 Classification loss 0.4455 AP 0.9000 AR 0.0400
Epoch 305 batch 00004: Loss 0.3782 Regression loss 0.0201 Classification loss 0.3581 AP 0.5000 AR 0.2000
Epoch 305 batch 00005: Loss 0.3733 Regression loss 0.0153 Classification loss 0.3580 AP 0.7167 AR 0.0800
Epoch 305 batch 00006: Loss 0.3829 Regression loss 0.0186 Classification loss 0.3643 AP 0.6000 AR 0.2000
Epoch 305 batch 00007: Loss 0.4101 Regression loss 0.0169 Classification loss 0.3933 AP 0.4000 AR 0.0000
Epoch 305 batch 00008: Loss 0.4334 Regression loss 0.0125 Classification loss 0.4209 AP 0.2000 AR 0.1000
Epoch 305 batch 00009: Loss 0.4020 Regression loss 0.0227 Classification loss 0.3793 AP 0.6667 AR 0.2500
Epoch 305 batch 00010: Loss 0.5280 Regression loss 0.0192 Classification loss 0.5089 AP 0.7667 AR 0.0900
Epoch 306 batch 00001: Loss 0.4761 Regression loss 0.0167 Classification loss 0.4594 AP 0.9000 AR 0.3000
Epoch 306 batch 00002: Loss 0.3774 Regression loss 0.0137 Classification loss 0.3636 AP 0.4000 AR 0.0000
Epoch 306 batch 00003: Loss 0.5372 Regression loss 0.0204 Classification loss 0.5168 AP 0.6667 AR 0.2500
Epoch 306 batch 00004: Loss 0.5351 Regression loss 0.0141 Classification loss 0.5210 AP 0.7000 AR 0.3000
Epoch 306 batch 00005: Loss 0.3405 Regression loss 0.0149 Classification loss 0.3255 AP 0.5333 AR 0.0900
Epoch 306 batch 00006: Loss 0.4554 Regression loss 0.0158 Classification loss 0.4396 AP 0.6667 AR 0.0400
Epoch 306 batch 00007: Loss 0.4110 Regression loss 0.0185 Classification loss 0.3925 AP 0.1000 AR 0.1000
Epoch 306 batch 00008: Loss 0.3461 Regression loss 0.0187 Classification loss 0.3274 AP 0.5667 AR 0.1700
Epoch 306 batch 00009: Loss 0.4017 Regression loss 0.0163 Classification loss 0.3854 AP 0.7000 AR 0.1000
Epoch 306 batch 00010: Loss 0.4250 Regression loss 0.0141 Classification loss 0.4109 AP 0.4500 AR 0.0667
Epoch 307 batch 00001: Loss 0.4436 Regression loss 0.0147 Classification loss 0.4288 AP 1.0000 AR 0.0000
Epoch 307 batch 00002: Loss 0.4689 Regression loss 0.0167 Classification loss 0.4522 AP 0.5000 AR 0.0500
Epoch 307 batch 00003: Loss 0.3332 Regression loss 0.0168 Classification loss 0.3164 AP 0.5000 AR 0.3000
Epoch 307 batch 00004: Loss 0.3178 Regression loss 0.0162 Classification loss 0.3017 AP 0.7000 AR 0.0400
Epoch 307 batch 00005: Loss 0.3656 Regression loss 0.0169 Classification loss 0.3487 AP 0.2400 AR 0.1500
Epoch 307 batch 00006: Loss 0.4852 Regression loss 0.0173 Classification loss 0.4679 AP 0.5000 AR 0.0400
Epoch 307 batch 00007: Loss 0.4265 Regression loss 0.0146 Classification loss 0.4119 AP 0.1667 AR 0.1500
Epoch 307 batch 00008: Loss 0.4005 Regression loss 0.0192 Classification loss 0.3814 AP 0.5000 AR 0.3000
Epoch 307 batch 00009: Loss 0.6420 Regression loss 0.0155 Classification loss 0.6265 AP 0.6000 AR 0.0000
Epoch 307 batch 00010: Loss 0.4318 Regression loss 0.0174 Classification loss 0.4144 AP 0.2500 AR 0.0667
Epoch 308 batch 00001: Loss 0.4757 Regression loss 0.0138 Classification loss 0.4619 AP 0.5667 AR 0.2000
Epoch 308 batch 00002: Loss 0.5882 Regression loss 0.0138 Classification loss 0.5744 AP 0.6000 AR 0.0000
Epoch 308 batch 00003: Loss 0.5212 Regression loss 0.0162 Classification loss 0.5050 AP 0.4000 AR 0.0000
Epoch 308 batch 00004: Loss 0.3582 Regression loss 0.0141 Classification loss 0.3441 AP 0.3333 AR 0.3000
Epoch 308 batch 00005: Loss 0.2569 Regression loss 0.0160 Classification loss 0.2410 AP 0.5000 AR 0.1000
Epoch 308 batch 00006: Loss 0.4111 Regression loss 0.0158 Classification loss 0.3953 AP 0.4000 AR 0.0000
Epoch 308 batch 00007: Loss 0.3231 Regression loss 0.0133 Classification loss 0.3099 AP 0.7067 AR 0.1067
Epoch 308 batch 00008: Loss 0.5221 Regression loss 0.0215 Classification loss 0.5005 AP 0.7000 AR 0.0400
Epoch 308 batch 00009: Loss 0.3342 Regression loss 0.0156 Classification loss 0.3185 AP 0.4667 AR 0.3000
Epoch 308 batch 00010: Loss 0.4713 Regression loss 0.0240 Classification loss 0.4473 AP 0.6000 AR 0.3000
Epoch 309 batch 00001: Loss 0.4631 Regression loss 0.0167 Classification loss 0.4464 AP 0.8667 AR 0.0500
Epoch 309 batch 00002: Loss 0.5110 Regression loss 0.0185 Classification loss 0.4925 AP 0.4000 AR 0.1400
Epoch 309 batch 00003: Loss 0.3755 Regression loss 0.0194 Classification loss 0.3561 AP 0.2667 AR 0.0400
Epoch 309 batch 00004: Loss 0.4834 Regression loss 0.0156 Classification loss 0.4678 AP 0.4667 AR 0.1000
Epoch 309 batch 00005: Loss 0.2796 Regression loss 0.0151 Classification loss 0.2646 AP 0.5000 AR 0.0800
Epoch 309 batch 00006: Loss 0.3711 Regression loss 0.0159 Classification loss 0.3552 AP 0.4000 AR 0.2000
Epoch 309 batch 00007: Loss 0.4772 Regression loss 0.0164 Classification loss 0.4607 AP 0.6000 AR 0.0800
Epoch 309 batch 00008: Loss 0.3465 Regression loss 0.0144 Classification loss 0.3321 AP 0.3000 AR 0.3067
Epoch 309 batch 00009: Loss 0.4522 Regression loss 0.0136 Classification loss 0.4386 AP 0.8000 AR 0.5000
Epoch 309 batch 00010: Loss 0.3785 Regression loss 0.0132 Classification loss 0.3653 AP 0.8000 AR 0.0000
Epoch 310 batch 00001: Loss 0.5451 Regression loss 0.0202 Classification loss 0.5249 AP 0.6000 AR 0.2000
Epoch 310 batch 00002: Loss 0.5040 Regression loss 0.0146 Classification loss 0.4894 AP 0.7000 AR 0.1000
Epoch 310 batch 00003: Loss 0.5240 Regression loss 0.0139 Classification loss 0.5101 AP 0.2000 AR 0.0000
Epoch 310 batch 00004: Loss 0.4836 Regression loss 0.0176 Classification loss 0.4660 AP 0.8000 AR 0.0000
Epoch 310 batch 00005: Loss 0.3390 Regression loss 0.0180 Classification loss 0.3209 AP 0.6000 AR 0.2500
Epoch 310 batch 00006: Loss 0.3628 Regression loss 0.0132 Classification loss 0.3496 AP 0.3833 AR 0.1800
Epoch 310 batch 00007: Loss 0.2942 Regression loss 0.0143 Classification loss 0.2799 AP 0.3500 AR 0.1167
Epoch 310 batch 00008: Loss 0.4143 Regression loss 0.0151 Classification loss 0.3993 AP 0.6667 AR 0.1500
Epoch 310 batch 00009: Loss 0.3966 Regression loss 0.0189 Classification loss 0.3777 AP 0.7667 AR 0.0800
Epoch 310 batch 00010: Loss 0.4329 Regression loss 0.0184 Classification loss 0.4144 AP 0.3667 AR 0.1400
Epoch 311 batch 00001: Loss 0.3724 Regression loss 0.0188 Classification loss 0.3535 AP 1.0000 AR 0.2000
Epoch 311 batch 00002: Loss 0.6320 Regression loss 0.0190 Classification loss 0.6130 AP 0.7000 AR 0.0500
Epoch 311 batch 00003: Loss 0.5302 Regression loss 0.0199 Classification loss 0.5102 AP 0.4333 AR 0.0500
Epoch 311 batch 00004: Loss 0.2731 Regression loss 0.0128 Classification loss 0.2603 AP 0.8000 AR 0.4500
Epoch 311 batch 00005: Loss 0.3833 Regression loss 0.0160 Classification loss 0.3673 AP 0.7000 AR 0.0400
Epoch 311 batch 00006: Loss 0.4878 Regression loss 0.0140 Classification loss 0.4738 AP 0.2667 AR 0.0400
Epoch 311 batch 00007: Loss 0.3990 Regression loss 0.0161 Classification loss 0.3829 AP 0.6667 AR 0.1900
Epoch 311 batch 00008: Loss 0.4412 Regression loss 0.0166 Classification loss 0.4246 AP 0.8000 AR 0.1000
Epoch 311 batch 00009: Loss 0.3981 Regression loss 0.0132 Classification loss 0.3849 AP 0.1000 AR 0.1000
Epoch 311 batch 00010: Loss 0.4212 Regression loss 0.0164 Classification loss 0.4048 AP 0.5500 AR 0.1067
Epoch 312 batch 00001: Loss 0.3976 Regression loss 0.0148 Classification loss 0.3827 AP 0.6000 AR 0.1000
Epoch 312 batch 00002: Loss 0.3391 Regression loss 0.0129 Classification loss 0.3261 AP 0.7000 AR 0.3000
Epoch 312 batch 00003: Loss 0.4339 Regression loss 0.0151 Classification loss 0.4188 AP 0.6667 AR 0.2900
Epoch 312 batch 00004: Loss 0.5530 Regression loss 0.0158 Classification loss 0.5372 AP 0.4000 AR 0.1400
Epoch 312 batch 00005: Loss 0.4522 Regression loss 0.0164 Classification loss 0.4359 AP 0.5333 AR 0.1000
Epoch 312 batch 00006: Loss 0.4528 Regression loss 0.0165 Classification loss 0.4363 AP 0.6000 AR 0.0000
Epoch 312 batch 00007: Loss 0.3702 Regression loss 0.0146 Classification loss 0.3556 AP 0.4500 AR 0.0667
Epoch 312 batch 00008: Loss 0.3834 Regression loss 0.0163 Classification loss 0.3671 AP 0.4000 AR 0.1800
Epoch 312 batch 00009: Loss 0.4857 Regression loss 0.0211 Classification loss 0.4646 AP 0.8000 AR 0.0000
Epoch 312 batch 00010: Loss 0.4164 Regression loss 0.0158 Classification loss 0.4006 AP 0.5400 AR 0.3000
Epoch 313 batch 00001: Loss 0.2688 Regression loss 0.0160 Classification loss 0.2528 AP 0.8000 AR 0.1600
Epoch 313 batch 00002: Loss 0.4608 Regression loss 0.0166 Classification loss 0.4442 AP 0.3000 AR 0.0400
Epoch 313 batch 00003: Loss 0.3294 Regression loss 0.0133 Classification loss 0.3162 AP 0.1400 AR 0.1667
Epoch 313 batch 00004: Loss 0.3937 Regression loss 0.0124 Classification loss 0.3813 AP 0.8000 AR 0.4000
Epoch 313 batch 00005: Loss 0.5603 Regression loss 0.0184 Classification loss 0.5419 AP 0.4000 AR 0.0000
Epoch 313 batch 00006: Loss 0.4172 Regression loss 0.0144 Classification loss 0.4028 AP 0.5067 AR 0.1500
Epoch 313 batch 00007: Loss 0.4334 Regression loss 0.0220 Classification loss 0.4113 AP 0.7000 AR 0.0500
Epoch 313 batch 00008: Loss 0.4686 Regression loss 0.0177 Classification loss 0.4509 AP 0.6667 AR 0.1400
Epoch 313 batch 00009: Loss 0.4362 Regression loss 0.0143 Classification loss 0.4219 AP 0.4000 AR 0.0000
Epoch 313 batch 00010: Loss 0.4816 Regression loss 0.0137 Classification loss 0.4678 AP 0.6000 AR 0.2000
Epoch 314 batch 00001: Loss 0.4309 Regression loss 0.0149 Classification loss 0.4160 AP 0.4667 AR 0.0500
Epoch 314 batch 00002: Loss 0.3699 Regression loss 0.0154 Classification loss 0.3545 AP 0.6000 AR 0.2000
Epoch 314 batch 00003: Loss 0.5068 Regression loss 0.0144 Classification loss 0.4925 AP 0.2000 AR 0.0000
Epoch 314 batch 00004: Loss 0.3520 Regression loss 0.0183 Classification loss 0.3337 AP 0.8000 AR 0.2500
Epoch 314 batch 00005: Loss 0.5003 Regression loss 0.0182 Classification loss 0.4820 AP 0.7000 AR 0.1000
Epoch 314 batch 00006: Loss 0.3648 Regression loss 0.0167 Classification loss 0.3481 AP 0.5667 AR 0.1300
Epoch 314 batch 00007: Loss 0.3569 Regression loss 0.0112 Classification loss 0.3457 AP 0.7000 AR 0.2000
Epoch 314 batch 00008: Loss 0.5306 Regression loss 0.0169 Classification loss 0.5137 AP 0.6000 AR 0.2000
Epoch 314 batch 00009: Loss 0.3884 Regression loss 0.0164 Classification loss 0.3720 AP 0.4667 AR 0.2300
Epoch 314 batch 00010: Loss 0.4699 Regression loss 0.0175 Classification loss 0.4524 AP 0.4500 AR 0.0667
Epoch 315 batch 00001: Loss 0.3829 Regression loss 0.0160 Classification loss 0.3669 AP 0.4667 AR 0.2500
Epoch 315 batch 00002: Loss 0.3302 Regression loss 0.0171 Classification loss 0.3131 AP 0.9000 AR 0.0900
Epoch 315 batch 00003: Loss 0.4317 Regression loss 0.0153 Classification loss 0.4164 AP 0.4000 AR 0.2000
Epoch 315 batch 00004: Loss 0.3906 Regression loss 0.0146 Classification loss 0.3759 AP 0.4000 AR 0.2400
Epoch 315 batch 00005: Loss 0.5539 Regression loss 0.0162 Classification loss 0.5377 AP 0.6000 AR 0.2400
Epoch 315 batch 00006: Loss 0.3178 Regression loss 0.0126 Classification loss 0.3051 AP 0.6000 AR 0.0000
Epoch 315 batch 00007: Loss 0.4027 Regression loss 0.0211 Classification loss 0.3816 AP 0.8000 AR 0.0000
Epoch 315 batch 00008: Loss 0.3281 Regression loss 0.0135 Classification loss 0.3146 AP 0.3400 AR 0.1467
Epoch 315 batch 00009: Loss 0.5548 Regression loss 0.0176 Classification loss 0.5372 AP 0.7000 AR 0.0500
Epoch 315 batch 00010: Loss 0.4232 Regression loss 0.0152 Classification loss 0.4081 AP 0.5333 AR 0.3000
Epoch 316 batch 00001: Loss 0.4285 Regression loss 0.0167 Classification loss 0.4118 AP 0.5667 AR 0.1400
Epoch 316 batch 00002: Loss 0.3486 Regression loss 0.0148 Classification loss 0.3338 AP 0.4833 AR 0.1167
Epoch 316 batch 00003: Loss 0.4582 Regression loss 0.0176 Classification loss 0.4406 AP 0.7000 AR 0.2000
Epoch 316 batch 00004: Loss 0.5293 Regression loss 0.0176 Classification loss 0.5117 AP 0.6000 AR 0.0000
Epoch 316 batch 00005: Loss 0.3923 Regression loss 0.0129 Classification loss 0.3795 AP 0.3000 AR 0.2667
Epoch 316 batch 00006: Loss 0.4423 Regression loss 0.0145 Classification loss 0.4277 AP 0.6000 AR 0.2000
Epoch 316 batch 00007: Loss 0.4800 Regression loss 0.0171 Classification loss 0.4629 AP 0.6667 AR 0.2400
Epoch 316 batch 00008: Loss 0.3461 Regression loss 0.0185 Classification loss 0.3276 AP 0.9000 AR 0.1900
Epoch 316 batch 00009: Loss 0.4277 Regression loss 0.0191 Classification loss 0.4086 AP 0.4000 AR 0.0000
Epoch 316 batch 00010: Loss 0.3443 Regression loss 0.0142 Classification loss 0.3301 AP 0.4467 AR 0.1800
Epoch 317 batch 00001: Loss 0.3991 Regression loss 0.0195 Classification loss 0.3796 AP 0.4000 AR 0.0000
Epoch 317 batch 00002: Loss 0.3891 Regression loss 0.0169 Classification loss 0.3721 AP 0.9000 AR 0.4000
Epoch 317 batch 00003: Loss 0.5130 Regression loss 0.0186 Classification loss 0.4944 AP 0.7000 AR 0.1000
Epoch 317 batch 00004: Loss 0.4486 Regression loss 0.0187 Classification loss 0.4299 AP 0.4500 AR 0.0667
Epoch 317 batch 00005: Loss 0.4926 Regression loss 0.0156 Classification loss 0.4771 AP 0.3667 AR 0.0800
Epoch 317 batch 00006: Loss 0.2795 Regression loss 0.0173 Classification loss 0.2622 AP 0.7000 AR 0.1500
Epoch 317 batch 00007: Loss 0.5104 Regression loss 0.0174 Classification loss 0.4930 AP 0.6167 AR 0.2000
Epoch 317 batch 00008: Loss 0.4408 Regression loss 0.0140 Classification loss 0.4268 AP 0.3333 AR 0.0900
Epoch 317 batch 00009: Loss 0.4290 Regression loss 0.0124 Classification loss 0.4166 AP 0.5400 AR 0.1167
Epoch 317 batch 00010: Loss 0.3094 Regression loss 0.0143 Classification loss 0.2951 AP 0.5000 AR 0.1800
Epoch 318 batch 00001: Loss 0.4094 Regression loss 0.0190 Classification loss 0.3904 AP 0.5667 AR 0.1500
Epoch 318 batch 00002: Loss 0.4709 Regression loss 0.0140 Classification loss 0.4568 AP 0.4000 AR 0.0000
Epoch 318 batch 00003: Loss 0.3819 Regression loss 0.0151 Classification loss 0.3668 AP 0.4500 AR 0.0667
Epoch 318 batch 00004: Loss 0.3519 Regression loss 0.0176 Classification loss 0.3343 AP 0.6000 AR 0.1800
Epoch 318 batch 00005: Loss 0.4123 Regression loss 0.0135 Classification loss 0.3989 AP 0.7000 AR 0.2500
Epoch 318 batch 00006: Loss 0.4123 Regression loss 0.0109 Classification loss 0.4014 AP 0.7000 AR 0.3000
Epoch 318 batch 00007: Loss 0.4898 Regression loss 0.0208 Classification loss 0.4690 AP 0.7000 AR 0.1000
Epoch 318 batch 00008: Loss 0.4137 Regression loss 0.0138 Classification loss 0.3998 AP 0.3500 AR 0.0900
Epoch 318 batch 00009: Loss 0.3628 Regression loss 0.0191 Classification loss 0.3437 AP 0.6000 AR 0.0500
Epoch 318 batch 00010: Loss 0.4426 Regression loss 0.0173 Classification loss 0.4253 AP 0.6000 AR 0.2000
Epoch 319 batch 00001: Loss 0.5212 Regression loss 0.0172 Classification loss 0.5040 AP 0.7000 AR 0.0500
Epoch 319 batch 00002: Loss 0.4859 Regression loss 0.0175 Classification loss 0.4684 AP 0.8000 AR 0.2000
Epoch 319 batch 00003: Loss 0.4080 Regression loss 0.0161 Classification loss 0.3919 AP 0.5000 AR 0.0900
Epoch 319 batch 00004: Loss 0.5474 Regression loss 0.0216 Classification loss 0.5258 AP 0.6333 AR 0.0500
Epoch 319 batch 00005: Loss 0.4342 Regression loss 0.0149 Classification loss 0.4192 AP 0.6000 AR 0.0800
Epoch 319 batch 00006: Loss 0.3834 Regression loss 0.0158 Classification loss 0.3676 AP 0.5000 AR 0.4667
Epoch 319 batch 00007: Loss 0.2635 Regression loss 0.0135 Classification loss 0.2500 AP 0.5500 AR 0.1400
Epoch 319 batch 00008: Loss 0.3508 Regression loss 0.0138 Classification loss 0.3369 AP 0.5667 AR 0.1500
Epoch 319 batch 00009: Loss 0.4081 Regression loss 0.0183 Classification loss 0.3898 AP 0.6667 AR 0.1400
Epoch 319 batch 00010: Loss 0.3397 Regression loss 0.0137 Classification loss 0.3261 AP 0.3167 AR 0.1167
Epoch 320 batch 00001: Loss 0.6000 Regression loss 0.0160 Classification loss 0.5841 AP 0.6000 AR 0.0000
Epoch 320 batch 00002: Loss 0.4380 Regression loss 0.0182 Classification loss 0.4198 AP 0.0333 AR 0.0500
Epoch 320 batch 00003: Loss 0.3494 Regression loss 0.0146 Classification loss 0.3348 AP 0.4000 AR 0.1800
Epoch 320 batch 00004: Loss 0.3375 Regression loss 0.0171 Classification loss 0.3204 AP 0.5000 AR 0.2800
Epoch 320 batch 00005: Loss 0.3361 Regression loss 0.0179 Classification loss 0.3182 AP 0.4000 AR 0.0000
Epoch 320 batch 00006: Loss 0.3959 Regression loss 0.0122 Classification loss 0.3837 AP 0.7000 AR 0.3000
Epoch 320 batch 00007: Loss 0.4484 Regression loss 0.0174 Classification loss 0.4311 AP 0.8667 AR 0.0500
Epoch 320 batch 00008: Loss 0.5774 Regression loss 0.0186 Classification loss 0.5588 AP 0.6500 AR 0.0400
Epoch 320 batch 00009: Loss 0.4804 Regression loss 0.0156 Classification loss 0.4648 AP 0.4000 AR 0.1400
Epoch 320 batch 00010: Loss 0.4714 Regression loss 0.0132 Classification loss 0.4582 AP 0.5000 AR 0.0500
Epoch 321 batch 00001: Loss 0.3809 Regression loss 0.0171 Classification loss 0.3638 AP 0.6000 AR 0.0000
Epoch 321 batch 00002: Loss 0.4672 Regression loss 0.0189 Classification loss 0.4483 AP 0.4000 AR 0.0500
Epoch 321 batch 00003: Loss 0.4262 Regression loss 0.0159 Classification loss 0.4104 AP 0.2667 AR 0.0500
Epoch 321 batch 00004: Loss 0.3154 Regression loss 0.0171 Classification loss 0.2983 AP 0.7667 AR 0.2300
Epoch 321 batch 00005: Loss 0.4276 Regression loss 0.0162 Classification loss 0.4114 AP 0.5500 AR 0.2500
Epoch 321 batch 00006: Loss 0.3912 Regression loss 0.0172 Classification loss 0.3740 AP 0.6400 AR 0.2667
Epoch 321 batch 00007: Loss 0.4600 Regression loss 0.0164 Classification loss 0.4436 AP 0.8000 AR 0.2000
Epoch 321 batch 00008: Loss 0.4032 Regression loss 0.0144 Classification loss 0.3887 AP 0.2000 AR 0.0000
Epoch 321 batch 00009: Loss 0.4917 Regression loss 0.0124 Classification loss 0.4792 AP 0.3667 AR 0.2000
Epoch 321 batch 00010: Loss 0.5741 Regression loss 0.0207 Classification loss 0.5534 AP 1.0000 AR 0.1400
Epoch 322 batch 00001: Loss 0.5715 Regression loss 0.0184 Classification loss 0.5531 AP 0.6667 AR 0.0400
Epoch 322 batch 00002: Loss 0.4229 Regression loss 0.0162 Classification loss 0.4068 AP 0.8000 AR 0.0000
Epoch 322 batch 00003: Loss 0.4516 Regression loss 0.0144 Classification loss 0.4372 AP 0.6400 AR 0.0500
Epoch 322 batch 00004: Loss 0.3794 Regression loss 0.0175 Classification loss 0.3619 AP 0.3000 AR 0.1000
Epoch 322 batch 00005: Loss 0.3984 Regression loss 0.0135 Classification loss 0.3849 AP 0.2333 AR 0.0500
Epoch 322 batch 00006: Loss 0.5866 Regression loss 0.0138 Classification loss 0.5728 AP 0.9000 AR 0.3500
Epoch 322 batch 00007: Loss 0.5117 Regression loss 0.0147 Classification loss 0.4970 AP 0.5000 AR 0.1000
Epoch 322 batch 00008: Loss 0.3371 Regression loss 0.0162 Classification loss 0.3209 AP 0.7000 AR 0.2400
Epoch 322 batch 00009: Loss 0.4549 Regression loss 0.0182 Classification loss 0.4368 AP 0.4667 AR 0.0500
Epoch 322 batch 00010: Loss 0.3556 Regression loss 0.0184 Classification loss 0.3372 AP 0.5833 AR 0.1967
Epoch 323 batch 00001: Loss 0.3822 Regression loss 0.0148 Classification loss 0.3673 AP 0.6667 AR 0.3500
Epoch 323 batch 00002: Loss 0.4053 Regression loss 0.0179 Classification loss 0.3874 AP 0.5067 AR 0.0800
Epoch 323 batch 00003: Loss 0.3541 Regression loss 0.0144 Classification loss 0.3397 AP 0.4000 AR 0.2000
Epoch 323 batch 00004: Loss 0.5915 Regression loss 0.0166 Classification loss 0.5749 AP 0.5667 AR 0.0900
Epoch 323 batch 00005: Loss 0.6690 Regression loss 0.0195 Classification loss 0.6496 AP 1.0000 AR 0.0000
Epoch 323 batch 00006: Loss 0.2693 Regression loss 0.0114 Classification loss 0.2579 AP 0.3400 AR 0.2667
Epoch 323 batch 00007: Loss 0.3454 Regression loss 0.0167 Classification loss 0.3287 AP 0.5733 AR 0.2300
Epoch 323 batch 00008: Loss 0.4327 Regression loss 0.0123 Classification loss 0.4204 AP 0.7667 AR 0.2000
Epoch 323 batch 00009: Loss 0.4380 Regression loss 0.0182 Classification loss 0.4199 AP 0.4500 AR 0.0400
Epoch 323 batch 00010: Loss 0.4925 Regression loss 0.0182 Classification loss 0.4743 AP 0.3000 AR 0.1000
Epoch 324 batch 00001: Loss 0.3145 Regression loss 0.0160 Classification loss 0.2984 AP 0.8000 AR 0.1067
Epoch 324 batch 00002: Loss 0.4171 Regression loss 0.0140 Classification loss 0.4032 AP 0.3833 AR 0.1467
Epoch 324 batch 00003: Loss 0.4184 Regression loss 0.0181 Classification loss 0.4003 AP 0.9000 AR 0.2000
Epoch 324 batch 00004: Loss 0.3294 Regression loss 0.0155 Classification loss 0.3139 AP 0.4000 AR 0.1000
Epoch 324 batch 00005: Loss 0.3078 Regression loss 0.0194 Classification loss 0.2884 AP 0.7000 AR 0.1000
Epoch 324 batch 00006: Loss 0.6595 Regression loss 0.0157 Classification loss 0.6439 AP 0.9000 AR 0.1000
Epoch 324 batch 00007: Loss 0.4267 Regression loss 0.0132 Classification loss 0.4135 AP 0.3000 AR 0.0500
Epoch 324 batch 00008: Loss 0.4701 Regression loss 0.0143 Classification loss 0.4558 AP 0.8667 AR 0.4000
Epoch 324 batch 00009: Loss 0.5611 Regression loss 0.0203 Classification loss 0.5408 AP 0.3333 AR 0.0900
Epoch 324 batch 00010: Loss 0.4136 Regression loss 0.0138 Classification loss 0.3998 AP 0.3167 AR 0.3167
Epoch 325 batch 00001: Loss 0.2860 Regression loss 0.0149 Classification loss 0.2711 AP 0.4000 AR 0.1733
Epoch 325 batch 00002: Loss 0.4281 Regression loss 0.0157 Classification loss 0.4123 AP 0.7000 AR 0.2000
Epoch 325 batch 00003: Loss 0.4813 Regression loss 0.0155 Classification loss 0.4658 AP 0.2667 AR 0.0500
Epoch 325 batch 00004: Loss 0.4142 Regression loss 0.0135 Classification loss 0.4008 AP 0.9000 AR 0.1800
Epoch 325 batch 00005: Loss 0.3854 Regression loss 0.0131 Classification loss 0.3723 AP 0.9000 AR 0.1000
Epoch 325 batch 00006: Loss 0.5398 Regression loss 0.0161 Classification loss 0.5237 AP 0.5667 AR 0.3900
Epoch 325 batch 00007: Loss 0.2868 Regression loss 0.0146 Classification loss 0.2722 AP 0.6000 AR 0.2500
Epoch 325 batch 00008: Loss 0.4897 Regression loss 0.0193 Classification loss 0.4704 AP 0.6000 AR 0.0000
Epoch 325 batch 00009: Loss 0.4388 Regression loss 0.0184 Classification loss 0.4203 AP 0.6000 AR 0.0900
Epoch 325 batch 00010: Loss 0.4096 Regression loss 0.0168 Classification loss 0.3927 AP 0.3667 AR 0.1400
Epoch 326 batch 00001: Loss 0.4490 Regression loss 0.0127 Classification loss 0.4363 AP 0.6000 AR 0.2000
Epoch 326 batch 00002: Loss 0.3243 Regression loss 0.0154 Classification loss 0.3089 AP 0.7333 AR 0.2300
Epoch 326 batch 00003: Loss 0.4330 Regression loss 0.0150 Classification loss 0.4179 AP 0.4667 AR 0.1300
Epoch 326 batch 00004: Loss 0.5411 Regression loss 0.0149 Classification loss 0.5262 AP 0.4000 AR 0.0000
Epoch 326 batch 00005: Loss 0.5812 Regression loss 0.0232 Classification loss 0.5580 AP 1.0000 AR 0.0500
Epoch 326 batch 00006: Loss 0.4487 Regression loss 0.0174 Classification loss 0.4313 AP 0.6000 AR 0.0000
Epoch 326 batch 00007: Loss 0.4779 Regression loss 0.0153 Classification loss 0.4626 AP 0.8400 AR 0.2667
Epoch 326 batch 00008: Loss 0.4027 Regression loss 0.0170 Classification loss 0.3857 AP 0.6000 AR 0.0000
Epoch 326 batch 00009: Loss 0.4326 Regression loss 0.0185 Classification loss 0.4141 AP 0.5000 AR 0.1000
Epoch 326 batch 00010: Loss 0.3845 Regression loss 0.0155 Classification loss 0.3690 AP 0.2667 AR 0.1800
Epoch 327 batch 00001: Loss 0.5368 Regression loss 0.0140 Classification loss 0.5227 AP 0.6667 AR 0.0500
Epoch 327 batch 00002: Loss 0.4021 Regression loss 0.0170 Classification loss 0.3851 AP 0.3667 AR 0.0800
Epoch 327 batch 00003: Loss 0.3353 Regression loss 0.0167 Classification loss 0.3186 AP 0.2167 AR 0.1900
Epoch 327 batch 00004: Loss 0.4833 Regression loss 0.0199 Classification loss 0.4635 AP 0.8000 AR 0.2400
Epoch 327 batch 00005: Loss 0.4012 Regression loss 0.0157 Classification loss 0.3855 AP 0.4500 AR 0.0667
Epoch 327 batch 00006: Loss 0.3603 Regression loss 0.0121 Classification loss 0.3482 AP 0.3000 AR 0.3000
Epoch 327 batch 00007: Loss 0.5630 Regression loss 0.0182 Classification loss 0.5447 AP 0.6500 AR 0.1000
Epoch 327 batch 00008: Loss 0.4534 Regression loss 0.0162 Classification loss 0.4373 AP 0.5000 AR 0.0400
Epoch 327 batch 00009: Loss 0.3671 Regression loss 0.0152 Classification loss 0.3519 AP 0.6333 AR 0.0500
Epoch 327 batch 00010: Loss 0.5138 Regression loss 0.0158 Classification loss 0.4980 AP 0.7000 AR 0.2500
Epoch 328 batch 00001: Loss 0.3159 Regression loss 0.0162 Classification loss 0.2997 AP 0.6286 AR 0.1000
Epoch 328 batch 00002: Loss 0.5628 Regression loss 0.0196 Classification loss 0.5432 AP 0.6000 AR 0.0000
Epoch 328 batch 00003: Loss 0.2361 Regression loss 0.0126 Classification loss 0.2235 AP 0.4000 AR 0.1400
Epoch 328 batch 00004: Loss 0.4910 Regression loss 0.0204 Classification loss 0.4706 AP 0.8000 AR 0.0000
Epoch 328 batch 00005: Loss 0.5192 Regression loss 0.0109 Classification loss 0.5084 AP 0.3000 AR 0.1000
Epoch 328 batch 00006: Loss 0.5074 Regression loss 0.0190 Classification loss 0.4884 AP 0.7667 AR 0.1500
Epoch 328 batch 00007: Loss 0.4355 Regression loss 0.0162 Classification loss 0.4194 AP 0.5000 AR 0.2400
Epoch 328 batch 00008: Loss 0.4739 Regression loss 0.0191 Classification loss 0.4548 AP 0.4000 AR 0.1000
Epoch 328 batch 00009: Loss 0.5654 Regression loss 0.0160 Classification loss 0.5494 AP 0.7167 AR 0.2900
Epoch 328 batch 00010: Loss 0.3478 Regression loss 0.0167 Classification loss 0.3311 AP 0.7167 AR 0.3067
Epoch 329 batch 00001: Loss 0.4120 Regression loss 0.0164 Classification loss 0.3956 AP 0.8000 AR 0.2000
Epoch 329 batch 00002: Loss 0.2920 Regression loss 0.0116 Classification loss 0.2803 AP 0.5333 AR 0.2500
Epoch 329 batch 00003: Loss 0.3668 Regression loss 0.0146 Classification loss 0.3522 AP 0.6000 AR 0.1000
Epoch 329 batch 00004: Loss 0.4683 Regression loss 0.0155 Classification loss 0.4527 AP 0.6000 AR 0.0900
Epoch 329 batch 00005: Loss 0.4811 Regression loss 0.0175 Classification loss 0.4635 AP 0.4000 AR 0.0000
Epoch 329 batch 00006: Loss 0.5735 Regression loss 0.0187 Classification loss 0.5547 AP 0.4000 AR 0.2000
Epoch 329 batch 00007: Loss 0.5511 Regression loss 0.0220 Classification loss 0.5290 AP 0.8000 AR 0.0000
Epoch 329 batch 00008: Loss 0.4054 Regression loss 0.0162 Classification loss 0.3892 AP 0.3000 AR 0.1667
Epoch 329 batch 00009: Loss 0.3156 Regression loss 0.0130 Classification loss 0.3026 AP 0.4000 AR 0.1300
Epoch 329 batch 00010: Loss 0.4861 Regression loss 0.0182 Classification loss 0.4679 AP 0.3000 AR 0.0500
Epoch 330 batch 00001: Loss 0.4941 Regression loss 0.0141 Classification loss 0.4801 AP 0.5000 AR 0.0400
Epoch 330 batch 00002: Loss 0.4235 Regression loss 0.0107 Classification loss 0.4129 AP 0.1000 AR 0.2000
Epoch 330 batch 00003: Loss 0.3550 Regression loss 0.0157 Classification loss 0.3392 AP 0.8000 AR 0.1900
Epoch 330 batch 00004: Loss 0.3813 Regression loss 0.0155 Classification loss 0.3658 AP 0.6000 AR 0.1000
Epoch 330 batch 00005: Loss 0.4575 Regression loss 0.0145 Classification loss 0.4431 AP 0.5000 AR 0.3000
Epoch 330 batch 00006: Loss 0.4028 Regression loss 0.0201 Classification loss 0.3827 AP 0.7167 AR 0.1067
Epoch 330 batch 00007: Loss 0.5540 Regression loss 0.0218 Classification loss 0.5322 AP 0.4667 AR 0.0500
Epoch 330 batch 00008: Loss 0.3973 Regression loss 0.0145 Classification loss 0.3828 AP 0.8500 AR 0.2500
Epoch 330 batch 00009: Loss 0.2450 Regression loss 0.0124 Classification loss 0.2326 AP 0.5333 AR 0.0800
Epoch 330 batch 00010: Loss 0.5014 Regression loss 0.0168 Classification loss 0.4845 AP 0.6000 AR 0.1000
Epoch 331 batch 00001: Loss 0.5509 Regression loss 0.0251 Classification loss 0.5257 AP 0.6000 AR 0.0000
Epoch 331 batch 00002: Loss 0.6303 Regression loss 0.0172 Classification loss 0.6131 AP 0.7000 AR 0.0667
Epoch 331 batch 00003: Loss 0.4765 Regression loss 0.0145 Classification loss 0.4620 AP 0.3333 AR 0.0800
Epoch 331 batch 00004: Loss 0.4205 Regression loss 0.0174 Classification loss 0.4031 AP 0.2667 AR 0.2500
Epoch 331 batch 00005: Loss 0.5931 Regression loss 0.0148 Classification loss 0.5783 AP 0.6000 AR 0.2000
Epoch 331 batch 00006: Loss 0.4442 Regression loss 0.0132 Classification loss 0.4310 AP 0.7000 AR 0.1000
Epoch 331 batch 00007: Loss 0.3075 Regression loss 0.0135 Classification loss 0.2940 AP 0.4667 AR 0.1800
Epoch 331 batch 00008: Loss 0.3409 Regression loss 0.0140 Classification loss 0.3269 AP 0.4667 AR 0.1500
Epoch 331 batch 00009: Loss 0.4338 Regression loss 0.0141 Classification loss 0.4196 AP 0.5000 AR 0.2000
Epoch 331 batch 00010: Loss 0.4853 Regression loss 0.0161 Classification loss 0.4692 AP 0.5167 AR 0.1900
Epoch 332 batch 00001: Loss 0.6285 Regression loss 0.0126 Classification loss 0.6158 AP 0.7067 AR 0.3000
Epoch 332 batch 00002: Loss 0.4216 Regression loss 0.0191 Classification loss 0.4025 AP 0.6667 AR 0.0400
Epoch 332 batch 00003: Loss 0.3136 Regression loss 0.0153 Classification loss 0.2984 AP 0.7333 AR 0.0900
Epoch 332 batch 00004: Loss 0.4054 Regression loss 0.0167 Classification loss 0.3886 AP 0.4500 AR 0.2400
Epoch 332 batch 00005: Loss 0.3624 Regression loss 0.0187 Classification loss 0.3437 AP 0.4000 AR 0.0000
Epoch 332 batch 00006: Loss 0.3687 Regression loss 0.0162 Classification loss 0.3525 AP 0.5000 AR 0.1000
Epoch 332 batch 00007: Loss 0.2911 Regression loss 0.0116 Classification loss 0.2795 AP 0.3167 AR 0.3333
Epoch 332 batch 00008: Loss 0.5691 Regression loss 0.0219 Classification loss 0.5472 AP 0.6000 AR 0.0000
Epoch 332 batch 00009: Loss 0.5200 Regression loss 0.0169 Classification loss 0.5031 AP 0.4000 AR 0.0400
Epoch 332 batch 00010: Loss 0.5476 Regression loss 0.0159 Classification loss 0.5317 AP 0.4000 AR 0.2000
Epoch 333 batch 00001: Loss 0.5028 Regression loss 0.0141 Classification loss 0.4887 AP 0.7000 AR 0.1000
Epoch 333 batch 00002: Loss 0.5114 Regression loss 0.0156 Classification loss 0.4957 AP 0.6000 AR 0.0000
Epoch 333 batch 00003: Loss 0.3701 Regression loss 0.0162 Classification loss 0.3539 AP 0.4000 AR 0.1500
Epoch 333 batch 00004: Loss 0.3868 Regression loss 0.0162 Classification loss 0.3706 AP 0.6000 AR 0.0000
Epoch 333 batch 00005: Loss 0.4253 Regression loss 0.0144 Classification loss 0.4109 AP 0.7000 AR 0.1500
Epoch 333 batch 00006: Loss 0.4150 Regression loss 0.0180 Classification loss 0.3970 AP 0.6000 AR 0.2000
Epoch 333 batch 00007: Loss 0.5557 Regression loss 0.0143 Classification loss 0.5415 AP 0.3000 AR 0.0500
Epoch 333 batch 00008: Loss 0.3044 Regression loss 0.0156 Classification loss 0.2888 AP 0.6500 AR 0.2667
Epoch 333 batch 00009: Loss 0.4497 Regression loss 0.0204 Classification loss 0.4293 AP 0.4667 AR 0.0400
Epoch 333 batch 00010: Loss 0.3484 Regression loss 0.0153 Classification loss 0.3331 AP 0.5333 AR 0.3200
Epoch 334 batch 00001: Loss 0.4235 Regression loss 0.0140 Classification loss 0.4096 AP 0.4667 AR 0.0500
Epoch 334 batch 00002: Loss 0.3375 Regression loss 0.0192 Classification loss 0.3183 AP 0.6000 AR 0.0500
Epoch 334 batch 00003: Loss 0.4476 Regression loss 0.0170 Classification loss 0.4305 AP 0.3000 AR 0.1000
Epoch 334 batch 00004: Loss 0.3405 Regression loss 0.0174 Classification loss 0.3231 AP 0.6000 AR 0.1467
Epoch 334 batch 00005: Loss 0.4880 Regression loss 0.0211 Classification loss 0.4669 AP 0.4500 AR 0.0667
Epoch 334 batch 00006: Loss 0.4082 Regression loss 0.0196 Classification loss 0.3886 AP 0.6000 AR 0.0800
Epoch 334 batch 00007: Loss 0.4055 Regression loss 0.0129 Classification loss 0.3926 AP 0.6000 AR 0.2000
Epoch 334 batch 00008: Loss 0.5424 Regression loss 0.0111 Classification loss 0.5313 AP 0.4000 AR 0.0000
Epoch 334 batch 00009: Loss 0.2805 Regression loss 0.0141 Classification loss 0.2664 AP 0.5667 AR 0.3500
Epoch 334 batch 00010: Loss 0.5155 Regression loss 0.0115 Classification loss 0.5041 AP 0.5500 AR 0.1000
Epoch 335 batch 00001: Loss 0.2835 Regression loss 0.0133 Classification loss 0.2702 AP 0.5500 AR 0.1667
Epoch 335 batch 00002: Loss 0.3658 Regression loss 0.0180 Classification loss 0.3478 AP 0.4000 AR 0.0000
Epoch 335 batch 00003: Loss 0.5044 Regression loss 0.0144 Classification loss 0.4899 AP 0.4000 AR 0.0000
Epoch 335 batch 00004: Loss 0.4727 Regression loss 0.0155 Classification loss 0.4572 AP 0.5000 AR 0.3000
Epoch 335 batch 00005: Loss 0.5007 Regression loss 0.0134 Classification loss 0.4872 AP 0.6167 AR 0.1400
Epoch 335 batch 00006: Loss 0.3788 Regression loss 0.0155 Classification loss 0.3633 AP 0.6000 AR 0.0000
Epoch 335 batch 00007: Loss 0.3727 Regression loss 0.0174 Classification loss 0.3553 AP 0.7333 AR 0.0800
Epoch 335 batch 00008: Loss 0.4419 Regression loss 0.0168 Classification loss 0.4251 AP 0.2333 AR 0.2000
Epoch 335 batch 00009: Loss 0.5173 Regression loss 0.0172 Classification loss 0.5000 AP 0.8000 AR 0.2000
Epoch 335 batch 00010: Loss 0.4398 Regression loss 0.0171 Classification loss 0.4227 AP 0.2500 AR 0.0400
Epoch 336 batch 00001: Loss 0.4889 Regression loss 0.0163 Classification loss 0.4726 AP 0.6000 AR 0.0000
Epoch 336 batch 00002: Loss 0.3556 Regression loss 0.0162 Classification loss 0.3394 AP 0.9000 AR 0.0900
Epoch 336 batch 00003: Loss 0.4179 Regression loss 0.0128 Classification loss 0.4051 AP 0.4000 AR 0.1167
Epoch 336 batch 00004: Loss 0.5162 Regression loss 0.0189 Classification loss 0.4973 AP 0.6000 AR 0.2667
Epoch 336 batch 00005: Loss 0.3215 Regression loss 0.0140 Classification loss 0.3075 AP 0.5333 AR 0.1400
Epoch 336 batch 00006: Loss 0.4739 Regression loss 0.0168 Classification loss 0.4571 AP 0.5000 AR 0.2500
Epoch 336 batch 00007: Loss 0.3633 Regression loss 0.0143 Classification loss 0.3489 AP 0.5000 AR 0.1000
Epoch 336 batch 00008: Loss 0.4677 Regression loss 0.0156 Classification loss 0.4521 AP 0.5167 AR 0.1000
Epoch 336 batch 00009: Loss 0.3396 Regression loss 0.0103 Classification loss 0.3293 AP 0.4333 AR 0.3800
Epoch 336 batch 00010: Loss 0.5712 Regression loss 0.0185 Classification loss 0.5526 AP 0.7000 AR 0.0400
Epoch 337 batch 00001: Loss 0.6891 Regression loss 0.0244 Classification loss 0.6647 AP 1.0000 AR 0.2000
Epoch 337 batch 00002: Loss 0.4269 Regression loss 0.0177 Classification loss 0.4092 AP 0.4000 AR 0.1000
Epoch 337 batch 00003: Loss 0.3894 Regression loss 0.0170 Classification loss 0.3723 AP 0.2000 AR 0.0000
Epoch 337 batch 00004: Loss 0.3251 Regression loss 0.0128 Classification loss 0.3124 AP 0.1000 AR 0.2000
Epoch 337 batch 00005: Loss 0.3971 Regression loss 0.0149 Classification loss 0.3822 AP 0.7667 AR 0.0900
Epoch 337 batch 00006: Loss 0.2135 Regression loss 0.0149 Classification loss 0.1985 AP 0.7333 AR 0.3300
Epoch 337 batch 00007: Loss 0.4144 Regression loss 0.0127 Classification loss 0.4017 AP 0.3167 AR 0.1167
Epoch 337 batch 00008: Loss 0.5370 Regression loss 0.0198 Classification loss 0.5172 AP 0.7000 AR 0.0400
Epoch 337 batch 00009: Loss 0.4149 Regression loss 0.0150 Classification loss 0.3999 AP 0.5900 AR 0.2000
Epoch 337 batch 00010: Loss 0.5916 Regression loss 0.0201 Classification loss 0.5715 AP 0.7000 AR 0.1000
Epoch 338 batch 00001: Loss 0.3326 Regression loss 0.0161 Classification loss 0.3166 AP 0.5000 AR 0.0800
Epoch 338 batch 00002: Loss 0.4863 Regression loss 0.0135 Classification loss 0.4728 AP 0.5667 AR 0.1167
Epoch 338 batch 00003: Loss 0.3320 Regression loss 0.0149 Classification loss 0.3170 AP 0.4667 AR 0.1000
Epoch 338 batch 00004: Loss 0.5014 Regression loss 0.0185 Classification loss 0.4829 AP 0.4000 AR 0.0900
Epoch 338 batch 00005: Loss 0.3712 Regression loss 0.0163 Classification loss 0.3549 AP 0.7500 AR 0.1400
Epoch 338 batch 00006: Loss 0.5019 Regression loss 0.0145 Classification loss 0.4874 AP 0.7000 AR 0.2000
Epoch 338 batch 00007: Loss 0.3948 Regression loss 0.0133 Classification loss 0.3815 AP 0.6000 AR 0.2000
Epoch 338 batch 00008: Loss 0.4472 Regression loss 0.0108 Classification loss 0.4364 AP 0.8000 AR 0.5000
Epoch 338 batch 00009: Loss 0.3628 Regression loss 0.0172 Classification loss 0.3455 AP 0.6000 AR 0.0000
Epoch 338 batch 00010: Loss 0.5388 Regression loss 0.0157 Classification loss 0.5231 AP 0.5000 AR 0.0900
Epoch 339 batch 00001: Loss 0.4480 Regression loss 0.0203 Classification loss 0.4277 AP 0.4000 AR 0.2500
Epoch 339 batch 00002: Loss 0.5169 Regression loss 0.0158 Classification loss 0.5010 AP 0.5000 AR 0.2400
Epoch 339 batch 00003: Loss 0.4703 Regression loss 0.0123 Classification loss 0.4580 AP 0.4667 AR 0.0500
Epoch 339 batch 00004: Loss 0.4253 Regression loss 0.0149 Classification loss 0.4105 AP 0.6000 AR 0.0000
Epoch 339 batch 00005: Loss 0.4207 Regression loss 0.0157 Classification loss 0.4050 AP 0.3667 AR 0.1067
Epoch 339 batch 00006: Loss 0.3599 Regression loss 0.0174 Classification loss 0.3425 AP 0.4000 AR 0.2067
Epoch 339 batch 00007: Loss 0.5424 Regression loss 0.0133 Classification loss 0.5290 AP 0.6667 AR 0.0500
Epoch 339 batch 00008: Loss 0.4232 Regression loss 0.0172 Classification loss 0.4060 AP 0.8000 AR 0.2000
Epoch 339 batch 00009: Loss 0.4174 Regression loss 0.0176 Classification loss 0.3998 AP 0.6000 AR 0.1400
Epoch 339 batch 00010: Loss 0.4741 Regression loss 0.0130 Classification loss 0.4612 AP 0.6400 AR 0.1300
Epoch 340 batch 00001: Loss 0.5058 Regression loss 0.0182 Classification loss 0.4876 AP 0.6000 AR 0.0000
Epoch 340 batch 00002: Loss 0.5280 Regression loss 0.0135 Classification loss 0.5144 AP 0.8500 AR 0.1500
Epoch 340 batch 00003: Loss 0.3403 Regression loss 0.0134 Classification loss 0.3269 AP 0.6000 AR 0.2000
Epoch 340 batch 00004: Loss 0.5032 Regression loss 0.0190 Classification loss 0.4842 AP 0.7000 AR 0.0667
Epoch 340 batch 00005: Loss 0.4674 Regression loss 0.0203 Classification loss 0.4471 AP 0.3000 AR 0.0800
Epoch 340 batch 00006: Loss 0.4629 Regression loss 0.0178 Classification loss 0.4451 AP 0.6500 AR 0.0500
Epoch 340 batch 00007: Loss 0.3763 Regression loss 0.0160 Classification loss 0.3603 AP 0.6667 AR 0.2400
Epoch 340 batch 00008: Loss 0.3265 Regression loss 0.0141 Classification loss 0.3125 AP 0.4333 AR 0.1467
Epoch 340 batch 00009: Loss 0.4089 Regression loss 0.0113 Classification loss 0.3976 AP 0.3000 AR 0.1000
Epoch 340 batch 00010: Loss 0.4499 Regression loss 0.0140 Classification loss 0.4360 AP 0.4000 AR 0.2000
Epoch 341 batch 00001: Loss 0.4617 Regression loss 0.0164 Classification loss 0.4453 AP 0.6000 AR 0.4200
Epoch 341 batch 00002: Loss 0.3510 Regression loss 0.0142 Classification loss 0.3368 AP 0.1000 AR 0.0400
Epoch 341 batch 00003: Loss 0.4377 Regression loss 0.0199 Classification loss 0.4178 AP 0.8000 AR 0.0000
Epoch 341 batch 00004: Loss 0.4436 Regression loss 0.0140 Classification loss 0.4297 AP 0.6000 AR 0.2000
Epoch 341 batch 00005: Loss 0.3466 Regression loss 0.0123 Classification loss 0.3342 AP 0.3500 AR 0.1667
Epoch 341 batch 00006: Loss 0.5008 Regression loss 0.0174 Classification loss 0.4834 AP 0.4000 AR 0.0000
Epoch 341 batch 00007: Loss 0.3768 Regression loss 0.0145 Classification loss 0.3623 AP 0.4667 AR 0.1000
Epoch 341 batch 00008: Loss 0.4891 Regression loss 0.0159 Classification loss 0.4732 AP 0.7000 AR 0.0500
Epoch 341 batch 00009: Loss 0.5454 Regression loss 0.0181 Classification loss 0.5273 AP 0.5667 AR 0.1067
Epoch 341 batch 00010: Loss 0.3657 Regression loss 0.0115 Classification loss 0.3542 AP 0.7333 AR 0.0800
Epoch 342 batch 00001: Loss 0.3675 Regression loss 0.0156 Classification loss 0.3520 AP 0.5000 AR 0.0800
Epoch 342 batch 00002: Loss 0.2751 Regression loss 0.0142 Classification loss 0.2609 AP 0.3000 AR 0.1000
Epoch 342 batch 00003: Loss 0.4901 Regression loss 0.0088 Classification loss 0.4812 AP 0.7000 AR 0.3500
Epoch 342 batch 00004: Loss 0.4534 Regression loss 0.0155 Classification loss 0.4379 AP 0.6000 AR 0.0500
Epoch 342 batch 00005: Loss 0.2831 Regression loss 0.0132 Classification loss 0.2699 AP 0.5500 AR 0.4667
Epoch 342 batch 00006: Loss 0.4134 Regression loss 0.0148 Classification loss 0.3985 AP 0.5500 AR 0.0900
Epoch 342 batch 00007: Loss 0.6005 Regression loss 0.0174 Classification loss 0.5831 AP 0.6000 AR 0.0000
Epoch 342 batch 00008: Loss 0.4666 Regression loss 0.0160 Classification loss 0.4507 AP 0.6667 AR 0.2400
Epoch 342 batch 00009: Loss 0.4974 Regression loss 0.0170 Classification loss 0.4804 AP 0.6000 AR 0.0000
Epoch 342 batch 00010: Loss 0.4310 Regression loss 0.0187 Classification loss 0.4124 AP 0.4500 AR 0.0500
Epoch 343 batch 00001: Loss 0.4289 Regression loss 0.0187 Classification loss 0.4102 AP 0.5000 AR 0.1000
Epoch 343 batch 00002: Loss 0.4407 Regression loss 0.0175 Classification loss 0.4232 AP 0.4667 AR 0.0400
Epoch 343 batch 00003: Loss 0.2988 Regression loss 0.0108 Classification loss 0.2880 AP 0.5500 AR 0.1667
Epoch 343 batch 00004: Loss 0.2287 Regression loss 0.0137 Classification loss 0.2150 AP 0.8000 AR 0.0800
Epoch 343 batch 00005: Loss 0.5317 Regression loss 0.0153 Classification loss 0.5164 AP 0.7667 AR 0.2900
Epoch 343 batch 00006: Loss 0.4968 Regression loss 0.0163 Classification loss 0.4805 AP 0.5000 AR 0.1500
Epoch 343 batch 00007: Loss 0.4968 Regression loss 0.0150 Classification loss 0.4818 AP 0.6500 AR 0.2500
Epoch 343 batch 00008: Loss 0.3179 Regression loss 0.0141 Classification loss 0.3038 AP 0.7333 AR 0.2900
Epoch 343 batch 00009: Loss 0.4674 Regression loss 0.0140 Classification loss 0.4534 AP 0.8000 AR 0.1167
Epoch 343 batch 00010: Loss 0.4823 Regression loss 0.0160 Classification loss 0.4663 AP 0.1000 AR 0.0400
Epoch 344 batch 00001: Loss 0.3586 Regression loss 0.0171 Classification loss 0.3415 AP 0.6333 AR 0.3467
Epoch 344 batch 00002: Loss 0.5085 Regression loss 0.0142 Classification loss 0.4943 AP 0.2500 AR 0.0500
Epoch 344 batch 00003: Loss 0.3488 Regression loss 0.0178 Classification loss 0.3310 AP 0.8000 AR 0.0500
Epoch 344 batch 00004: Loss 0.4627 Regression loss 0.0106 Classification loss 0.4522 AP 0.2333 AR 0.1567
Epoch 344 batch 00005: Loss 0.4261 Regression loss 0.0186 Classification loss 0.4076 AP 0.8500 AR 0.1467
Epoch 344 batch 00006: Loss 0.4731 Regression loss 0.0116 Classification loss 0.4615 AP 0.6000 AR 0.0000
Epoch 344 batch 00007: Loss 0.5030 Regression loss 0.0152 Classification loss 0.4879 AP 0.8000 AR 0.0000
Epoch 344 batch 00008: Loss 0.3834 Regression loss 0.0165 Classification loss 0.3669 AP 0.4000 AR 0.0000
Epoch 344 batch 00009: Loss 0.3181 Regression loss 0.0130 Classification loss 0.3051 AP 0.4333 AR 0.4900
Epoch 344 batch 00010: Loss 0.4277 Regression loss 0.0149 Classification loss 0.4129 AP 0.7000 AR 0.3000
Epoch 345 batch 00001: Loss 0.3234 Regression loss 0.0148 Classification loss 0.3087 AP 0.7000 AR 0.4500
Epoch 345 batch 00002: Loss 0.4209 Regression loss 0.0164 Classification loss 0.4046 AP 0.5667 AR 0.1400
Epoch 345 batch 00003: Loss 0.4919 Regression loss 0.0185 Classification loss 0.4734 AP 0.7000 AR 0.0400
Epoch 345 batch 00004: Loss 0.4034 Regression loss 0.0126 Classification loss 0.3908 AP 0.4667 AR 0.1667
Epoch 345 batch 00005: Loss 0.3536 Regression loss 0.0132 Classification loss 0.3404 AP 0.6400 AR 0.0500
Epoch 345 batch 00006: Loss 0.4771 Regression loss 0.0177 Classification loss 0.4594 AP 0.4667 AR 0.2067
Epoch 345 batch 00007: Loss 0.3969 Regression loss 0.0172 Classification loss 0.3797 AP 0.6667 AR 0.0400
Epoch 345 batch 00008: Loss 0.4850 Regression loss 0.0162 Classification loss 0.4688 AP 0.7333 AR 0.0800
Epoch 345 batch 00009: Loss 0.4941 Regression loss 0.0116 Classification loss 0.4825 AP 0.4500 AR 0.2000
Epoch 345 batch 00010: Loss 0.4082 Regression loss 0.0112 Classification loss 0.3970 AP 0.5000 AR 0.2500
Epoch 346 batch 00001: Loss 0.4047 Regression loss 0.0146 Classification loss 0.3901 AP 0.3000 AR 0.0667
Epoch 346 batch 00002: Loss 0.5227 Regression loss 0.0121 Classification loss 0.5106 AP 0.4000 AR 0.0000
Epoch 346 batch 00003: Loss 0.5681 Regression loss 0.0134 Classification loss 0.5547 AP 0.4667 AR 0.2500
Epoch 346 batch 00004: Loss 0.3781 Regression loss 0.0219 Classification loss 0.3562 AP 0.7333 AR 0.0800
Epoch 346 batch 00005: Loss 0.3463 Regression loss 0.0139 Classification loss 0.3325 AP 0.6167 AR 0.2900
Epoch 346 batch 00006: Loss 0.4037 Regression loss 0.0126 Classification loss 0.3911 AP 0.6400 AR 0.0400
Epoch 346 batch 00007: Loss 0.4094 Regression loss 0.0180 Classification loss 0.3914 AP 0.7667 AR 0.3500
Epoch 346 batch 00008: Loss 0.3302 Regression loss 0.0144 Classification loss 0.3158 AP 0.5667 AR 0.2400
Epoch 346 batch 00009: Loss 0.4344 Regression loss 0.0109 Classification loss 0.4235 AP 0.7000 AR 0.1800
Epoch 346 batch 00010: Loss 0.4646 Regression loss 0.0162 Classification loss 0.4485 AP 0.5000 AR 0.0400
Epoch 347 batch 00001: Loss 0.4518 Regression loss 0.0188 Classification loss 0.4330 AP 0.4000 AR 0.0000
Epoch 347 batch 00002: Loss 0.4182 Regression loss 0.0156 Classification loss 0.4026 AP 0.5000 AR 0.1000
Epoch 347 batch 00003: Loss 0.4139 Regression loss 0.0136 Classification loss 0.4003 AP 0.4000 AR 0.0000
Epoch 347 batch 00004: Loss 0.4903 Regression loss 0.0169 Classification loss 0.4734 AP 0.6000 AR 0.0000
Epoch 347 batch 00005: Loss 0.3966 Regression loss 0.0174 Classification loss 0.3791 AP 0.7000 AR 0.3800
Epoch 347 batch 00006: Loss 0.5461 Regression loss 0.0201 Classification loss 0.5260 AP 0.6667 AR 0.1000
Epoch 347 batch 00007: Loss 0.4133 Regression loss 0.0128 Classification loss 0.4005 AP 0.5667 AR 0.3167
Epoch 347 batch 00008: Loss 0.4337 Regression loss 0.0082 Classification loss 0.4255 AP 0.8000 AR 0.2167
Epoch 347 batch 00009: Loss 0.3129 Regression loss 0.0132 Classification loss 0.2997 AP 0.7333 AR 0.1600
Epoch 347 batch 00010: Loss 0.5411 Regression loss 0.0136 Classification loss 0.5276 AP 0.5167 AR 0.1000
Epoch 348 batch 00001: Loss 0.2595 Regression loss 0.0132 Classification loss 0.2463 AP 0.5400 AR 0.2800
Epoch 348 batch 00002: Loss 0.5013 Regression loss 0.0162 Classification loss 0.4851 AP 0.4000 AR 0.0000
Epoch 348 batch 00003: Loss 0.4937 Regression loss 0.0175 Classification loss 0.4762 AP 0.8000 AR 0.2400
Epoch 348 batch 00004: Loss 0.3599 Regression loss 0.0183 Classification loss 0.3416 AP 0.6000 AR 0.0500
Epoch 348 batch 00005: Loss 0.5721 Regression loss 0.0142 Classification loss 0.5579 AP 0.6000 AR 0.0000
Epoch 348 batch 00006: Loss 0.3171 Regression loss 0.0150 Classification loss 0.3021 AP 0.7333 AR 0.0800
Epoch 348 batch 00007: Loss 0.5608 Regression loss 0.0190 Classification loss 0.5418 AP 0.6000 AR 0.1000
Epoch 348 batch 00008: Loss 0.5482 Regression loss 0.0157 Classification loss 0.5326 AP 0.6000 AR 0.1500
Epoch 348 batch 00009: Loss 0.2896 Regression loss 0.0100 Classification loss 0.2796 AP 0.3400 AR 0.3500
Epoch 348 batch 00010: Loss 0.4326 Regression loss 0.0142 Classification loss 0.4185 AP 0.2667 AR 0.0500
Epoch 349 batch 00001: Loss 0.3834 Regression loss 0.0136 Classification loss 0.3697 AP 0.5667 AR 0.2000
Epoch 349 batch 00002: Loss 0.2729 Regression loss 0.0146 Classification loss 0.2583 AP 0.6333 AR 0.1800
Epoch 349 batch 00003: Loss 0.3509 Regression loss 0.0117 Classification loss 0.3392 AP 0.4000 AR 0.0000
Epoch 349 batch 00004: Loss 0.3494 Regression loss 0.0155 Classification loss 0.3339 AP 0.4667 AR 0.2500
Epoch 349 batch 00005: Loss 0.3631 Regression loss 0.0150 Classification loss 0.3481 AP 0.4000 AR 0.0000
Epoch 349 batch 00006: Loss 0.4734 Regression loss 0.0175 Classification loss 0.4559 AP 0.5000 AR 0.1400
Epoch 349 batch 00007: Loss 0.5066 Regression loss 0.0165 Classification loss 0.4901 AP 0.4500 AR 0.2400
Epoch 349 batch 00008: Loss 0.6850 Regression loss 0.0284 Classification loss 0.6567 AP 1.0000 AR 0.0000
Epoch 349 batch 00009: Loss 0.4786 Regression loss 0.0120 Classification loss 0.4666 AP 0.3500 AR 0.1000
Epoch 349 batch 00010: Loss 0.4870 Regression loss 0.0115 Classification loss 0.4755 AP 0.6167 AR 0.1833
Epoch 350 batch 00001: Loss 0.5146 Regression loss 0.0155 Classification loss 0.4991 AP 0.5000 AR 0.2000
Epoch 350 batch 00002: Loss 0.4668 Regression loss 0.0198 Classification loss 0.4470 AP 0.7000 AR 0.2400
Epoch 350 batch 00003: Loss 0.3749 Regression loss 0.0156 Classification loss 0.3593 AP 0.3833 AR 0.1467
Epoch 350 batch 00004: Loss 0.5200 Regression loss 0.0232 Classification loss 0.4969 AP 0.8000 AR 0.0500
Epoch 350 batch 00005: Loss 0.4615 Regression loss 0.0178 Classification loss 0.4438 AP 0.5667 AR 0.2500
Epoch 350 batch 00006: Loss 0.2564 Regression loss 0.0123 Classification loss 0.2442 AP 0.7000 AR 0.2667
Epoch 350 batch 00007: Loss 0.5263 Regression loss 0.0100 Classification loss 0.5163 AP 0.7000 AR 0.1000
Epoch 350 batch 00008: Loss 0.4772 Regression loss 0.0145 Classification loss 0.4627 AP 0.6500 AR 0.0500
Epoch 350 batch 00009: Loss 0.4326 Regression loss 0.0114 Classification loss 0.4211 AP 0.3000 AR 0.1000
Epoch 350 batch 00010: Loss 0.3358 Regression loss 0.0137 Classification loss 0.3220 AP 0.4000 AR 0.1300
Epoch 351 batch 00001: Loss 0.3869 Regression loss 0.0148 Classification loss 0.3721 AP 0.5333 AR 0.1500
Epoch 351 batch 00002: Loss 0.4998 Regression loss 0.0147 Classification loss 0.4851 AP 0.7000 AR 0.1000
Epoch 351 batch 00003: Loss 0.6119 Regression loss 0.0170 Classification loss 0.5949 AP 0.6000 AR 0.0000
Epoch 351 batch 00004: Loss 0.4457 Regression loss 0.0162 Classification loss 0.4295 AP 0.5000 AR 0.1600
Epoch 351 batch 00005: Loss 0.2504 Regression loss 0.0160 Classification loss 0.2344 AP 0.4000 AR 0.2000
Epoch 351 batch 00006: Loss 0.4014 Regression loss 0.0137 Classification loss 0.3878 AP 0.7000 AR 0.1167
Epoch 351 batch 00007: Loss 0.4694 Regression loss 0.0167 Classification loss 0.4527 AP 0.8000 AR 0.0000
Epoch 351 batch 00008: Loss 0.6237 Regression loss 0.0171 Classification loss 0.6066 AP 0.8000 AR 0.2000
Epoch 351 batch 00009: Loss 0.4433 Regression loss 0.0178 Classification loss 0.4256 AP 0.3500 AR 0.3167
Epoch 351 batch 00010: Loss 0.5005 Regression loss 0.0131 Classification loss 0.4874 AP 0.2667 AR 0.0500
Epoch 352 batch 00001: Loss 0.5606 Regression loss 0.0170 Classification loss 0.5436 AP 0.4000 AR 0.2000
Epoch 352 batch 00002: Loss 0.4088 Regression loss 0.0150 Classification loss 0.3938 AP 0.8000 AR 0.0500
Epoch 352 batch 00003: Loss 0.5102 Regression loss 0.0160 Classification loss 0.4943 AP 0.6000 AR 0.2900
Epoch 352 batch 00004: Loss 0.4495 Regression loss 0.0124 Classification loss 0.4372 AP 0.3000 AR 0.1000
Epoch 352 batch 00005: Loss 0.4243 Regression loss 0.0163 Classification loss 0.4079 AP 0.6333 AR 0.2400
Epoch 352 batch 00006: Loss 0.3170 Regression loss 0.0180 Classification loss 0.2990 AP 0.2000 AR 0.1800
Epoch 352 batch 00007: Loss 0.4654 Regression loss 0.0184 Classification loss 0.4470 AP 0.6400 AR 0.0500
Epoch 352 batch 00008: Loss 0.4586 Regression loss 0.0133 Classification loss 0.4454 AP 0.4000 AR 0.0000
Epoch 352 batch 00009: Loss 0.6096 Regression loss 0.0159 Classification loss 0.5936 AP 1.0000 AR 0.2000
Epoch 352 batch 00010: Loss 0.4245 Regression loss 0.0157 Classification loss 0.4087 AP 0.5667 AR 0.1800
Epoch 353 batch 00001: Loss 0.4742 Regression loss 0.0150 Classification loss 0.4591 AP 0.8000 AR 0.1500
Epoch 353 batch 00002: Loss 0.4808 Regression loss 0.0205 Classification loss 0.4602 AP 0.7000 AR 0.2400
Epoch 353 batch 00003: Loss 0.3766 Regression loss 0.0125 Classification loss 0.3640 AP 0.3167 AR 0.1167
Epoch 353 batch 00004: Loss 0.5024 Regression loss 0.0121 Classification loss 0.4904 AP 0.4667 AR 0.2500
Epoch 353 batch 00005: Loss 0.4461 Regression loss 0.0120 Classification loss 0.4341 AP 0.3167 AR 0.0900
Epoch 353 batch 00006: Loss 0.5402 Regression loss 0.0123 Classification loss 0.5279 AP 0.6000 AR 0.2000
Epoch 353 batch 00007: Loss 0.3371 Regression loss 0.0171 Classification loss 0.3200 AP 0.4667 AR 0.0400
Epoch 353 batch 00008: Loss 0.2719 Regression loss 0.0134 Classification loss 0.2584 AP 0.8333 AR 0.1800
Epoch 353 batch 00009: Loss 0.5524 Regression loss 0.0193 Classification loss 0.5331 AP 0.6000 AR 0.0000
Epoch 353 batch 00010: Loss 0.4381 Regression loss 0.0135 Classification loss 0.4246 AP 0.5500 AR 0.1067
Epoch 354 batch 00001: Loss 0.3237 Regression loss 0.0160 Classification loss 0.3077 AP 0.2000 AR 0.0000
Epoch 354 batch 00002: Loss 0.2811 Regression loss 0.0123 Classification loss 0.2688 AP 0.8000 AR 0.4000
Epoch 354 batch 00003: Loss 0.3639 Regression loss 0.0191 Classification loss 0.3448 AP 0.8000 AR 0.1200
Epoch 354 batch 00004: Loss 0.5808 Regression loss 0.0155 Classification loss 0.5654 AP 0.7000 AR 0.1000
Epoch 354 batch 00005: Loss 0.4380 Regression loss 0.0131 Classification loss 0.4249 AP 0.3000 AR 0.1000
Epoch 354 batch 00006: Loss 0.5609 Regression loss 0.0140 Classification loss 0.5469 AP 0.8000 AR 0.2000
Epoch 354 batch 00007: Loss 0.3855 Regression loss 0.0146 Classification loss 0.3709 AP 0.3500 AR 0.1167
Epoch 354 batch 00008: Loss 0.3982 Regression loss 0.0142 Classification loss 0.3840 AP 0.6000 AR 0.1400
Epoch 354 batch 00009: Loss 0.5363 Regression loss 0.0133 Classification loss 0.5230 AP 0.5667 AR 0.0900
Epoch 354 batch 00010: Loss 0.3510 Regression loss 0.0174 Classification loss 0.3337 AP 0.5500 AR 0.2000
Epoch 355 batch 00001: Loss 0.4194 Regression loss 0.0113 Classification loss 0.4081 AP 0.6000 AR 0.0000
Epoch 355 batch 00002: Loss 0.4440 Regression loss 0.0184 Classification loss 0.4256 AP 0.6000 AR 0.0500
Epoch 355 batch 00003: Loss 0.4119 Regression loss 0.0138 Classification loss 0.3980 AP 0.3000 AR 0.1000
Epoch 355 batch 00004: Loss 0.4304 Regression loss 0.0156 Classification loss 0.4148 AP 0.7000 AR 0.2000
Epoch 355 batch 00005: Loss 0.5786 Regression loss 0.0209 Classification loss 0.5576 AP 0.6000 AR 0.0000
Epoch 355 batch 00006: Loss 0.2782 Regression loss 0.0149 Classification loss 0.2634 AP 0.3167 AR 0.2900
Epoch 355 batch 00007: Loss 0.2604 Regression loss 0.0112 Classification loss 0.2492 AP 0.6333 AR 0.1467
Epoch 355 batch 00008: Loss 0.4817 Regression loss 0.0166 Classification loss 0.4651 AP 0.6667 AR 0.1800
Epoch 355 batch 00009: Loss 0.4324 Regression loss 0.0128 Classification loss 0.4196 AP 0.6500 AR 0.2400
Epoch 355 batch 00010: Loss 0.5354 Regression loss 0.0109 Classification loss 0.5245 AP 0.4667 AR 0.2000
Epoch 356 batch 00001: Loss 0.4642 Regression loss 0.0114 Classification loss 0.4528 AP 0.5333 AR 0.2567
Epoch 356 batch 00002: Loss 0.4457 Regression loss 0.0163 Classification loss 0.4294 AP 0.6000 AR 0.0000
Epoch 356 batch 00003: Loss 0.3161 Regression loss 0.0172 Classification loss 0.2989 AP 0.7667 AR 0.1067
Epoch 356 batch 00004: Loss 0.4283 Regression loss 0.0114 Classification loss 0.4170 AP 0.2000 AR 0.3000
Epoch 356 batch 00005: Loss 0.3236 Regression loss 0.0166 Classification loss 0.3070 AP 0.5833 AR 0.3467
Epoch 356 batch 00006: Loss 0.3258 Regression loss 0.0131 Classification loss 0.3127 AP 0.4000 AR 0.2500
Epoch 356 batch 00007: Loss 0.4953 Regression loss 0.0160 Classification loss 0.4793 AP 0.7500 AR 0.1167
Epoch 356 batch 00008: Loss 0.5575 Regression loss 0.0158 Classification loss 0.5417 AP 0.5000 AR 0.0400
Epoch 356 batch 00009: Loss 0.3659 Regression loss 0.0151 Classification loss 0.3508 AP 0.4400 AR 0.0500
Epoch 356 batch 00010: Loss 0.6284 Regression loss 0.0156 Classification loss 0.6128 AP 0.8667 AR 0.0500
Epoch 357 batch 00001: Loss 0.3473 Regression loss 0.0134 Classification loss 0.3340 AP 0.6000 AR 0.2000
Epoch 357 batch 00002: Loss 0.5180 Regression loss 0.0144 Classification loss 0.5036 AP 0.8000 AR 0.0000
Epoch 357 batch 00003: Loss 0.2989 Regression loss 0.0127 Classification loss 0.2862 AP 0.7167 AR 0.4200
Epoch 357 batch 00004: Loss 0.3921 Regression loss 0.0141 Classification loss 0.3780 AP 0.4000 AR 0.2500
Epoch 357 batch 00005: Loss 0.2994 Regression loss 0.0135 Classification loss 0.2858 AP 0.7000 AR 0.0500
Epoch 357 batch 00006: Loss 0.4022 Regression loss 0.0156 Classification loss 0.3866 AP 0.7000 AR 0.1000
Epoch 357 batch 00007: Loss 0.7540 Regression loss 0.0164 Classification loss 0.7376 AP 0.6000 AR 0.2000
Epoch 357 batch 00008: Loss 0.4046 Regression loss 0.0174 Classification loss 0.3871 AP 0.4333 AR 0.2267
Epoch 357 batch 00009: Loss 0.6925 Regression loss 0.0147 Classification loss 0.6778 AP 0.7000 AR 0.0500
Epoch 357 batch 00010: Loss 0.4167 Regression loss 0.0130 Classification loss 0.4037 AP 0.4000 AR 0.1667
Epoch 358 batch 00001: Loss 0.3819 Regression loss 0.0149 Classification loss 0.3669 AP 0.1667 AR 0.1067
Epoch 358 batch 00002: Loss 0.4835 Regression loss 0.0128 Classification loss 0.4707 AP 0.5667 AR 0.1400
Epoch 358 batch 00003: Loss 0.4990 Regression loss 0.0131 Classification loss 0.4860 AP 0.7000 AR 0.3167
Epoch 358 batch 00004: Loss 0.2907 Regression loss 0.0124 Classification loss 0.2783 AP 0.6333 AR 0.3200
Epoch 358 batch 00005: Loss 0.4606 Regression loss 0.0193 Classification loss 0.4413 AP 1.0000 AR 0.0500
Epoch 358 batch 00006: Loss 0.5510 Regression loss 0.0145 Classification loss 0.5365 AP 0.6000 AR 0.1500
Epoch 358 batch 00007: Loss 0.4632 Regression loss 0.0136 Classification loss 0.4496 AP 0.7000 AR 0.2000
Epoch 358 batch 00008: Loss 0.3947 Regression loss 0.0169 Classification loss 0.3778 AP 0.3000 AR 0.0500
Epoch 358 batch 00009: Loss 0.5525 Regression loss 0.0132 Classification loss 0.5393 AP 0.4500 AR 0.0500
Epoch 358 batch 00010: Loss 0.3454 Regression loss 0.0137 Classification loss 0.3317 AP 0.6667 AR 0.0400
Epoch 359 batch 00001: Loss 0.4864 Regression loss 0.0154 Classification loss 0.4710 AP 0.3000 AR 0.1000
Epoch 359 batch 00002: Loss 0.5676 Regression loss 0.0173 Classification loss 0.5503 AP 0.7000 AR 0.0500
Epoch 359 batch 00003: Loss 0.3429 Regression loss 0.0133 Classification loss 0.3296 AP 0.7500 AR 0.3800
Epoch 359 batch 00004: Loss 0.3644 Regression loss 0.0141 Classification loss 0.3503 AP 0.6000 AR 0.1800
Epoch 359 batch 00005: Loss 0.4184 Regression loss 0.0162 Classification loss 0.4022 AP 0.4000 AR 0.0500
Epoch 359 batch 00006: Loss 0.4335 Regression loss 0.0120 Classification loss 0.4215 AP 0.2400 AR 0.0500
Epoch 359 batch 00007: Loss 0.3280 Regression loss 0.0160 Classification loss 0.3120 AP 0.8000 AR 0.4000
Epoch 359 batch 00008: Loss 0.3322 Regression loss 0.0113 Classification loss 0.3209 AP 0.7000 AR 0.0667
Epoch 359 batch 00009: Loss 0.4743 Regression loss 0.0157 Classification loss 0.4586 AP 0.6500 AR 0.1467
Epoch 359 batch 00010: Loss 0.4575 Regression loss 0.0146 Classification loss 0.4429 AP 0.7667 AR 0.1400
Epoch 360 batch 00001: Loss 0.4523 Regression loss 0.0140 Classification loss 0.4383 AP 0.2667 AR 0.0400
Epoch 360 batch 00002: Loss 0.5313 Regression loss 0.0175 Classification loss 0.5139 AP 0.5000 AR 0.0667
Epoch 360 batch 00003: Loss 0.4457 Regression loss 0.0107 Classification loss 0.4350 AP 0.6667 AR 0.3000
Epoch 360 batch 00004: Loss 0.5580 Regression loss 0.0164 Classification loss 0.5416 AP 0.8000 AR 0.0000
Epoch 360 batch 00005: Loss 0.3695 Regression loss 0.0131 Classification loss 0.3565 AP 0.5000 AR 0.4000
Epoch 360 batch 00006: Loss 0.4078 Regression loss 0.0125 Classification loss 0.3953 AP 0.7000 AR 0.1500
Epoch 360 batch 00007: Loss 0.5956 Regression loss 0.0168 Classification loss 0.5788 AP 0.7000 AR 0.0400
Epoch 360 batch 00008: Loss 0.2719 Regression loss 0.0135 Classification loss 0.2584 AP 0.5000 AR 0.1600
Epoch 360 batch 00009: Loss 0.5595 Regression loss 0.0169 Classification loss 0.5427 AP 0.5000 AR 0.1000
Epoch 360 batch 00010: Loss 0.3901 Regression loss 0.0137 Classification loss 0.3764 AP 0.5500 AR 0.1667
Epoch 361 batch 00001: Loss 0.3222 Regression loss 0.0111 Classification loss 0.3111 AP 0.6000 AR 0.3167
Epoch 361 batch 00002: Loss 0.4575 Regression loss 0.0147 Classification loss 0.4428 AP 0.6000 AR 0.0000
Epoch 361 batch 00003: Loss 0.4516 Regression loss 0.0165 Classification loss 0.4351 AP 0.5000 AR 0.1000
Epoch 361 batch 00004: Loss 0.3942 Regression loss 0.0147 Classification loss 0.3795 AP 0.5333 AR 0.1300
Epoch 361 batch 00005: Loss 0.3154 Regression loss 0.0140 Classification loss 0.3015 AP 0.7000 AR 0.2400
Epoch 361 batch 00006: Loss 0.4994 Regression loss 0.0144 Classification loss 0.4851 AP 0.7000 AR 0.3800
Epoch 361 batch 00007: Loss 0.5131 Regression loss 0.0177 Classification loss 0.4954 AP 0.6000 AR 0.0000
Epoch 361 batch 00008: Loss 0.3838 Regression loss 0.0143 Classification loss 0.3695 AP 0.6167 AR 0.2500
Epoch 361 batch 00009: Loss 0.4782 Regression loss 0.0204 Classification loss 0.4578 AP 0.6000 AR 0.0000
Epoch 361 batch 00010: Loss 0.4063 Regression loss 0.0113 Classification loss 0.3950 AP 0.4500 AR 0.2067
Epoch 362 batch 00001: Loss 0.3854 Regression loss 0.0175 Classification loss 0.3679 AP 0.8667 AR 0.0900
Epoch 362 batch 00002: Loss 0.3099 Regression loss 0.0141 Classification loss 0.2959 AP 0.2000 AR 0.0000
Epoch 362 batch 00003: Loss 0.3624 Regression loss 0.0105 Classification loss 0.3519 AP 0.5500 AR 0.1167
Epoch 362 batch 00004: Loss 0.3378 Regression loss 0.0161 Classification loss 0.3218 AP 0.4333 AR 0.1800
Epoch 362 batch 00005: Loss 0.5378 Regression loss 0.0156 Classification loss 0.5222 AP 0.7000 AR 0.1000
Epoch 362 batch 00006: Loss 0.4985 Regression loss 0.0162 Classification loss 0.4823 AP 0.5667 AR 0.3067
Epoch 362 batch 00007: Loss 0.3776 Regression loss 0.0148 Classification loss 0.3628 AP 0.6500 AR 0.4500
Epoch 362 batch 00008: Loss 0.5024 Regression loss 0.0174 Classification loss 0.4850 AP 0.7000 AR 0.2400
Epoch 362 batch 00009: Loss 0.5296 Regression loss 0.0103 Classification loss 0.5193 AP 0.5000 AR 0.0500
Epoch 362 batch 00010: Loss 0.5203 Regression loss 0.0126 Classification loss 0.5076 AP 0.6400 AR 0.0400
Epoch 363 batch 00001: Loss 0.3685 Regression loss 0.0124 Classification loss 0.3561 AP 0.5000 AR 0.1000
Epoch 363 batch 00002: Loss 0.3070 Regression loss 0.0140 Classification loss 0.2930 AP 0.9000 AR 0.2667
Epoch 363 batch 00003: Loss 0.4199 Regression loss 0.0156 Classification loss 0.4043 AP 0.4667 AR 0.1800
Epoch 363 batch 00004: Loss 0.4828 Regression loss 0.0163 Classification loss 0.4665 AP 0.6000 AR 0.2000
Epoch 363 batch 00005: Loss 0.6020 Regression loss 0.0180 Classification loss 0.5841 AP 0.8000 AR 0.1167
Epoch 363 batch 00006: Loss 0.5281 Regression loss 0.0123 Classification loss 0.5159 AP 0.0000 AR 0.0000
Epoch 363 batch 00007: Loss 0.3901 Regression loss 0.0136 Classification loss 0.3765 AP 0.6000 AR 0.2800
Epoch 363 batch 00008: Loss 0.3460 Regression loss 0.0126 Classification loss 0.3334 AP 0.6333 AR 0.1800
Epoch 363 batch 00009: Loss 0.4070 Regression loss 0.0161 Classification loss 0.3909 AP 0.7667 AR 0.1900
Epoch 363 batch 00010: Loss 0.3890 Regression loss 0.0151 Classification loss 0.3739 AP 0.7000 AR 0.1000
Epoch 364 batch 00001: Loss 0.4831 Regression loss 0.0182 Classification loss 0.4648 AP 0.8000 AR 0.0000
Epoch 364 batch 00002: Loss 0.4004 Regression loss 0.0140 Classification loss 0.3865 AP 0.5667 AR 0.1400
Epoch 364 batch 00003: Loss 0.3350 Regression loss 0.0129 Classification loss 0.3221 AP 0.6000 AR 0.2000
Epoch 364 batch 00004: Loss 0.3008 Regression loss 0.0129 Classification loss 0.2879 AP 0.5733 AR 0.1300
Epoch 364 batch 00005: Loss 0.3242 Regression loss 0.0163 Classification loss 0.3079 AP 0.6067 AR 0.3900
Epoch 364 batch 00006: Loss 0.4116 Regression loss 0.0106 Classification loss 0.4010 AP 0.6667 AR 0.0667
Epoch 364 batch 00007: Loss 0.4999 Regression loss 0.0176 Classification loss 0.4824 AP 0.4000 AR 0.0000
Epoch 364 batch 00008: Loss 0.4980 Regression loss 0.0144 Classification loss 0.4835 AP 0.7000 AR 0.2667
Epoch 364 batch 00009: Loss 0.5368 Regression loss 0.0152 Classification loss 0.5217 AP 0.5000 AR 0.1000
Epoch 364 batch 00010: Loss 0.4858 Regression loss 0.0146 Classification loss 0.4712 AP 0.3333 AR 0.1700
Epoch 365 batch 00001: Loss 0.3563 Regression loss 0.0140 Classification loss 0.3423 AP 0.4000 AR 0.0000
Epoch 365 batch 00002: Loss 0.3402 Regression loss 0.0144 Classification loss 0.3258 AP 0.4667 AR 0.2300
Epoch 365 batch 00003: Loss 0.5431 Regression loss 0.0113 Classification loss 0.5318 AP 0.6000 AR 0.2000
Epoch 365 batch 00004: Loss 0.3323 Regression loss 0.0138 Classification loss 0.3185 AP 0.4333 AR 0.2900
Epoch 365 batch 00005: Loss 0.5271 Regression loss 0.0190 Classification loss 0.5081 AP 0.7000 AR 0.1000
Epoch 365 batch 00006: Loss 0.3677 Regression loss 0.0142 Classification loss 0.3536 AP 0.2000 AR 0.0000
Epoch 365 batch 00007: Loss 0.4291 Regression loss 0.0129 Classification loss 0.4162 AP 0.7000 AR 0.1500
Epoch 365 batch 00008: Loss 0.6286 Regression loss 0.0171 Classification loss 0.6115 AP 0.8000 AR 0.0000
Epoch 365 batch 00009: Loss 0.4754 Regression loss 0.0172 Classification loss 0.4582 AP 0.8500 AR 0.3300
Epoch 365 batch 00010: Loss 0.5571 Regression loss 0.0140 Classification loss 0.5431 AP 0.4000 AR 0.1500
Epoch 366 batch 00001: Loss 0.5113 Regression loss 0.0177 Classification loss 0.4935 AP 0.7000 AR 0.2800
Epoch 366 batch 00002: Loss 0.4005 Regression loss 0.0134 Classification loss 0.3870 AP 0.3000 AR 0.0667
Epoch 366 batch 00003: Loss 0.3686 Regression loss 0.0136 Classification loss 0.3551 AP 0.4333 AR 0.1467
Epoch 366 batch 00004: Loss 0.5369 Regression loss 0.0185 Classification loss 0.5184 AP 0.6667 AR 0.0400
Epoch 366 batch 00005: Loss 0.4094 Regression loss 0.0178 Classification loss 0.3915 AP 0.8000 AR 0.0500
Epoch 366 batch 00006: Loss 0.4705 Regression loss 0.0142 Classification loss 0.4562 AP 0.7000 AR 0.1000
Epoch 366 batch 00007: Loss 0.4117 Regression loss 0.0125 Classification loss 0.3993 AP 0.2500 AR 0.1900
Epoch 366 batch 00008: Loss 0.5570 Regression loss 0.0126 Classification loss 0.5445 AP 0.7000 AR 0.2500
Epoch 366 batch 00009: Loss 0.4949 Regression loss 0.0142 Classification loss 0.4806 AP 0.6667 AR 0.1900
Epoch 366 batch 00010: Loss 0.3985 Regression loss 0.0157 Classification loss 0.3828 AP 0.8000 AR 0.0000
Epoch 367 batch 00001: Loss 0.5085 Regression loss 0.0197 Classification loss 0.4888 AP 0.7000 AR 0.0667
Epoch 367 batch 00002: Loss 0.3791 Regression loss 0.0100 Classification loss 0.3691 AP 0.3500 AR 0.1067
Epoch 367 batch 00003: Loss 0.4104 Regression loss 0.0138 Classification loss 0.3966 AP 0.4000 AR 0.2000
Epoch 367 batch 00004: Loss 0.4118 Regression loss 0.0145 Classification loss 0.3972 AP 0.4667 AR 0.1000
Epoch 367 batch 00005: Loss 0.4940 Regression loss 0.0150 Classification loss 0.4790 AP 0.4667 AR 0.0400
Epoch 367 batch 00006: Loss 0.2498 Regression loss 0.0144 Classification loss 0.2354 AP 0.6500 AR 0.0667
Epoch 367 batch 00007: Loss 0.4511 Regression loss 0.0158 Classification loss 0.4353 AP 0.7000 AR 0.0500
Epoch 367 batch 00008: Loss 0.5300 Regression loss 0.0146 Classification loss 0.5154 AP 0.5500 AR 0.2500
Epoch 367 batch 00009: Loss 0.4277 Regression loss 0.0147 Classification loss 0.4130 AP 0.8333 AR 0.1300
Epoch 367 batch 00010: Loss 0.5053 Regression loss 0.0154 Classification loss 0.4899 AP 0.6667 AR 0.2900
Epoch 368 batch 00001: Loss 0.3699 Regression loss 0.0110 Classification loss 0.3590 AP 0.3500 AR 0.3167
Epoch 368 batch 00002: Loss 0.4569 Regression loss 0.0142 Classification loss 0.4427 AP 0.6500 AR 0.2000
Epoch 368 batch 00003: Loss 0.6003 Regression loss 0.0177 Classification loss 0.5826 AP 0.8000 AR 0.0000
Epoch 368 batch 00004: Loss 0.5414 Regression loss 0.0121 Classification loss 0.5293 AP 0.5000 AR 0.1000
Epoch 368 batch 00005: Loss 0.4583 Regression loss 0.0135 Classification loss 0.4447 AP 0.6000 AR 0.2000
Epoch 368 batch 00006: Loss 0.3699 Regression loss 0.0162 Classification loss 0.3536 AP 0.5667 AR 0.0900
Epoch 368 batch 00007: Loss 0.4752 Regression loss 0.0180 Classification loss 0.4572 AP 0.6000 AR 0.0000
Epoch 368 batch 00008: Loss 0.4903 Regression loss 0.0147 Classification loss 0.4756 AP 0.5000 AR 0.0400
Epoch 368 batch 00009: Loss 0.3134 Regression loss 0.0174 Classification loss 0.2961 AP 0.8333 AR 0.3267
Epoch 368 batch 00010: Loss 0.4051 Regression loss 0.0161 Classification loss 0.3890 AP 0.7000 AR 0.3500
Epoch 369 batch 00001: Loss 0.4194 Regression loss 0.0121 Classification loss 0.4073 AP 0.6167 AR 0.2667
Epoch 369 batch 00002: Loss 0.4710 Regression loss 0.0100 Classification loss 0.4610 AP 0.5000 AR 0.2667
Epoch 369 batch 00003: Loss 0.4520 Regression loss 0.0159 Classification loss 0.4361 AP 0.2500 AR 0.0500
Epoch 369 batch 00004: Loss 0.5708 Regression loss 0.0157 Classification loss 0.5551 AP 0.4667 AR 0.0400
Epoch 369 batch 00005: Loss 0.2451 Regression loss 0.0152 Classification loss 0.2299 AP 0.8000 AR 0.0800
Epoch 369 batch 00006: Loss 0.4979 Regression loss 0.0172 Classification loss 0.4807 AP 0.9000 AR 0.2400
Epoch 369 batch 00007: Loss 0.5901 Regression loss 0.0168 Classification loss 0.5733 AP 0.7000 AR 0.0400
Epoch 369 batch 00008: Loss 0.3143 Regression loss 0.0137 Classification loss 0.3006 AP 0.7000 AR 0.4500
Epoch 369 batch 00009: Loss 0.4411 Regression loss 0.0151 Classification loss 0.4260 AP 0.2900 AR 0.0900
Epoch 369 batch 00010: Loss 0.3895 Regression loss 0.0129 Classification loss 0.3766 AP 0.2833 AR 0.1000
Epoch 370 batch 00001: Loss 0.5116 Regression loss 0.0211 Classification loss 0.4906 AP 0.6000 AR 0.0000
Epoch 370 batch 00002: Loss 0.4955 Regression loss 0.0121 Classification loss 0.4834 AP 0.4000 AR 0.3000
Epoch 370 batch 00003: Loss 0.4083 Regression loss 0.0185 Classification loss 0.3899 AP 0.8667 AR 0.0667
Epoch 370 batch 00004: Loss 0.3738 Regression loss 0.0165 Classification loss 0.3573 AP 0.6667 AR 0.0500
Epoch 370 batch 00005: Loss 0.4289 Regression loss 0.0135 Classification loss 0.4154 AP 0.4667 AR 0.2400
Epoch 370 batch 00006: Loss 0.5193 Regression loss 0.0103 Classification loss 0.5090 AP 0.5500 AR 0.3000
Epoch 370 batch 00007: Loss 0.4204 Regression loss 0.0108 Classification loss 0.4097 AP 0.5000 AR 0.0667
Epoch 370 batch 00008: Loss 0.2529 Regression loss 0.0156 Classification loss 0.2373 AP 0.9000 AR 0.0400
Epoch 370 batch 00009: Loss 0.3836 Regression loss 0.0148 Classification loss 0.3688 AP 0.4000 AR 0.2000
Epoch 370 batch 00010: Loss 0.4186 Regression loss 0.0162 Classification loss 0.4023 AP 0.4667 AR 0.2200
Epoch 371 batch 00001: Loss 0.5690 Regression loss 0.0166 Classification loss 0.5523 AP 0.7000 AR 0.1000
Epoch 371 batch 00002: Loss 0.3092 Regression loss 0.0134 Classification loss 0.2958 AP 0.7000 AR 0.2000
Epoch 371 batch 00003: Loss 0.3284 Regression loss 0.0141 Classification loss 0.3144 AP 0.1000 AR 0.0800
Epoch 371 batch 00004: Loss 0.3761 Regression loss 0.0173 Classification loss 0.3589 AP 0.9333 AR 0.3300
Epoch 371 batch 00005: Loss 0.3917 Regression loss 0.0111 Classification loss 0.3806 AP 0.4500 AR 0.0667
Epoch 371 batch 00006: Loss 0.4567 Regression loss 0.0137 Classification loss 0.4431 AP 0.4667 AR 0.0667
Epoch 371 batch 00007: Loss 0.5758 Regression loss 0.0164 Classification loss 0.5594 AP 0.6000 AR 0.1400
Epoch 371 batch 00008: Loss 0.4377 Regression loss 0.0163 Classification loss 0.4213 AP 0.4000 AR 0.0000
Epoch 371 batch 00009: Loss 0.4831 Regression loss 0.0108 Classification loss 0.4723 AP 0.3167 AR 0.1000
Epoch 371 batch 00010: Loss 0.3761 Regression loss 0.0167 Classification loss 0.3595 AP 0.6067 AR 0.1900
Epoch 372 batch 00001: Loss 0.3515 Regression loss 0.0123 Classification loss 0.3391 AP 0.3500 AR 0.1667
Epoch 372 batch 00002: Loss 0.3283 Regression loss 0.0139 Classification loss 0.3143 AP 0.8667 AR 0.2000
Epoch 372 batch 00003: Loss 0.5064 Regression loss 0.0214 Classification loss 0.4850 AP 0.6667 AR 0.2067
Epoch 372 batch 00004: Loss 0.4338 Regression loss 0.0136 Classification loss 0.4203 AP 0.4500 AR 0.0400
Epoch 372 batch 00005: Loss 0.4308 Regression loss 0.0122 Classification loss 0.4186 AP 0.5500 AR 0.1000
Epoch 372 batch 00006: Loss 0.6193 Regression loss 0.0126 Classification loss 0.6067 AP 0.6667 AR 0.0500
Epoch 372 batch 00007: Loss 0.4149 Regression loss 0.0141 Classification loss 0.4008 AP 0.7000 AR 0.1000
Epoch 372 batch 00008: Loss 0.4137 Regression loss 0.0151 Classification loss 0.3986 AP 0.5000 AR 0.3200
Epoch 372 batch 00009: Loss 0.6208 Regression loss 0.0192 Classification loss 0.6016 AP 0.8000 AR 0.2000
Epoch 372 batch 00010: Loss 0.3145 Regression loss 0.0137 Classification loss 0.3008 AP 0.5667 AR 0.3567
Epoch 373 batch 00001: Loss 0.4443 Regression loss 0.0107 Classification loss 0.4336 AP 0.6000 AR 0.1500
Epoch 373 batch 00002: Loss 0.4540 Regression loss 0.0148 Classification loss 0.4392 AP 0.4000 AR 0.0000
Epoch 373 batch 00003: Loss 0.5434 Regression loss 0.0143 Classification loss 0.5291 AP 0.7000 AR 0.2500
Epoch 373 batch 00004: Loss 0.4691 Regression loss 0.0162 Classification loss 0.4529 AP 0.5500 AR 0.1500
Epoch 373 batch 00005: Loss 0.3661 Regression loss 0.0134 Classification loss 0.3528 AP 0.5833 AR 0.2500
Epoch 373 batch 00006: Loss 0.4942 Regression loss 0.0136 Classification loss 0.4807 AP 0.7000 AR 0.1000
Epoch 373 batch 00007: Loss 0.3844 Regression loss 0.0129 Classification loss 0.3716 AP 0.2667 AR 0.0400
Epoch 373 batch 00008: Loss 0.3839 Regression loss 0.0150 Classification loss 0.3690 AP 0.8000 AR 0.2000
Epoch 373 batch 00009: Loss 0.2971 Regression loss 0.0099 Classification loss 0.2872 AP 0.6000 AR 0.2167
Epoch 373 batch 00010: Loss 0.5412 Regression loss 0.0203 Classification loss 0.5209 AP 0.4500 AR 0.0400
Epoch 374 batch 00001: Loss 0.5884 Regression loss 0.0194 Classification loss 0.5690 AP 0.6000 AR 0.1667
Epoch 374 batch 00002: Loss 0.5310 Regression loss 0.0121 Classification loss 0.5189 AP 0.2667 AR 0.0500
Epoch 374 batch 00003: Loss 0.4451 Regression loss 0.0163 Classification loss 0.4288 AP 0.4000 AR 0.1800
Epoch 374 batch 00004: Loss 0.3646 Regression loss 0.0153 Classification loss 0.3493 AP 0.7000 AR 0.0400
Epoch 374 batch 00005: Loss 0.4019 Regression loss 0.0132 Classification loss 0.3887 AP 0.6667 AR 0.2900
Epoch 374 batch 00006: Loss 0.5143 Regression loss 0.0139 Classification loss 0.5004 AP 0.4667 AR 0.1400
Epoch 374 batch 00007: Loss 0.3105 Regression loss 0.0117 Classification loss 0.2988 AP 0.8000 AR 0.3300
Epoch 374 batch 00008: Loss 0.3111 Regression loss 0.0121 Classification loss 0.2989 AP 0.6000 AR 0.0000
Epoch 374 batch 00009: Loss 0.4196 Regression loss 0.0146 Classification loss 0.4050 AP 0.3000 AR 0.0500
Epoch 374 batch 00010: Loss 0.5537 Regression loss 0.0185 Classification loss 0.5352 AP 0.9000 AR 0.3000
Epoch 375 batch 00001: Loss 0.5220 Regression loss 0.0201 Classification loss 0.5020 AP 0.7000 AR 0.3000
Epoch 375 batch 00002: Loss 0.3998 Regression loss 0.0128 Classification loss 0.3870 AP 0.2500 AR 0.0500
Epoch 375 batch 00003: Loss 0.3521 Regression loss 0.0093 Classification loss 0.3429 AP 0.3833 AR 0.2167
Epoch 375 batch 00004: Loss 0.5975 Regression loss 0.0194 Classification loss 0.5781 AP 0.8000 AR 0.0000
Epoch 375 batch 00005: Loss 0.3406 Regression loss 0.0102 Classification loss 0.3304 AP 0.8000 AR 0.0800
Epoch 375 batch 00006: Loss 0.3826 Regression loss 0.0144 Classification loss 0.3682 AP 0.8000 AR 0.0800
Epoch 375 batch 00007: Loss 0.4614 Regression loss 0.0123 Classification loss 0.4490 AP 0.7000 AR 0.0500
Epoch 375 batch 00008: Loss 0.4606 Regression loss 0.0108 Classification loss 0.4498 AP 0.5333 AR 0.4467
Epoch 375 batch 00009: Loss 0.4077 Regression loss 0.0172 Classification loss 0.3904 AP 0.4667 AR 0.0500
Epoch 375 batch 00010: Loss 0.3749 Regression loss 0.0149 Classification loss 0.3600 AP 0.5667 AR 0.3900
Epoch 376 batch 00001: Loss 0.6059 Regression loss 0.0221 Classification loss 0.5838 AP 1.0000 AR 0.2000
Epoch 376 batch 00002: Loss 0.4833 Regression loss 0.0181 Classification loss 0.4652 AP 0.7000 AR 0.1000
Epoch 376 batch 00003: Loss 0.3469 Regression loss 0.0094 Classification loss 0.3375 AP 0.2500 AR 0.0500
Epoch 376 batch 00004: Loss 0.4662 Regression loss 0.0120 Classification loss 0.4542 AP 0.5000 AR 0.3467
Epoch 376 batch 00005: Loss 0.3164 Regression loss 0.0135 Classification loss 0.3029 AP 0.6000 AR 0.3800
Epoch 376 batch 00006: Loss 0.3327 Regression loss 0.0139 Classification loss 0.3188 AP 0.6400 AR 0.0500
Epoch 376 batch 00007: Loss 0.3930 Regression loss 0.0158 Classification loss 0.3772 AP 0.6000 AR 0.0500
Epoch 376 batch 00008: Loss 0.5525 Regression loss 0.0157 Classification loss 0.5368 AP 0.4000 AR 0.1167
Epoch 376 batch 00009: Loss 0.2879 Regression loss 0.0126 Classification loss 0.2753 AP 0.3333 AR 0.0800
Epoch 376 batch 00010: Loss 0.5276 Regression loss 0.0118 Classification loss 0.5158 AP 0.6667 AR 0.0400
Epoch 377 batch 00001: Loss 0.3826 Regression loss 0.0110 Classification loss 0.3717 AP 0.2500 AR 0.1900
Epoch 377 batch 00002: Loss 0.4478 Regression loss 0.0154 Classification loss 0.4324 AP 0.6667 AR 0.0400
Epoch 377 batch 00003: Loss 0.5488 Regression loss 0.0141 Classification loss 0.5347 AP 0.6000 AR 0.2000
Epoch 377 batch 00004: Loss 0.4500 Regression loss 0.0142 Classification loss 0.4358 AP 0.7000 AR 0.0400
Epoch 377 batch 00005: Loss 0.2544 Regression loss 0.0142 Classification loss 0.2403 AP 0.6500 AR 0.2500
Epoch 377 batch 00006: Loss 0.3135 Regression loss 0.0119 Classification loss 0.3016 AP 0.4333 AR 0.3300
Epoch 377 batch 00007: Loss 0.3860 Regression loss 0.0158 Classification loss 0.3702 AP 0.8000 AR 0.0500
Epoch 377 batch 00008: Loss 0.4836 Regression loss 0.0149 Classification loss 0.4687 AP 0.3000 AR 0.0667
Epoch 377 batch 00009: Loss 0.4706 Regression loss 0.0133 Classification loss 0.4573 AP 0.7667 AR 0.2300
Epoch 377 batch 00010: Loss 0.5514 Regression loss 0.0138 Classification loss 0.5376 AP 0.6000 AR 0.0000
Epoch 378 batch 00001: Loss 0.3727 Regression loss 0.0077 Classification loss 0.3649 AP 0.7000 AR 0.2500
Epoch 378 batch 00002: Loss 0.4767 Regression loss 0.0154 Classification loss 0.4614 AP 0.8667 AR 0.2400
Epoch 378 batch 00003: Loss 0.4362 Regression loss 0.0133 Classification loss 0.4229 AP 0.5000 AR 0.0500
Epoch 378 batch 00004: Loss 0.3571 Regression loss 0.0121 Classification loss 0.3449 AP 0.5833 AR 0.1567
Epoch 378 batch 00005: Loss 0.5303 Regression loss 0.0189 Classification loss 0.5114 AP 0.8000 AR 0.1300
Epoch 378 batch 00006: Loss 0.3093 Regression loss 0.0164 Classification loss 0.2929 AP 0.5333 AR 0.0800
Epoch 378 batch 00007: Loss 0.4910 Regression loss 0.0152 Classification loss 0.4758 AP 0.2000 AR 0.0000
Epoch 378 batch 00008: Loss 0.5880 Regression loss 0.0151 Classification loss 0.5728 AP 0.6667 AR 0.0400
Epoch 378 batch 00009: Loss 0.3503 Regression loss 0.0142 Classification loss 0.3361 AP 0.5000 AR 0.0667
Epoch 378 batch 00010: Loss 0.4354 Regression loss 0.0148 Classification loss 0.4206 AP 0.3000 AR 0.2667
Epoch 379 batch 00001: Loss 0.4449 Regression loss 0.0166 Classification loss 0.4283 AP 0.0000 AR 0.0000
Epoch 379 batch 00002: Loss 0.4577 Regression loss 0.0104 Classification loss 0.4473 AP 0.6667 AR 0.2500
Epoch 379 batch 00003: Loss 0.5746 Regression loss 0.0196 Classification loss 0.5550 AP 0.7000 AR 0.2167
Epoch 379 batch 00004: Loss 0.4636 Regression loss 0.0207 Classification loss 0.4429 AP 0.4000 AR 0.0000
Epoch 379 batch 00005: Loss 0.5225 Regression loss 0.0119 Classification loss 0.5105 AP 0.4500 AR 0.1567
Epoch 379 batch 00006: Loss 0.3527 Regression loss 0.0130 Classification loss 0.3397 AP 0.6000 AR 0.2400
Epoch 379 batch 00007: Loss 0.2872 Regression loss 0.0173 Classification loss 0.2699 AP 0.8000 AR 0.0800
Epoch 379 batch 00008: Loss 0.3592 Regression loss 0.0129 Classification loss 0.3463 AP 0.5667 AR 0.1500
Epoch 379 batch 00009: Loss 0.5956 Regression loss 0.0124 Classification loss 0.5832 AP 0.5000 AR 0.3000
Epoch 379 batch 00010: Loss 0.3820 Regression loss 0.0111 Classification loss 0.3709 AP 0.4000 AR 0.0000
Epoch 380 batch 00001: Loss 0.3063 Regression loss 0.0153 Classification loss 0.2910 AP 0.6667 AR 0.0900
Epoch 380 batch 00002: Loss 0.4462 Regression loss 0.0168 Classification loss 0.4294 AP 0.9000 AR 0.2500
Epoch 380 batch 00003: Loss 0.3058 Regression loss 0.0126 Classification loss 0.2931 AP 0.6667 AR 0.3300
Epoch 380 batch 00004: Loss 0.5054 Regression loss 0.0136 Classification loss 0.4918 AP 0.6000 AR 0.0000
Epoch 380 batch 00005: Loss 0.4677 Regression loss 0.0131 Classification loss 0.4546 AP 0.0500 AR 0.0500
Epoch 380 batch 00006: Loss 0.5690 Regression loss 0.0173 Classification loss 0.5517 AP 0.3667 AR 0.1067
Epoch 380 batch 00007: Loss 0.5344 Regression loss 0.0108 Classification loss 0.5236 AP 0.6000 AR 0.0000
Epoch 380 batch 00008: Loss 0.4075 Regression loss 0.0156 Classification loss 0.3919 AP 0.6667 AR 0.0667
Epoch 380 batch 00009: Loss 0.4870 Regression loss 0.0131 Classification loss 0.4739 AP 0.2167 AR 0.2500
Epoch 380 batch 00010: Loss 0.4961 Regression loss 0.0193 Classification loss 0.4768 AP 0.4333 AR 0.3800
Epoch 381 batch 00001: Loss 0.3940 Regression loss 0.0123 Classification loss 0.3818 AP 0.1067 AR 0.1000
Epoch 381 batch 00002: Loss 0.3030 Regression loss 0.0125 Classification loss 0.2905 AP 0.5667 AR 0.1867
Epoch 381 batch 00003: Loss 0.4446 Regression loss 0.0119 Classification loss 0.4327 AP 0.6000 AR 0.0500
Epoch 381 batch 00004: Loss 0.4779 Regression loss 0.0217 Classification loss 0.4562 AP 0.7000 AR 0.5067
Epoch 381 batch 00005: Loss 0.4610 Regression loss 0.0184 Classification loss 0.4426 AP 0.6000 AR 0.1000
Epoch 381 batch 00006: Loss 0.4953 Regression loss 0.0147 Classification loss 0.4807 AP 0.5000 AR 0.1000
Epoch 381 batch 00007: Loss 0.4967 Regression loss 0.0138 Classification loss 0.4828 AP 0.7500 AR 0.1000
Epoch 381 batch 00008: Loss 0.4367 Regression loss 0.0134 Classification loss 0.4233 AP 0.4667 AR 0.1000
Epoch 381 batch 00009: Loss 0.3656 Regression loss 0.0146 Classification loss 0.3510 AP 0.6000 AR 0.2000
Epoch 381 batch 00010: Loss 0.5692 Regression loss 0.0143 Classification loss 0.5549 AP 0.6000 AR 0.0000
Epoch 382 batch 00001: Loss 0.3903 Regression loss 0.0132 Classification loss 0.3772 AP 0.4167 AR 0.1900
Epoch 382 batch 00002: Loss 0.3700 Regression loss 0.0155 Classification loss 0.3544 AP 0.1067 AR 0.0900
Epoch 382 batch 00003: Loss 0.5392 Regression loss 0.0148 Classification loss 0.5245 AP 0.5667 AR 0.1500
Epoch 382 batch 00004: Loss 0.4903 Regression loss 0.0097 Classification loss 0.4806 AP 0.8000 AR 0.0000
Epoch 382 batch 00005: Loss 0.2339 Regression loss 0.0139 Classification loss 0.2200 AP 0.5333 AR 0.3467
Epoch 382 batch 00006: Loss 0.4616 Regression loss 0.0141 Classification loss 0.4475 AP 0.8000 AR 0.2000
Epoch 382 batch 00007: Loss 0.5833 Regression loss 0.0190 Classification loss 0.5643 AP 0.8000 AR 0.2000
Epoch 382 batch 00008: Loss 0.4662 Regression loss 0.0153 Classification loss 0.4509 AP 0.5667 AR 0.1400
Epoch 382 batch 00009: Loss 0.5042 Regression loss 0.0176 Classification loss 0.4866 AP 0.5667 AR 0.1400
Epoch 382 batch 00010: Loss 0.3069 Regression loss 0.0106 Classification loss 0.2963 AP 0.5500 AR 0.1667
Epoch 383 batch 00001: Loss 0.5637 Regression loss 0.0149 Classification loss 0.5488 AP 0.6000 AR 0.1400
Epoch 383 batch 00002: Loss 0.4679 Regression loss 0.0175 Classification loss 0.4503 AP 0.4000 AR 0.0000
Epoch 383 batch 00003: Loss 0.4523 Regression loss 0.0153 Classification loss 0.4370 AP 0.6667 AR 0.1900
Epoch 383 batch 00004: Loss 0.5949 Regression loss 0.0228 Classification loss 0.5720 AP 0.5000 AR 0.2667
Epoch 383 batch 00005: Loss 0.4038 Regression loss 0.0109 Classification loss 0.3930 AP 0.5400 AR 0.3500
Epoch 383 batch 00006: Loss 0.5670 Regression loss 0.0183 Classification loss 0.5488 AP 0.8000 AR 0.0000
Epoch 383 batch 00007: Loss 0.3718 Regression loss 0.0140 Classification loss 0.3579 AP 0.7000 AR 0.3000
Epoch 383 batch 00008: Loss 0.4163 Regression loss 0.0090 Classification loss 0.4073 AP 0.6000 AR 0.1667
Epoch 383 batch 00009: Loss 0.3166 Regression loss 0.0142 Classification loss 0.3024 AP 0.6733 AR 0.1867
Epoch 383 batch 00010: Loss 0.2356 Regression loss 0.0159 Classification loss 0.2197 AP 0.4400 AR 0.1300
Epoch 384 batch 00001: Loss 0.3612 Regression loss 0.0139 Classification loss 0.3473 AP 0.4400 AR 0.0500
Epoch 384 batch 00002: Loss 0.3249 Regression loss 0.0120 Classification loss 0.3129 AP 0.5000 AR 0.0667
Epoch 384 batch 00003: Loss 0.4416 Regression loss 0.0215 Classification loss 0.4202 AP 1.0000 AR 0.0800
Epoch 384 batch 00004: Loss 0.4247 Regression loss 0.0122 Classification loss 0.4125 AP 0.4000 AR 0.2000
Epoch 384 batch 00005: Loss 0.4158 Regression loss 0.0144 Classification loss 0.4014 AP 0.6400 AR 0.0500
Epoch 384 batch 00006: Loss 0.4930 Regression loss 0.0121 Classification loss 0.4809 AP 0.5000 AR 0.1900
Epoch 384 batch 00007: Loss 0.4945 Regression loss 0.0136 Classification loss 0.4809 AP 0.3000 AR 0.1000
Epoch 384 batch 00008: Loss 0.5026 Regression loss 0.0226 Classification loss 0.4801 AP 0.7000 AR 0.3000
Epoch 384 batch 00009: Loss 0.4265 Regression loss 0.0169 Classification loss 0.4096 AP 0.9000 AR 0.1000
Epoch 384 batch 00010: Loss 0.4062 Regression loss 0.0155 Classification loss 0.3907 AP 0.3667 AR 0.1600
Epoch 385 batch 00001: Loss 0.4002 Regression loss 0.0143 Classification loss 0.3859 AP 0.4500 AR 0.4333
Epoch 385 batch 00002: Loss 0.5748 Regression loss 0.0183 Classification loss 0.5565 AP 0.6000 AR 0.0000
Epoch 385 batch 00003: Loss 0.4965 Regression loss 0.0139 Classification loss 0.4826 AP 0.4667 AR 0.1000
Epoch 385 batch 00004: Loss 0.4052 Regression loss 0.0122 Classification loss 0.3930 AP 0.7000 AR 0.3000
Epoch 385 batch 00005: Loss 0.3645 Regression loss 0.0145 Classification loss 0.3500 AP 0.4667 AR 0.1200
Epoch 385 batch 00006: Loss 0.3889 Regression loss 0.0164 Classification loss 0.3725 AP 0.8667 AR 0.1000
Epoch 385 batch 00007: Loss 0.4300 Regression loss 0.0114 Classification loss 0.4186 AP 0.7500 AR 0.3800
Epoch 385 batch 00008: Loss 0.3591 Regression loss 0.0118 Classification loss 0.3472 AP 0.6000 AR 0.0000
Epoch 385 batch 00009: Loss 0.4203 Regression loss 0.0154 Classification loss 0.4049 AP 0.6000 AR 0.0000
Epoch 385 batch 00010: Loss 0.4991 Regression loss 0.0153 Classification loss 0.4838 AP 0.5000 AR 0.1900
Epoch 386 batch 00001: Loss 0.4295 Regression loss 0.0142 Classification loss 0.4153 AP 0.7000 AR 0.0667
Epoch 386 batch 00002: Loss 0.5215 Regression loss 0.0139 Classification loss 0.5077 AP 0.4000 AR 0.3400
Epoch 386 batch 00003: Loss 0.4586 Regression loss 0.0165 Classification loss 0.4420 AP 0.7500 AR 0.1500
Epoch 386 batch 00004: Loss 0.4818 Regression loss 0.0126 Classification loss 0.4692 AP 0.6667 AR 0.1900
Epoch 386 batch 00005: Loss 0.4388 Regression loss 0.0156 Classification loss 0.4232 AP 0.8667 AR 0.2400
Epoch 386 batch 00006: Loss 0.5387 Regression loss 0.0147 Classification loss 0.5241 AP 0.6500 AR 0.0667
Epoch 386 batch 00007: Loss 0.4080 Regression loss 0.0182 Classification loss 0.3898 AP 0.3667 AR 0.1067
Epoch 386 batch 00008: Loss 0.3984 Regression loss 0.0133 Classification loss 0.3851 AP 0.8000 AR 0.0500
Epoch 386 batch 00009: Loss 0.3436 Regression loss 0.0117 Classification loss 0.3319 AP 0.2667 AR 0.1000
Epoch 386 batch 00010: Loss 0.3128 Regression loss 0.0112 Classification loss 0.3015 AP 0.3500 AR 0.3000
Epoch 387 batch 00001: Loss 0.5000 Regression loss 0.0147 Classification loss 0.4853 AP 0.7000 AR 0.0400
Epoch 387 batch 00002: Loss 0.4332 Regression loss 0.0147 Classification loss 0.4185 AP 0.4667 AR 0.0500
Epoch 387 batch 00003: Loss 0.4506 Regression loss 0.0199 Classification loss 0.4307 AP 0.7000 AR 0.2667
Epoch 387 batch 00004: Loss 0.1473 Regression loss 0.0099 Classification loss 0.1375 AP 0.6333 AR 0.2600
Epoch 387 batch 00005: Loss 0.4599 Regression loss 0.0138 Classification loss 0.4461 AP 0.7500 AR 0.2300
Epoch 387 batch 00006: Loss 0.3078 Regression loss 0.0099 Classification loss 0.2980 AP 0.5000 AR 0.2667
Epoch 387 batch 00007: Loss 0.4526 Regression loss 0.0122 Classification loss 0.4404 AP 0.5333 AR 0.2900
Epoch 387 batch 00008: Loss 0.4087 Regression loss 0.0163 Classification loss 0.3925 AP 0.8000 AR 0.2500
Epoch 387 batch 00009: Loss 0.6180 Regression loss 0.0138 Classification loss 0.6042 AP 0.5000 AR 0.0500
Epoch 387 batch 00010: Loss 0.5512 Regression loss 0.0155 Classification loss 0.5357 AP 0.6000 AR 0.0000
Epoch 388 batch 00001: Loss 0.4446 Regression loss 0.0141 Classification loss 0.4305 AP 0.6000 AR 0.0900
Epoch 388 batch 00002: Loss 0.4324 Regression loss 0.0103 Classification loss 0.4221 AP 0.4167 AR 0.3000
Epoch 388 batch 00003: Loss 0.4535 Regression loss 0.0141 Classification loss 0.4393 AP 0.7667 AR 0.1067
Epoch 388 batch 00004: Loss 0.3147 Regression loss 0.0133 Classification loss 0.3013 AP 0.3833 AR 0.3300
Epoch 388 batch 00005: Loss 0.4724 Regression loss 0.0134 Classification loss 0.4591 AP 0.4000 AR 0.1733
Epoch 388 batch 00006: Loss 0.4494 Regression loss 0.0101 Classification loss 0.4393 AP 0.5667 AR 0.2000
Epoch 388 batch 00007: Loss 0.4494 Regression loss 0.0217 Classification loss 0.4277 AP 0.8000 AR 0.2000
Epoch 388 batch 00008: Loss 0.3132 Regression loss 0.0112 Classification loss 0.3020 AP 0.5000 AR 0.1467
Epoch 388 batch 00009: Loss 0.5483 Regression loss 0.0228 Classification loss 0.5255 AP 0.6000 AR 0.0000
Epoch 388 batch 00010: Loss 0.5387 Regression loss 0.0150 Classification loss 0.5237 AP 0.6667 AR 0.1500
Epoch 389 batch 00001: Loss 0.4232 Regression loss 0.0155 Classification loss 0.4077 AP 0.5000 AR 0.2667
Epoch 389 batch 00002: Loss 0.3821 Regression loss 0.0136 Classification loss 0.3685 AP 0.2000 AR 0.1667
Epoch 389 batch 00003: Loss 0.3206 Regression loss 0.0144 Classification loss 0.3062 AP 0.7000 AR 0.0900
Epoch 389 batch 00004: Loss 0.4702 Regression loss 0.0134 Classification loss 0.4568 AP 0.8000 AR 0.0000
Epoch 389 batch 00005: Loss 0.4369 Regression loss 0.0151 Classification loss 0.4219 AP 0.4000 AR 0.2000
Epoch 389 batch 00006: Loss 0.3394 Regression loss 0.0165 Classification loss 0.3230 AP 0.2000 AR 0.0000
Epoch 389 batch 00007: Loss 0.7245 Regression loss 0.0151 Classification loss 0.7094 AP 0.8000 AR 0.0000
Epoch 389 batch 00008: Loss 0.5429 Regression loss 0.0141 Classification loss 0.5288 AP 0.3000 AR 0.0500
Epoch 389 batch 00009: Loss 0.4090 Regression loss 0.0116 Classification loss 0.3974 AP 0.7500 AR 0.4500
Epoch 389 batch 00010: Loss 0.5069 Regression loss 0.0200 Classification loss 0.4869 AP 1.0000 AR 0.0800
Epoch 390 batch 00001: Loss 0.4678 Regression loss 0.0116 Classification loss 0.4562 AP 0.5000 AR 0.0667
Epoch 390 batch 00002: Loss 0.3320 Regression loss 0.0139 Classification loss 0.3181 AP 0.7000 AR 0.3000
Epoch 390 batch 00003: Loss 0.3134 Regression loss 0.0146 Classification loss 0.2988 AP 0.5333 AR 0.1300
Epoch 390 batch 00004: Loss 0.6078 Regression loss 0.0123 Classification loss 0.5956 AP 0.9000 AR 0.0500
Epoch 390 batch 00005: Loss 0.3622 Regression loss 0.0105 Classification loss 0.3517 AP 0.8000 AR 0.2300
Epoch 390 batch 00006: Loss 0.3322 Regression loss 0.0146 Classification loss 0.3176 AP 0.7000 AR 0.3500
Epoch 390 batch 00007: Loss 0.5403 Regression loss 0.0187 Classification loss 0.5215 AP 0.3000 AR 0.0667
Epoch 390 batch 00008: Loss 0.4121 Regression loss 0.0129 Classification loss 0.3991 AP 0.4667 AR 0.2400
Epoch 390 batch 00009: Loss 0.4661 Regression loss 0.0123 Classification loss 0.4538 AP 0.6667 AR 0.1000
Epoch 390 batch 00010: Loss 0.5153 Regression loss 0.0149 Classification loss 0.5004 AP 0.5833 AR 0.1300
Epoch 391 batch 00001: Loss 0.5656 Regression loss 0.0219 Classification loss 0.5437 AP 0.6000 AR 0.0000
Epoch 391 batch 00002: Loss 0.6597 Regression loss 0.0151 Classification loss 0.6446 AP 0.7000 AR 0.3000
Epoch 391 batch 00003: Loss 0.4601 Regression loss 0.0162 Classification loss 0.4439 AP 0.4667 AR 0.2500
Epoch 391 batch 00004: Loss 0.3989 Regression loss 0.0115 Classification loss 0.3875 AP 0.2500 AR 0.1300
Epoch 391 batch 00005: Loss 0.4256 Regression loss 0.0123 Classification loss 0.4133 AP 0.6000 AR 0.0000
Epoch 391 batch 00006: Loss 0.4667 Regression loss 0.0081 Classification loss 0.4587 AP 0.8000 AR 0.1500
Epoch 391 batch 00007: Loss 0.4498 Regression loss 0.0118 Classification loss 0.4380 AP 0.5000 AR 0.3000
Epoch 391 batch 00008: Loss 0.4559 Regression loss 0.0207 Classification loss 0.4352 AP 0.9000 AR 0.1167
Epoch 391 batch 00009: Loss 0.3121 Regression loss 0.0101 Classification loss 0.3020 AP 0.7000 AR 0.2300
Epoch 391 batch 00010: Loss 0.3778 Regression loss 0.0150 Classification loss 0.3628 AP 0.4333 AR 0.1467
Epoch 392 batch 00001: Loss 0.4006 Regression loss 0.0127 Classification loss 0.3878 AP 0.2000 AR 0.1667
Epoch 392 batch 00002: Loss 0.6211 Regression loss 0.0153 Classification loss 0.6058 AP 1.0000 AR 0.0000
Epoch 392 batch 00003: Loss 0.4122 Regression loss 0.0123 Classification loss 0.4000 AP 0.4500 AR 0.0500
Epoch 392 batch 00004: Loss 0.2813 Regression loss 0.0130 Classification loss 0.2683 AP 0.5000 AR 0.1200
Epoch 392 batch 00005: Loss 0.4359 Regression loss 0.0148 Classification loss 0.4210 AP 0.5500 AR 0.2000
Epoch 392 batch 00006: Loss 0.5683 Regression loss 0.0109 Classification loss 0.5575 AP 0.5000 AR 0.2500
Epoch 392 batch 00007: Loss 0.4412 Regression loss 0.0135 Classification loss 0.4277 AP 0.4000 AR 0.1500
Epoch 392 batch 00008: Loss 0.4077 Regression loss 0.0180 Classification loss 0.3896 AP 0.9000 AR 0.2400
Epoch 392 batch 00009: Loss 0.5691 Regression loss 0.0152 Classification loss 0.5539 AP 0.7500 AR 0.1400
Epoch 392 batch 00010: Loss 0.5090 Regression loss 0.0151 Classification loss 0.4939 AP 0.5667 AR 0.1067
Epoch 393 batch 00001: Loss 0.4289 Regression loss 0.0179 Classification loss 0.4109 AP 0.5000 AR 0.1000
Epoch 393 batch 00002: Loss 0.4092 Regression loss 0.0099 Classification loss 0.3992 AP 0.4667 AR 0.2167
Epoch 393 batch 00003: Loss 0.4323 Regression loss 0.0126 Classification loss 0.4197 AP 0.7000 AR 0.1000
Epoch 393 batch 00004: Loss 0.5231 Regression loss 0.0121 Classification loss 0.5110 AP 0.7000 AR 0.4500
Epoch 393 batch 00005: Loss 0.3759 Regression loss 0.0150 Classification loss 0.3609 AP 0.8000 AR 0.0800
Epoch 393 batch 00006: Loss 0.4513 Regression loss 0.0164 Classification loss 0.4349 AP 0.4000 AR 0.1167
Epoch 393 batch 00007: Loss 0.3779 Regression loss 0.0120 Classification loss 0.3659 AP 0.6500 AR 0.1000
Epoch 393 batch 00008: Loss 0.4381 Regression loss 0.0172 Classification loss 0.4209 AP 0.6000 AR 0.0800
Epoch 393 batch 00009: Loss 0.4207 Regression loss 0.0169 Classification loss 0.4037 AP 0.7667 AR 0.3200
Epoch 393 batch 00010: Loss 0.4681 Regression loss 0.0083 Classification loss 0.4598 AP 0.5000 AR 0.1000
Epoch 394 batch 00001: Loss 0.2673 Regression loss 0.0142 Classification loss 0.2531 AP 0.5500 AR 0.0900
Epoch 394 batch 00002: Loss 0.3530 Regression loss 0.0115 Classification loss 0.3416 AP 0.5333 AR 0.1967
Epoch 394 batch 00003: Loss 0.6376 Regression loss 0.0151 Classification loss 0.6225 AP 0.4667 AR 0.0400
Epoch 394 batch 00004: Loss 0.5405 Regression loss 0.0181 Classification loss 0.5224 AP 0.6000 AR 0.0000
Epoch 394 batch 00005: Loss 0.4894 Regression loss 0.0134 Classification loss 0.4759 AP 0.5000 AR 0.0400
Epoch 394 batch 00006: Loss 0.4557 Regression loss 0.0090 Classification loss 0.4467 AP 0.7000 AR 0.2500
Epoch 394 batch 00007: Loss 0.3942 Regression loss 0.0138 Classification loss 0.3804 AP 0.8000 AR 0.4167
Epoch 394 batch 00008: Loss 0.4191 Regression loss 0.0120 Classification loss 0.4072 AP 0.3067 AR 0.2500
Epoch 394 batch 00009: Loss 0.6756 Regression loss 0.0192 Classification loss 0.6564 AP 0.3000 AR 0.2667
Epoch 394 batch 00010: Loss 0.4589 Regression loss 0.0184 Classification loss 0.4405 AP 0.7000 AR 0.1000
Epoch 395 batch 00001: Loss 0.4986 Regression loss 0.0099 Classification loss 0.4887 AP 0.7500 AR 0.3500
Epoch 395 batch 00002: Loss 0.4115 Regression loss 0.0141 Classification loss 0.3973 AP 0.6000 AR 0.0000
Epoch 395 batch 00003: Loss 0.2863 Regression loss 0.0125 Classification loss 0.2739 AP 0.8000 AR 0.1300
Epoch 395 batch 00004: Loss 0.4597 Regression loss 0.0144 Classification loss 0.4453 AP 0.7000 AR 0.0667
Epoch 395 batch 00005: Loss 0.5545 Regression loss 0.0164 Classification loss 0.5381 AP 0.5000 AR 0.0667
Epoch 395 batch 00006: Loss 0.5099 Regression loss 0.0117 Classification loss 0.4982 AP 0.4000 AR 0.1500
Epoch 395 batch 00007: Loss 0.3827 Regression loss 0.0136 Classification loss 0.3691 AP 0.6000 AR 0.1400
Epoch 395 batch 00008: Loss 0.5944 Regression loss 0.0166 Classification loss 0.5778 AP 0.3500 AR 0.0800
Epoch 395 batch 00009: Loss 0.4191 Regression loss 0.0114 Classification loss 0.4077 AP 0.5333 AR 0.1500
Epoch 395 batch 00010: Loss 0.2800 Regression loss 0.0172 Classification loss 0.2628 AP 0.4667 AR 0.2400
Epoch 396 batch 00001: Loss 0.5786 Regression loss 0.0105 Classification loss 0.5682 AP 0.7000 AR 0.0500
Epoch 396 batch 00002: Loss 0.3869 Regression loss 0.0156 Classification loss 0.3713 AP 0.2000 AR 0.1400
Epoch 396 batch 00003: Loss 0.4614 Regression loss 0.0133 Classification loss 0.4481 AP 0.1400 AR 0.1500
Epoch 396 batch 00004: Loss 0.5392 Regression loss 0.0204 Classification loss 0.5189 AP 1.0000 AR 0.4000
Epoch 396 batch 00005: Loss 0.3822 Regression loss 0.0132 Classification loss 0.3690 AP 0.4167 AR 0.1700
Epoch 396 batch 00006: Loss 0.4337 Regression loss 0.0099 Classification loss 0.4239 AP 0.2667 AR 0.0500
Epoch 396 batch 00007: Loss 0.4188 Regression loss 0.0179 Classification loss 0.4009 AP 0.7000 AR 0.0667
Epoch 396 batch 00008: Loss 0.5831 Regression loss 0.0127 Classification loss 0.5703 AP 0.4667 AR 0.1000
Epoch 396 batch 00009: Loss 0.3336 Regression loss 0.0138 Classification loss 0.3198 AP 0.6000 AR 0.0500
Epoch 396 batch 00010: Loss 0.4955 Regression loss 0.0176 Classification loss 0.4779 AP 0.8667 AR 0.1000
Epoch 397 batch 00001: Loss 0.3647 Regression loss 0.0082 Classification loss 0.3564 AP 0.8000 AR 0.4000
Epoch 397 batch 00002: Loss 0.4832 Regression loss 0.0188 Classification loss 0.4644 AP 0.9000 AR 0.0400
Epoch 397 batch 00003: Loss 0.5079 Regression loss 0.0161 Classification loss 0.4918 AP 0.6000 AR 0.0000
Epoch 397 batch 00004: Loss 0.4570 Regression loss 0.0149 Classification loss 0.4421 AP 0.5000 AR 0.2000
Epoch 397 batch 00005: Loss 0.6779 Regression loss 0.0179 Classification loss 0.6600 AP 0.6000 AR 0.1167
Epoch 397 batch 00006: Loss 0.4051 Regression loss 0.0159 Classification loss 0.3892 AP 0.4000 AR 0.2000
Epoch 397 batch 00007: Loss 0.4379 Regression loss 0.0147 Classification loss 0.4232 AP 0.5000 AR 0.3067
Epoch 397 batch 00008: Loss 0.5248 Regression loss 0.0147 Classification loss 0.5101 AP 0.6500 AR 0.0500
Epoch 397 batch 00009: Loss 0.3128 Regression loss 0.0124 Classification loss 0.3004 AP 0.5833 AR 0.1800
Epoch 397 batch 00010: Loss 0.3454 Regression loss 0.0093 Classification loss 0.3361 AP 0.2667 AR 0.0500
Epoch 398 batch 00001: Loss 0.4145 Regression loss 0.0107 Classification loss 0.4038 AP 0.6333 AR 0.2167
Epoch 398 batch 00002: Loss 0.5602 Regression loss 0.0160 Classification loss 0.5442 AP 1.0000 AR 0.0500
Epoch 398 batch 00003: Loss 0.5851 Regression loss 0.0212 Classification loss 0.5639 AP 0.9000 AR 0.1000
Epoch 398 batch 00004: Loss 0.4629 Regression loss 0.0145 Classification loss 0.4484 AP 0.3333 AR 0.0800
Epoch 398 batch 00005: Loss 0.5105 Regression loss 0.0160 Classification loss 0.4945 AP 0.2667 AR 0.0500
Epoch 398 batch 00006: Loss 0.4498 Regression loss 0.0156 Classification loss 0.4342 AP 0.5333 AR 0.2800
Epoch 398 batch 00007: Loss 0.5659 Regression loss 0.0094 Classification loss 0.5564 AP 0.4667 AR 0.3000
Epoch 398 batch 00008: Loss 0.4841 Regression loss 0.0189 Classification loss 0.4652 AP 0.6500 AR 0.0400
Epoch 398 batch 00009: Loss 0.2750 Regression loss 0.0125 Classification loss 0.2625 AP 0.6000 AR 0.3300
Epoch 398 batch 00010: Loss 0.3436 Regression loss 0.0139 Classification loss 0.3297 AP 0.5000 AR 0.0667
Epoch 399 batch 00001: Loss 0.4278 Regression loss 0.0126 Classification loss 0.4152 AP 0.6000 AR 0.1600
Epoch 399 batch 00002: Loss 0.4183 Regression loss 0.0168 Classification loss 0.4015 AP 0.8000 AR 0.0800
Epoch 399 batch 00003: Loss 0.4680 Regression loss 0.0186 Classification loss 0.4494 AP 0.4000 AR 0.0000
Epoch 399 batch 00004: Loss 0.3878 Regression loss 0.0157 Classification loss 0.3721 AP 0.6667 AR 0.0500
Epoch 399 batch 00005: Loss 0.6628 Regression loss 0.0104 Classification loss 0.6523 AP 0.3667 AR 0.1167
Epoch 399 batch 00006: Loss 0.3363 Regression loss 0.0176 Classification loss 0.3186 AP 0.5000 AR 0.0667
Epoch 399 batch 00007: Loss 0.3071 Regression loss 0.0131 Classification loss 0.2939 AP 0.7000 AR 0.4000
Epoch 399 batch 00008: Loss 0.6944 Regression loss 0.0144 Classification loss 0.6801 AP 0.7000 AR 0.3000
Epoch 399 batch 00009: Loss 0.5839 Regression loss 0.0194 Classification loss 0.5645 AP 0.3000 AR 0.1000
Epoch 399 batch 00010: Loss 0.3364 Regression loss 0.0166 Classification loss 0.3199 AP 0.6000 AR 0.0500
Epoch 400 batch 00001: Loss 0.4097 Regression loss 0.0148 Classification loss 0.3949 AP 0.6000 AR 0.1400
Epoch 400 batch 00002: Loss 0.4669 Regression loss 0.0166 Classification loss 0.4502 AP 0.6000 AR 0.0000
Epoch 400 batch 00003: Loss 0.3831 Regression loss 0.0141 Classification loss 0.3690 AP 0.4000 AR 0.0000
Epoch 400 batch 00004: Loss 0.5306 Regression loss 0.0203 Classification loss 0.5103 AP 0.4000 AR 0.0000
Epoch 400 batch 00005: Loss 0.4914 Regression loss 0.0154 Classification loss 0.4761 AP 0.6000 AR 0.3000
Epoch 400 batch 00006: Loss 0.3251 Regression loss 0.0203 Classification loss 0.3048 AP 0.6333 AR 0.3467
Epoch 400 batch 00007: Loss 0.4193 Regression loss 0.0163 Classification loss 0.4030 AP 0.5333 AR 0.1400
Epoch 400 batch 00008: Loss 0.4599 Regression loss 0.0121 Classification loss 0.4478 AP 0.5500 AR 0.3000
Epoch 400 batch 00009: Loss 0.4752 Regression loss 0.0130 Classification loss 0.4622 AP 0.3667 AR 0.1400
Epoch 400 batch 00010: Loss 0.3972 Regression loss 0.0161 Classification loss 0.3811 AP 0.7000 AR 0.0500
Epoch 401 batch 00001: Loss 0.4565 Regression loss 0.0147 Classification loss 0.4417 AP 0.5500 AR 0.1500
Epoch 401 batch 00002: Loss 0.6085 Regression loss 0.0130 Classification loss 0.5954 AP 0.6000 AR 0.0000
Epoch 401 batch 00003: Loss 0.5341 Regression loss 0.0200 Classification loss 0.5141 AP 0.6667 AR 0.1900
Epoch 401 batch 00004: Loss 0.2663 Regression loss 0.0130 Classification loss 0.2533 AP 0.5833 AR 0.1467
Epoch 401 batch 00005: Loss 0.3461 Regression loss 0.0154 Classification loss 0.3307 AP 0.5000 AR 0.2000
Epoch 401 batch 00006: Loss 0.5092 Regression loss 0.0200 Classification loss 0.4892 AP 0.6000 AR 0.1400
Epoch 401 batch 00007: Loss 0.4999 Regression loss 0.0167 Classification loss 0.4832 AP 0.5000 AR 0.3667
Epoch 401 batch 00008: Loss 0.3800 Regression loss 0.0123 Classification loss 0.3677 AP 0.6833 AR 0.1967
Epoch 401 batch 00009: Loss 0.4554 Regression loss 0.0151 Classification loss 0.4403 AP 0.2000 AR 0.2000
Epoch 401 batch 00010: Loss 0.3398 Regression loss 0.0138 Classification loss 0.3261 AP 0.8000 AR 0.0500
Epoch 402 batch 00001: Loss 0.4036 Regression loss 0.0107 Classification loss 0.3930 AP 0.7000 AR 0.3000
Epoch 402 batch 00002: Loss 0.3678 Regression loss 0.0153 Classification loss 0.3526 AP 0.2500 AR 0.0500
Epoch 402 batch 00003: Loss 0.3796 Regression loss 0.0154 Classification loss 0.3643 AP 0.4000 AR 0.0000
Epoch 402 batch 00004: Loss 0.5197 Regression loss 0.0156 Classification loss 0.5040 AP 0.5667 AR 0.2400
Epoch 402 batch 00005: Loss 0.4328 Regression loss 0.0141 Classification loss 0.4187 AP 0.3333 AR 0.0800
Epoch 402 batch 00006: Loss 0.4934 Regression loss 0.0166 Classification loss 0.4768 AP 0.7000 AR 0.1300
Epoch 402 batch 00007: Loss 0.5085 Regression loss 0.0152 Classification loss 0.4933 AP 0.6000 AR 0.2000
Epoch 402 batch 00008: Loss 0.3745 Regression loss 0.0130 Classification loss 0.3615 AP 0.6000 AR 0.0500
Epoch 402 batch 00009: Loss 0.4696 Regression loss 0.0119 Classification loss 0.4577 AP 0.7000 AR 0.1000
Epoch 402 batch 00010: Loss 0.3204 Regression loss 0.0129 Classification loss 0.3075 AP 0.6667 AR 0.1200
Epoch 403 batch 00001: Loss 0.5824 Regression loss 0.0139 Classification loss 0.5684 AP 0.7000 AR 0.0500
Epoch 403 batch 00002: Loss 0.4322 Regression loss 0.0138 Classification loss 0.4184 AP 0.8667 AR 0.2500
Epoch 403 batch 00003: Loss 0.2022 Regression loss 0.0100 Classification loss 0.1921 AP 0.4667 AR 0.4067
Epoch 403 batch 00004: Loss 0.5639 Regression loss 0.0178 Classification loss 0.5461 AP 0.7000 AR 0.0667
Epoch 403 batch 00005: Loss 0.4655 Regression loss 0.0144 Classification loss 0.4511 AP 0.6000 AR 0.3000
Epoch 403 batch 00006: Loss 0.4321 Regression loss 0.0096 Classification loss 0.4225 AP 0.4500 AR 0.0500
Epoch 403 batch 00007: Loss 0.6203 Regression loss 0.0212 Classification loss 0.5991 AP 0.8000 AR 0.0800
Epoch 403 batch 00008: Loss 0.4036 Regression loss 0.0112 Classification loss 0.3924 AP 0.3667 AR 0.1167
Epoch 403 batch 00009: Loss 0.5656 Regression loss 0.0133 Classification loss 0.5523 AP 0.5000 AR 0.1000
Epoch 403 batch 00010: Loss 0.2625 Regression loss 0.0131 Classification loss 0.2493 AP 0.4333 AR 0.1300
Epoch 404 batch 00001: Loss 0.3799 Regression loss 0.0150 Classification loss 0.3649 AP 0.6000 AR 0.0000
Epoch 404 batch 00002: Loss 0.4993 Regression loss 0.0167 Classification loss 0.4826 AP 0.4667 AR 0.1000
Epoch 404 batch 00003: Loss 0.5139 Regression loss 0.0073 Classification loss 0.5065 AP 0.4667 AR 0.2500
Epoch 404 batch 00004: Loss 0.4840 Regression loss 0.0190 Classification loss 0.4650 AP 0.6333 AR 0.1467
Epoch 404 batch 00005: Loss 0.3979 Regression loss 0.0106 Classification loss 0.3873 AP 0.4500 AR 0.0500
Epoch 404 batch 00006: Loss 0.5202 Regression loss 0.0143 Classification loss 0.5059 AP 0.7000 AR 0.0667
Epoch 404 batch 00007: Loss 0.4420 Regression loss 0.0121 Classification loss 0.4299 AP 0.6000 AR 0.2000
Epoch 404 batch 00008: Loss 0.3941 Regression loss 0.0153 Classification loss 0.3787 AP 0.6667 AR 0.1000
Epoch 404 batch 00009: Loss 0.4926 Regression loss 0.0144 Classification loss 0.4782 AP 0.7000 AR 0.1300
Epoch 404 batch 00010: Loss 0.2401 Regression loss 0.0113 Classification loss 0.2288 AP 0.6000 AR 0.5800
Epoch 405 batch 00001: Loss 0.4457 Regression loss 0.0097 Classification loss 0.4360 AP 0.6667 AR 0.0667
Epoch 405 batch 00002: Loss 0.3734 Regression loss 0.0118 Classification loss 0.3616 AP 0.2667 AR 0.0500
Epoch 405 batch 00003: Loss 0.3830 Regression loss 0.0140 Classification loss 0.3690 AP 0.6000 AR 0.0800
Epoch 405 batch 00004: Loss 0.6346 Regression loss 0.0191 Classification loss 0.6155 AP 0.7000 AR 0.0667
Epoch 405 batch 00005: Loss 0.4881 Regression loss 0.0148 Classification loss 0.4733 AP 0.4667 AR 0.1000
Epoch 405 batch 00006: Loss 0.4397 Regression loss 0.0147 Classification loss 0.4250 AP 0.4000 AR 0.0000
Epoch 405 batch 00007: Loss 0.4102 Regression loss 0.0161 Classification loss 0.3941 AP 0.6000 AR 0.1200
Epoch 405 batch 00008: Loss 0.3475 Regression loss 0.0101 Classification loss 0.3374 AP 0.6500 AR 0.3000
Epoch 405 batch 00009: Loss 0.4706 Regression loss 0.0160 Classification loss 0.4547 AP 0.6000 AR 0.4000
Epoch 405 batch 00010: Loss 0.5104 Regression loss 0.0078 Classification loss 0.5027 AP 0.7333 AR 0.2000
Epoch 406 batch 00001: Loss 0.3104 Regression loss 0.0142 Classification loss 0.2962 AP 0.4667 AR 0.1200
Epoch 406 batch 00002: Loss 0.4553 Regression loss 0.0126 Classification loss 0.4427 AP 0.6000 AR 0.3400
Epoch 406 batch 00003: Loss 0.5120 Regression loss 0.0102 Classification loss 0.5019 AP 0.4500 AR 0.0500
Epoch 406 batch 00004: Loss 0.5379 Regression loss 0.0137 Classification loss 0.5242 AP 0.6667 AR 0.3000
Epoch 406 batch 00005: Loss 0.4155 Regression loss 0.0130 Classification loss 0.4024 AP 0.6000 AR 0.1667
Epoch 406 batch 00006: Loss 0.3985 Regression loss 0.0134 Classification loss 0.3851 AP 0.6400 AR 0.1833
Epoch 406 batch 00007: Loss 0.5844 Regression loss 0.0145 Classification loss 0.5699 AP 0.8000 AR 0.0000
Epoch 406 batch 00008: Loss 0.4301 Regression loss 0.0166 Classification loss 0.4135 AP 0.3667 AR 0.2500
Epoch 406 batch 00009: Loss 0.3362 Regression loss 0.0168 Classification loss 0.3194 AP 0.3667 AR 0.2000
Epoch 406 batch 00010: Loss 0.5699 Regression loss 0.0175 Classification loss 0.5524 AP 0.8000 AR 0.0000
Epoch 407 batch 00001: Loss 0.5142 Regression loss 0.0163 Classification loss 0.4979 AP 0.6667 AR 0.0500
Epoch 407 batch 00002: Loss 0.4014 Regression loss 0.0144 Classification loss 0.3871 AP 0.6667 AR 0.0500
Epoch 407 batch 00003: Loss 0.5154 Regression loss 0.0180 Classification loss 0.4974 AP 0.5333 AR 0.1400
Epoch 407 batch 00004: Loss 0.3587 Regression loss 0.0117 Classification loss 0.3470 AP 0.7000 AR 0.4467
Epoch 407 batch 00005: Loss 0.3716 Regression loss 0.0142 Classification loss 0.3574 AP 0.6000 AR 0.0500
Epoch 407 batch 00006: Loss 0.5164 Regression loss 0.0125 Classification loss 0.5039 AP 0.7000 AR 0.1000
Epoch 407 batch 00007: Loss 0.4246 Regression loss 0.0150 Classification loss 0.4096 AP 0.7667 AR 0.3400
Epoch 407 batch 00008: Loss 0.5157 Regression loss 0.0122 Classification loss 0.5036 AP 0.1000 AR 0.0667
Epoch 407 batch 00009: Loss 0.3613 Regression loss 0.0092 Classification loss 0.3521 AP 0.6500 AR 0.2500
Epoch 407 batch 00010: Loss 0.4646 Regression loss 0.0147 Classification loss 0.4499 AP 0.6000 AR 0.1600
Epoch 408 batch 00001: Loss 0.5370 Regression loss 0.0131 Classification loss 0.5239 AP 0.5000 AR 0.3167
Epoch 408 batch 00002: Loss 0.2676 Regression loss 0.0117 Classification loss 0.2560 AP 0.3000 AR 0.1500
Epoch 408 batch 00003: Loss 0.4381 Regression loss 0.0156 Classification loss 0.4225 AP 0.6333 AR 0.1300
Epoch 408 batch 00004: Loss 0.2840 Regression loss 0.0131 Classification loss 0.2709 AP 0.7333 AR 0.2800
Epoch 408 batch 00005: Loss 0.4747 Regression loss 0.0126 Classification loss 0.4621 AP 0.3667 AR 0.1900
Epoch 408 batch 00006: Loss 0.4501 Regression loss 0.0143 Classification loss 0.4358 AP 0.5667 AR 0.1400
Epoch 408 batch 00007: Loss 0.5753 Regression loss 0.0170 Classification loss 0.5583 AP 0.7000 AR 0.2000
Epoch 408 batch 00008: Loss 0.5396 Regression loss 0.0172 Classification loss 0.5224 AP 0.5000 AR 0.1800
Epoch 408 batch 00009: Loss 0.4732 Regression loss 0.0135 Classification loss 0.4598 AP 1.0000 AR 0.0000
Epoch 408 batch 00010: Loss 0.4315 Regression loss 0.0150 Classification loss 0.4164 AP 0.2500 AR 0.0500
Epoch 409 batch 00001: Loss 0.2710 Regression loss 0.0158 Classification loss 0.2552 AP 0.4167 AR 0.1567
Epoch 409 batch 00002: Loss 0.5083 Regression loss 0.0150 Classification loss 0.4933 AP 0.6500 AR 0.0400
Epoch 409 batch 00003: Loss 0.4742 Regression loss 0.0163 Classification loss 0.4579 AP 0.3333 AR 0.0800
Epoch 409 batch 00004: Loss 0.4914 Regression loss 0.0144 Classification loss 0.4770 AP 0.3000 AR 0.0400
Epoch 409 batch 00005: Loss 0.3180 Regression loss 0.0141 Classification loss 0.3039 AP 0.5667 AR 0.3400
Epoch 409 batch 00006: Loss 0.3971 Regression loss 0.0139 Classification loss 0.3832 AP 0.6000 AR 0.0000
Epoch 409 batch 00007: Loss 0.5723 Regression loss 0.0190 Classification loss 0.5533 AP 0.9000 AR 0.0667
Epoch 409 batch 00008: Loss 0.4585 Regression loss 0.0092 Classification loss 0.4493 AP 0.2000 AR 0.1500
Epoch 409 batch 00009: Loss 0.4756 Regression loss 0.0090 Classification loss 0.4665 AP 0.7500 AR 0.3500
Epoch 409 batch 00010: Loss 0.3461 Regression loss 0.0154 Classification loss 0.3307 AP 0.7000 AR 0.2500
Epoch 410 batch 00001: Loss 0.3639 Regression loss 0.0149 Classification loss 0.3490 AP 0.9000 AR 0.1000
Epoch 410 batch 00002: Loss 0.4947 Regression loss 0.0201 Classification loss 0.4746 AP 0.7000 AR 0.0667
Epoch 410 batch 00003: Loss 0.5504 Regression loss 0.0148 Classification loss 0.5356 AP 0.7667 AR 0.0800
Epoch 410 batch 00004: Loss 0.6067 Regression loss 0.0149 Classification loss 0.5918 AP 0.7000 AR 0.0500
Epoch 410 batch 00005: Loss 0.4168 Regression loss 0.0128 Classification loss 0.4040 AP 0.5000 AR 0.1000
Epoch 410 batch 00006: Loss 0.3725 Regression loss 0.0161 Classification loss 0.3564 AP 0.7667 AR 0.2000
Epoch 410 batch 00007: Loss 0.5974 Regression loss 0.0120 Classification loss 0.5854 AP 0.5000 AR 0.0667
Epoch 410 batch 00008: Loss 0.2935 Regression loss 0.0120 Classification loss 0.2815 AP 0.2500 AR 0.1300
Epoch 410 batch 00009: Loss 0.3501 Regression loss 0.0084 Classification loss 0.3416 AP 0.3500 AR 0.3500
Epoch 410 batch 00010: Loss 0.4366 Regression loss 0.0150 Classification loss 0.4216 AP 0.5333 AR 0.3600
Epoch 411 batch 00001: Loss 0.5456 Regression loss 0.0115 Classification loss 0.5340 AP 0.6500 AR 0.0500
Epoch 411 batch 00002: Loss 0.4965 Regression loss 0.0129 Classification loss 0.4836 AP 0.8000 AR 0.2467
Epoch 411 batch 00003: Loss 0.3921 Regression loss 0.0163 Classification loss 0.3758 AP 0.5000 AR 0.0667
Epoch 411 batch 00004: Loss 0.3261 Regression loss 0.0105 Classification loss 0.3156 AP 0.5167 AR 0.1167
Epoch 411 batch 00005: Loss 0.5322 Regression loss 0.0162 Classification loss 0.5160 AP 0.8000 AR 0.2000
Epoch 411 batch 00006: Loss 0.4370 Regression loss 0.0197 Classification loss 0.4173 AP 0.7000 AR 0.1000
Epoch 411 batch 00007: Loss 0.5067 Regression loss 0.0125 Classification loss 0.4942 AP 0.5667 AR 0.0900
Epoch 411 batch 00008: Loss 0.5015 Regression loss 0.0121 Classification loss 0.4893 AP 0.1667 AR 0.0900
Epoch 411 batch 00009: Loss 0.3114 Regression loss 0.0126 Classification loss 0.2988 AP 0.5333 AR 0.3300
Epoch 411 batch 00010: Loss 0.5078 Regression loss 0.0128 Classification loss 0.4950 AP 0.8000 AR 0.4000
Epoch 412 batch 00001: Loss 0.3614 Regression loss 0.0156 Classification loss 0.3459 AP 0.8000 AR 0.0000
Epoch 412 batch 00002: Loss 0.3319 Regression loss 0.0119 Classification loss 0.3200 AP 0.2333 AR 0.2067
Epoch 412 batch 00003: Loss 0.6835 Regression loss 0.0173 Classification loss 0.6661 AP 0.8000 AR 0.0000
Epoch 412 batch 00004: Loss 0.3536 Regression loss 0.0149 Classification loss 0.3387 AP 0.6000 AR 0.0500
Epoch 412 batch 00005: Loss 0.3738 Regression loss 0.0127 Classification loss 0.3611 AP 0.2000 AR 0.1300
Epoch 412 batch 00006: Loss 0.4359 Regression loss 0.0138 Classification loss 0.4221 AP 0.6667 AR 0.2667
Epoch 412 batch 00007: Loss 0.4730 Regression loss 0.0141 Classification loss 0.4589 AP 0.7500 AR 0.1500
Epoch 412 batch 00008: Loss 0.5491 Regression loss 0.0107 Classification loss 0.5384 AP 0.5667 AR 0.4500
Epoch 412 batch 00009: Loss 0.6316 Regression loss 0.0134 Classification loss 0.6182 AP 0.4000 AR 0.0000
Epoch 412 batch 00010: Loss 0.3727 Regression loss 0.0162 Classification loss 0.3566 AP 0.6667 AR 0.2367
Epoch 413 batch 00001: Loss 0.5488 Regression loss 0.0180 Classification loss 0.5308 AP 0.5667 AR 0.1400
Epoch 413 batch 00002: Loss 0.3835 Regression loss 0.0139 Classification loss 0.3696 AP 0.5000 AR 0.3167
Epoch 413 batch 00003: Loss 0.4197 Regression loss 0.0130 Classification loss 0.4067 AP 0.3500 AR 0.1500
Epoch 413 batch 00004: Loss 0.5595 Regression loss 0.0147 Classification loss 0.5449 AP 0.6667 AR 0.0500
Epoch 413 batch 00005: Loss 0.2117 Regression loss 0.0090 Classification loss 0.2027 AP 0.6000 AR 0.3800
Epoch 413 batch 00006: Loss 0.4218 Regression loss 0.0136 Classification loss 0.4082 AP 0.2667 AR 0.1567
Epoch 413 batch 00007: Loss 0.4157 Regression loss 0.0150 Classification loss 0.4007 AP 0.6500 AR 0.0500
Epoch 413 batch 00008: Loss 0.5417 Regression loss 0.0168 Classification loss 0.5249 AP 0.6000 AR 0.0000
Epoch 413 batch 00009: Loss 0.3620 Regression loss 0.0122 Classification loss 0.3498 AP 0.7000 AR 0.2400
Epoch 413 batch 00010: Loss 0.3967 Regression loss 0.0174 Classification loss 0.3793 AP 0.8000 AR 0.0000
Epoch 414 batch 00001: Loss 0.6310 Regression loss 0.0149 Classification loss 0.6162 AP 0.9000 AR 0.1000
Epoch 414 batch 00002: Loss 0.4373 Regression loss 0.0165 Classification loss 0.4208 AP 0.4667 AR 0.0500
Epoch 414 batch 00003: Loss 0.4150 Regression loss 0.0132 Classification loss 0.4018 AP 0.2000 AR 0.0000
Epoch 414 batch 00004: Loss 0.6261 Regression loss 0.0111 Classification loss 0.6149 AP 0.2000 AR 0.1500
Epoch 414 batch 00005: Loss 0.4748 Regression loss 0.0187 Classification loss 0.4561 AP 0.6000 AR 0.0000
Epoch 414 batch 00006: Loss 0.5313 Regression loss 0.0111 Classification loss 0.5202 AP 0.7000 AR 0.3000
Epoch 414 batch 00007: Loss 0.3484 Regression loss 0.0151 Classification loss 0.3334 AP 0.4000 AR 0.0000
Epoch 414 batch 00008: Loss 0.3122 Regression loss 0.0109 Classification loss 0.3013 AP 0.8000 AR 0.4167
Epoch 414 batch 00009: Loss 0.2953 Regression loss 0.0153 Classification loss 0.2800 AP 0.5000 AR 0.3200
Epoch 414 batch 00010: Loss 0.5946 Regression loss 0.0157 Classification loss 0.5789 AP 0.7167 AR 0.0900
Epoch 415 batch 00001: Loss 0.3367 Regression loss 0.0103 Classification loss 0.3264 AP 0.6833 AR 0.2300
Epoch 415 batch 00002: Loss 0.6569 Regression loss 0.0185 Classification loss 0.6383 AP 0.8000 AR 0.0000
Epoch 415 batch 00003: Loss 0.3105 Regression loss 0.0112 Classification loss 0.2993 AP 0.6000 AR 0.2000
Epoch 415 batch 00004: Loss 0.5507 Regression loss 0.0203 Classification loss 0.5303 AP 0.5000 AR 0.0667
Epoch 415 batch 00005: Loss 0.3932 Regression loss 0.0124 Classification loss 0.3808 AP 0.5000 AR 0.3667
Epoch 415 batch 00006: Loss 0.3845 Regression loss 0.0096 Classification loss 0.3749 AP 0.4500 AR 0.2467
Epoch 415 batch 00007: Loss 0.4090 Regression loss 0.0124 Classification loss 0.3966 AP 0.7667 AR 0.1900
Epoch 415 batch 00008: Loss 0.5067 Regression loss 0.0191 Classification loss 0.4876 AP 0.4000 AR 0.0000
Epoch 415 batch 00009: Loss 0.4673 Regression loss 0.0139 Classification loss 0.4534 AP 0.3500 AR 0.0900
Epoch 415 batch 00010: Loss 0.4512 Regression loss 0.0205 Classification loss 0.4307 AP 0.8667 AR 0.2400
Epoch 416 batch 00001: Loss 0.3696 Regression loss 0.0129 Classification loss 0.3567 AP 0.7000 AR 0.2000
Epoch 416 batch 00002: Loss 0.4059 Regression loss 0.0101 Classification loss 0.3958 AP 0.5667 AR 0.2667
Epoch 416 batch 00003: Loss 0.6267 Regression loss 0.0145 Classification loss 0.6123 AP 0.8000 AR 0.0800
Epoch 416 batch 00004: Loss 0.3693 Regression loss 0.0132 Classification loss 0.3561 AP 0.5333 AR 0.0800
Epoch 416 batch 00005: Loss 0.5201 Regression loss 0.0119 Classification loss 0.5082 AP 0.1500 AR 0.1500
Epoch 416 batch 00006: Loss 0.3259 Regression loss 0.0171 Classification loss 0.3088 AP 1.0000 AR 0.2500
Epoch 416 batch 00007: Loss 0.5826 Regression loss 0.0188 Classification loss 0.5638 AP 0.6000 AR 0.0000
Epoch 416 batch 00008: Loss 0.4173 Regression loss 0.0134 Classification loss 0.4039 AP 0.3000 AR 0.0667
Epoch 416 batch 00009: Loss 0.4630 Regression loss 0.0172 Classification loss 0.4458 AP 0.6000 AR 0.1900
Epoch 416 batch 00010: Loss 0.3789 Regression loss 0.0122 Classification loss 0.3667 AP 0.5167 AR 0.3400
Epoch 417 batch 00001: Loss 0.3359 Regression loss 0.0122 Classification loss 0.3237 AP 0.4667 AR 0.0667
Epoch 417 batch 00002: Loss 0.4363 Regression loss 0.0124 Classification loss 0.4239 AP 0.4333 AR 0.1300
Epoch 417 batch 00003: Loss 0.3892 Regression loss 0.0169 Classification loss 0.3724 AP 0.8000 AR 0.0000
Epoch 417 batch 00004: Loss 0.4595 Regression loss 0.0075 Classification loss 0.4520 AP 0.6000 AR 0.3667
Epoch 417 batch 00005: Loss 0.4310 Regression loss 0.0119 Classification loss 0.4191 AP 0.8000 AR 0.2500
Epoch 417 batch 00006: Loss 0.5599 Regression loss 0.0179 Classification loss 0.5420 AP 0.9000 AR 0.1000
Epoch 417 batch 00007: Loss 0.3825 Regression loss 0.0127 Classification loss 0.3698 AP 0.3400 AR 0.1500
Epoch 417 batch 00008: Loss 0.5350 Regression loss 0.0108 Classification loss 0.5242 AP 0.7000 AR 0.2500
Epoch 417 batch 00009: Loss 0.4558 Regression loss 0.0130 Classification loss 0.4428 AP 0.4500 AR 0.1300
Epoch 417 batch 00010: Loss 0.4633 Regression loss 0.0180 Classification loss 0.4453 AP 0.5667 AR 0.2467
Epoch 418 batch 00001: Loss 0.4469 Regression loss 0.0141 Classification loss 0.4328 AP 0.5500 AR 0.1500
Epoch 418 batch 00002: Loss 0.2778 Regression loss 0.0065 Classification loss 0.2713 AP 0.6000 AR 0.5000
Epoch 418 batch 00003: Loss 0.5236 Regression loss 0.0135 Classification loss 0.5100 AP 0.3167 AR 0.1967
Epoch 418 batch 00004: Loss 0.5521 Regression loss 0.0145 Classification loss 0.5376 AP 0.6000 AR 0.2000
Epoch 418 batch 00005: Loss 0.4126 Regression loss 0.0193 Classification loss 0.3934 AP 1.0000 AR 0.0500
Epoch 418 batch 00006: Loss 0.3790 Regression loss 0.0132 Classification loss 0.3658 AP 0.7333 AR 0.0800
Epoch 418 batch 00007: Loss 0.6178 Regression loss 0.0137 Classification loss 0.6041 AP 0.9000 AR 0.0667
Epoch 418 batch 00008: Loss 0.3170 Regression loss 0.0111 Classification loss 0.3059 AP 0.1667 AR 0.2000
Epoch 418 batch 00009: Loss 0.4830 Regression loss 0.0115 Classification loss 0.4715 AP 0.3667 AR 0.1000
Epoch 418 batch 00010: Loss 0.4522 Regression loss 0.0182 Classification loss 0.4340 AP 0.6333 AR 0.1200
Epoch 419 batch 00001: Loss 0.3980 Regression loss 0.0091 Classification loss 0.3889 AP 0.7000 AR 0.2500
Epoch 419 batch 00002: Loss 0.4117 Regression loss 0.0136 Classification loss 0.3982 AP 0.5167 AR 0.0900
Epoch 419 batch 00003: Loss 0.5097 Regression loss 0.0168 Classification loss 0.4929 AP 0.6333 AR 0.1700
Epoch 419 batch 00004: Loss 0.4258 Regression loss 0.0129 Classification loss 0.4129 AP 0.4667 AR 0.1000
Epoch 419 batch 00005: Loss 0.3015 Regression loss 0.0142 Classification loss 0.2874 AP 1.0000 AR 0.2800
Epoch 419 batch 00006: Loss 0.6047 Regression loss 0.0143 Classification loss 0.5904 AP 0.3667 AR 0.1500
Epoch 419 batch 00007: Loss 0.3504 Regression loss 0.0160 Classification loss 0.3344 AP 0.8000 AR 0.3467
Epoch 419 batch 00008: Loss 0.4524 Regression loss 0.0085 Classification loss 0.4439 AP 0.6667 AR 0.2667
Epoch 419 batch 00009: Loss 0.3602 Regression loss 0.0116 Classification loss 0.3486 AP 0.5667 AR 0.1167
Epoch 419 batch 00010: Loss 0.5443 Regression loss 0.0171 Classification loss 0.5272 AP 0.4000 AR 0.0000
Epoch 420 batch 00001: Loss 0.3649 Regression loss 0.0159 Classification loss 0.3490 AP 0.6000 AR 0.0000
Epoch 420 batch 00002: Loss 0.3681 Regression loss 0.0122 Classification loss 0.3559 AP 0.7500 AR 0.3067
Epoch 420 batch 00003: Loss 0.3696 Regression loss 0.0128 Classification loss 0.3568 AP 0.4000 AR 0.1867
Epoch 420 batch 00004: Loss 0.5363 Regression loss 0.0154 Classification loss 0.5209 AP 0.8667 AR 0.0400
Epoch 420 batch 00005: Loss 0.5551 Regression loss 0.0142 Classification loss 0.5409 AP 0.4500 AR 0.0500
Epoch 420 batch 00006: Loss 0.4153 Regression loss 0.0111 Classification loss 0.4042 AP 0.1500 AR 0.1500
Epoch 420 batch 00007: Loss 0.4283 Regression loss 0.0173 Classification loss 0.4110 AP 0.7500 AR 0.1167
Epoch 420 batch 00008: Loss 0.5047 Regression loss 0.0161 Classification loss 0.4886 AP 0.8000 AR 0.2500
Epoch 420 batch 00009: Loss 0.3819 Regression loss 0.0152 Classification loss 0.3667 AP 0.4667 AR 0.3000
Epoch 420 batch 00010: Loss 0.3680 Regression loss 0.0126 Classification loss 0.3554 AP 0.6000 AR 0.2000
Epoch 421 batch 00001: Loss 0.4376 Regression loss 0.0152 Classification loss 0.4225 AP 0.5000 AR 0.1000
Epoch 421 batch 00002: Loss 0.7388 Regression loss 0.0257 Classification loss 0.7131 AP 1.0000 AR 0.2000
Epoch 421 batch 00003: Loss 0.2913 Regression loss 0.0112 Classification loss 0.2801 AP 0.8000 AR 0.2000
Epoch 421 batch 00004: Loss 0.3179 Regression loss 0.0121 Classification loss 0.3058 AP 0.7167 AR 0.3700
Epoch 421 batch 00005: Loss 0.5202 Regression loss 0.0160 Classification loss 0.5042 AP 0.8000 AR 0.0800
Epoch 421 batch 00006: Loss 0.5676 Regression loss 0.0145 Classification loss 0.5531 AP 0.5000 AR 0.1000
Epoch 421 batch 00007: Loss 0.5436 Regression loss 0.0176 Classification loss 0.5260 AP 0.5667 AR 0.1667
Epoch 421 batch 00008: Loss 0.3216 Regression loss 0.0092 Classification loss 0.3124 AP 0.4333 AR 0.2800
Epoch 421 batch 00009: Loss 0.6020 Regression loss 0.0125 Classification loss 0.5895 AP 0.4667 AR 0.0400
Epoch 421 batch 00010: Loss 0.3319 Regression loss 0.0096 Classification loss 0.3223 AP 0.4667 AR 0.2333
Epoch 422 batch 00001: Loss 0.4653 Regression loss 0.0139 Classification loss 0.4515 AP 0.6000 AR 0.2000
Epoch 422 batch 00002: Loss 0.4636 Regression loss 0.0177 Classification loss 0.4458 AP 0.9000 AR 0.1000
Epoch 422 batch 00003: Loss 0.4190 Regression loss 0.0152 Classification loss 0.4039 AP 0.8000 AR 0.1667
Epoch 422 batch 00004: Loss 0.6097 Regression loss 0.0157 Classification loss 0.5941 AP 0.6000 AR 0.1500
Epoch 422 batch 00005: Loss 0.5704 Regression loss 0.0125 Classification loss 0.5579 AP 0.4000 AR 0.3400
Epoch 422 batch 00006: Loss 0.5492 Regression loss 0.0124 Classification loss 0.5368 AP 0.5000 AR 0.2000
Epoch 422 batch 00007: Loss 0.3254 Regression loss 0.0129 Classification loss 0.3124 AP 0.5000 AR 0.0400
Epoch 422 batch 00008: Loss 0.3500 Regression loss 0.0098 Classification loss 0.3403 AP 0.5833 AR 0.1567
Epoch 422 batch 00009: Loss 0.3354 Regression loss 0.0134 Classification loss 0.3220 AP 0.4000 AR 0.1200
Epoch 422 batch 00010: Loss 0.3894 Regression loss 0.0141 Classification loss 0.3753 AP 0.5400 AR 0.1500
Epoch 423 batch 00001: Loss 0.4983 Regression loss 0.0154 Classification loss 0.4828 AP 0.6000 AR 0.0000
Epoch 423 batch 00002: Loss 0.2934 Regression loss 0.0068 Classification loss 0.2866 AP 0.5667 AR 0.3967
Epoch 423 batch 00003: Loss 0.4462 Regression loss 0.0189 Classification loss 0.4273 AP 0.7000 AR 0.0667
Epoch 423 batch 00004: Loss 0.3195 Regression loss 0.0128 Classification loss 0.3068 AP 0.6000 AR 0.4400
Epoch 423 batch 00005: Loss 0.3691 Regression loss 0.0113 Classification loss 0.3577 AP 0.4667 AR 0.0900
Epoch 423 batch 00006: Loss 0.4749 Regression loss 0.0170 Classification loss 0.4580 AP 0.8333 AR 0.2800
Epoch 423 batch 00007: Loss 0.4471 Regression loss 0.0130 Classification loss 0.4342 AP 0.2667 AR 0.0500
Epoch 423 batch 00008: Loss 0.4394 Regression loss 0.0125 Classification loss 0.4269 AP 0.2500 AR 0.0500
Epoch 423 batch 00009: Loss 0.5780 Regression loss 0.0148 Classification loss 0.5632 AP 0.6500 AR 0.0500
Epoch 423 batch 00010: Loss 0.5027 Regression loss 0.0076 Classification loss 0.4951 AP 0.9000 AR 0.2667
Epoch 424 batch 00001: Loss 0.3245 Regression loss 0.0124 Classification loss 0.3120 AP 0.6000 AR 0.1400
Epoch 424 batch 00002: Loss 0.4080 Regression loss 0.0119 Classification loss 0.3961 AP 0.7167 AR 0.1000
Epoch 424 batch 00003: Loss 0.5618 Regression loss 0.0128 Classification loss 0.5491 AP 0.8000 AR 0.1400
Epoch 424 batch 00004: Loss 0.4341 Regression loss 0.0133 Classification loss 0.4209 AP 0.6000 AR 0.2000
Epoch 424 batch 00005: Loss 0.5873 Regression loss 0.0145 Classification loss 0.5728 AP 0.4000 AR 0.2400
Epoch 424 batch 00006: Loss 0.4576 Regression loss 0.0149 Classification loss 0.4427 AP 0.5000 AR 0.1733
Epoch 424 batch 00007: Loss 0.4355 Regression loss 0.0109 Classification loss 0.4247 AP 0.3333 AR 0.3500
Epoch 424 batch 00008: Loss 0.3832 Regression loss 0.0180 Classification loss 0.3652 AP 0.8000 AR 0.1467
Epoch 424 batch 00009: Loss 0.5050 Regression loss 0.0136 Classification loss 0.4914 AP 0.3000 AR 0.1000
Epoch 424 batch 00010: Loss 0.5066 Regression loss 0.0134 Classification loss 0.4932 AP 0.9000 AR 0.1000
Epoch 425 batch 00001: Loss 0.3743 Regression loss 0.0124 Classification loss 0.3619 AP 0.7000 AR 0.2667
Epoch 425 batch 00002: Loss 0.4121 Regression loss 0.0151 Classification loss 0.3970 AP 0.5667 AR 0.1667
Epoch 425 batch 00003: Loss 0.4965 Regression loss 0.0163 Classification loss 0.4802 AP 0.3000 AR 0.2167
Epoch 425 batch 00004: Loss 0.4297 Regression loss 0.0142 Classification loss 0.4155 AP 0.2500 AR 0.1500
Epoch 425 batch 00005: Loss 0.4232 Regression loss 0.0179 Classification loss 0.4053 AP 0.8667 AR 0.3200
Epoch 425 batch 00006: Loss 0.5168 Regression loss 0.0109 Classification loss 0.5059 AP 0.7000 AR 0.1300
Epoch 425 batch 00007: Loss 0.4890 Regression loss 0.0174 Classification loss 0.4716 AP 0.8000 AR 0.0000
Epoch 425 batch 00008: Loss 0.3692 Regression loss 0.0130 Classification loss 0.3562 AP 0.2667 AR 0.1000
Epoch 425 batch 00009: Loss 0.5241 Regression loss 0.0156 Classification loss 0.5086 AP 0.6000 AR 0.0000
Epoch 425 batch 00010: Loss 0.5213 Regression loss 0.0175 Classification loss 0.5038 AP 0.9000 AR 0.0900
Epoch 426 batch 00001: Loss 0.4964 Regression loss 0.0164 Classification loss 0.4800 AP 0.4000 AR 0.0000
Epoch 426 batch 00002: Loss 0.4636 Regression loss 0.0120 Classification loss 0.4517 AP 0.5500 AR 0.1500
Epoch 426 batch 00003: Loss 0.4014 Regression loss 0.0134 Classification loss 0.3880 AP 0.9000 AR 0.5800
Epoch 426 batch 00004: Loss 0.2092 Regression loss 0.0129 Classification loss 0.1963 AP 0.5667 AR 0.2200
Epoch 426 batch 00005: Loss 0.5228 Regression loss 0.0165 Classification loss 0.5063 AP 0.7000 AR 0.1833
Epoch 426 batch 00006: Loss 0.3800 Regression loss 0.0121 Classification loss 0.3679 AP 0.8500 AR 0.2500
Epoch 426 batch 00007: Loss 0.3818 Regression loss 0.0130 Classification loss 0.3688 AP 0.4667 AR 0.0400
Epoch 426 batch 00008: Loss 0.5313 Regression loss 0.0116 Classification loss 0.5197 AP 0.5000 AR 0.1000
Epoch 426 batch 00009: Loss 0.5319 Regression loss 0.0109 Classification loss 0.5210 AP 0.6667 AR 0.1000
Epoch 426 batch 00010: Loss 0.4993 Regression loss 0.0140 Classification loss 0.4853 AP 0.5000 AR 0.0667
Epoch 427 batch 00001: Loss 0.4578 Regression loss 0.0162 Classification loss 0.4415 AP 0.8000 AR 0.2800
Epoch 427 batch 00002: Loss 0.6033 Regression loss 0.0115 Classification loss 0.5918 AP 0.4667 AR 0.1000
Epoch 427 batch 00003: Loss 0.3745 Regression loss 0.0133 Classification loss 0.3613 AP 0.3000 AR 0.1000
Epoch 427 batch 00004: Loss 0.3071 Regression loss 0.0129 Classification loss 0.2942 AP 0.8000 AR 0.0000
Epoch 427 batch 00005: Loss 0.4988 Regression loss 0.0110 Classification loss 0.4878 AP 0.6000 AR 0.1000
Epoch 427 batch 00006: Loss 0.2503 Regression loss 0.0148 Classification loss 0.2355 AP 1.0000 AR 0.3300
Epoch 427 batch 00007: Loss 0.5028 Regression loss 0.0152 Classification loss 0.4876 AP 0.5000 AR 0.0500
Epoch 427 batch 00008: Loss 0.5752 Regression loss 0.0143 Classification loss 0.5609 AP 0.7000 AR 0.2667
Epoch 427 batch 00009: Loss 0.5966 Regression loss 0.0113 Classification loss 0.5852 AP 0.4500 AR 0.0500
Epoch 427 batch 00010: Loss 0.3651 Regression loss 0.0110 Classification loss 0.3541 AP 0.3333 AR 0.3467
Epoch 428 batch 00001: Loss 0.5052 Regression loss 0.0179 Classification loss 0.4873 AP 0.9000 AR 0.3000
Epoch 428 batch 00002: Loss 0.3400 Regression loss 0.0121 Classification loss 0.3279 AP 0.4000 AR 0.2500
Epoch 428 batch 00003: Loss 0.4055 Regression loss 0.0143 Classification loss 0.3913 AP 0.8667 AR 0.0400
Epoch 428 batch 00004: Loss 0.5281 Regression loss 0.0172 Classification loss 0.5109 AP 0.8000 AR 0.3200
Epoch 428 batch 00005: Loss 0.2242 Regression loss 0.0139 Classification loss 0.2103 AP 0.7333 AR 0.3300
Epoch 428 batch 00006: Loss 0.4204 Regression loss 0.0098 Classification loss 0.4106 AP 0.4500 AR 0.1667
Epoch 428 batch 00007: Loss 0.5991 Regression loss 0.0123 Classification loss 0.5868 AP 0.2000 AR 0.0000
Epoch 428 batch 00008: Loss 0.4702 Regression loss 0.0115 Classification loss 0.4587 AP 0.5667 AR 0.0900
Epoch 428 batch 00009: Loss 0.4419 Regression loss 0.0132 Classification loss 0.4287 AP 0.4000 AR 0.1333
Epoch 428 batch 00010: Loss 0.4083 Regression loss 0.0115 Classification loss 0.3968 AP 0.7000 AR 0.1000
Epoch 429 batch 00001: Loss 0.5232 Regression loss 0.0120 Classification loss 0.5113 AP 0.7000 AR 0.1000
Epoch 429 batch 00002: Loss 0.3977 Regression loss 0.0153 Classification loss 0.3824 AP 0.4667 AR 0.0400
Epoch 429 batch 00003: Loss 0.3365 Regression loss 0.0136 Classification loss 0.3229 AP 0.6000 AR 0.3400
Epoch 429 batch 00004: Loss 0.5389 Regression loss 0.0111 Classification loss 0.5277 AP 0.7000 AR 0.3000
Epoch 429 batch 00005: Loss 0.3081 Regression loss 0.0088 Classification loss 0.2993 AP 0.4667 AR 0.3000
Epoch 429 batch 00006: Loss 0.4350 Regression loss 0.0128 Classification loss 0.4222 AP 0.5000 AR 0.1467
Epoch 429 batch 00007: Loss 0.5888 Regression loss 0.0139 Classification loss 0.5749 AP 0.8000 AR 0.0000
Epoch 429 batch 00008: Loss 0.4147 Regression loss 0.0152 Classification loss 0.3995 AP 0.6500 AR 0.1300
Epoch 429 batch 00009: Loss 0.4515 Regression loss 0.0128 Classification loss 0.4388 AP 0.5000 AR 0.1833
Epoch 429 batch 00010: Loss 0.3936 Regression loss 0.0133 Classification loss 0.3803 AP 0.7167 AR 0.1500
Epoch 430 batch 00001: Loss 0.4533 Regression loss 0.0082 Classification loss 0.4450 AP 0.6667 AR 0.2167
Epoch 430 batch 00002: Loss 0.5157 Regression loss 0.0126 Classification loss 0.5031 AP 0.6000 AR 0.0000
Epoch 430 batch 00003: Loss 0.4074 Regression loss 0.0115 Classification loss 0.3959 AP 0.4167 AR 0.2900
Epoch 430 batch 00004: Loss 0.4080 Regression loss 0.0125 Classification loss 0.3956 AP 0.3000 AR 0.1000
Epoch 430 batch 00005: Loss 0.3217 Regression loss 0.0095 Classification loss 0.3121 AP 0.5000 AR 0.0400
Epoch 430 batch 00006: Loss 0.5176 Regression loss 0.0173 Classification loss 0.5003 AP 0.7333 AR 0.2200
Epoch 430 batch 00007: Loss 0.5025 Regression loss 0.0168 Classification loss 0.4856 AP 0.8000 AR 0.0000
Epoch 430 batch 00008: Loss 0.3793 Regression loss 0.0137 Classification loss 0.3656 AP 0.6333 AR 0.3467
Epoch 430 batch 00009: Loss 0.3416 Regression loss 0.0115 Classification loss 0.3301 AP 0.4000 AR 0.2000
Epoch 430 batch 00010: Loss 0.4376 Regression loss 0.0153 Classification loss 0.4223 AP 0.6500 AR 0.2500
Epoch 431 batch 00001: Loss 0.4105 Regression loss 0.0148 Classification loss 0.3957 AP 0.3667 AR 0.2000
Epoch 431 batch 00002: Loss 0.5425 Regression loss 0.0136 Classification loss 0.5289 AP 0.8000 AR 0.0500
Epoch 431 batch 00003: Loss 0.3576 Regression loss 0.0114 Classification loss 0.3462 AP 0.5833 AR 0.3800
Epoch 431 batch 00004: Loss 0.5450 Regression loss 0.0145 Classification loss 0.5305 AP 0.3667 AR 0.1067
Epoch 431 batch 00005: Loss 0.4154 Regression loss 0.0130 Classification loss 0.4024 AP 0.6000 AR 0.1400
Epoch 431 batch 00006: Loss 0.3787 Regression loss 0.0145 Classification loss 0.3642 AP 0.8667 AR 0.0667
Epoch 431 batch 00007: Loss 0.4789 Regression loss 0.0077 Classification loss 0.4712 AP 0.6000 AR 0.1667
Epoch 431 batch 00008: Loss 0.3340 Regression loss 0.0111 Classification loss 0.3228 AP 0.4167 AR 0.3400
Epoch 431 batch 00009: Loss 0.3423 Regression loss 0.0124 Classification loss 0.3299 AP 0.4667 AR 0.0400
Epoch 431 batch 00010: Loss 0.5680 Regression loss 0.0143 Classification loss 0.5537 AP 0.7000 AR 0.2000
Epoch 432 batch 00001: Loss 0.4474 Regression loss 0.0106 Classification loss 0.4368 AP 0.6000 AR 0.0800
Epoch 432 batch 00002: Loss 0.5643 Regression loss 0.0159 Classification loss 0.5484 AP 0.6000 AR 0.2900
Epoch 432 batch 00003: Loss 0.3802 Regression loss 0.0108 Classification loss 0.3694 AP 0.4667 AR 0.2400
Epoch 432 batch 00004: Loss 0.4872 Regression loss 0.0121 Classification loss 0.4751 AP 0.2667 AR 0.1000
Epoch 432 batch 00005: Loss 0.4386 Regression loss 0.0114 Classification loss 0.4272 AP 0.5333 AR 0.3400
Epoch 432 batch 00006: Loss 0.3321 Regression loss 0.0135 Classification loss 0.3186 AP 0.8000 AR 0.0500
Epoch 432 batch 00007: Loss 0.4580 Regression loss 0.0085 Classification loss 0.4495 AP 0.6500 AR 0.2000
Epoch 432 batch 00008: Loss 0.6525 Regression loss 0.0209 Classification loss 0.6316 AP 0.8000 AR 0.0000
Epoch 432 batch 00009: Loss 0.2828 Regression loss 0.0125 Classification loss 0.2703 AP 0.4500 AR 0.1833
Epoch 432 batch 00010: Loss 0.3529 Regression loss 0.0156 Classification loss 0.3373 AP 0.8667 AR 0.1800
Epoch 433 batch 00001: Loss 0.5690 Regression loss 0.0144 Classification loss 0.5546 AP 0.5000 AR 0.2000
Epoch 433 batch 00002: Loss 0.5036 Regression loss 0.0121 Classification loss 0.4915 AP 0.5667 AR 0.2300
Epoch 433 batch 00003: Loss 0.2497 Regression loss 0.0127 Classification loss 0.2370 AP 0.8000 AR 0.0500
Epoch 433 batch 00004: Loss 0.3576 Regression loss 0.0111 Classification loss 0.3465 AP 0.6500 AR 0.0500
Epoch 433 batch 00005: Loss 0.4768 Regression loss 0.0119 Classification loss 0.4649 AP 0.3667 AR 0.2400
Epoch 433 batch 00006: Loss 0.5924 Regression loss 0.0155 Classification loss 0.5770 AP 0.4667 AR 0.0400
Epoch 433 batch 00007: Loss 0.4726 Regression loss 0.0139 Classification loss 0.4588 AP 0.4500 AR 0.0500
Epoch 433 batch 00008: Loss 0.3770 Regression loss 0.0131 Classification loss 0.3639 AP 0.6000 AR 0.3667
Epoch 433 batch 00009: Loss 0.4494 Regression loss 0.0190 Classification loss 0.4304 AP 0.8000 AR 0.0800
Epoch 433 batch 00010: Loss 0.3918 Regression loss 0.0108 Classification loss 0.3811 AP 0.5667 AR 0.2567
Epoch 434 batch 00001: Loss 0.4019 Regression loss 0.0154 Classification loss 0.3864 AP 0.6167 AR 0.2167
Epoch 434 batch 00002: Loss 0.4877 Regression loss 0.0134 Classification loss 0.4743 AP 0.4500 AR 0.0500
Epoch 434 batch 00003: Loss 0.5078 Regression loss 0.0142 Classification loss 0.4936 AP 0.7000 AR 0.0400
Epoch 434 batch 00004: Loss 0.4784 Regression loss 0.0130 Classification loss 0.4654 AP 0.4000 AR 0.1400
Epoch 434 batch 00005: Loss 0.6159 Regression loss 0.0173 Classification loss 0.5985 AP 0.9000 AR 0.0667
Epoch 434 batch 00006: Loss 0.4666 Regression loss 0.0152 Classification loss 0.4514 AP 0.6000 AR 0.0000
Epoch 434 batch 00007: Loss 0.3997 Regression loss 0.0119 Classification loss 0.3878 AP 0.4667 AR 0.2700
Epoch 434 batch 00008: Loss 0.3562 Regression loss 0.0151 Classification loss 0.3412 AP 0.7000 AR 0.2000
Epoch 434 batch 00009: Loss 0.3152 Regression loss 0.0061 Classification loss 0.3091 AP 0.5000 AR 0.5667
Epoch 434 batch 00010: Loss 0.2973 Regression loss 0.0108 Classification loss 0.2865 AP 0.5000 AR 0.1000
Epoch 435 batch 00001: Loss 0.4272 Regression loss 0.0091 Classification loss 0.4181 AP 0.7000 AR 0.3000
Epoch 435 batch 00002: Loss 0.3644 Regression loss 0.0131 Classification loss 0.3513 AP 0.5667 AR 0.1167
Epoch 435 batch 00003: Loss 0.5287 Regression loss 0.0122 Classification loss 0.5166 AP 0.6000 AR 0.0000
Epoch 435 batch 00004: Loss 0.4155 Regression loss 0.0114 Classification loss 0.4041 AP 0.8000 AR 0.2000
Epoch 435 batch 00005: Loss 0.4072 Regression loss 0.0116 Classification loss 0.3956 AP 0.5500 AR 0.0900
Epoch 435 batch 00006: Loss 0.5327 Regression loss 0.0163 Classification loss 0.5164 AP 0.4000 AR 0.3000
Epoch 435 batch 00007: Loss 0.2939 Regression loss 0.0175 Classification loss 0.2764 AP 0.8000 AR 0.0500
Epoch 435 batch 00008: Loss 0.4742 Regression loss 0.0114 Classification loss 0.4628 AP 0.2667 AR 0.1833
Epoch 435 batch 00009: Loss 0.4981 Regression loss 0.0128 Classification loss 0.4852 AP 0.5667 AR 0.2800
Epoch 435 batch 00010: Loss 0.4258 Regression loss 0.0139 Classification loss 0.4119 AP 0.6000 AR 0.0900
Epoch 436 batch 00001: Loss 0.4597 Regression loss 0.0147 Classification loss 0.4450 AP 0.6000 AR 0.2567
Epoch 436 batch 00002: Loss 0.4860 Regression loss 0.0084 Classification loss 0.4776 AP 0.4667 AR 0.0500
Epoch 436 batch 00003: Loss 0.4054 Regression loss 0.0130 Classification loss 0.3924 AP 0.7000 AR 0.3000
Epoch 436 batch 00004: Loss 0.2574 Regression loss 0.0143 Classification loss 0.2431 AP 0.6000 AR 0.2200
Epoch 436 batch 00005: Loss 0.6796 Regression loss 0.0187 Classification loss 0.6609 AP 0.8000 AR 0.0000
Epoch 436 batch 00006: Loss 0.4049 Regression loss 0.0140 Classification loss 0.3909 AP 0.6000 AR 0.0000
Epoch 436 batch 00007: Loss 0.5580 Regression loss 0.0074 Classification loss 0.5505 AP 0.4000 AR 0.1667
Epoch 436 batch 00008: Loss 0.4977 Regression loss 0.0132 Classification loss 0.4846 AP 0.3333 AR 0.0900
Epoch 436 batch 00009: Loss 0.4595 Regression loss 0.0181 Classification loss 0.4415 AP 0.9000 AR 0.2400
Epoch 436 batch 00010: Loss 0.2525 Regression loss 0.0088 Classification loss 0.2437 AP 0.6500 AR 0.3667
Epoch 437 batch 00001: Loss 0.3618 Regression loss 0.0140 Classification loss 0.3478 AP 0.2500 AR 0.1900
Epoch 437 batch 00002: Loss 0.4031 Regression loss 0.0165 Classification loss 0.3866 AP 0.5667 AR 0.1067
Epoch 437 batch 00003: Loss 0.6880 Regression loss 0.0097 Classification loss 0.6783 AP 0.5000 AR 0.3000
Epoch 437 batch 00004: Loss 0.4459 Regression loss 0.0128 Classification loss 0.4331 AP 0.8000 AR 0.0500
Epoch 437 batch 00005: Loss 0.5403 Regression loss 0.0147 Classification loss 0.5257 AP 0.8000 AR 0.2000
Epoch 437 batch 00006: Loss 0.4343 Regression loss 0.0115 Classification loss 0.4228 AP 0.4667 AR 0.0500
Epoch 437 batch 00007: Loss 0.4114 Regression loss 0.0107 Classification loss 0.4006 AP 0.5667 AR 0.4000
Epoch 437 batch 00008: Loss 0.4771 Regression loss 0.0131 Classification loss 0.4639 AP 0.4000 AR 0.0800
Epoch 437 batch 00009: Loss 0.3185 Regression loss 0.0121 Classification loss 0.3064 AP 0.8000 AR 0.0000
Epoch 437 batch 00010: Loss 0.4890 Regression loss 0.0124 Classification loss 0.4767 AP 0.4667 AR 0.0400
Epoch 438 batch 00001: Loss 0.3788 Regression loss 0.0175 Classification loss 0.3613 AP 0.7000 AR 0.1200
Epoch 438 batch 00002: Loss 0.5532 Regression loss 0.0168 Classification loss 0.5365 AP 0.6000 AR 0.1300
Epoch 438 batch 00003: Loss 0.5549 Regression loss 0.0153 Classification loss 0.5395 AP 0.6667 AR 0.2400
Epoch 438 batch 00004: Loss 0.3621 Regression loss 0.0113 Classification loss 0.3508 AP 0.5000 AR 0.1000
Epoch 438 batch 00005: Loss 0.4234 Regression loss 0.0090 Classification loss 0.4144 AP 0.5500 AR 0.3000
Epoch 438 batch 00006: Loss 0.4601 Regression loss 0.0139 Classification loss 0.4462 AP 0.7000 AR 0.1000
Epoch 438 batch 00007: Loss 0.5223 Regression loss 0.0125 Classification loss 0.5098 AP 0.4000 AR 0.0000
Epoch 438 batch 00008: Loss 0.3327 Regression loss 0.0120 Classification loss 0.3207 AP 0.4000 AR 0.0500
Epoch 438 batch 00009: Loss 0.4452 Regression loss 0.0110 Classification loss 0.4342 AP 0.5000 AR 0.1000
Epoch 438 batch 00010: Loss 0.4437 Regression loss 0.0135 Classification loss 0.4302 AP 0.6667 AR 0.2400
Epoch 439 batch 00001: Loss 0.5244 Regression loss 0.0162 Classification loss 0.5082 AP 0.6000 AR 0.0800
Epoch 439 batch 00002: Loss 0.4456 Regression loss 0.0137 Classification loss 0.4318 AP 0.5000 AR 0.1000
Epoch 439 batch 00003: Loss 0.3021 Regression loss 0.0110 Classification loss 0.2911 AP 0.8000 AR 0.4500
Epoch 439 batch 00004: Loss 0.5296 Regression loss 0.0130 Classification loss 0.5166 AP 0.5667 AR 0.2400
Epoch 439 batch 00005: Loss 0.5152 Regression loss 0.0138 Classification loss 0.5014 AP 0.7500 AR 0.1500
Epoch 439 batch 00006: Loss 0.3443 Regression loss 0.0066 Classification loss 0.3376 AP 0.6000 AR 0.1667
Epoch 439 batch 00007: Loss 0.5220 Regression loss 0.0125 Classification loss 0.5094 AP 0.9000 AR 0.1000
Epoch 439 batch 00008: Loss 0.2697 Regression loss 0.0116 Classification loss 0.2581 AP 0.5000 AR 0.1700
Epoch 439 batch 00009: Loss 0.5942 Regression loss 0.0130 Classification loss 0.5812 AP 0.1000 AR 0.0667
Epoch 439 batch 00010: Loss 0.6412 Regression loss 0.0139 Classification loss 0.6274 AP 0.7000 AR 0.1300
Epoch 440 batch 00001: Loss 0.3491 Regression loss 0.0099 Classification loss 0.3392 AP 0.3333 AR 0.2300
Epoch 440 batch 00002: Loss 0.3154 Regression loss 0.0133 Classification loss 0.3021 AP 0.5667 AR 0.1400
Epoch 440 batch 00003: Loss 0.5400 Regression loss 0.0130 Classification loss 0.5270 AP 0.0952 AR 0.0800
Epoch 440 batch 00004: Loss 0.5312 Regression loss 0.0193 Classification loss 0.5120 AP 0.0786 AR 0.1067
Epoch 440 batch 00005: Loss 0.6801 Regression loss 0.0142 Classification loss 0.6660 AP 0.0667 AR 0.0500
Epoch 440 batch 00006: Loss 0.4006 Regression loss 0.0156 Classification loss 0.3850 AP 0.9000 AR 0.4000
Epoch 440 batch 00007: Loss 0.4193 Regression loss 0.0140 Classification loss 0.4054 AP 0.6667 AR 0.2667
Epoch 440 batch 00008: Loss 0.6106 Regression loss 0.0142 Classification loss 0.5964 AP 0.4000 AR 0.2000
Epoch 440 batch 00009: Loss 0.4525 Regression loss 0.0155 Classification loss 0.4370 AP 0.6000 AR 0.0000
Epoch 440 batch 00010: Loss 0.4431 Regression loss 0.0129 Classification loss 0.4303 AP 0.4500 AR 0.1000
Epoch 441 batch 00001: Loss 0.5882 Regression loss 0.0131 Classification loss 0.5752 AP 0.6000 AR 0.0000
Epoch 441 batch 00002: Loss 0.4617 Regression loss 0.0159 Classification loss 0.4459 AP 0.2000 AR 0.2000
Epoch 441 batch 00003: Loss 0.4344 Regression loss 0.0200 Classification loss 0.4145 AP 0.7000 AR 0.2667
Epoch 441 batch 00004: Loss 0.3031 Regression loss 0.0117 Classification loss 0.2915 AP 0.2300 AR 0.2167
Epoch 441 batch 00005: Loss 0.4277 Regression loss 0.0153 Classification loss 0.4124 AP 0.4667 AR 0.1200
Epoch 441 batch 00006: Loss 0.5599 Regression loss 0.0159 Classification loss 0.5440 AP 0.7000 AR 0.0500
Epoch 441 batch 00007: Loss 0.3669 Regression loss 0.0111 Classification loss 0.3558 AP 0.5000 AR 0.3000
Epoch 441 batch 00008: Loss 0.4210 Regression loss 0.0146 Classification loss 0.4064 AP 0.6500 AR 0.0500
Epoch 441 batch 00009: Loss 0.5026 Regression loss 0.0118 Classification loss 0.4908 AP 0.8000 AR 0.2000
Epoch 441 batch 00010: Loss 0.5099 Regression loss 0.0124 Classification loss 0.4975 AP 0.7000 AR 0.1000
Epoch 442 batch 00001: Loss 0.4393 Regression loss 0.0152 Classification loss 0.4241 AP 0.6667 AR 0.0500
Epoch 442 batch 00002: Loss 0.4232 Regression loss 0.0145 Classification loss 0.4087 AP 0.3000 AR 0.2000
Epoch 442 batch 00003: Loss 0.4832 Regression loss 0.0154 Classification loss 0.4678 AP 0.8000 AR 0.0000
Epoch 442 batch 00004: Loss 0.4648 Regression loss 0.0210 Classification loss 0.4439 AP 1.0000 AR 0.2800
Epoch 442 batch 00005: Loss 0.5057 Regression loss 0.0165 Classification loss 0.4892 AP 0.5000 AR 0.2667
Epoch 442 batch 00006: Loss 0.3497 Regression loss 0.0114 Classification loss 0.3383 AP 0.5333 AR 0.2300
Epoch 442 batch 00007: Loss 0.3353 Regression loss 0.0125 Classification loss 0.3228 AP 0.4333 AR 0.2500
Epoch 442 batch 00008: Loss 0.4469 Regression loss 0.0118 Classification loss 0.4351 AP 0.5500 AR 0.1400
Epoch 442 batch 00009: Loss 0.4268 Regression loss 0.0117 Classification loss 0.4151 AP 0.3667 AR 0.0900
Epoch 442 batch 00010: Loss 0.5606 Regression loss 0.0114 Classification loss 0.5493 AP 0.4667 AR 0.0400
Epoch 443 batch 00001: Loss 0.4104 Regression loss 0.0139 Classification loss 0.3965 AP 0.5667 AR 0.1167
Epoch 443 batch 00002: Loss 0.5134 Regression loss 0.0159 Classification loss 0.4975 AP 0.8667 AR 0.2900
Epoch 443 batch 00003: Loss 0.7509 Regression loss 0.0176 Classification loss 0.7334 AP 1.0000 AR 0.0000
Epoch 443 batch 00004: Loss 0.4016 Regression loss 0.0126 Classification loss 0.3890 AP 0.2500 AR 0.0400
Epoch 443 batch 00005: Loss 0.4051 Regression loss 0.0127 Classification loss 0.3923 AP 0.2000 AR 0.1500
Epoch 443 batch 00006: Loss 0.3371 Regression loss 0.0157 Classification loss 0.3214 AP 0.6667 AR 0.1900
Epoch 443 batch 00007: Loss 0.5230 Regression loss 0.0140 Classification loss 0.5090 AP 0.4000 AR 0.0000
Epoch 443 batch 00008: Loss 0.2985 Regression loss 0.0091 Classification loss 0.2894 AP 0.6333 AR 0.1800
Epoch 443 batch 00009: Loss 0.4557 Regression loss 0.0120 Classification loss 0.4438 AP 0.2500 AR 0.2500
Epoch 443 batch 00010: Loss 0.4459 Regression loss 0.0128 Classification loss 0.4330 AP 0.7000 AR 0.1000
Epoch 444 batch 00001: Loss 0.2110 Regression loss 0.0073 Classification loss 0.2037 AP 0.6500 AR 0.4967
Epoch 444 batch 00002: Loss 0.5600 Regression loss 0.0098 Classification loss 0.5501 AP 0.6000 AR 0.3500
Epoch 444 batch 00003: Loss 0.4499 Regression loss 0.0133 Classification loss 0.4365 AP 0.4667 AR 0.1000
Epoch 444 batch 00004: Loss 0.4411 Regression loss 0.0159 Classification loss 0.4252 AP 0.3667 AR 0.2200
Epoch 444 batch 00005: Loss 0.5743 Regression loss 0.0155 Classification loss 0.5589 AP 0.8000 AR 0.0000
Epoch 444 batch 00006: Loss 0.3003 Regression loss 0.0104 Classification loss 0.2899 AP 0.6333 AR 0.1467
Epoch 444 batch 00007: Loss 0.4760 Regression loss 0.0128 Classification loss 0.4632 AP 0.2667 AR 0.0500
Epoch 444 batch 00008: Loss 0.4941 Regression loss 0.0192 Classification loss 0.4749 AP 0.8000 AR 0.0000
Epoch 444 batch 00009: Loss 0.6851 Regression loss 0.0211 Classification loss 0.6640 AP 1.0000 AR 0.2000
Epoch 444 batch 00010: Loss 0.4305 Regression loss 0.0169 Classification loss 0.4136 AP 0.5000 AR 0.0667
Epoch 445 batch 00001: Loss 0.5064 Regression loss 0.0205 Classification loss 0.4859 AP 0.9000 AR 0.0667
Epoch 445 batch 00002: Loss 0.4797 Regression loss 0.0131 Classification loss 0.4666 AP 0.6667 AR 0.2400
Epoch 445 batch 00003: Loss 0.3759 Regression loss 0.0156 Classification loss 0.3603 AP 0.5000 AR 0.0400
Epoch 445 batch 00004: Loss 0.3239 Regression loss 0.0129 Classification loss 0.3110 AP 0.9333 AR 0.3300
Epoch 445 batch 00005: Loss 0.5726 Regression loss 0.0104 Classification loss 0.5622 AP 0.2667 AR 0.1000
Epoch 445 batch 00006: Loss 0.5146 Regression loss 0.0124 Classification loss 0.5023 AP 0.5000 AR 0.0667
Epoch 445 batch 00007: Loss 0.3441 Regression loss 0.0122 Classification loss 0.3319 AP 0.5667 AR 0.1500
Epoch 445 batch 00008: Loss 0.4292 Regression loss 0.0154 Classification loss 0.4138 AP 0.5667 AR 0.1400
Epoch 445 batch 00009: Loss 0.5530 Regression loss 0.0141 Classification loss 0.5389 AP 0.7000 AR 0.3300
Epoch 445 batch 00010: Loss 0.4842 Regression loss 0.0092 Classification loss 0.4751 AP 0.4500 AR 0.2000
Epoch 446 batch 00001: Loss 0.5902 Regression loss 0.0127 Classification loss 0.5775 AP 0.2000 AR 0.0000
Epoch 446 batch 00002: Loss 0.4590 Regression loss 0.0125 Classification loss 0.4464 AP 0.5667 AR 0.4167
Epoch 446 batch 00003: Loss 0.3546 Regression loss 0.0131 Classification loss 0.3416 AP 0.5667 AR 0.1667
Epoch 446 batch 00004: Loss 0.5121 Regression loss 0.0192 Classification loss 0.4929 AP 0.5000 AR 0.1000
Epoch 446 batch 00005: Loss 0.3876 Regression loss 0.0115 Classification loss 0.3761 AP 0.6500 AR 0.0500
Epoch 446 batch 00006: Loss 0.3952 Regression loss 0.0152 Classification loss 0.3800 AP 0.6500 AR 0.2500
Epoch 446 batch 00007: Loss 0.2772 Regression loss 0.0110 Classification loss 0.2662 AP 0.8000 AR 0.2500
Epoch 446 batch 00008: Loss 0.3444 Regression loss 0.0091 Classification loss 0.3353 AP 0.4333 AR 0.3367
Epoch 446 batch 00009: Loss 0.5176 Regression loss 0.0121 Classification loss 0.5055 AP 0.5000 AR 0.0400
Epoch 446 batch 00010: Loss 0.6314 Regression loss 0.0171 Classification loss 0.6144 AP 0.9333 AR 0.0800
Epoch 447 batch 00001: Loss 0.5471 Regression loss 0.0119 Classification loss 0.5351 AP 0.2667 AR 0.1000
Epoch 447 batch 00002: Loss 0.4609 Regression loss 0.0159 Classification loss 0.4449 AP 0.8500 AR 0.0500
Epoch 447 batch 00003: Loss 0.3051 Regression loss 0.0145 Classification loss 0.2906 AP 0.5667 AR 0.3067
Epoch 447 batch 00004: Loss 0.3537 Regression loss 0.0112 Classification loss 0.3425 AP 0.5000 AR 0.2400
Epoch 447 batch 00005: Loss 0.5086 Regression loss 0.0120 Classification loss 0.4966 AP 0.1500 AR 0.1167
Epoch 447 batch 00006: Loss 0.5409 Regression loss 0.0141 Classification loss 0.5268 AP 0.6000 AR 0.0900
Epoch 447 batch 00007: Loss 0.4706 Regression loss 0.0179 Classification loss 0.4528 AP 0.9000 AR 0.3500
Epoch 447 batch 00008: Loss 0.3808 Regression loss 0.0119 Classification loss 0.3690 AP 0.7000 AR 0.1400
Epoch 447 batch 00009: Loss 0.3157 Regression loss 0.0136 Classification loss 0.3020 AP 0.6000 AR 0.0000
Epoch 447 batch 00010: Loss 0.4951 Regression loss 0.0103 Classification loss 0.4848 AP 0.8000 AR 0.1500
Epoch 448 batch 00001: Loss 0.4904 Regression loss 0.0140 Classification loss 0.4764 AP 0.1500 AR 0.1167
Epoch 448 batch 00002: Loss 0.3771 Regression loss 0.0140 Classification loss 0.3631 AP 0.8000 AR 0.0000
Epoch 448 batch 00003: Loss 0.4456 Regression loss 0.0104 Classification loss 0.4352 AP 0.2667 AR 0.1000
Epoch 448 batch 00004: Loss 0.3701 Regression loss 0.0143 Classification loss 0.3557 AP 0.9000 AR 0.3200
Epoch 448 batch 00005: Loss 0.5027 Regression loss 0.0156 Classification loss 0.4871 AP 0.8000 AR 0.2000
Epoch 448 batch 00006: Loss 0.3941 Regression loss 0.0133 Classification loss 0.3808 AP 0.6000 AR 0.2500
Epoch 448 batch 00007: Loss 0.4169 Regression loss 0.0134 Classification loss 0.4035 AP 0.6667 AR 0.2067
Epoch 448 batch 00008: Loss 0.4162 Regression loss 0.0103 Classification loss 0.4059 AP 0.5500 AR 0.1000
Epoch 448 batch 00009: Loss 0.3096 Regression loss 0.0048 Classification loss 0.3048 AP 0.4000 AR 0.3167
Epoch 448 batch 00010: Loss 0.5783 Regression loss 0.0186 Classification loss 0.5597 AP 0.8667 AR 0.0400
Epoch 449 batch 00001: Loss 0.4557 Regression loss 0.0133 Classification loss 0.4424 AP 0.7500 AR 0.1667
Epoch 449 batch 00002: Loss 0.4352 Regression loss 0.0062 Classification loss 0.4290 AP 0.4000 AR 0.1500
Epoch 449 batch 00003: Loss 0.4832 Regression loss 0.0149 Classification loss 0.4683 AP 0.7667 AR 0.2200
Epoch 449 batch 00004: Loss 0.4713 Regression loss 0.0112 Classification loss 0.4601 AP 0.3000 AR 0.0500
Epoch 449 batch 00005: Loss 0.5819 Regression loss 0.0156 Classification loss 0.5664 AP 0.5000 AR 0.1000
Epoch 449 batch 00006: Loss 0.3604 Regression loss 0.0142 Classification loss 0.3462 AP 0.9000 AR 0.3800
Epoch 449 batch 00007: Loss 0.3771 Regression loss 0.0124 Classification loss 0.3647 AP 0.3000 AR 0.0900
Epoch 449 batch 00008: Loss 0.4169 Regression loss 0.0122 Classification loss 0.4046 AP 0.4000 AR 0.1333
Epoch 449 batch 00009: Loss 0.4056 Regression loss 0.0121 Classification loss 0.3936 AP 0.9000 AR 0.2000
Epoch 449 batch 00010: Loss 0.2863 Regression loss 0.0132 Classification loss 0.2731 AP 0.8000 AR 0.2000
Epoch 450 batch 00001: Loss 0.4720 Regression loss 0.0132 Classification loss 0.4588 AP 0.8000 AR 0.1067
Epoch 450 batch 00002: Loss 0.5077 Regression loss 0.0108 Classification loss 0.4969 AP 0.3000 AR 0.3000
Epoch 450 batch 00003: Loss 0.2112 Regression loss 0.0096 Classification loss 0.2016 AP 0.6667 AR 0.6300
Epoch 450 batch 00004: Loss 0.4551 Regression loss 0.0170 Classification loss 0.4380 AP 0.6000 AR 0.0000
Epoch 450 batch 00005: Loss 0.7760 Regression loss 0.0125 Classification loss 0.7635 AP 0.7000 AR 0.0500
Epoch 450 batch 00006: Loss 0.4884 Regression loss 0.0122 Classification loss 0.4762 AP 0.5000 AR 0.1000
Epoch 450 batch 00007: Loss 0.6198 Regression loss 0.0155 Classification loss 0.6043 AP 0.7000 AR 0.0667
Epoch 450 batch 00008: Loss 0.3844 Regression loss 0.0149 Classification loss 0.3695 AP 0.6667 AR 0.0900
Epoch 450 batch 00009: Loss 0.3378 Regression loss 0.0108 Classification loss 0.3270 AP 0.5000 AR 0.2167
Epoch 450 batch 00010: Loss 0.4530 Regression loss 0.0149 Classification loss 0.4381 AP 0.4500 AR 0.0500
Epoch 451 batch 00001: Loss 0.4585 Regression loss 0.0108 Classification loss 0.4477 AP 0.3667 AR 0.2000
Epoch 451 batch 00002: Loss 0.3950 Regression loss 0.0126 Classification loss 0.3824 AP 0.4333 AR 0.3200
Epoch 451 batch 00003: Loss 0.3974 Regression loss 0.0109 Classification loss 0.3866 AP 0.5500 AR 0.3667
Epoch 451 batch 00004: Loss 0.4259 Regression loss 0.0124 Classification loss 0.4134 AP 0.8000 AR 0.1967
Epoch 451 batch 00005: Loss 0.7911 Regression loss 0.0185 Classification loss 0.7726 AP 1.0000 AR 0.2000
Epoch 451 batch 00006: Loss 0.4083 Regression loss 0.0102 Classification loss 0.3981 AP 0.6000 AR 0.0000
Epoch 451 batch 00007: Loss 0.4703 Regression loss 0.0132 Classification loss 0.4571 AP 0.4667 AR 0.0500
Epoch 451 batch 00008: Loss 0.5678 Regression loss 0.0181 Classification loss 0.5497 AP 0.7000 AR 0.0400
Epoch 451 batch 00009: Loss 0.4711 Regression loss 0.0100 Classification loss 0.4611 AP 0.5500 AR 0.1500
Epoch 451 batch 00010: Loss 0.3157 Regression loss 0.0175 Classification loss 0.2982 AP 0.5000 AR 0.0667
Epoch 452 batch 00001: Loss 0.6320 Regression loss 0.0135 Classification loss 0.6185 AP 0.5000 AR 0.0400
Epoch 452 batch 00002: Loss 0.6261 Regression loss 0.0132 Classification loss 0.6129 AP 0.3000 AR 0.2067
Epoch 452 batch 00003: Loss 0.3676 Regression loss 0.0135 Classification loss 0.3541 AP 0.7000 AR 0.1300
Epoch 452 batch 00004: Loss 0.4690 Regression loss 0.0143 Classification loss 0.4547 AP 0.5000 AR 0.1500
Epoch 452 batch 00005: Loss 0.3884 Regression loss 0.0156 Classification loss 0.3728 AP 0.9000 AR 0.0667
Epoch 452 batch 00006: Loss 0.4780 Regression loss 0.0091 Classification loss 0.4689 AP 0.7500 AR 0.5000
Epoch 452 batch 00007: Loss 0.4259 Regression loss 0.0183 Classification loss 0.4076 AP 0.7000 AR 0.0500
Epoch 452 batch 00008: Loss 0.3484 Regression loss 0.0111 Classification loss 0.3373 AP 0.3000 AR 0.1000
Epoch 452 batch 00009: Loss 0.4004 Regression loss 0.0128 Classification loss 0.3876 AP 0.5000 AR 0.2800
Epoch 452 batch 00010: Loss 0.3811 Regression loss 0.0161 Classification loss 0.3650 AP 0.8667 AR 0.1000
Epoch 453 batch 00001: Loss 0.4405 Regression loss 0.0170 Classification loss 0.4235 AP 0.8500 AR 0.2500
Epoch 453 batch 00002: Loss 0.5138 Regression loss 0.0104 Classification loss 0.5034 AP 0.6667 AR 0.2367
Epoch 453 batch 00003: Loss 0.5734 Regression loss 0.0101 Classification loss 0.5634 AP 0.6000 AR 0.3667
Epoch 453 batch 00004: Loss 0.5145 Regression loss 0.0128 Classification loss 0.5018 AP 0.6000 AR 0.0000
Epoch 453 batch 00005: Loss 0.3309 Regression loss 0.0141 Classification loss 0.3168 AP 0.4500 AR 0.3167
Epoch 453 batch 00006: Loss 0.4494 Regression loss 0.0116 Classification loss 0.4378 AP 0.4667 AR 0.1000
Epoch 453 batch 00007: Loss 0.3352 Regression loss 0.0140 Classification loss 0.3212 AP 0.8500 AR 0.1200
Epoch 453 batch 00008: Loss 0.4600 Regression loss 0.0129 Classification loss 0.4471 AP 0.6000 AR 0.2167
Epoch 453 batch 00009: Loss 0.3843 Regression loss 0.0153 Classification loss 0.3691 AP 0.6000 AR 0.0500
Epoch 453 batch 00010: Loss 0.4188 Regression loss 0.0137 Classification loss 0.4051 AP 0.5000 AR 0.1000
Epoch 454 batch 00001: Loss 0.5187 Regression loss 0.0180 Classification loss 0.5007 AP 0.7667 AR 0.2400
Epoch 454 batch 00002: Loss 0.4271 Regression loss 0.0149 Classification loss 0.4122 AP 0.5000 AR 0.1167
Epoch 454 batch 00003: Loss 0.4163 Regression loss 0.0076 Classification loss 0.4087 AP 0.5000 AR 0.4167
Epoch 454 batch 00004: Loss 0.4511 Regression loss 0.0108 Classification loss 0.4403 AP 0.8500 AR 0.0500
Epoch 454 batch 00005: Loss 0.3488 Regression loss 0.0126 Classification loss 0.3362 AP 0.6000 AR 0.2000
Epoch 454 batch 00006: Loss 0.2836 Regression loss 0.0106 Classification loss 0.2731 AP 0.6667 AR 0.2367
Epoch 454 batch 00007: Loss 0.5284 Regression loss 0.0198 Classification loss 0.5086 AP 0.8000 AR 0.0000
Epoch 454 batch 00008: Loss 0.5801 Regression loss 0.0135 Classification loss 0.5665 AP 0.5667 AR 0.1400
Epoch 454 batch 00009: Loss 0.5818 Regression loss 0.0135 Classification loss 0.5682 AP 0.2000 AR 0.0800
Epoch 454 batch 00010: Loss 0.3810 Regression loss 0.0120 Classification loss 0.3690 AP 0.5667 AR 0.2500
Epoch 455 batch 00001: Loss 0.5858 Regression loss 0.0120 Classification loss 0.5738 AP 0.6000 AR 0.2000
Epoch 455 batch 00002: Loss 0.5545 Regression loss 0.0144 Classification loss 0.5400 AP 0.4000 AR 0.0000
Epoch 455 batch 00003: Loss 0.4340 Regression loss 0.0166 Classification loss 0.4174 AP 0.7000 AR 0.2667
Epoch 455 batch 00004: Loss 0.4857 Regression loss 0.0116 Classification loss 0.4741 AP 0.6667 AR 0.2067
Epoch 455 batch 00005: Loss 0.4506 Regression loss 0.0122 Classification loss 0.4384 AP 0.4667 AR 0.2067
Epoch 455 batch 00006: Loss 0.4336 Regression loss 0.0190 Classification loss 0.4146 AP 0.7000 AR 0.1000
Epoch 455 batch 00007: Loss 0.4232 Regression loss 0.0123 Classification loss 0.4109 AP 0.6733 AR 0.3800
Epoch 455 batch 00008: Loss 0.3051 Regression loss 0.0106 Classification loss 0.2944 AP 0.6333 AR 0.2700
Epoch 455 batch 00009: Loss 0.2399 Regression loss 0.0105 Classification loss 0.2294 AP 0.6000 AR 0.0500
Epoch 455 batch 00010: Loss 0.5077 Regression loss 0.0130 Classification loss 0.4947 AP 0.6500 AR 0.0500
Epoch 456 batch 00001: Loss 0.4722 Regression loss 0.0180 Classification loss 0.4542 AP 0.6000 AR 0.0000
Epoch 456 batch 00002: Loss 0.5047 Regression loss 0.0180 Classification loss 0.4867 AP 0.7000 AR 0.2667
Epoch 456 batch 00003: Loss 0.5552 Regression loss 0.0150 Classification loss 0.5402 AP 0.6000 AR 0.0500
Epoch 456 batch 00004: Loss 0.4733 Regression loss 0.0133 Classification loss 0.4600 AP 0.5733 AR 0.1300
Epoch 456 batch 00005: Loss 0.3993 Regression loss 0.0124 Classification loss 0.3869 AP 0.3500 AR 0.0900
Epoch 456 batch 00006: Loss 0.3624 Regression loss 0.0081 Classification loss 0.3543 AP 0.4000 AR 0.1500
Epoch 456 batch 00007: Loss 0.4728 Regression loss 0.0083 Classification loss 0.4645 AP 0.5000 AR 0.2167
Epoch 456 batch 00008: Loss 0.4124 Regression loss 0.0137 Classification loss 0.3987 AP 0.8000 AR 0.3000
Epoch 456 batch 00009: Loss 0.3230 Regression loss 0.0116 Classification loss 0.3113 AP 0.7333 AR 0.1467
Epoch 456 batch 00010: Loss 0.3718 Regression loss 0.0088 Classification loss 0.3630 AP 0.6000 AR 0.1667
Epoch 457 batch 00001: Loss 0.5364 Regression loss 0.0157 Classification loss 0.5208 AP 0.4000 AR 0.0800
Epoch 457 batch 00002: Loss 0.2922 Regression loss 0.0109 Classification loss 0.2813 AP 0.8000 AR 0.4800
Epoch 457 batch 00003: Loss 0.5026 Regression loss 0.0121 Classification loss 0.4905 AP 0.4000 AR 0.0000
Epoch 457 batch 00004: Loss 0.2870 Regression loss 0.0107 Classification loss 0.2763 AP 0.8000 AR 0.1667
Epoch 457 batch 00005: Loss 0.6911 Regression loss 0.0157 Classification loss 0.6755 AP 0.7000 AR 0.0667
Epoch 457 batch 00006: Loss 0.4690 Regression loss 0.0127 Classification loss 0.4563 AP 0.5333 AR 0.1400
Epoch 457 batch 00007: Loss 0.2698 Regression loss 0.0114 Classification loss 0.2584 AP 0.8000 AR 0.2400
Epoch 457 batch 00008: Loss 0.4356 Regression loss 0.0092 Classification loss 0.4264 AP 0.3500 AR 0.3000
Epoch 457 batch 00009: Loss 0.4319 Regression loss 0.0128 Classification loss 0.4191 AP 0.6000 AR 0.0000
Epoch 457 batch 00010: Loss 0.4131 Regression loss 0.0160 Classification loss 0.3971 AP 0.6000 AR 0.1667
Epoch 458 batch 00001: Loss 0.5360 Regression loss 0.0110 Classification loss 0.5250 AP 0.6000 AR 0.2000
Epoch 458 batch 00002: Loss 0.3789 Regression loss 0.0106 Classification loss 0.3683 AP 0.4500 AR 0.3167
Epoch 458 batch 00003: Loss 0.5830 Regression loss 0.0204 Classification loss 0.5626 AP 0.9000 AR 0.0400
Epoch 458 batch 00004: Loss 0.2484 Regression loss 0.0081 Classification loss 0.2402 AP 0.4067 AR 0.3500
Epoch 458 batch 00005: Loss 0.4282 Regression loss 0.0096 Classification loss 0.4185 AP 0.5500 AR 0.0900
Epoch 458 batch 00006: Loss 0.4908 Regression loss 0.0177 Classification loss 0.4731 AP 1.0000 AR 0.0000
Epoch 458 batch 00007: Loss 0.4875 Regression loss 0.0147 Classification loss 0.4728 AP 0.2000 AR 0.1667
Epoch 458 batch 00008: Loss 0.5581 Regression loss 0.0165 Classification loss 0.5416 AP 0.2000 AR 0.0000
Epoch 458 batch 00009: Loss 0.4795 Regression loss 0.0143 Classification loss 0.4652 AP 0.9000 AR 0.2400
Epoch 458 batch 00010: Loss 0.3438 Regression loss 0.0113 Classification loss 0.3325 AP 0.6000 AR 0.2467
Epoch 459 batch 00001: Loss 0.6510 Regression loss 0.0097 Classification loss 0.6414 AP 0.5000 AR 0.0500
Epoch 459 batch 00002: Loss 0.3812 Regression loss 0.0152 Classification loss 0.3660 AP 0.8667 AR 0.0900
Epoch 459 batch 00003: Loss 0.4604 Regression loss 0.0173 Classification loss 0.4431 AP 0.6000 AR 0.1167
Epoch 459 batch 00004: Loss 0.4890 Regression loss 0.0139 Classification loss 0.4751 AP 0.7333 AR 0.3400
Epoch 459 batch 00005: Loss 0.5488 Regression loss 0.0168 Classification loss 0.5320 AP 0.9000 AR 0.1467
Epoch 459 batch 00006: Loss 0.5999 Regression loss 0.0118 Classification loss 0.5881 AP 0.7000 AR 0.1000
Epoch 459 batch 00007: Loss 0.3013 Regression loss 0.0128 Classification loss 0.2885 AP 0.5333 AR 0.2800
Epoch 459 batch 00008: Loss 0.3878 Regression loss 0.0131 Classification loss 0.3747 AP 0.2167 AR 0.1567
Epoch 459 batch 00009: Loss 0.4471 Regression loss 0.0140 Classification loss 0.4331 AP 0.8000 AR 0.3400
Epoch 459 batch 00010: Loss 0.4451 Regression loss 0.0128 Classification loss 0.4324 AP 0.3000 AR 0.1000
Epoch 460 batch 00001: Loss 0.4425 Regression loss 0.0163 Classification loss 0.4261 AP 0.7333 AR 0.1600
Epoch 460 batch 00002: Loss 0.4606 Regression loss 0.0195 Classification loss 0.4410 AP 0.7000 AR 0.0667
Epoch 460 batch 00003: Loss 0.3433 Regression loss 0.0091 Classification loss 0.3342 AP 0.3667 AR 0.1667
Epoch 460 batch 00004: Loss 0.5252 Regression loss 0.0195 Classification loss 0.5057 AP 0.7000 AR 0.1000
Epoch 460 batch 00005: Loss 0.4814 Regression loss 0.0112 Classification loss 0.4702 AP 0.4000 AR 0.1167
Epoch 460 batch 00006: Loss 0.4368 Regression loss 0.0102 Classification loss 0.4267 AP 0.5000 AR 0.1000
Epoch 460 batch 00007: Loss 0.4203 Regression loss 0.0093 Classification loss 0.4110 AP 0.7000 AR 0.3500
Epoch 460 batch 00008: Loss 0.4114 Regression loss 0.0080 Classification loss 0.4034 AP 0.5500 AR 0.3000
Epoch 460 batch 00009: Loss 0.3806 Regression loss 0.0115 Classification loss 0.3691 AP 0.7167 AR 0.2900
Epoch 460 batch 00010: Loss 0.5776 Regression loss 0.0145 Classification loss 0.5631 AP 0.6000 AR 0.0000
Epoch 461 batch 00001: Loss 0.4294 Regression loss 0.0095 Classification loss 0.4199 AP 0.6000 AR 0.3667
Epoch 461 batch 00002: Loss 0.3087 Regression loss 0.0075 Classification loss 0.3012 AP 0.7500 AR 0.1167
Epoch 461 batch 00003: Loss 0.2963 Regression loss 0.0106 Classification loss 0.2857 AP 0.5000 AR 0.2800
Epoch 461 batch 00004: Loss 0.5426 Regression loss 0.0191 Classification loss 0.5236 AP 0.4000 AR 0.0000
Epoch 461 batch 00005: Loss 0.4799 Regression loss 0.0125 Classification loss 0.4674 AP 0.6000 AR 0.1400
Epoch 461 batch 00006: Loss 0.5112 Regression loss 0.0147 Classification loss 0.4964 AP 0.4000 AR 0.1400
Epoch 461 batch 00007: Loss 0.4148 Regression loss 0.0116 Classification loss 0.4031 AP 0.4500 AR 0.0500
Epoch 461 batch 00008: Loss 0.4245 Regression loss 0.0105 Classification loss 0.4140 AP 0.7000 AR 0.2500
Epoch 461 batch 00009: Loss 0.3565 Regression loss 0.0145 Classification loss 0.3420 AP 0.6000 AR 0.1667
Epoch 461 batch 00010: Loss 0.5296 Regression loss 0.0128 Classification loss 0.5168 AP 0.7333 AR 0.0900
Epoch 462 batch 00001: Loss 0.5020 Regression loss 0.0128 Classification loss 0.4892 AP 0.4500 AR 0.0400
Epoch 462 batch 00002: Loss 0.4551 Regression loss 0.0129 Classification loss 0.4422 AP 0.6000 AR 0.0000
Epoch 462 batch 00003: Loss 0.3400 Regression loss 0.0120 Classification loss 0.3281 AP 0.7000 AR 0.1500
Epoch 462 batch 00004: Loss 0.5106 Regression loss 0.0105 Classification loss 0.5002 AP 0.2667 AR 0.0400
Epoch 462 batch 00005: Loss 0.4182 Regression loss 0.0140 Classification loss 0.4042 AP 0.7000 AR 0.3667
Epoch 462 batch 00006: Loss 0.2279 Regression loss 0.0088 Classification loss 0.2191 AP 1.0000 AR 0.4800
Epoch 462 batch 00007: Loss 0.6552 Regression loss 0.0199 Classification loss 0.6353 AP 0.9000 AR 0.0667
Epoch 462 batch 00008: Loss 0.4757 Regression loss 0.0124 Classification loss 0.4633 AP 0.4667 AR 0.1900
Epoch 462 batch 00009: Loss 0.4991 Regression loss 0.0161 Classification loss 0.4830 AP 0.8000 AR 0.2200
Epoch 462 batch 00010: Loss 0.3611 Regression loss 0.0081 Classification loss 0.3530 AP 0.2667 AR 0.1667
Epoch 463 batch 00001: Loss 0.4118 Regression loss 0.0145 Classification loss 0.3973 AP 0.9000 AR 0.2900
Epoch 463 batch 00002: Loss 0.3773 Regression loss 0.0121 Classification loss 0.3652 AP 0.3000 AR 0.1000
Epoch 463 batch 00003: Loss 0.4752 Regression loss 0.0115 Classification loss 0.4638 AP 0.3000 AR 0.0400
Epoch 463 batch 00004: Loss 0.4315 Regression loss 0.0106 Classification loss 0.4209 AP 0.5667 AR 0.1667
Epoch 463 batch 00005: Loss 0.6277 Regression loss 0.0088 Classification loss 0.6188 AP 0.7667 AR 0.0900
Epoch 463 batch 00006: Loss 0.4948 Regression loss 0.0167 Classification loss 0.4781 AP 0.6667 AR 0.0400
Epoch 463 batch 00007: Loss 0.4048 Regression loss 0.0078 Classification loss 0.3970 AP 0.6500 AR 0.1667
Epoch 463 batch 00008: Loss 0.3713 Regression loss 0.0141 Classification loss 0.3573 AP 0.5667 AR 0.3500
Epoch 463 batch 00009: Loss 0.4319 Regression loss 0.0135 Classification loss 0.4184 AP 0.7333 AR 0.2800
Epoch 463 batch 00010: Loss 0.6003 Regression loss 0.0191 Classification loss 0.5812 AP 0.6000 AR 0.1667
Epoch 464 batch 00001: Loss 0.3788 Regression loss 0.0085 Classification loss 0.3703 AP 0.5500 AR 0.1167
Epoch 464 batch 00002: Loss 0.5726 Regression loss 0.0121 Classification loss 0.5606 AP 0.8000 AR 0.2000
Epoch 464 batch 00003: Loss 0.4735 Regression loss 0.0103 Classification loss 0.4632 AP 0.6000 AR 0.2500
Epoch 464 batch 00004: Loss 0.3372 Regression loss 0.0120 Classification loss 0.3252 AP 0.5333 AR 0.3600
Epoch 464 batch 00005: Loss 0.6333 Regression loss 0.0146 Classification loss 0.6187 AP 0.6000 AR 0.1167
Epoch 464 batch 00006: Loss 0.3144 Regression loss 0.0147 Classification loss 0.2997 AP 0.6000 AR 0.3400
Epoch 464 batch 00007: Loss 0.5143 Regression loss 0.0103 Classification loss 0.5039 AP 0.5667 AR 0.1500
Epoch 464 batch 00008: Loss 0.3296 Regression loss 0.0130 Classification loss 0.3166 AP 0.6667 AR 0.0900
Epoch 464 batch 00009: Loss 0.5008 Regression loss 0.0147 Classification loss 0.4861 AP 0.5000 AR 0.0667
Epoch 464 batch 00010: Loss 0.4178 Regression loss 0.0159 Classification loss 0.4019 AP 0.7000 AR 0.0400
Epoch 465 batch 00001: Loss 0.7448 Regression loss 0.0181 Classification loss 0.7267 AP 0.8000 AR 0.0000
Epoch 465 batch 00002: Loss 0.2537 Regression loss 0.0104 Classification loss 0.2433 AP 0.5333 AR 0.2967
Epoch 465 batch 00003: Loss 0.5974 Regression loss 0.0134 Classification loss 0.5841 AP 0.6000 AR 0.0000
Epoch 465 batch 00004: Loss 0.4073 Regression loss 0.0133 Classification loss 0.3940 AP 0.7167 AR 0.1700
Epoch 465 batch 00005: Loss 0.3681 Regression loss 0.0112 Classification loss 0.3569 AP 0.8400 AR 0.0500
Epoch 465 batch 00006: Loss 0.3708 Regression loss 0.0204 Classification loss 0.3504 AP 0.7333 AR 0.0800
Epoch 465 batch 00007: Loss 0.3477 Regression loss 0.0113 Classification loss 0.3364 AP 0.5000 AR 0.2667
Epoch 465 batch 00008: Loss 0.5157 Regression loss 0.0138 Classification loss 0.5019 AP 0.5000 AR 0.2667
Epoch 465 batch 00009: Loss 0.5462 Regression loss 0.0105 Classification loss 0.5357 AP 0.4000 AR 0.2000
Epoch 465 batch 00010: Loss 0.5018 Regression loss 0.0118 Classification loss 0.4900 AP 0.4000 AR 0.1500
Epoch 466 batch 00001: Loss 0.3697 Regression loss 0.0132 Classification loss 0.3565 AP 0.6500 AR 0.2900
Epoch 466 batch 00002: Loss 0.6173 Regression loss 0.0182 Classification loss 0.5991 AP 0.8000 AR 0.0000
Epoch 466 batch 00003: Loss 0.4863 Regression loss 0.0133 Classification loss 0.4730 AP 0.6000 AR 0.0800
Epoch 466 batch 00004: Loss 0.4257 Regression loss 0.0093 Classification loss 0.4164 AP 0.4667 AR 0.3667
Epoch 466 batch 00005: Loss 0.5204 Regression loss 0.0139 Classification loss 0.5065 AP 0.7000 AR 0.1000
Epoch 466 batch 00006: Loss 0.3532 Regression loss 0.0097 Classification loss 0.3435 AP 0.6000 AR 0.2167
Epoch 466 batch 00007: Loss 0.4361 Regression loss 0.0122 Classification loss 0.4239 AP 0.6000 AR 0.0800
Epoch 466 batch 00008: Loss 0.4980 Regression loss 0.0163 Classification loss 0.4816 AP 0.3500 AR 0.1400
Epoch 466 batch 00009: Loss 0.4865 Regression loss 0.0141 Classification loss 0.4724 AP 0.5000 AR 0.1000
Epoch 466 batch 00010: Loss 0.5281 Regression loss 0.0153 Classification loss 0.5128 AP 0.7000 AR 0.2667
Epoch 467 batch 00001: Loss 0.4864 Regression loss 0.0143 Classification loss 0.4721 AP 0.5667 AR 0.1400
Epoch 467 batch 00002: Loss 0.3986 Regression loss 0.0136 Classification loss 0.3850 AP 0.5400 AR 0.1567
Epoch 467 batch 00003: Loss 0.4226 Regression loss 0.0150 Classification loss 0.4076 AP 0.3067 AR 0.2567
Epoch 467 batch 00004: Loss 0.2741 Regression loss 0.0116 Classification loss 0.2626 AP 0.4000 AR 0.2000
Epoch 467 batch 00005: Loss 0.5491 Regression loss 0.0125 Classification loss 0.5366 AP 0.4500 AR 0.0500
Epoch 467 batch 00006: Loss 0.6367 Regression loss 0.0084 Classification loss 0.6283 AP 0.7000 AR 0.0500
Epoch 467 batch 00007: Loss 0.3917 Regression loss 0.0147 Classification loss 0.3770 AP 1.0000 AR 0.4400
Epoch 467 batch 00008: Loss 0.3259 Regression loss 0.0112 Classification loss 0.3147 AP 0.8000 AR 0.2467
Epoch 467 batch 00009: Loss 0.6238 Regression loss 0.0149 Classification loss 0.6089 AP 0.6000 AR 0.0000
Epoch 467 batch 00010: Loss 0.4356 Regression loss 0.0166 Classification loss 0.4191 AP 0.7500 AR 0.1500
Epoch 468 batch 00001: Loss 0.5135 Regression loss 0.0105 Classification loss 0.5029 AP 0.9000 AR 0.0500
Epoch 468 batch 00002: Loss 0.5851 Regression loss 0.0174 Classification loss 0.5678 AP 0.6400 AR 0.0400
Epoch 468 batch 00003: Loss 0.6005 Regression loss 0.0138 Classification loss 0.5867 AP 0.4667 AR 0.1000
Epoch 468 batch 00004: Loss 0.3679 Regression loss 0.0159 Classification loss 0.3521 AP 0.5000 AR 0.2400
Epoch 468 batch 00005: Loss 0.2879 Regression loss 0.0124 Classification loss 0.2755 AP 0.5333 AR 0.3367
Epoch 468 batch 00006: Loss 0.4897 Regression loss 0.0111 Classification loss 0.4786 AP 0.6000 AR 0.2000
Epoch 468 batch 00007: Loss 0.3980 Regression loss 0.0120 Classification loss 0.3860 AP 0.6000 AR 0.3000
Epoch 468 batch 00008: Loss 0.3852 Regression loss 0.0149 Classification loss 0.3703 AP 0.5500 AR 0.1067
Epoch 468 batch 00009: Loss 0.5104 Regression loss 0.0110 Classification loss 0.4994 AP 0.4000 AR 0.0000
Epoch 468 batch 00010: Loss 0.4636 Regression loss 0.0112 Classification loss 0.4524 AP 0.5500 AR 0.2000
Epoch 469 batch 00001: Loss 0.3518 Regression loss 0.0106 Classification loss 0.3412 AP 0.4667 AR 0.2500
Epoch 469 batch 00002: Loss 0.3764 Regression loss 0.0144 Classification loss 0.3619 AP 0.5000 AR 0.0900
Epoch 469 batch 00003: Loss 0.3817 Regression loss 0.0127 Classification loss 0.3690 AP 0.4000 AR 0.0000
Epoch 469 batch 00004: Loss 0.4731 Regression loss 0.0093 Classification loss 0.4638 AP 0.6400 AR 0.0500
Epoch 469 batch 00005: Loss 0.5753 Regression loss 0.0135 Classification loss 0.5618 AP 0.5667 AR 0.1067
Epoch 469 batch 00006: Loss 0.3631 Regression loss 0.0112 Classification loss 0.3519 AP 0.5667 AR 0.2467
Epoch 469 batch 00007: Loss 0.4267 Regression loss 0.0166 Classification loss 0.4101 AP 0.9000 AR 0.1467
Epoch 469 batch 00008: Loss 0.3544 Regression loss 0.0150 Classification loss 0.3393 AP 0.8000 AR 0.0000
Epoch 469 batch 00009: Loss 0.5324 Regression loss 0.0126 Classification loss 0.5197 AP 0.3000 AR 0.3500
Epoch 469 batch 00010: Loss 0.5229 Regression loss 0.0175 Classification loss 0.5054 AP 0.6000 AR 0.2000
Epoch 470 batch 00001: Loss 0.3751 Regression loss 0.0124 Classification loss 0.3627 AP 0.5000 AR 0.1000
Epoch 470 batch 00002: Loss 0.4298 Regression loss 0.0131 Classification loss 0.4167 AP 0.6167 AR 0.2700
Epoch 470 batch 00003: Loss 0.4188 Regression loss 0.0103 Classification loss 0.4085 AP 0.0000 AR 0.0000
Epoch 470 batch 00004: Loss 0.4432 Regression loss 0.0138 Classification loss 0.4295 AP 0.6667 AR 0.2500
Epoch 470 batch 00005: Loss 0.2244 Regression loss 0.0107 Classification loss 0.2137 AP 0.7000 AR 0.3067
Epoch 470 batch 00006: Loss 0.4026 Regression loss 0.0122 Classification loss 0.3904 AP 0.6000 AR 0.1400
Epoch 470 batch 00007: Loss 0.3883 Regression loss 0.0116 Classification loss 0.3767 AP 0.8000 AR 0.2500
Epoch 470 batch 00008: Loss 0.5630 Regression loss 0.0134 Classification loss 0.5496 AP 0.8000 AR 0.1167
Epoch 470 batch 00009: Loss 0.6030 Regression loss 0.0151 Classification loss 0.5879 AP 0.7000 AR 0.0667
Epoch 470 batch 00010: Loss 0.5470 Regression loss 0.0143 Classification loss 0.5327 AP 0.5667 AR 0.1400
Epoch 471 batch 00001: Loss 0.5769 Regression loss 0.0137 Classification loss 0.5632 AP 0.7000 AR 0.1000
Epoch 471 batch 00002: Loss 0.3831 Regression loss 0.0134 Classification loss 0.3697 AP 0.4000 AR 0.0000
Epoch 471 batch 00003: Loss 0.4699 Regression loss 0.0138 Classification loss 0.4561 AP 0.5400 AR 0.0900
Epoch 471 batch 00004: Loss 0.3255 Regression loss 0.0121 Classification loss 0.3134 AP 0.5500 AR 0.0900
Epoch 471 batch 00005: Loss 0.6012 Regression loss 0.0122 Classification loss 0.5889 AP 0.7000 AR 0.5000
Epoch 471 batch 00006: Loss 0.6974 Regression loss 0.0101 Classification loss 0.6873 AP 0.4667 AR 0.0500
Epoch 471 batch 00007: Loss 0.4196 Regression loss 0.0158 Classification loss 0.4038 AP 0.8667 AR 0.0900
Epoch 471 batch 00008: Loss 0.4797 Regression loss 0.0119 Classification loss 0.4678 AP 0.9000 AR 0.2400
Epoch 471 batch 00009: Loss 0.5723 Regression loss 0.0121 Classification loss 0.5601 AP 0.3000 AR 0.2333
Epoch 471 batch 00010: Loss 0.2957 Regression loss 0.0082 Classification loss 0.2875 AP 0.6000 AR 0.2567
Epoch 472 batch 00001: Loss 0.3928 Regression loss 0.0121 Classification loss 0.3807 AP 0.5000 AR 0.1000
Epoch 472 batch 00002: Loss 0.4289 Regression loss 0.0106 Classification loss 0.4183 AP 0.4500 AR 0.2000
Epoch 472 batch 00003: Loss 0.4649 Regression loss 0.0131 Classification loss 0.4518 AP 1.0000 AR 0.2800
Epoch 472 batch 00004: Loss 0.4936 Regression loss 0.0172 Classification loss 0.4764 AP 0.5667 AR 0.1400
Epoch 472 batch 00005: Loss 0.5439 Regression loss 0.0139 Classification loss 0.5300 AP 0.8000 AR 0.1967
Epoch 472 batch 00006: Loss 0.3549 Regression loss 0.0111 Classification loss 0.3437 AP 0.5000 AR 0.0667
Epoch 472 batch 00007: Loss 0.4870 Regression loss 0.0158 Classification loss 0.4712 AP 0.7500 AR 0.1067
Epoch 472 batch 00008: Loss 0.2362 Regression loss 0.0118 Classification loss 0.2244 AP 0.6500 AR 0.2900
Epoch 472 batch 00009: Loss 0.4732 Regression loss 0.0094 Classification loss 0.4638 AP 0.6000 AR 0.0500
Epoch 472 batch 00010: Loss 0.5007 Regression loss 0.0095 Classification loss 0.4913 AP 0.2333 AR 0.3400
Epoch 473 batch 00001: Loss 0.5060 Regression loss 0.0091 Classification loss 0.4970 AP 0.5000 AR 0.0500
Epoch 473 batch 00002: Loss 0.4626 Regression loss 0.0089 Classification loss 0.4537 AP 0.4667 AR 0.2667
Epoch 473 batch 00003: Loss 0.4715 Regression loss 0.0117 Classification loss 0.4598 AP 0.4900 AR 0.0900
Epoch 473 batch 00004: Loss 0.6304 Regression loss 0.0189 Classification loss 0.6115 AP 0.9000 AR 0.0400
Epoch 473 batch 00005: Loss 0.3171 Regression loss 0.0131 Classification loss 0.3040 AP 0.7667 AR 0.2200
Epoch 473 batch 00006: Loss 0.3078 Regression loss 0.0149 Classification loss 0.2929 AP 0.7000 AR 0.2000
Epoch 473 batch 00007: Loss 0.6878 Regression loss 0.0072 Classification loss 0.6806 AP 0.5000 AR 0.2500
Epoch 473 batch 00008: Loss 0.3460 Regression loss 0.0120 Classification loss 0.3340 AP 0.4000 AR 0.0900
Epoch 473 batch 00009: Loss 0.4966 Regression loss 0.0198 Classification loss 0.4768 AP 0.7000 AR 0.1167
Epoch 473 batch 00010: Loss 0.5024 Regression loss 0.0104 Classification loss 0.4920 AP 0.3000 AR 0.0667
Epoch 474 batch 00001: Loss 0.4421 Regression loss 0.0136 Classification loss 0.4284 AP 0.7000 AR 0.2400
Epoch 474 batch 00002: Loss 0.3857 Regression loss 0.0092 Classification loss 0.3765 AP 0.2500 AR 0.1400
Epoch 474 batch 00003: Loss 0.3883 Regression loss 0.0145 Classification loss 0.3738 AP 0.9000 AR 0.0400
Epoch 474 batch 00004: Loss 0.5009 Regression loss 0.0164 Classification loss 0.4846 AP 0.3667 AR 0.1067
Epoch 474 batch 00005: Loss 0.4010 Regression loss 0.0141 Classification loss 0.3869 AP 0.6667 AR 0.0400
Epoch 474 batch 00006: Loss 0.3851 Regression loss 0.0101 Classification loss 0.3751 AP 0.7667 AR 0.4167
Epoch 474 batch 00007: Loss 0.6559 Regression loss 0.0083 Classification loss 0.6476 AP 0.6000 AR 0.1500
Epoch 474 batch 00008: Loss 0.4598 Regression loss 0.0161 Classification loss 0.4437 AP 0.6000 AR 0.2000
Epoch 474 batch 00009: Loss 0.4471 Regression loss 0.0124 Classification loss 0.4347 AP 0.7000 AR 0.0667
Epoch 474 batch 00010: Loss 0.3510 Regression loss 0.0098 Classification loss 0.3412 AP 0.3500 AR 0.2500
Epoch 475 batch 00001: Loss 0.3156 Regression loss 0.0115 Classification loss 0.3041 AP 0.4667 AR 0.1200
Epoch 475 batch 00002: Loss 0.5674 Regression loss 0.0134 Classification loss 0.5540 AP 0.6000 AR 0.2667
Epoch 475 batch 00003: Loss 0.3534 Regression loss 0.0115 Classification loss 0.3420 AP 0.8000 AR 0.1667
Epoch 475 batch 00004: Loss 0.5535 Regression loss 0.0104 Classification loss 0.5431 AP 0.6000 AR 0.0000
Epoch 475 batch 00005: Loss 0.3813 Regression loss 0.0117 Classification loss 0.3696 AP 0.6000 AR 0.3167
Epoch 475 batch 00006: Loss 0.2889 Regression loss 0.0107 Classification loss 0.2782 AP 0.6500 AR 0.1000
Epoch 475 batch 00007: Loss 0.4901 Regression loss 0.0142 Classification loss 0.4759 AP 0.5667 AR 0.1400
Epoch 475 batch 00008: Loss 0.4081 Regression loss 0.0113 Classification loss 0.3968 AP 0.6067 AR 0.3400
Epoch 475 batch 00009: Loss 0.4229 Regression loss 0.0127 Classification loss 0.4102 AP 0.3333 AR 0.0800
Epoch 475 batch 00010: Loss 0.6511 Regression loss 0.0152 Classification loss 0.6359 AP 0.6500 AR 0.0400
Epoch 476 batch 00001: Loss 0.4897 Regression loss 0.0101 Classification loss 0.4796 AP 0.6667 AR 0.1000
Epoch 476 batch 00002: Loss 0.4144 Regression loss 0.0117 Classification loss 0.4027 AP 0.4000 AR 0.3667
Epoch 476 batch 00003: Loss 0.3460 Regression loss 0.0113 Classification loss 0.3347 AP 0.4000 AR 0.0000
Epoch 476 batch 00004: Loss 0.5367 Regression loss 0.0130 Classification loss 0.5237 AP 0.8000 AR 0.2000
Epoch 476 batch 00005: Loss 0.4845 Regression loss 0.0116 Classification loss 0.4729 AP 0.4167 AR 0.1900
Epoch 476 batch 00006: Loss 0.5055 Regression loss 0.0174 Classification loss 0.4880 AP 0.7000 AR 0.0400
Epoch 476 batch 00007: Loss 0.3122 Regression loss 0.0130 Classification loss 0.2992 AP 0.8000 AR 0.2200
Epoch 476 batch 00008: Loss 0.4126 Regression loss 0.0093 Classification loss 0.4033 AP 0.5000 AR 0.1667
Epoch 476 batch 00009: Loss 0.5183 Regression loss 0.0127 Classification loss 0.5056 AP 0.4667 AR 0.0900
Epoch 476 batch 00010: Loss 0.4544 Regression loss 0.0171 Classification loss 0.4373 AP 0.7000 AR 0.0667
Epoch 477 batch 00001: Loss 0.4669 Regression loss 0.0143 Classification loss 0.4526 AP 0.5333 AR 0.3567
Epoch 477 batch 00002: Loss 0.4669 Regression loss 0.0135 Classification loss 0.4534 AP 0.6000 AR 0.0000
Epoch 477 batch 00003: Loss 0.6965 Regression loss 0.0132 Classification loss 0.6833 AP 0.7000 AR 0.1000
Epoch 477 batch 00004: Loss 0.3929 Regression loss 0.0084 Classification loss 0.3845 AP 0.6000 AR 0.1500
Epoch 477 batch 00005: Loss 0.5486 Regression loss 0.0146 Classification loss 0.5340 AP 0.5500 AR 0.0900
Epoch 477 batch 00006: Loss 0.5249 Regression loss 0.0110 Classification loss 0.5139 AP 0.5067 AR 0.3400
Epoch 477 batch 00007: Loss 0.5298 Regression loss 0.0173 Classification loss 0.5125 AP 0.7000 AR 0.1000
Epoch 477 batch 00008: Loss 0.2525 Regression loss 0.0081 Classification loss 0.2444 AP 0.4000 AR 0.2133
Epoch 477 batch 00009: Loss 0.4012 Regression loss 0.0115 Classification loss 0.3897 AP 0.5667 AR 0.0900
Epoch 477 batch 00010: Loss 0.2925 Regression loss 0.0110 Classification loss 0.2815 AP 0.7000 AR 0.2500
Epoch 478 batch 00001: Loss 0.3251 Regression loss 0.0104 Classification loss 0.3147 AP 0.4000 AR 0.0000
Epoch 478 batch 00002: Loss 0.4204 Regression loss 0.0094 Classification loss 0.4110 AP 0.5667 AR 0.1567
Epoch 478 batch 00003: Loss 0.4396 Regression loss 0.0095 Classification loss 0.4300 AP 0.8000 AR 0.3500
Epoch 478 batch 00004: Loss 0.4409 Regression loss 0.0134 Classification loss 0.4275 AP 0.7667 AR 0.1967
Epoch 478 batch 00005: Loss 0.4690 Regression loss 0.0091 Classification loss 0.4599 AP 0.8000 AR 0.1167
Epoch 478 batch 00006: Loss 0.4700 Regression loss 0.0148 Classification loss 0.4552 AP 0.8500 AR 0.1300
Epoch 478 batch 00007: Loss 0.3234 Regression loss 0.0113 Classification loss 0.3121 AP 0.5000 AR 0.4000
Epoch 478 batch 00008: Loss 0.5466 Regression loss 0.0143 Classification loss 0.5323 AP 0.6000 AR 0.0000
Epoch 478 batch 00009: Loss 0.4576 Regression loss 0.0133 Classification loss 0.4443 AP 0.4000 AR 0.3400
Epoch 478 batch 00010: Loss 0.5204 Regression loss 0.0159 Classification loss 0.5045 AP 0.4000 AR 0.0000
Epoch 479 batch 00001: Loss 0.5064 Regression loss 0.0116 Classification loss 0.4948 AP 0.4500 AR 0.1800
Epoch 479 batch 00002: Loss 0.6034 Regression loss 0.0146 Classification loss 0.5888 AP 0.9000 AR 0.2500
Epoch 479 batch 00003: Loss 0.3452 Regression loss 0.0108 Classification loss 0.3344 AP 0.5667 AR 0.1567
Epoch 479 batch 00004: Loss 0.4175 Regression loss 0.0115 Classification loss 0.4059 AP 0.2667 AR 0.3000
Epoch 479 batch 00005: Loss 0.6292 Regression loss 0.0158 Classification loss 0.6134 AP 0.6000 AR 0.0000
Epoch 479 batch 00006: Loss 0.4115 Regression loss 0.0145 Classification loss 0.3970 AP 0.8000 AR 0.3000
Epoch 479 batch 00007: Loss 0.3809 Regression loss 0.0119 Classification loss 0.3689 AP 0.2667 AR 0.1467
Epoch 479 batch 00008: Loss 0.5599 Regression loss 0.0180 Classification loss 0.5419 AP 0.7000 AR 0.1000
Epoch 479 batch 00009: Loss 0.4707 Regression loss 0.0136 Classification loss 0.4571 AP 0.5000 AR 0.1000
Epoch 479 batch 00010: Loss 0.3918 Regression loss 0.0098 Classification loss 0.3821 AP 0.7400 AR 0.0900
Epoch 480 batch 00001: Loss 0.4745 Regression loss 0.0131 Classification loss 0.4613 AP 0.7000 AR 0.3500
Epoch 480 batch 00002: Loss 0.4924 Regression loss 0.0152 Classification loss 0.4773 AP 0.5667 AR 0.1067
Epoch 480 batch 00003: Loss 0.3739 Regression loss 0.0134 Classification loss 0.3605 AP 0.4900 AR 0.1800
Epoch 480 batch 00004: Loss 0.3077 Regression loss 0.0131 Classification loss 0.2946 AP 0.4667 AR 0.3000
Epoch 480 batch 00005: Loss 0.5193 Regression loss 0.0089 Classification loss 0.5104 AP 0.6667 AR 0.1567
Epoch 480 batch 00006: Loss 0.3535 Regression loss 0.0143 Classification loss 0.3392 AP 0.7000 AR 0.1000
Epoch 480 batch 00007: Loss 0.4571 Regression loss 0.0118 Classification loss 0.4453 AP 0.7667 AR 0.1167
Epoch 480 batch 00008: Loss 0.3647 Regression loss 0.0158 Classification loss 0.3489 AP 0.5500 AR 0.3400
Epoch 480 batch 00009: Loss 0.5222 Regression loss 0.0142 Classification loss 0.5080 AP 0.6000 AR 0.0800
Epoch 480 batch 00010: Loss 0.6223 Regression loss 0.0165 Classification loss 0.6057 AP 0.6000 AR 0.0000
Epoch 481 batch 00001: Loss 0.5181 Regression loss 0.0154 Classification loss 0.5028 AP 0.7000 AR 0.0667
Epoch 481 batch 00002: Loss 0.2849 Regression loss 0.0127 Classification loss 0.2722 AP 0.3400 AR 0.1400
Epoch 481 batch 00003: Loss 0.3684 Regression loss 0.0131 Classification loss 0.3553 AP 0.4667 AR 0.0400
Epoch 481 batch 00004: Loss 0.3634 Regression loss 0.0117 Classification loss 0.3517 AP 0.8000 AR 0.0500
Epoch 481 batch 00005: Loss 0.2904 Regression loss 0.0098 Classification loss 0.2806 AP 0.4667 AR 0.2167
Epoch 481 batch 00006: Loss 0.5094 Regression loss 0.0160 Classification loss 0.4934 AP 0.4500 AR 0.4067
Epoch 481 batch 00007: Loss 0.4549 Regression loss 0.0158 Classification loss 0.4391 AP 0.6000 AR 0.2000
Epoch 481 batch 00008: Loss 0.5185 Regression loss 0.0141 Classification loss 0.5044 AP 0.3667 AR 0.2500
Epoch 481 batch 00009: Loss 0.5977 Regression loss 0.0176 Classification loss 0.5801 AP 0.6500 AR 0.0400
Epoch 481 batch 00010: Loss 0.7182 Regression loss 0.0166 Classification loss 0.7017 AP 0.8667 AR 0.2400
Epoch 482 batch 00001: Loss 0.5966 Regression loss 0.0165 Classification loss 0.5801 AP 1.0000 AR 0.0000
Epoch 482 batch 00002: Loss 0.4713 Regression loss 0.0199 Classification loss 0.4513 AP 0.4667 AR 0.0400
Epoch 482 batch 00003: Loss 0.5212 Regression loss 0.0128 Classification loss 0.5084 AP 0.5000 AR 0.1000
Epoch 482 batch 00004: Loss 0.4779 Regression loss 0.0126 Classification loss 0.4653 AP 0.0000 AR 0.0000
Epoch 482 batch 00005: Loss 0.3045 Regression loss 0.0123 Classification loss 0.2922 AP 0.5667 AR 0.4133
Epoch 482 batch 00006: Loss 0.6643 Regression loss 0.0181 Classification loss 0.6462 AP 0.8000 AR 0.2000
Epoch 482 batch 00007: Loss 0.3334 Regression loss 0.0164 Classification loss 0.3170 AP 0.7000 AR 0.3500
Epoch 482 batch 00008: Loss 0.3397 Regression loss 0.0133 Classification loss 0.3264 AP 0.3500 AR 0.0900
Epoch 482 batch 00009: Loss 0.3585 Regression loss 0.0122 Classification loss 0.3463 AP 0.2500 AR 0.0500
Epoch 482 batch 00010: Loss 0.6556 Regression loss 0.0151 Classification loss 0.6404 AP 0.7000 AR 0.0667
Epoch 483 batch 00001: Loss 0.4441 Regression loss 0.0172 Classification loss 0.4269 AP 0.4667 AR 0.3000
Epoch 483 batch 00002: Loss 0.6071 Regression loss 0.0211 Classification loss 0.5860 AP 0.9000 AR 0.2000
Epoch 483 batch 00003: Loss 0.4543 Regression loss 0.0115 Classification loss 0.4428 AP 0.8000 AR 0.2000
Epoch 483 batch 00004: Loss 0.4946 Regression loss 0.0150 Classification loss 0.4796 AP 0.7333 AR 0.2200
Epoch 483 batch 00005: Loss 0.5924 Regression loss 0.0168 Classification loss 0.5757 AP 0.6000 AR 0.1333
Epoch 483 batch 00006: Loss 0.3505 Regression loss 0.0122 Classification loss 0.3383 AP 0.9000 AR 0.1300
Epoch 483 batch 00007: Loss 0.4350 Regression loss 0.0166 Classification loss 0.4184 AP 0.6000 AR 0.0500
Epoch 483 batch 00008: Loss 0.3671 Regression loss 0.0104 Classification loss 0.3566 AP 0.1000 AR 0.0667
Epoch 483 batch 00009: Loss 0.4118 Regression loss 0.0162 Classification loss 0.3956 AP 0.5400 AR 0.1500
Epoch 483 batch 00010: Loss 0.3744 Regression loss 0.0085 Classification loss 0.3659 AP 0.2400 AR 0.1300
Epoch 484 batch 00001: Loss 0.3374 Regression loss 0.0141 Classification loss 0.3233 AP 0.3500 AR 0.0900
Epoch 484 batch 00002: Loss 0.5201 Regression loss 0.0141 Classification loss 0.5060 AP 0.2500 AR 0.0400
Epoch 484 batch 00003: Loss 0.5154 Regression loss 0.0154 Classification loss 0.5000 AP 0.8000 AR 0.0500
Epoch 484 batch 00004: Loss 0.4645 Regression loss 0.0145 Classification loss 0.4501 AP 0.5000 AR 0.0400
Epoch 484 batch 00005: Loss 0.5570 Regression loss 0.0155 Classification loss 0.5415 AP 0.7667 AR 0.2000
Epoch 484 batch 00006: Loss 0.4415 Regression loss 0.0108 Classification loss 0.4307 AP 0.6667 AR 0.0667
Epoch 484 batch 00007: Loss 0.3682 Regression loss 0.0123 Classification loss 0.3559 AP 0.6400 AR 0.2500
Epoch 484 batch 00008: Loss 0.3893 Regression loss 0.0115 Classification loss 0.3778 AP 0.5000 AR 0.3000
Epoch 484 batch 00009: Loss 0.3667 Regression loss 0.0123 Classification loss 0.3544 AP 0.7667 AR 0.1600
Epoch 484 batch 00010: Loss 0.4692 Regression loss 0.0156 Classification loss 0.4536 AP 0.5000 AR 0.3000
Epoch 485 batch 00001: Loss 0.5671 Regression loss 0.0156 Classification loss 0.5515 AP 1.0000 AR 0.2000
Epoch 485 batch 00002: Loss 0.4195 Regression loss 0.0145 Classification loss 0.4050 AP 0.8000 AR 0.0500
Epoch 485 batch 00003: Loss 0.4727 Regression loss 0.0152 Classification loss 0.4575 AP 0.4167 AR 0.1567
Epoch 485 batch 00004: Loss 0.5641 Regression loss 0.0141 Classification loss 0.5500 AP 0.3167 AR 0.1400
Epoch 485 batch 00005: Loss 0.5305 Regression loss 0.0109 Classification loss 0.5196 AP 0.3667 AR 0.1333
Epoch 485 batch 00006: Loss 0.4518 Regression loss 0.0116 Classification loss 0.4402 AP 0.4500 AR 0.0500
Epoch 485 batch 00007: Loss 0.4871 Regression loss 0.0131 Classification loss 0.4740 AP 0.4500 AR 0.2000
Epoch 485 batch 00008: Loss 0.4384 Regression loss 0.0127 Classification loss 0.4257 AP 0.2667 AR 0.3000
Epoch 485 batch 00009: Loss 0.4359 Regression loss 0.0120 Classification loss 0.4239 AP 0.5000 AR 0.1000
Epoch 485 batch 00010: Loss 0.3139 Regression loss 0.0121 Classification loss 0.3019 AP 1.0000 AR 0.0800
Epoch 486 batch 00001: Loss 0.4571 Regression loss 0.0078 Classification loss 0.4493 AP 0.7000 AR 0.2500
Epoch 486 batch 00002: Loss 0.2852 Regression loss 0.0129 Classification loss 0.2724 AP 0.5000 AR 0.3000
Epoch 486 batch 00003: Loss 0.1794 Regression loss 0.0085 Classification loss 0.1708 AP 0.9000 AR 0.3967
Epoch 486 batch 00004: Loss 0.4567 Regression loss 0.0099 Classification loss 0.4468 AP 0.5500 AR 0.1500
Epoch 486 batch 00005: Loss 0.6093 Regression loss 0.0154 Classification loss 0.5939 AP 0.7000 AR 0.0400
Epoch 486 batch 00006: Loss 0.2928 Regression loss 0.0130 Classification loss 0.2798 AP 0.8000 AR 0.0000
Epoch 486 batch 00007: Loss 0.5607 Regression loss 0.0120 Classification loss 0.5487 AP 0.2667 AR 0.0667
Epoch 486 batch 00008: Loss 0.5876 Regression loss 0.0149 Classification loss 0.5726 AP 0.4667 AR 0.1800
Epoch 486 batch 00009: Loss 0.4937 Regression loss 0.0148 Classification loss 0.4789 AP 0.5000 AR 0.0667
Epoch 486 batch 00010: Loss 0.5422 Regression loss 0.0151 Classification loss 0.5272 AP 0.5667 AR 0.1000
Epoch 487 batch 00001: Loss 0.5567 Regression loss 0.0136 Classification loss 0.5431 AP 0.5167 AR 0.2800
Epoch 487 batch 00002: Loss 0.5431 Regression loss 0.0120 Classification loss 0.5311 AP 0.6000 AR 0.0000
Epoch 487 batch 00003: Loss 0.4380 Regression loss 0.0118 Classification loss 0.4262 AP 0.3000 AR 0.1000
Epoch 487 batch 00004: Loss 0.4163 Regression loss 0.0140 Classification loss 0.4023 AP 0.5000 AR 0.0667
Epoch 487 batch 00005: Loss 0.5319 Regression loss 0.0136 Classification loss 0.5183 AP 0.8000 AR 0.1167
Epoch 487 batch 00006: Loss 0.4270 Regression loss 0.0080 Classification loss 0.4190 AP 0.6667 AR 0.6000
Epoch 487 batch 00007: Loss 0.3220 Regression loss 0.0123 Classification loss 0.3096 AP 0.5333 AR 0.0800
Epoch 487 batch 00008: Loss 0.4199 Regression loss 0.0114 Classification loss 0.4085 AP 0.4500 AR 0.3100
Epoch 487 batch 00009: Loss 0.3706 Regression loss 0.0145 Classification loss 0.3561 AP 1.0000 AR 0.0500
Epoch 487 batch 00010: Loss 0.5917 Regression loss 0.0125 Classification loss 0.5792 AP 0.5667 AR 0.1000
Epoch 488 batch 00001: Loss 0.4479 Regression loss 0.0111 Classification loss 0.4368 AP 0.7667 AR 0.0900
Epoch 488 batch 00002: Loss 0.4403 Regression loss 0.0136 Classification loss 0.4267 AP 0.6400 AR 0.2167
Epoch 488 batch 00003: Loss 0.3789 Regression loss 0.0107 Classification loss 0.3682 AP 0.4000 AR 0.0800
Epoch 488 batch 00004: Loss 0.5192 Regression loss 0.0120 Classification loss 0.5072 AP 0.5667 AR 0.1067
Epoch 488 batch 00005: Loss 0.3844 Regression loss 0.0191 Classification loss 0.3653 AP 0.9000 AR 0.2400
Epoch 488 batch 00006: Loss 0.2952 Regression loss 0.0093 Classification loss 0.2859 AP 0.9000 AR 0.0667
Epoch 488 batch 00007: Loss 0.4092 Regression loss 0.0119 Classification loss 0.3973 AP 0.5000 AR 0.4000
Epoch 488 batch 00008: Loss 0.4138 Regression loss 0.0124 Classification loss 0.4014 AP 0.3000 AR 0.1500
Epoch 488 batch 00009: Loss 0.6893 Regression loss 0.0104 Classification loss 0.6789 AP 0.5000 AR 0.0500
Epoch 488 batch 00010: Loss 0.5752 Regression loss 0.0130 Classification loss 0.5621 AP 0.6000 AR 0.2900
Epoch 489 batch 00001: Loss 0.5237 Regression loss 0.0115 Classification loss 0.5123 AP 0.5667 AR 0.3400
Epoch 489 batch 00002: Loss 0.4410 Regression loss 0.0204 Classification loss 0.4206 AP 0.9000 AR 0.0667
Epoch 489 batch 00003: Loss 0.4068 Regression loss 0.0091 Classification loss 0.3978 AP 0.7667 AR 0.3667
Epoch 489 batch 00004: Loss 0.6382 Regression loss 0.0108 Classification loss 0.6274 AP 0.5333 AR 0.1500
Epoch 489 batch 00005: Loss 0.2722 Regression loss 0.0091 Classification loss 0.2631 AP 0.0900 AR 0.1000
Epoch 489 batch 00006: Loss 0.4616 Regression loss 0.0120 Classification loss 0.4496 AP 0.5000 AR 0.0500
Epoch 489 batch 00007: Loss 0.4040 Regression loss 0.0138 Classification loss 0.3902 AP 0.7000 AR 0.1500
Epoch 489 batch 00008: Loss 0.3252 Regression loss 0.0102 Classification loss 0.3150 AP 0.8000 AR 0.3867
Epoch 489 batch 00009: Loss 0.5298 Regression loss 0.0134 Classification loss 0.5164 AP 0.6667 AR 0.0400
Epoch 489 batch 00010: Loss 0.6063 Regression loss 0.0124 Classification loss 0.5939 AP 0.6000 AR 0.0800
Epoch 490 batch 00001: Loss 0.5440 Regression loss 0.0157 Classification loss 0.5283 AP 0.4000 AR 0.1167
Epoch 490 batch 00002: Loss 0.2436 Regression loss 0.0106 Classification loss 0.2330 AP 0.7000 AR 0.3067
Epoch 490 batch 00003: Loss 0.4547 Regression loss 0.0134 Classification loss 0.4412 AP 0.7000 AR 0.2000
Epoch 490 batch 00004: Loss 0.4470 Regression loss 0.0106 Classification loss 0.4365 AP 0.3833 AR 0.1900
Epoch 490 batch 00005: Loss 0.4654 Regression loss 0.0076 Classification loss 0.4578 AP 0.5400 AR 0.1167
Epoch 490 batch 00006: Loss 0.3159 Regression loss 0.0102 Classification loss 0.3056 AP 0.6000 AR 0.0800
Epoch 490 batch 00007: Loss 0.6118 Regression loss 0.0177 Classification loss 0.5941 AP 0.9000 AR 0.1800
Epoch 490 batch 00008: Loss 0.3204 Regression loss 0.0135 Classification loss 0.3068 AP 1.0000 AR 0.2500
Epoch 490 batch 00009: Loss 0.5875 Regression loss 0.0124 Classification loss 0.5751 AP 0.5000 AR 0.1000
Epoch 490 batch 00010: Loss 0.3535 Regression loss 0.0092 Classification loss 0.3443 AP 0.2000 AR 0.1400
Epoch 491 batch 00001: Loss 0.5265 Regression loss 0.0120 Classification loss 0.5146 AP 0.8000 AR 0.4000
Epoch 491 batch 00002: Loss 0.4828 Regression loss 0.0138 Classification loss 0.4690 AP 0.6400 AR 0.1833
Epoch 491 batch 00003: Loss 0.4433 Regression loss 0.0131 Classification loss 0.4302 AP 0.7000 AR 0.1800
Epoch 491 batch 00004: Loss 0.3562 Regression loss 0.0106 Classification loss 0.3457 AP 0.5000 AR 0.1800
Epoch 491 batch 00005: Loss 0.3888 Regression loss 0.0109 Classification loss 0.3780 AP 0.7000 AR 0.1167
Epoch 491 batch 00006: Loss 0.4323 Regression loss 0.0176 Classification loss 0.4148 AP 0.6000 AR 0.1400
Epoch 491 batch 00007: Loss 0.4840 Regression loss 0.0108 Classification loss 0.4732 AP 0.5000 AR 0.2500
Epoch 491 batch 00008: Loss 0.4195 Regression loss 0.0100 Classification loss 0.4095 AP 0.5500 AR 0.1400
Epoch 491 batch 00009: Loss 0.4175 Regression loss 0.0114 Classification loss 0.4061 AP 0.6500 AR 0.0500
Epoch 491 batch 00010: Loss 0.5621 Regression loss 0.0135 Classification loss 0.5486 AP 0.6667 AR 0.1300
Epoch 492 batch 00001: Loss 0.5581 Regression loss 0.0155 Classification loss 0.5426 AP 0.7000 AR 0.1000
Epoch 492 batch 00002: Loss 0.3953 Regression loss 0.0095 Classification loss 0.3858 AP 0.7000 AR 0.1000
Epoch 492 batch 00003: Loss 0.5048 Regression loss 0.0089 Classification loss 0.4959 AP 0.3667 AR 0.3900
Epoch 492 batch 00004: Loss 0.4452 Regression loss 0.0164 Classification loss 0.4288 AP 0.6000 AR 0.0000
Epoch 492 batch 00005: Loss 0.3128 Regression loss 0.0124 Classification loss 0.3004 AP 0.5500 AR 0.2500
Epoch 492 batch 00006: Loss 0.3266 Regression loss 0.0103 Classification loss 0.3163 AP 0.3667 AR 0.1967
Epoch 492 batch 00007: Loss 0.5265 Regression loss 0.0144 Classification loss 0.5121 AP 0.4000 AR 0.0000
Epoch 492 batch 00008: Loss 0.3857 Regression loss 0.0097 Classification loss 0.3760 AP 0.5167 AR 0.3467
Epoch 492 batch 00009: Loss 0.4907 Regression loss 0.0181 Classification loss 0.4727 AP 0.9000 AR 0.0400
Epoch 492 batch 00010: Loss 0.6220 Regression loss 0.0122 Classification loss 0.6098 AP 0.6000 AR 0.2000
Epoch 493 batch 00001: Loss 0.3987 Regression loss 0.0107 Classification loss 0.3879 AP 0.5067 AR 0.1000
Epoch 493 batch 00002: Loss 0.4564 Regression loss 0.0141 Classification loss 0.4423 AP 0.5000 AR 0.2000
Epoch 493 batch 00003: Loss 0.3925 Regression loss 0.0138 Classification loss 0.3787 AP 0.6000 AR 0.2800
Epoch 493 batch 00004: Loss 0.3940 Regression loss 0.0120 Classification loss 0.3820 AP 0.5667 AR 0.1400
Epoch 493 batch 00005: Loss 0.5636 Regression loss 0.0137 Classification loss 0.5500 AP 0.8667 AR 0.3200
Epoch 493 batch 00006: Loss 0.3732 Regression loss 0.0146 Classification loss 0.3586 AP 0.7000 AR 0.0400
Epoch 493 batch 00007: Loss 0.5383 Regression loss 0.0148 Classification loss 0.5235 AP 0.7000 AR 0.0667
Epoch 493 batch 00008: Loss 0.3960 Regression loss 0.0074 Classification loss 0.3886 AP 0.7667 AR 0.2000
Epoch 493 batch 00009: Loss 0.4841 Regression loss 0.0129 Classification loss 0.4712 AP 0.5000 AR 0.1500
Epoch 493 batch 00010: Loss 0.5062 Regression loss 0.0098 Classification loss 0.4964 AP 0.3000 AR 0.1833
Epoch 494 batch 00001: Loss 0.5257 Regression loss 0.0119 Classification loss 0.5138 AP 0.4000 AR 0.2900
Epoch 494 batch 00002: Loss 0.2991 Regression loss 0.0107 Classification loss 0.2883 AP 0.6000 AR 0.3800
Epoch 494 batch 00003: Loss 0.4227 Regression loss 0.0136 Classification loss 0.4091 AP 0.4667 AR 0.0400
Epoch 494 batch 00004: Loss 0.5919 Regression loss 0.0144 Classification loss 0.5775 AP 0.5000 AR 0.1000
Epoch 494 batch 00005: Loss 0.4148 Regression loss 0.0091 Classification loss 0.4057 AP 0.8500 AR 0.0500
Epoch 494 batch 00006: Loss 0.3887 Regression loss 0.0158 Classification loss 0.3729 AP 0.5667 AR 0.1400
Epoch 494 batch 00007: Loss 0.5180 Regression loss 0.0099 Classification loss 0.5080 AP 0.7667 AR 0.1167
Epoch 494 batch 00008: Loss 0.3352 Regression loss 0.0090 Classification loss 0.3262 AP 0.5667 AR 0.4667
Epoch 494 batch 00009: Loss 0.4163 Regression loss 0.0105 Classification loss 0.4059 AP 0.4000 AR 0.0000
Epoch 494 batch 00010: Loss 0.6067 Regression loss 0.0147 Classification loss 0.5920 AP 0.7000 AR 0.0667
Epoch 495 batch 00001: Loss 0.4320 Regression loss 0.0133 Classification loss 0.4188 AP 0.8000 AR 0.3167
Epoch 495 batch 00002: Loss 0.3118 Regression loss 0.0133 Classification loss 0.2985 AP 1.0000 AR 0.2800
Epoch 495 batch 00003: Loss 0.4418 Regression loss 0.0130 Classification loss 0.4287 AP 0.7000 AR 0.1000
Epoch 495 batch 00004: Loss 0.4324 Regression loss 0.0086 Classification loss 0.4239 AP 0.7000 AR 0.0667
Epoch 495 batch 00005: Loss 0.4443 Regression loss 0.0083 Classification loss 0.4359 AP 0.4000 AR 0.0900
Epoch 495 batch 00006: Loss 0.4670 Regression loss 0.0102 Classification loss 0.4568 AP 0.6333 AR 0.3567
Epoch 495 batch 00007: Loss 0.5328 Regression loss 0.0124 Classification loss 0.5204 AP 0.7333 AR 0.0900
Epoch 495 batch 00008: Loss 0.5654 Regression loss 0.0148 Classification loss 0.5506 AP 0.5000 AR 0.1800
Epoch 495 batch 00009: Loss 0.3537 Regression loss 0.0122 Classification loss 0.3416 AP 0.2000 AR 0.0500
Epoch 495 batch 00010: Loss 0.4970 Regression loss 0.0163 Classification loss 0.4806 AP 0.4667 AR 0.1000
Epoch 496 batch 00001: Loss 0.4809 Regression loss 0.0179 Classification loss 0.4631 AP 0.9000 AR 0.0667
Epoch 496 batch 00002: Loss 0.5854 Regression loss 0.0096 Classification loss 0.5758 AP 0.4000 AR 0.2000
Epoch 496 batch 00003: Loss 0.4376 Regression loss 0.0166 Classification loss 0.4210 AP 0.4400 AR 0.0500
Epoch 496 batch 00004: Loss 0.3406 Regression loss 0.0092 Classification loss 0.3314 AP 0.3667 AR 0.2000
Epoch 496 batch 00005: Loss 0.5290 Regression loss 0.0086 Classification loss 0.5204 AP 0.7000 AR 0.1000
Epoch 496 batch 00006: Loss 0.6720 Regression loss 0.0173 Classification loss 0.6547 AP 0.4667 AR 0.0400
Epoch 496 batch 00007: Loss 0.6075 Regression loss 0.0104 Classification loss 0.5971 AP 0.8000 AR 0.1500
Epoch 496 batch 00008: Loss 0.2797 Regression loss 0.0091 Classification loss 0.2705 AP 0.5000 AR 0.1467
Epoch 496 batch 00009: Loss 0.4185 Regression loss 0.0135 Classification loss 0.4050 AP 0.5667 AR 0.1500
Epoch 496 batch 00010: Loss 0.3358 Regression loss 0.0133 Classification loss 0.3224 AP 0.6667 AR 0.3867
Epoch 497 batch 00001: Loss 0.5022 Regression loss 0.0101 Classification loss 0.4921 AP 0.2000 AR 0.0000
Epoch 497 batch 00002: Loss 0.5019 Regression loss 0.0146 Classification loss 0.4873 AP 0.6000 AR 0.3000
Epoch 497 batch 00003: Loss 0.4708 Regression loss 0.0156 Classification loss 0.4552 AP 0.5000 AR 0.1167
Epoch 497 batch 00004: Loss 0.5961 Regression loss 0.0153 Classification loss 0.5808 AP 0.8000 AR 0.0000
Epoch 497 batch 00005: Loss 0.5231 Regression loss 0.0166 Classification loss 0.5065 AP 0.8000 AR 0.0900
Epoch 497 batch 00006: Loss 0.2862 Regression loss 0.0107 Classification loss 0.2756 AP 0.5000 AR 0.0400
Epoch 497 batch 00007: Loss 0.4658 Regression loss 0.0124 Classification loss 0.4535 AP 0.4000 AR 0.1667
Epoch 497 batch 00008: Loss 0.3987 Regression loss 0.0120 Classification loss 0.3867 AP 0.7000 AR 0.4000
Epoch 497 batch 00009: Loss 0.4911 Regression loss 0.0106 Classification loss 0.4806 AP 0.1400 AR 0.1500
Epoch 497 batch 00010: Loss 0.3304 Regression loss 0.0112 Classification loss 0.3192 AP 0.7500 AR 0.1167
Epoch 498 batch 00001: Loss 0.4880 Regression loss 0.0147 Classification loss 0.4733 AP 0.8000 AR 0.0000
Epoch 498 batch 00002: Loss 0.3601 Regression loss 0.0113 Classification loss 0.3488 AP 0.5333 AR 0.4200
Epoch 498 batch 00003: Loss 0.2988 Regression loss 0.0089 Classification loss 0.2899 AP 0.2500 AR 0.1667
Epoch 498 batch 00004: Loss 0.3996 Regression loss 0.0107 Classification loss 0.3889 AP 0.6667 AR 0.1900
Epoch 498 batch 00005: Loss 0.4780 Regression loss 0.0177 Classification loss 0.4603 AP 0.8000 AR 0.1833
Epoch 498 batch 00006: Loss 0.5979 Regression loss 0.0108 Classification loss 0.5871 AP 1.0000 AR 0.0000
Epoch 498 batch 00007: Loss 0.5541 Regression loss 0.0109 Classification loss 0.5431 AP 0.4400 AR 0.0500
Epoch 498 batch 00008: Loss 0.4763 Regression loss 0.0114 Classification loss 0.4649 AP 0.2000 AR 0.0000
Epoch 498 batch 00009: Loss 0.5288 Regression loss 0.0167 Classification loss 0.5121 AP 0.5000 AR 0.0400
Epoch 498 batch 00010: Loss 0.3786 Regression loss 0.0122 Classification loss 0.3664 AP 0.8000 AR 0.6000
Epoch 499 batch 00001: Loss 0.6097 Regression loss 0.0102 Classification loss 0.5995 AP 0.5000 AR 0.3000
Epoch 499 batch 00002: Loss 0.3300 Regression loss 0.0148 Classification loss 0.3151 AP 0.9000 AR 0.1467
Epoch 499 batch 00003: Loss 0.6438 Regression loss 0.0133 Classification loss 0.6306 AP 0.6500 AR 0.0400
Epoch 499 batch 00004: Loss 0.4293 Regression loss 0.0132 Classification loss 0.4161 AP 0.4667 AR 0.0400
Epoch 499 batch 00005: Loss 0.4362 Regression loss 0.0121 Classification loss 0.4241 AP 0.5000 AR 0.2500
Epoch 499 batch 00006: Loss 0.5482 Regression loss 0.0107 Classification loss 0.5375 AP 0.7667 AR 0.1500
Epoch 499 batch 00007: Loss 0.4535 Regression loss 0.0173 Classification loss 0.4362 AP 0.8000 AR 0.0000
Epoch 499 batch 00008: Loss 0.2955 Regression loss 0.0110 Classification loss 0.2845 AP 0.6000 AR 0.1300
Epoch 499 batch 00009: Loss 0.4100 Regression loss 0.0119 Classification loss 0.3981 AP 0.5000 AR 0.2667
Epoch 499 batch 00010: Loss 0.3648 Regression loss 0.0111 Classification loss 0.3537 AP 0.4167 AR 0.3400
Epoch 500 batch 00001: Loss 0.4199 Regression loss 0.0103 Classification loss 0.4096 AP 0.2500 AR 0.0500
Epoch 500 batch 00002: Loss 0.4435 Regression loss 0.0118 Classification loss 0.4318 AP 0.6667 AR 0.2533
Epoch 500 batch 00003: Loss 0.6892 Regression loss 0.0160 Classification loss 0.6732 AP 0.8000 AR 0.0000
Epoch 500 batch 00004: Loss 0.4301 Regression loss 0.0110 Classification loss 0.4190 AP 0.7667 AR 0.1000
Epoch 500 batch 00005: Loss 0.5056 Regression loss 0.0148 Classification loss 0.4908 AP 0.8000 AR 0.2800
Epoch 500 batch 00006: Loss 0.3976 Regression loss 0.0120 Classification loss 0.3857 AP 0.4000 AR 0.0000
Epoch 500 batch 00007: Loss 0.4412 Regression loss 0.0151 Classification loss 0.4261 AP 0.6000 AR 0.2500
Epoch 500 batch 00008: Loss 0.4782 Regression loss 0.0146 Classification loss 0.4636 AP 0.6000 AR 0.2000
Epoch 500 batch 00009: Loss 0.4145 Regression loss 0.0105 Classification loss 0.4040 AP 0.4000 AR 0.1167
Epoch 500 batch 00010: Loss 0.4904 Regression loss 0.0123 Classification loss 0.4781 AP 0.7000 AR 0.1800
