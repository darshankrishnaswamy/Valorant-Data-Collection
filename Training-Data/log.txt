Epoch 001 batch 00001: Loss 0.0023 Regression loss 0.0018 Classification loss 0.0004 AP 0.7062 AR 0.9000
Epoch 001 batch 00002: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7219 AR 1.0000
Epoch 001 batch 00003: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.5421 AR 0.7300
Epoch 001 batch 00004: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6067 AR 0.8750
Epoch 001 batch 00005: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6849 AR 0.9100
Epoch 001 batch 00006: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.5905 AR 0.8550
Epoch 001 batch 00007: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.7358 AR 0.9467
Epoch 001 batch 00008: Loss 0.0033 Regression loss 0.0027 Classification loss 0.0005 AP 0.6542 AR 1.0000
Epoch 001 batch 00009: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0004 AP 0.7067 AR 0.8750
Epoch 001 batch 00010: Loss 0.0033 Regression loss 0.0028 Classification loss 0.0005 AP 0.6425 AR 0.8317
Epoch 002 batch 00001: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0003 AP 0.5921 AR 0.7550
Epoch 002 batch 00002: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0004 AP 0.6625 AR 0.9000
Epoch 002 batch 00003: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0003 AP 0.4696 AR 0.8000
Epoch 002 batch 00004: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.5944 AR 0.8350
Epoch 002 batch 00005: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0004 AP 0.7056 AR 0.9500
Epoch 002 batch 00006: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0005 AP 0.6431 AR 0.8600
Epoch 002 batch 00007: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0005 AP 0.5525 AR 0.7500
Epoch 002 batch 00008: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0004 AP 0.6100 AR 0.9417
Epoch 002 batch 00009: Loss 0.0035 Regression loss 0.0028 Classification loss 0.0007 AP 0.7342 AR 0.8550
Epoch 002 batch 00010: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7179 AR 0.9550
Epoch 003 batch 00001: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0002 AP 0.8131 AR 0.9800
Epoch 003 batch 00002: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.5805 AR 0.7967
Epoch 003 batch 00003: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.6517 AR 0.8250
Epoch 003 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7838 AR 0.9750
Epoch 003 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6500 AR 0.8667
Epoch 003 batch 00006: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6583 AR 0.9750
Epoch 003 batch 00007: Loss 0.0028 Regression loss 0.0023 Classification loss 0.0005 AP 0.5842 AR 0.8750
Epoch 003 batch 00008: Loss 0.0032 Regression loss 0.0026 Classification loss 0.0006 AP 0.6435 AR 0.8567
Epoch 003 batch 00009: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.5078 AR 0.7750
Epoch 003 batch 00010: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6106 AR 0.8800
Epoch 004 batch 00001: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0003 AP 0.7479 AR 0.8400
Epoch 004 batch 00002: Loss 0.0030 Regression loss 0.0025 Classification loss 0.0005 AP 0.6167 AR 0.8267
Epoch 004 batch 00003: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.6545 AR 0.9350
Epoch 004 batch 00004: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7258 AR 0.9750
Epoch 004 batch 00005: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.6517 AR 0.8417
Epoch 004 batch 00006: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0005 AP 0.5283 AR 0.8167
Epoch 004 batch 00007: Loss 0.0028 Regression loss 0.0023 Classification loss 0.0005 AP 0.7740 AR 0.9750
Epoch 004 batch 00008: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.6211 AR 0.9800
Epoch 004 batch 00009: Loss 0.0028 Regression loss 0.0022 Classification loss 0.0006 AP 0.6267 AR 0.9350
Epoch 004 batch 00010: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6961 AR 0.9500
Epoch 005 batch 00001: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6298 AR 1.0000
Epoch 005 batch 00002: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6478 AR 0.8550
Epoch 005 batch 00003: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0003 AP 0.6383 AR 0.7717
Epoch 005 batch 00004: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.7622 AR 0.9800
Epoch 005 batch 00005: Loss 0.0028 Regression loss 0.0023 Classification loss 0.0005 AP 0.6100 AR 0.9250
Epoch 005 batch 00006: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0004 AP 0.6696 AR 1.0000
Epoch 005 batch 00007: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.6350 AR 0.8750
Epoch 005 batch 00008: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.6574 AR 0.8500
Epoch 005 batch 00009: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0005 AP 0.6368 AR 0.8467
Epoch 005 batch 00010: Loss 0.0034 Regression loss 0.0030 Classification loss 0.0004 AP 0.5967 AR 0.7600
Epoch 006 batch 00001: Loss 0.0030 Regression loss 0.0025 Classification loss 0.0005 AP 0.5325 AR 0.8067
Epoch 006 batch 00002: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.6417 AR 0.7750
Epoch 006 batch 00003: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.6761 AR 0.8750
Epoch 006 batch 00004: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0003 AP 0.5683 AR 0.7967
Epoch 006 batch 00005: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0005 AP 0.5983 AR 0.7500
Epoch 006 batch 00006: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0005 AP 0.5878 AR 0.8883
Epoch 006 batch 00007: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6595 AR 0.9000
Epoch 006 batch 00008: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.6733 AR 0.8567
Epoch 006 batch 00009: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.7167 AR 0.9550
Epoch 006 batch 00010: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.7281 AR 0.9800
Epoch 007 batch 00001: Loss 0.0031 Regression loss 0.0025 Classification loss 0.0006 AP 0.6905 AR 0.9600
Epoch 007 batch 00002: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0003 AP 0.6861 AR 0.9800
Epoch 007 batch 00003: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7900 AR 0.9800
Epoch 007 batch 00004: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.6425 AR 0.8800
Epoch 007 batch 00005: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.7850 AR 0.9000
Epoch 007 batch 00006: Loss 0.0028 Regression loss 0.0023 Classification loss 0.0005 AP 0.5232 AR 0.9167
Epoch 007 batch 00007: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5944 AR 0.8550
Epoch 007 batch 00008: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.5753 AR 0.7967
Epoch 007 batch 00009: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.8571 AR 0.9550
Epoch 007 batch 00010: Loss 0.0031 Regression loss 0.0026 Classification loss 0.0005 AP 0.5417 AR 0.7717
Epoch 008 batch 00001: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0004 AP 0.5230 AR 0.7550
Epoch 008 batch 00002: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.6461 AR 0.9300
Epoch 008 batch 00003: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7425 AR 0.9167
Epoch 008 batch 00004: Loss 0.0030 Regression loss 0.0025 Classification loss 0.0005 AP 0.5571 AR 0.8533
Epoch 008 batch 00005: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.6751 AR 0.9800
Epoch 008 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6308 AR 0.8800
Epoch 008 batch 00007: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6430 AR 0.8600
Epoch 008 batch 00008: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6480 AR 0.9050
Epoch 008 batch 00009: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.6233 AR 0.8750
Epoch 008 batch 00010: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6767 AR 0.8250
Epoch 009 batch 00001: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.6436 AR 0.9600
Epoch 009 batch 00002: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6100 AR 0.8500
Epoch 009 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6911 AR 0.9667
Epoch 009 batch 00004: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6195 AR 0.9150
Epoch 009 batch 00005: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6788 AR 0.9167
Epoch 009 batch 00006: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.4758 AR 0.7350
Epoch 009 batch 00007: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0004 AP 0.7622 AR 0.9800
Epoch 009 batch 00008: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.6939 AR 0.8500
Epoch 009 batch 00009: Loss 0.0034 Regression loss 0.0028 Classification loss 0.0006 AP 0.7048 AR 0.8467
Epoch 009 batch 00010: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.7377 AR 1.0000
Epoch 010 batch 00001: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.5682 AR 0.8167
Epoch 010 batch 00002: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.7263 AR 0.8800
Epoch 010 batch 00003: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0004 AP 0.7025 AR 0.9750
Epoch 010 batch 00004: Loss 0.0030 Regression loss 0.0025 Classification loss 0.0005 AP 0.7293 AR 0.9150
Epoch 010 batch 00005: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.6583 AR 0.8800
Epoch 010 batch 00006: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.5160 AR 0.8800
Epoch 010 batch 00007: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.8692 AR 0.9217
Epoch 010 batch 00008: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.5928 AR 0.9300
Epoch 010 batch 00009: Loss 0.0023 Regression loss 0.0018 Classification loss 0.0005 AP 0.5997 AR 0.9000
Epoch 010 batch 00010: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.6729 AR 0.9550
Epoch 011 batch 00001: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6167 AR 0.8250
Epoch 011 batch 00002: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.5808 AR 0.8017
Epoch 011 batch 00003: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6819 AR 0.9417
Epoch 011 batch 00004: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6748 AR 0.8800
Epoch 011 batch 00005: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0005 AP 0.6648 AR 0.9050
Epoch 011 batch 00006: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.8017 AR 0.9417
Epoch 011 batch 00007: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6705 AR 0.9550
Epoch 011 batch 00008: Loss 0.0039 Regression loss 0.0035 Classification loss 0.0005 AP 0.5142 AR 0.6750
Epoch 011 batch 00009: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6579 AR 0.9350
Epoch 011 batch 00010: Loss 0.0033 Regression loss 0.0029 Classification loss 0.0004 AP 0.5216 AR 0.8400
Epoch 012 batch 00001: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.6045 AR 0.7850
Epoch 012 batch 00002: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.5978 AR 0.8467
Epoch 012 batch 00003: Loss 0.0023 Regression loss 0.0018 Classification loss 0.0004 AP 0.6342 AR 0.8800
Epoch 012 batch 00004: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7905 AR 0.9800
Epoch 012 batch 00005: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.7417 AR 1.0000
Epoch 012 batch 00006: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.7133 AR 0.9550
Epoch 012 batch 00007: Loss 0.0033 Regression loss 0.0028 Classification loss 0.0005 AP 0.4669 AR 0.8417
Epoch 012 batch 00008: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0004 AP 0.6325 AR 0.9050
Epoch 012 batch 00009: Loss 0.0036 Regression loss 0.0033 Classification loss 0.0003 AP 0.6767 AR 0.7667
Epoch 012 batch 00010: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.5794 AR 0.8350
Epoch 013 batch 00001: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7983 AR 0.9800
Epoch 013 batch 00002: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7571 AR 0.9550
Epoch 013 batch 00003: Loss 0.0030 Regression loss 0.0025 Classification loss 0.0005 AP 0.4240 AR 0.7317
Epoch 013 batch 00004: Loss 0.0037 Regression loss 0.0033 Classification loss 0.0005 AP 0.5702 AR 0.7383
Epoch 013 batch 00005: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0005 AP 0.7200 AR 1.0000
Epoch 013 batch 00006: Loss 0.0034 Regression loss 0.0030 Classification loss 0.0004 AP 0.7970 AR 0.9750
Epoch 013 batch 00007: Loss 0.0033 Regression loss 0.0028 Classification loss 0.0005 AP 0.7083 AR 0.9300
Epoch 013 batch 00008: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.5383 AR 0.7550
Epoch 013 batch 00009: Loss 0.0032 Regression loss 0.0027 Classification loss 0.0005 AP 0.4439 AR 0.6800
Epoch 013 batch 00010: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6981 AR 0.9417
Epoch 014 batch 00001: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.7844 AR 0.9600
Epoch 014 batch 00002: Loss 0.0037 Regression loss 0.0031 Classification loss 0.0006 AP 0.5685 AR 0.9217
Epoch 014 batch 00003: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7121 AR 0.9500
Epoch 014 batch 00004: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.7389 AR 1.0000
Epoch 014 batch 00005: Loss 0.0034 Regression loss 0.0030 Classification loss 0.0004 AP 0.6104 AR 0.8417
Epoch 014 batch 00006: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0004 AP 0.6695 AR 0.8400
Epoch 014 batch 00007: Loss 0.0037 Regression loss 0.0031 Classification loss 0.0005 AP 0.6262 AR 0.8017
Epoch 014 batch 00008: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0004 AP 0.5881 AR 0.7800
Epoch 014 batch 00009: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.5988 AR 0.8000
Epoch 014 batch 00010: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0003 AP 0.8023 AR 0.9750
Epoch 015 batch 00001: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0003 AP 0.7019 AR 0.9217
Epoch 015 batch 00002: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.6862 AR 0.8400
Epoch 015 batch 00003: Loss 0.0028 Regression loss 0.0023 Classification loss 0.0004 AP 0.6963 AR 0.9217
Epoch 015 batch 00004: Loss 0.0028 Regression loss 0.0023 Classification loss 0.0005 AP 0.7194 AR 0.8800
Epoch 015 batch 00005: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.7725 AR 0.8750
Epoch 015 batch 00006: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0005 AP 0.7333 AR 0.9667
Epoch 015 batch 00007: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0005 AP 0.5788 AR 0.8167
Epoch 015 batch 00008: Loss 0.0030 Regression loss 0.0023 Classification loss 0.0006 AP 0.6500 AR 0.9600
Epoch 015 batch 00009: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0004 AP 0.5917 AR 0.9100
Epoch 015 batch 00010: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.5600 AR 0.8800
Epoch 016 batch 00001: Loss 0.0028 Regression loss 0.0022 Classification loss 0.0005 AP 0.7883 AR 0.9600
Epoch 016 batch 00002: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0003 AP 0.6721 AR 0.9300
Epoch 016 batch 00003: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7083 AR 0.8000
Epoch 016 batch 00004: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7642 AR 1.0000
Epoch 016 batch 00005: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6963 AR 0.9100
Epoch 016 batch 00006: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6600 AR 0.9217
Epoch 016 batch 00007: Loss 0.0028 Regression loss 0.0022 Classification loss 0.0006 AP 0.6201 AR 0.8300
Epoch 016 batch 00008: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.6613 AR 0.8667
Epoch 016 batch 00009: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.5483 AR 0.8000
Epoch 016 batch 00010: Loss 0.0031 Regression loss 0.0025 Classification loss 0.0006 AP 0.5058 AR 0.8900
Epoch 017 batch 00001: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0005 AP 0.6855 AR 0.9400
Epoch 017 batch 00002: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.6267 AR 0.8267
Epoch 017 batch 00003: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.6036 AR 0.8800
Epoch 017 batch 00004: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7192 AR 0.9500
Epoch 017 batch 00005: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.6292 AR 0.8600
Epoch 017 batch 00006: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.8288 AR 0.9800
Epoch 017 batch 00007: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.5711 AR 0.9550
Epoch 017 batch 00008: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.5770 AR 0.8817
Epoch 017 batch 00009: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.8217 AR 0.9667
Epoch 017 batch 00010: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.6063 AR 0.8500
Epoch 018 batch 00001: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0002 AP 0.6112 AR 0.8000
Epoch 018 batch 00002: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0005 AP 0.6552 AR 0.9667
Epoch 018 batch 00003: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6946 AR 0.9500
Epoch 018 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6183 AR 0.7750
Epoch 018 batch 00005: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6600 AR 0.9217
Epoch 018 batch 00006: Loss 0.0028 Regression loss 0.0023 Classification loss 0.0005 AP 0.6810 AR 0.9150
Epoch 018 batch 00007: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0005 AP 0.6505 AR 0.9550
Epoch 018 batch 00008: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.6845 AR 0.9600
Epoch 018 batch 00009: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.7783 AR 0.9467
Epoch 018 batch 00010: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.7614 AR 0.9550
Epoch 019 batch 00001: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.7202 AR 1.0000
Epoch 019 batch 00002: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6786 AR 0.8967
Epoch 019 batch 00003: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6367 AR 0.9667
Epoch 019 batch 00004: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.5628 AR 0.8800
Epoch 019 batch 00005: Loss 0.0031 Regression loss 0.0025 Classification loss 0.0006 AP 0.5950 AR 0.8217
Epoch 019 batch 00006: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.7496 AR 0.9800
Epoch 019 batch 00007: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.5743 AR 0.7400
Epoch 019 batch 00008: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.7144 AR 0.9550
Epoch 019 batch 00009: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7150 AR 0.8000
Epoch 019 batch 00010: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6481 AR 0.9500
Epoch 020 batch 00001: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6193 AR 0.7800
Epoch 020 batch 00002: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.6188 AR 0.8800
Epoch 020 batch 00003: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.4600 AR 0.7817
Epoch 020 batch 00004: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7044 AR 0.9000
Epoch 020 batch 00005: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0004 AP 0.6404 AR 0.8900
Epoch 020 batch 00006: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.6450 AR 0.8050
Epoch 020 batch 00007: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7742 AR 0.9050
Epoch 020 batch 00008: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.5931 AR 0.8667
Epoch 020 batch 00009: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7297 AR 0.9667
Epoch 020 batch 00010: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.7850 AR 1.0000
Epoch 021 batch 00001: Loss 0.0036 Regression loss 0.0033 Classification loss 0.0003 AP 0.5711 AR 0.7583
Epoch 021 batch 00002: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.8119 AR 0.9800
Epoch 021 batch 00003: Loss 0.0022 Regression loss 0.0016 Classification loss 0.0005 AP 0.5942 AR 0.9000
Epoch 021 batch 00004: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0004 AP 0.5883 AR 0.9150
Epoch 021 batch 00005: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.6955 AR 0.8800
Epoch 021 batch 00006: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0004 AP 0.6431 AR 0.8500
Epoch 021 batch 00007: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.6017 AR 0.8400
Epoch 021 batch 00008: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0003 AP 0.7175 AR 0.9300
Epoch 021 batch 00009: Loss 0.0026 Regression loss 0.0019 Classification loss 0.0007 AP 0.7529 AR 0.9300
Epoch 021 batch 00010: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.6447 AR 0.9000
Epoch 022 batch 00001: Loss 0.0031 Regression loss 0.0026 Classification loss 0.0004 AP 0.6417 AR 0.8550
Epoch 022 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.5452 AR 0.8667
Epoch 022 batch 00003: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7714 AR 0.9000
Epoch 022 batch 00004: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.5596 AR 0.8150
Epoch 022 batch 00005: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.6861 AR 0.9550
Epoch 022 batch 00006: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0004 AP 0.7042 AR 0.8217
Epoch 022 batch 00007: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.5905 AR 0.9000
Epoch 022 batch 00008: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6583 AR 0.8600
Epoch 022 batch 00009: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0005 AP 0.6448 AR 0.8750
Epoch 022 batch 00010: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.7033 AR 0.9500
Epoch 023 batch 00001: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.6862 AR 0.9300
Epoch 023 batch 00002: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7048 AR 0.8500
Epoch 023 batch 00003: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6564 AR 0.9067
Epoch 023 batch 00004: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0005 AP 0.6792 AR 0.9250
Epoch 023 batch 00005: Loss 0.0031 Regression loss 0.0026 Classification loss 0.0005 AP 0.4949 AR 0.7467
Epoch 023 batch 00006: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.7650 AR 0.9217
Epoch 023 batch 00007: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0005 AP 0.5388 AR 0.8150
Epoch 023 batch 00008: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.7421 AR 0.9750
Epoch 023 batch 00009: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7750 AR 1.0000
Epoch 023 batch 00010: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.6692 AR 0.8217
Epoch 024 batch 00001: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0004 AP 0.7829 AR 0.9167
Epoch 024 batch 00002: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.7833 AR 1.0000
Epoch 024 batch 00003: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0004 AP 0.7792 AR 1.0000
Epoch 024 batch 00004: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0004 AP 0.5098 AR 0.8000
Epoch 024 batch 00005: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0004 AP 0.5598 AR 0.7600
Epoch 024 batch 00006: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.6580 AR 0.9800
Epoch 024 batch 00007: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6141 AR 0.8217
Epoch 024 batch 00008: Loss 0.0032 Regression loss 0.0027 Classification loss 0.0005 AP 0.5669 AR 0.8750
Epoch 024 batch 00009: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.7383 AR 0.9800
Epoch 024 batch 00010: Loss 0.0036 Regression loss 0.0030 Classification loss 0.0006 AP 0.7667 AR 0.9350
Epoch 025 batch 00001: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.6533 AR 0.8417
Epoch 025 batch 00002: Loss 0.0031 Regression loss 0.0025 Classification loss 0.0006 AP 0.6252 AR 0.9467
Epoch 025 batch 00003: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.5916 AR 0.8100
Epoch 025 batch 00004: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.7350 AR 0.9667
Epoch 025 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6172 AR 0.9500
Epoch 025 batch 00006: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.6517 AR 0.8217
Epoch 025 batch 00007: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.7064 AR 0.9000
Epoch 025 batch 00008: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6686 AR 0.9417
Epoch 025 batch 00009: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7293 AR 0.9600
Epoch 025 batch 00010: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6620 AR 0.8750
Epoch 026 batch 00001: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.4867 AR 0.7967
Epoch 026 batch 00002: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6050 AR 0.9000
Epoch 026 batch 00003: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7036 AR 0.9800
Epoch 026 batch 00004: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0005 AP 0.6386 AR 0.9250
Epoch 026 batch 00005: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0004 AP 0.7333 AR 0.9500
Epoch 026 batch 00006: Loss 0.0036 Regression loss 0.0030 Classification loss 0.0006 AP 0.6743 AR 0.8400
Epoch 026 batch 00007: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6567 AR 0.8017
Epoch 026 batch 00008: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.7755 AR 0.9467
Epoch 026 batch 00009: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6381 AR 0.9550
Epoch 026 batch 00010: Loss 0.0037 Regression loss 0.0032 Classification loss 0.0005 AP 0.7772 AR 0.9800
Epoch 027 batch 00001: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.6561 AR 1.0000
Epoch 027 batch 00002: Loss 0.0027 Regression loss 0.0021 Classification loss 0.0006 AP 0.5997 AR 0.8350
Epoch 027 batch 00003: Loss 0.0036 Regression loss 0.0031 Classification loss 0.0004 AP 0.5883 AR 0.7850
Epoch 027 batch 00004: Loss 0.0034 Regression loss 0.0030 Classification loss 0.0004 AP 0.6838 AR 0.9083
Epoch 027 batch 00005: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.7550 AR 1.0000
Epoch 027 batch 00006: Loss 0.0032 Regression loss 0.0027 Classification loss 0.0005 AP 0.6195 AR 0.8750
Epoch 027 batch 00007: Loss 0.0046 Regression loss 0.0042 Classification loss 0.0004 AP 0.7564 AR 0.9750
Epoch 027 batch 00008: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0002 AP 0.6267 AR 0.9133
Epoch 027 batch 00009: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.4538 AR 0.6517
Epoch 027 batch 00010: Loss 0.0037 Regression loss 0.0033 Classification loss 0.0004 AP 0.8250 AR 0.9550
Epoch 028 batch 00001: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7083 AR 0.9550
Epoch 028 batch 00002: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0005 AP 0.5881 AR 0.8800
Epoch 028 batch 00003: Loss 0.0034 Regression loss 0.0029 Classification loss 0.0005 AP 0.7398 AR 0.9550
Epoch 028 batch 00004: Loss 0.0034 Regression loss 0.0031 Classification loss 0.0004 AP 0.6533 AR 0.9250
Epoch 028 batch 00005: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.6095 AR 0.7267
Epoch 028 batch 00006: Loss 0.0031 Regression loss 0.0026 Classification loss 0.0005 AP 0.6483 AR 0.9100
Epoch 028 batch 00007: Loss 0.0037 Regression loss 0.0033 Classification loss 0.0004 AP 0.6200 AR 0.8600
Epoch 028 batch 00008: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.5700 AR 0.7800
Epoch 028 batch 00009: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.8113 AR 1.0000
Epoch 028 batch 00010: Loss 0.0030 Regression loss 0.0025 Classification loss 0.0005 AP 0.6625 AR 0.9083
Epoch 029 batch 00001: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.7197 AR 0.9100
Epoch 029 batch 00002: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7278 AR 1.0000
Epoch 029 batch 00003: Loss 0.0028 Regression loss 0.0022 Classification loss 0.0006 AP 0.6481 AR 0.9467
Epoch 029 batch 00004: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.7244 AR 0.8800
Epoch 029 batch 00005: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.5043 AR 0.7217
Epoch 029 batch 00006: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.6321 AR 0.8800
Epoch 029 batch 00007: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.7495 AR 0.9400
Epoch 029 batch 00008: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.5892 AR 0.8250
Epoch 029 batch 00009: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6050 AR 0.8750
Epoch 029 batch 00010: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.5408 AR 0.7583
Epoch 030 batch 00001: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6836 AR 0.9100
Epoch 030 batch 00002: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.5310 AR 0.9200
Epoch 030 batch 00003: Loss 0.0032 Regression loss 0.0027 Classification loss 0.0005 AP 0.5908 AR 0.9133
Epoch 030 batch 00004: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0004 AP 0.7392 AR 0.9500
Epoch 030 batch 00005: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.8567 AR 0.9300
Epoch 030 batch 00006: Loss 0.0034 Regression loss 0.0031 Classification loss 0.0003 AP 0.6975 AR 0.9417
Epoch 030 batch 00007: Loss 0.0033 Regression loss 0.0029 Classification loss 0.0003 AP 0.7443 AR 0.9000
Epoch 030 batch 00008: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6837 AR 0.8500
Epoch 030 batch 00009: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.5542 AR 0.9000
Epoch 030 batch 00010: Loss 0.0042 Regression loss 0.0037 Classification loss 0.0005 AP 0.6567 AR 0.8750
Epoch 031 batch 00001: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6556 AR 0.9500
Epoch 031 batch 00002: Loss 0.0040 Regression loss 0.0037 Classification loss 0.0003 AP 0.5952 AR 0.8667
Epoch 031 batch 00003: Loss 0.0048 Regression loss 0.0044 Classification loss 0.0005 AP 0.6800 AR 0.8500
Epoch 031 batch 00004: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.7029 AR 0.8350
Epoch 031 batch 00005: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6144 AR 0.8600
Epoch 031 batch 00006: Loss 0.0036 Regression loss 0.0029 Classification loss 0.0007 AP 0.5124 AR 0.7833
Epoch 031 batch 00007: Loss 0.0033 Regression loss 0.0029 Classification loss 0.0003 AP 0.6958 AR 0.9417
Epoch 031 batch 00008: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.7327 AR 0.8800
Epoch 031 batch 00009: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6867 AR 0.9500
Epoch 031 batch 00010: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0003 AP 0.5821 AR 0.9000
Epoch 032 batch 00001: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6711 AR 0.8550
Epoch 032 batch 00002: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0002 AP 0.7573 AR 0.9550
Epoch 032 batch 00003: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6648 AR 0.8767
Epoch 032 batch 00004: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7405 AR 0.9467
Epoch 032 batch 00005: Loss 0.0033 Regression loss 0.0028 Classification loss 0.0006 AP 0.7750 AR 0.9800
Epoch 032 batch 00006: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0005 AP 0.5177 AR 0.7550
Epoch 032 batch 00007: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.5508 AR 0.9550
Epoch 032 batch 00008: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0004 AP 0.6306 AR 0.8217
Epoch 032 batch 00009: Loss 0.0031 Regression loss 0.0026 Classification loss 0.0005 AP 0.6536 AR 0.9300
Epoch 032 batch 00010: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7067 AR 0.9750
Epoch 033 batch 00001: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6483 AR 0.9250
Epoch 033 batch 00002: Loss 0.0033 Regression loss 0.0029 Classification loss 0.0004 AP 0.7833 AR 0.9750
Epoch 033 batch 00003: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6479 AR 0.8800
Epoch 033 batch 00004: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0004 AP 0.5802 AR 0.8250
Epoch 033 batch 00005: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.7050 AR 0.9467
Epoch 033 batch 00006: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.5667 AR 0.7867
Epoch 033 batch 00007: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.7094 AR 0.9417
Epoch 033 batch 00008: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.5156 AR 0.7550
Epoch 033 batch 00009: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6521 AR 0.9550
Epoch 033 batch 00010: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.7698 AR 0.9100
Epoch 034 batch 00001: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.7208 AR 0.9500
Epoch 034 batch 00002: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6623 AR 0.9500
Epoch 034 batch 00003: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0004 AP 0.7408 AR 0.9350
Epoch 034 batch 00004: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.5866 AR 0.8750
Epoch 034 batch 00005: Loss 0.0035 Regression loss 0.0028 Classification loss 0.0007 AP 0.5395 AR 0.7150
Epoch 034 batch 00006: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.5172 AR 0.8767
Epoch 034 batch 00007: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.7383 AR 1.0000
Epoch 034 batch 00008: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.7390 AR 0.9550
Epoch 034 batch 00009: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.5100 AR 0.7750
Epoch 034 batch 00010: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6625 AR 0.8000
Epoch 035 batch 00001: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.5667 AR 0.7750
Epoch 035 batch 00002: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.6405 AR 0.9000
Epoch 035 batch 00003: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0004 AP 0.4054 AR 0.6400
Epoch 035 batch 00004: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.7953 AR 0.9800
Epoch 035 batch 00005: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.7106 AR 0.9600
Epoch 035 batch 00006: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.5944 AR 0.8217
Epoch 035 batch 00007: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6733 AR 0.8967
Epoch 035 batch 00008: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6771 AR 0.9550
Epoch 035 batch 00009: Loss 0.0033 Regression loss 0.0029 Classification loss 0.0004 AP 0.7838 AR 0.8733
Epoch 035 batch 00010: Loss 0.0027 Regression loss 0.0021 Classification loss 0.0006 AP 0.6100 AR 0.9500
Epoch 036 batch 00001: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7683 AR 0.9800
Epoch 036 batch 00002: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7175 AR 0.9400
Epoch 036 batch 00003: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.5625 AR 0.8167
Epoch 036 batch 00004: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.6500 AR 0.7800
Epoch 036 batch 00005: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6286 AR 0.8000
Epoch 036 batch 00006: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7850 AR 1.0000
Epoch 036 batch 00007: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.6567 AR 0.7800
Epoch 036 batch 00008: Loss 0.0031 Regression loss 0.0026 Classification loss 0.0005 AP 0.6152 AR 0.8800
Epoch 036 batch 00009: Loss 0.0027 Regression loss 0.0021 Classification loss 0.0005 AP 0.6287 AR 0.9350
Epoch 036 batch 00010: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.7272 AR 0.9417
Epoch 037 batch 00001: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0004 AP 0.8288 AR 0.9550
Epoch 037 batch 00002: Loss 0.0029 Regression loss 0.0023 Classification loss 0.0006 AP 0.6467 AR 0.9133
Epoch 037 batch 00003: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7939 AR 0.9600
Epoch 037 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.5546 AR 0.8967
Epoch 037 batch 00005: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6970 AR 0.9350
Epoch 037 batch 00006: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.4850 AR 0.6417
Epoch 037 batch 00007: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.7052 AR 0.9167
Epoch 037 batch 00008: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.5975 AR 0.7550
Epoch 037 batch 00009: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6705 AR 0.9550
Epoch 037 batch 00010: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0003 AP 0.5483 AR 0.8417
Epoch 038 batch 00001: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0003 AP 0.5550 AR 0.8750
Epoch 038 batch 00002: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.6882 AR 0.9300
Epoch 038 batch 00003: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6550 AR 0.9000
Epoch 038 batch 00004: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0004 AP 0.6575 AR 0.9217
Epoch 038 batch 00005: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7817 AR 0.9000
Epoch 038 batch 00006: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0005 AP 0.6217 AR 0.8350
Epoch 038 batch 00007: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7050 AR 0.9750
Epoch 038 batch 00008: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7133 AR 1.0000
Epoch 038 batch 00009: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6164 AR 0.8500
Epoch 038 batch 00010: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6119 AR 0.9467
Epoch 039 batch 00001: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6306 AR 0.9600
Epoch 039 batch 00002: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6062 AR 0.7917
Epoch 039 batch 00003: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7100 AR 1.0000
Epoch 039 batch 00004: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.5750 AR 0.7500
Epoch 039 batch 00005: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7189 AR 0.9750
Epoch 039 batch 00006: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6108 AR 0.8800
Epoch 039 batch 00007: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.6563 AR 0.8350
Epoch 039 batch 00008: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0005 AP 0.6275 AR 0.7800
Epoch 039 batch 00009: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7500 AR 0.9150
Epoch 039 batch 00010: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6083 AR 1.0000
Epoch 040 batch 00001: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7633 AR 0.9600
Epoch 040 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6042 AR 0.8467
Epoch 040 batch 00003: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0004 AP 0.6125 AR 0.7600
Epoch 040 batch 00004: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7139 AR 0.9550
Epoch 040 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7750 AR 0.9000
Epoch 040 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7323 AR 0.9550
Epoch 040 batch 00007: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7517 AR 0.9750
Epoch 040 batch 00008: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.5768 AR 0.7650
Epoch 040 batch 00009: Loss 0.0026 Regression loss 0.0020 Classification loss 0.0006 AP 0.6600 AR 0.9550
Epoch 040 batch 00010: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.6900 AR 0.9250
Epoch 041 batch 00001: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7584 AR 0.9750
Epoch 041 batch 00002: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7150 AR 0.9500
Epoch 041 batch 00003: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6820 AR 1.0000
Epoch 041 batch 00004: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6870 AR 0.9150
Epoch 041 batch 00005: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0006 AP 0.5238 AR 0.8350
Epoch 041 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0002 AP 0.6342 AR 0.9667
Epoch 041 batch 00007: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.6261 AR 0.8550
Epoch 041 batch 00008: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7243 AR 0.8800
Epoch 041 batch 00009: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0003 AP 0.7288 AR 0.9300
Epoch 041 batch 00010: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0004 AP 0.6998 AR 0.9750
Epoch 042 batch 00001: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.5692 AR 0.8500
Epoch 042 batch 00002: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6333 AR 0.9600
Epoch 042 batch 00003: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.5979 AR 0.7600
Epoch 042 batch 00004: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7606 AR 0.9500
Epoch 042 batch 00005: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.8017 AR 0.9750
Epoch 042 batch 00006: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0004 AP 0.5210 AR 0.8550
Epoch 042 batch 00007: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6931 AR 0.8250
Epoch 042 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7000 AR 0.9667
Epoch 042 batch 00009: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6244 AR 0.8017
Epoch 042 batch 00010: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.7433 AR 0.9600
Epoch 043 batch 00001: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7233 AR 0.8500
Epoch 043 batch 00002: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.7392 AR 1.0000
Epoch 043 batch 00003: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0004 AP 0.5680 AR 0.9167
Epoch 043 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6431 AR 0.8833
Epoch 043 batch 00005: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7375 AR 0.9150
Epoch 043 batch 00006: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.5400 AR 0.8550
Epoch 043 batch 00007: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.7058 AR 1.0000
Epoch 043 batch 00008: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.6843 AR 0.9150
Epoch 043 batch 00009: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0005 AP 0.6836 AR 0.8800
Epoch 043 batch 00010: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7471 AR 0.9800
Epoch 044 batch 00001: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7003 AR 0.8800
Epoch 044 batch 00002: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6450 AR 0.8500
Epoch 044 batch 00003: Loss 0.0027 Regression loss 0.0021 Classification loss 0.0005 AP 0.5563 AR 0.8267
Epoch 044 batch 00004: Loss 0.0023 Regression loss 0.0018 Classification loss 0.0004 AP 0.6877 AR 0.9300
Epoch 044 batch 00005: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0003 AP 0.7333 AR 0.9000
Epoch 044 batch 00006: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.6776 AR 0.9400
Epoch 044 batch 00007: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6786 AR 1.0000
Epoch 044 batch 00008: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6614 AR 0.9500
Epoch 044 batch 00009: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.6458 AR 0.8833
Epoch 044 batch 00010: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0004 AP 0.7471 AR 0.8400
Epoch 045 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6344 AR 0.8900
Epoch 045 batch 00002: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.4951 AR 0.6767
Epoch 045 batch 00003: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7550 AR 1.0000
Epoch 045 batch 00004: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6708 AR 0.9250
Epoch 045 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6242 AR 0.9000
Epoch 045 batch 00006: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.5736 AR 0.8867
Epoch 045 batch 00007: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.7050 AR 0.8467
Epoch 045 batch 00008: Loss 0.0026 Regression loss 0.0020 Classification loss 0.0006 AP 0.6433 AR 0.7750
Epoch 045 batch 00009: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.6983 AR 0.8800
Epoch 045 batch 00010: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0003 AP 0.6977 AR 0.9800
Epoch 046 batch 00001: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.5525 AR 0.8550
Epoch 046 batch 00002: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6463 AR 0.8550
Epoch 046 batch 00003: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.6547 AR 0.9467
Epoch 046 batch 00004: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0003 AP 0.8231 AR 0.9750
Epoch 046 batch 00005: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0004 AP 0.6698 AR 0.9250
Epoch 046 batch 00006: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0002 AP 0.7700 AR 0.9250
Epoch 046 batch 00007: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0002 AP 0.7733 AR 0.9800
Epoch 046 batch 00008: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6344 AR 0.8667
Epoch 046 batch 00009: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6687 AR 0.9800
Epoch 046 batch 00010: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0005 AP 0.5517 AR 0.8167
Epoch 047 batch 00001: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.6164 AR 0.8883
Epoch 047 batch 00002: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6408 AR 0.8800
Epoch 047 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7450 AR 0.9750
Epoch 047 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7425 AR 0.9550
Epoch 047 batch 00005: Loss 0.0034 Regression loss 0.0029 Classification loss 0.0005 AP 0.6175 AR 0.9800
Epoch 047 batch 00006: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0004 AP 0.6598 AR 0.9217
Epoch 047 batch 00007: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.6700 AR 0.8667
Epoch 047 batch 00008: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0004 AP 0.7171 AR 0.9500
Epoch 047 batch 00009: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.5667 AR 0.6800
Epoch 047 batch 00010: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.5448 AR 0.7500
Epoch 048 batch 00001: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0005 AP 0.7048 AR 0.8800
Epoch 048 batch 00002: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.7071 AR 0.9800
Epoch 048 batch 00003: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.5585 AR 0.7800
Epoch 048 batch 00004: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6833 AR 0.8750
Epoch 048 batch 00005: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0004 AP 0.5586 AR 0.8417
Epoch 048 batch 00006: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0005 AP 0.7138 AR 0.9017
Epoch 048 batch 00007: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0003 AP 0.7686 AR 0.9217
Epoch 048 batch 00008: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6833 AR 0.9800
Epoch 048 batch 00009: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0003 AP 0.6430 AR 0.9800
Epoch 048 batch 00010: Loss 0.0033 Regression loss 0.0029 Classification loss 0.0004 AP 0.6213 AR 0.8500
Epoch 049 batch 00001: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.5789 AR 0.9000
Epoch 049 batch 00002: Loss 0.0035 Regression loss 0.0032 Classification loss 0.0004 AP 0.7031 AR 1.0000
Epoch 049 batch 00003: Loss 0.0042 Regression loss 0.0037 Classification loss 0.0005 AP 0.5675 AR 0.8500
Epoch 049 batch 00004: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.5798 AR 0.7917
Epoch 049 batch 00005: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.7977 AR 0.9417
Epoch 049 batch 00006: Loss 0.0039 Regression loss 0.0035 Classification loss 0.0004 AP 0.5588 AR 0.7650
Epoch 049 batch 00007: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0004 AP 0.7733 AR 0.9500
Epoch 049 batch 00008: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0003 AP 0.6029 AR 0.9250
Epoch 049 batch 00009: Loss 0.0035 Regression loss 0.0032 Classification loss 0.0002 AP 0.7280 AR 0.9550
Epoch 049 batch 00010: Loss 0.0039 Regression loss 0.0034 Classification loss 0.0005 AP 0.7650 AR 0.9467
Epoch 050 batch 00001: Loss 0.0024 Regression loss 0.0018 Classification loss 0.0006 AP 0.6421 AR 0.9800
Epoch 050 batch 00002: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6154 AR 0.8417
Epoch 050 batch 00003: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.6650 AR 0.8217
Epoch 050 batch 00004: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0004 AP 0.7608 AR 0.9500
Epoch 050 batch 00005: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0004 AP 0.4933 AR 0.6767
Epoch 050 batch 00006: Loss 0.0033 Regression loss 0.0030 Classification loss 0.0003 AP 0.7417 AR 0.9750
Epoch 050 batch 00007: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.6631 AR 0.9500
Epoch 050 batch 00008: Loss 0.0028 Regression loss 0.0022 Classification loss 0.0005 AP 0.7216 AR 0.9800
Epoch 050 batch 00009: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7278 AR 0.9800
Epoch 050 batch 00010: Loss 0.0035 Regression loss 0.0029 Classification loss 0.0006 AP 0.5595 AR 0.7767
Epoch 051 batch 00001: Loss 0.0028 Regression loss 0.0023 Classification loss 0.0005 AP 0.6905 AR 0.9550
Epoch 051 batch 00002: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0002 AP 0.7342 AR 0.9750
Epoch 051 batch 00003: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0003 AP 0.6422 AR 0.9067
Epoch 051 batch 00004: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0004 AP 0.7720 AR 0.9800
Epoch 051 batch 00005: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0005 AP 0.7613 AR 1.0000
Epoch 051 batch 00006: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.6542 AR 0.9500
Epoch 051 batch 00007: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7280 AR 0.9750
Epoch 051 batch 00008: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6750 AR 0.9600
Epoch 051 batch 00009: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6383 AR 0.8750
Epoch 051 batch 00010: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0005 AP 0.5386 AR 0.7550
Epoch 052 batch 00001: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6639 AR 0.9000
Epoch 052 batch 00002: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0005 AP 0.5911 AR 0.8550
Epoch 052 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0004 AP 0.6753 AR 1.0000
Epoch 052 batch 00004: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.4924 AR 0.9500
Epoch 052 batch 00005: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0004 AP 0.7117 AR 0.8350
Epoch 052 batch 00006: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7314 AR 0.9250
Epoch 052 batch 00007: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.6963 AR 0.8800
Epoch 052 batch 00008: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7494 AR 0.9467
Epoch 052 batch 00009: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7975 AR 0.9500
Epoch 052 batch 00010: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0003 AP 0.6331 AR 0.9750
Epoch 053 batch 00001: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7264 AR 0.8750
Epoch 053 batch 00002: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.6500 AR 0.9550
Epoch 053 batch 00003: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.6250 AR 0.8717
Epoch 053 batch 00004: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0004 AP 0.7122 AR 0.9267
Epoch 053 batch 00005: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6592 AR 0.8550
Epoch 053 batch 00006: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6112 AR 0.8767
Epoch 053 batch 00007: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.7014 AR 1.0000
Epoch 053 batch 00008: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.5869 AR 0.8800
Epoch 053 batch 00009: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.5066 AR 0.7467
Epoch 053 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5949 AR 0.8667
Epoch 054 batch 00001: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6233 AR 0.9500
Epoch 054 batch 00002: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6850 AR 0.9550
Epoch 054 batch 00003: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0005 AP 0.6161 AR 0.8467
Epoch 054 batch 00004: Loss 0.0023 Regression loss 0.0018 Classification loss 0.0004 AP 0.5614 AR 0.6550
Epoch 054 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7116 AR 1.0000
Epoch 054 batch 00006: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0004 AP 0.6992 AR 0.8800
Epoch 054 batch 00007: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7763 AR 0.9750
Epoch 054 batch 00008: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.7053 AR 0.9550
Epoch 054 batch 00009: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7158 AR 0.9217
Epoch 054 batch 00010: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.5904 AR 0.9350
Epoch 055 batch 00001: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0002 AP 0.6508 AR 0.8667
Epoch 055 batch 00002: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.6933 AR 0.9350
Epoch 055 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0002 AP 0.6720 AR 0.9350
Epoch 055 batch 00004: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.5678 AR 0.9417
Epoch 055 batch 00005: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7035 AR 0.8550
Epoch 055 batch 00006: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0004 AP 0.6606 AR 0.8550
Epoch 055 batch 00007: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7300 AR 0.9417
Epoch 055 batch 00008: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5467 AR 0.7333
Epoch 055 batch 00009: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.7171 AR 0.9500
Epoch 055 batch 00010: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0005 AP 0.5842 AR 0.7900
Epoch 056 batch 00001: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.6983 AR 0.9400
Epoch 056 batch 00002: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0004 AP 0.7740 AR 0.9467
Epoch 056 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6183 AR 0.9000
Epoch 056 batch 00004: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7117 AR 0.9800
Epoch 056 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.8217 AR 0.9800
Epoch 056 batch 00006: Loss 0.0028 Regression loss 0.0022 Classification loss 0.0006 AP 0.6889 AR 0.9800
Epoch 056 batch 00007: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0005 AP 0.5881 AR 0.8000
Epoch 056 batch 00008: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.7350 AR 0.9750
Epoch 056 batch 00009: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.5325 AR 0.7000
Epoch 056 batch 00010: Loss 0.0034 Regression loss 0.0030 Classification loss 0.0003 AP 0.6739 AR 0.8917
Epoch 057 batch 00001: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7983 AR 0.9550
Epoch 057 batch 00002: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0004 AP 0.6333 AR 0.9800
Epoch 057 batch 00003: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.6833 AR 0.9167
Epoch 057 batch 00004: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.8298 AR 0.9750
Epoch 057 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7914 AR 0.9500
Epoch 057 batch 00006: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0004 AP 0.6788 AR 0.9550
Epoch 057 batch 00007: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0005 AP 0.6967 AR 0.8800
Epoch 057 batch 00008: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.5675 AR 0.9350
Epoch 057 batch 00009: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.4705 AR 0.6467
Epoch 057 batch 00010: Loss 0.0037 Regression loss 0.0033 Classification loss 0.0004 AP 0.5767 AR 0.8750
Epoch 058 batch 00001: Loss 0.0031 Regression loss 0.0026 Classification loss 0.0004 AP 0.5129 AR 0.6900
Epoch 058 batch 00002: Loss 0.0028 Regression loss 0.0023 Classification loss 0.0005 AP 0.7425 AR 0.9600
Epoch 058 batch 00003: Loss 0.0041 Regression loss 0.0038 Classification loss 0.0003 AP 0.7381 AR 0.9300
Epoch 058 batch 00004: Loss 0.0035 Regression loss 0.0032 Classification loss 0.0003 AP 0.4513 AR 0.5800
Epoch 058 batch 00005: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.5455 AR 0.9000
Epoch 058 batch 00006: Loss 0.0034 Regression loss 0.0029 Classification loss 0.0005 AP 0.6767 AR 0.8050
Epoch 058 batch 00007: Loss 0.0039 Regression loss 0.0036 Classification loss 0.0004 AP 0.5383 AR 0.9600
Epoch 058 batch 00008: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0003 AP 0.7817 AR 1.0000
Epoch 058 batch 00009: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.6838 AR 0.9467
Epoch 058 batch 00010: Loss 0.0043 Regression loss 0.0040 Classification loss 0.0003 AP 0.4792 AR 0.7333
Epoch 059 batch 00001: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0003 AP 0.7567 AR 0.8800
Epoch 059 batch 00002: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0005 AP 0.6942 AR 0.9000
Epoch 059 batch 00003: Loss 0.0033 Regression loss 0.0031 Classification loss 0.0002 AP 0.5273 AR 0.8250
Epoch 059 batch 00004: Loss 0.0045 Regression loss 0.0042 Classification loss 0.0003 AP 0.6381 AR 0.9333
Epoch 059 batch 00005: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.5596 AR 0.8850
Epoch 059 batch 00006: Loss 0.0040 Regression loss 0.0035 Classification loss 0.0005 AP 0.6072 AR 0.7800
Epoch 059 batch 00007: Loss 0.0040 Regression loss 0.0037 Classification loss 0.0003 AP 0.6100 AR 0.8000
Epoch 059 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7558 AR 0.9417
Epoch 059 batch 00009: Loss 0.0040 Regression loss 0.0037 Classification loss 0.0003 AP 0.5942 AR 0.8750
Epoch 059 batch 00010: Loss 0.0060 Regression loss 0.0055 Classification loss 0.0005 AP 0.7306 AR 0.9600
Epoch 060 batch 00001: Loss 0.0034 Regression loss 0.0031 Classification loss 0.0002 AP 0.5716 AR 0.8250
Epoch 060 batch 00002: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.5364 AR 0.8000
Epoch 060 batch 00003: Loss 0.0055 Regression loss 0.0051 Classification loss 0.0004 AP 0.6647 AR 0.8800
Epoch 060 batch 00004: Loss 0.0035 Regression loss 0.0029 Classification loss 0.0006 AP 0.7506 AR 0.8800
Epoch 060 batch 00005: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.5250 AR 0.7667
Epoch 060 batch 00006: Loss 0.0046 Regression loss 0.0043 Classification loss 0.0003 AP 0.7450 AR 1.0000
Epoch 060 batch 00007: Loss 0.0034 Regression loss 0.0031 Classification loss 0.0004 AP 0.6019 AR 0.8667
Epoch 060 batch 00008: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.5775 AR 0.9300
Epoch 060 batch 00009: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7739 AR 0.9750
Epoch 060 batch 00010: Loss 0.0033 Regression loss 0.0029 Classification loss 0.0004 AP 0.7405 AR 0.9500
Epoch 061 batch 00001: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.6401 AR 0.9500
Epoch 061 batch 00002: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.8050 AR 0.9800
Epoch 061 batch 00003: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.5506 AR 0.8083
Epoch 061 batch 00004: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6667 AR 0.9750
Epoch 061 batch 00005: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0003 AP 0.6617 AR 0.9000
Epoch 061 batch 00006: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0005 AP 0.7622 AR 0.9800
Epoch 061 batch 00007: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.6517 AR 0.9800
Epoch 061 batch 00008: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0003 AP 0.7667 AR 0.9500
Epoch 061 batch 00009: Loss 0.0032 Regression loss 0.0027 Classification loss 0.0005 AP 0.6431 AR 0.8700
Epoch 061 batch 00010: Loss 0.0026 Regression loss 0.0020 Classification loss 0.0006 AP 0.7800 AR 0.8550
Epoch 062 batch 00001: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.7673 AR 0.9550
Epoch 062 batch 00002: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0004 AP 0.6700 AR 0.9667
Epoch 062 batch 00003: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.5135 AR 0.9150
Epoch 062 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7513 AR 0.9550
Epoch 062 batch 00005: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.6408 AR 0.8417
Epoch 062 batch 00006: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6067 AR 0.9750
Epoch 062 batch 00007: Loss 0.0026 Regression loss 0.0019 Classification loss 0.0007 AP 0.7648 AR 0.9550
Epoch 062 batch 00008: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6395 AR 0.7600
Epoch 062 batch 00009: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6425 AR 0.8250
Epoch 062 batch 00010: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.6650 AR 0.9000
Epoch 063 batch 00001: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0004 AP 0.7181 AR 1.0000
Epoch 063 batch 00002: Loss 0.0028 Regression loss 0.0022 Classification loss 0.0006 AP 0.5850 AR 0.7350
Epoch 063 batch 00003: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0005 AP 0.7594 AR 0.8850
Epoch 063 batch 00004: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.5808 AR 0.8217
Epoch 063 batch 00005: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.6929 AR 0.9600
Epoch 063 batch 00006: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.8006 AR 1.0000
Epoch 063 batch 00007: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6761 AR 0.9300
Epoch 063 batch 00008: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.8139 AR 0.9667
Epoch 063 batch 00009: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6875 AR 0.9667
Epoch 063 batch 00010: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0003 AP 0.6311 AR 0.9750
Epoch 064 batch 00001: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6939 AR 0.9000
Epoch 064 batch 00002: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.7383 AR 0.9550
Epoch 064 batch 00003: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6625 AR 0.9217
Epoch 064 batch 00004: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0003 AP 0.8404 AR 0.9750
Epoch 064 batch 00005: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.6530 AR 0.9000
Epoch 064 batch 00006: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5375 AR 0.8800
Epoch 064 batch 00007: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0003 AP 0.5122 AR 0.7800
Epoch 064 batch 00008: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.7475 AR 0.8500
Epoch 064 batch 00009: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7625 AR 1.0000
Epoch 064 batch 00010: Loss 0.0029 Regression loss 0.0023 Classification loss 0.0006 AP 0.6505 AR 0.9017
Epoch 065 batch 00001: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0002 AP 0.7467 AR 0.9333
Epoch 065 batch 00002: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6758 AR 0.9750
Epoch 065 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.5903 AR 0.9000
Epoch 065 batch 00004: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.7060 AR 0.9667
Epoch 065 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7549 AR 0.9750
Epoch 065 batch 00006: Loss 0.0023 Regression loss 0.0018 Classification loss 0.0005 AP 0.5932 AR 0.8400
Epoch 065 batch 00007: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.7563 AR 0.9600
Epoch 065 batch 00008: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.6600 AR 0.8500
Epoch 065 batch 00009: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6631 AR 0.7800
Epoch 065 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6231 AR 0.8417
Epoch 066 batch 00001: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6817 AR 0.9400
Epoch 066 batch 00002: Loss 0.0024 Regression loss 0.0018 Classification loss 0.0006 AP 0.5031 AR 0.8350
Epoch 066 batch 00003: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0003 AP 0.6783 AR 0.8750
Epoch 066 batch 00004: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6035 AR 1.0000
Epoch 066 batch 00005: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.8550 AR 0.9800
Epoch 066 batch 00006: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6713 AR 0.9300
Epoch 066 batch 00007: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6527 AR 0.8083
Epoch 066 batch 00008: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6306 AR 0.8350
Epoch 066 batch 00009: Loss 0.0023 Regression loss 0.0018 Classification loss 0.0004 AP 0.6702 AR 0.8550
Epoch 066 batch 00010: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6554 AR 0.9267
Epoch 067 batch 00001: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.5819 AR 0.8300
Epoch 067 batch 00002: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7533 AR 0.9000
Epoch 067 batch 00003: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.5991 AR 0.8900
Epoch 067 batch 00004: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0004 AP 0.5806 AR 0.8483
Epoch 067 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0004 AP 0.7737 AR 0.9417
Epoch 067 batch 00006: Loss 0.0030 Regression loss 0.0025 Classification loss 0.0004 AP 0.6155 AR 0.9217
Epoch 067 batch 00007: Loss 0.0043 Regression loss 0.0040 Classification loss 0.0003 AP 0.5550 AR 0.8167
Epoch 067 batch 00008: Loss 0.0035 Regression loss 0.0033 Classification loss 0.0003 AP 0.6933 AR 0.8550
Epoch 067 batch 00009: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5911 AR 0.9500
Epoch 067 batch 00010: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0004 AP 0.7433 AR 0.9500
Epoch 068 batch 00001: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0002 AP 0.7238 AR 0.9800
Epoch 068 batch 00002: Loss 0.0021 Regression loss 0.0016 Classification loss 0.0005 AP 0.5419 AR 0.8800
Epoch 068 batch 00003: Loss 0.0034 Regression loss 0.0031 Classification loss 0.0004 AP 0.6571 AR 0.8267
Epoch 068 batch 00004: Loss 0.0035 Regression loss 0.0032 Classification loss 0.0003 AP 0.8606 AR 1.0000
Epoch 068 batch 00005: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6405 AR 0.9050
Epoch 068 batch 00006: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.5300 AR 0.7800
Epoch 068 batch 00007: Loss 0.0041 Regression loss 0.0039 Classification loss 0.0002 AP 0.6817 AR 0.9500
Epoch 068 batch 00008: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.5547 AR 0.9417
Epoch 068 batch 00009: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.7500 AR 0.9500
Epoch 068 batch 00010: Loss 0.0031 Regression loss 0.0026 Classification loss 0.0006 AP 0.8433 AR 0.9550
Epoch 069 batch 00001: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0005 AP 0.6423 AR 0.9800
Epoch 069 batch 00002: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0003 AP 0.7198 AR 0.9750
Epoch 069 batch 00003: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0003 AP 0.5588 AR 0.9250
Epoch 069 batch 00004: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0002 AP 0.7496 AR 0.8750
Epoch 069 batch 00005: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.5900 AR 0.8717
Epoch 069 batch 00006: Loss 0.0036 Regression loss 0.0032 Classification loss 0.0004 AP 0.6056 AR 0.8150
Epoch 069 batch 00007: Loss 0.0032 Regression loss 0.0027 Classification loss 0.0005 AP 0.7054 AR 0.8667
Epoch 069 batch 00008: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.7112 AR 0.9400
Epoch 069 batch 00009: Loss 0.0034 Regression loss 0.0031 Classification loss 0.0003 AP 0.6148 AR 0.8800
Epoch 069 batch 00010: Loss 0.0034 Regression loss 0.0030 Classification loss 0.0004 AP 0.6717 AR 0.8467
Epoch 070 batch 00001: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.7433 AR 0.9300
Epoch 070 batch 00002: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.7272 AR 1.0000
Epoch 070 batch 00003: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0004 AP 0.4944 AR 0.7550
Epoch 070 batch 00004: Loss 0.0035 Regression loss 0.0029 Classification loss 0.0006 AP 0.6567 AR 0.8100
Epoch 070 batch 00005: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.6137 AR 0.9750
Epoch 070 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0004 AP 0.6727 AR 0.9333
Epoch 070 batch 00007: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0004 AP 0.6850 AR 0.8800
Epoch 070 batch 00008: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6905 AR 0.9600
Epoch 070 batch 00009: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0002 AP 0.7805 AR 0.9667
Epoch 070 batch 00010: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0004 AP 0.6955 AR 0.8800
Epoch 071 batch 00001: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7050 AR 0.9000
Epoch 071 batch 00002: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.6273 AR 0.8550
Epoch 071 batch 00003: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.6289 AR 1.0000
Epoch 071 batch 00004: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7231 AR 1.0000
Epoch 071 batch 00005: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0004 AP 0.5054 AR 0.7933
Epoch 071 batch 00006: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.6005 AR 0.8550
Epoch 071 batch 00007: Loss 0.0044 Regression loss 0.0041 Classification loss 0.0003 AP 0.7483 AR 0.9250
Epoch 071 batch 00008: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.6223 AR 0.8617
Epoch 071 batch 00009: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7214 AR 0.8083
Epoch 071 batch 00010: Loss 0.0042 Regression loss 0.0038 Classification loss 0.0004 AP 0.6944 AR 0.9750
Epoch 072 batch 00001: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.6058 AR 0.8550
Epoch 072 batch 00002: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.5667 AR 0.9500
Epoch 072 batch 00003: Loss 0.0038 Regression loss 0.0033 Classification loss 0.0006 AP 0.6083 AR 0.7600
Epoch 072 batch 00004: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7169 AR 0.9667
Epoch 072 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7933 AR 1.0000
Epoch 072 batch 00006: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.7139 AR 0.9500
Epoch 072 batch 00007: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.4812 AR 0.8267
Epoch 072 batch 00008: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.7503 AR 0.9200
Epoch 072 batch 00009: Loss 0.0032 Regression loss 0.0027 Classification loss 0.0005 AP 0.6884 AR 0.9600
Epoch 072 batch 00010: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6500 AR 0.8250
Epoch 073 batch 00001: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7850 AR 0.9417
Epoch 073 batch 00002: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.6373 AR 0.8500
Epoch 073 batch 00003: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6089 AR 0.9217
Epoch 073 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0004 AP 0.5850 AR 0.8550
Epoch 073 batch 00005: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0005 AP 0.6764 AR 0.9750
Epoch 073 batch 00006: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.7023 AR 0.8817
Epoch 073 batch 00007: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6886 AR 0.8267
Epoch 073 batch 00008: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.5979 AR 0.7733
Epoch 073 batch 00009: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6598 AR 0.9000
Epoch 073 batch 00010: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7614 AR 1.0000
Epoch 074 batch 00001: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.7250 AR 0.9600
Epoch 074 batch 00002: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.7631 AR 0.9250
Epoch 074 batch 00003: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.7446 AR 1.0000
Epoch 074 batch 00004: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0003 AP 0.7093 AR 0.9600
Epoch 074 batch 00005: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.4014 AR 0.6467
Epoch 074 batch 00006: Loss 0.0028 Regression loss 0.0023 Classification loss 0.0004 AP 0.5814 AR 0.7667
Epoch 074 batch 00007: Loss 0.0020 Regression loss 0.0015 Classification loss 0.0004 AP 0.6867 AR 0.9000
Epoch 074 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.6731 AR 0.8750
Epoch 074 batch 00009: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6252 AR 0.8550
Epoch 074 batch 00010: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.5683 AR 0.8350
Epoch 075 batch 00001: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.7612 AR 0.9550
Epoch 075 batch 00002: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0004 AP 0.7447 AR 1.0000
Epoch 075 batch 00003: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0005 AP 0.5816 AR 0.8900
Epoch 075 batch 00004: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0003 AP 0.6596 AR 0.9067
Epoch 075 batch 00005: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0002 AP 0.7300 AR 0.8800
Epoch 075 batch 00006: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6546 AR 0.8800
Epoch 075 batch 00007: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.5100 AR 0.8500
Epoch 075 batch 00008: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0003 AP 0.7100 AR 0.9667
Epoch 075 batch 00009: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7833 AR 0.9300
Epoch 075 batch 00010: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6764 AR 0.9000
Epoch 076 batch 00001: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.5688 AR 0.7667
Epoch 076 batch 00002: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.7558 AR 0.9750
Epoch 076 batch 00003: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6883 AR 1.0000
Epoch 076 batch 00004: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0003 AP 0.7050 AR 0.9750
Epoch 076 batch 00005: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.7017 AR 0.9800
Epoch 076 batch 00006: Loss 0.0028 Regression loss 0.0023 Classification loss 0.0005 AP 0.6461 AR 0.8800
Epoch 076 batch 00007: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0005 AP 0.6933 AR 0.9600
Epoch 076 batch 00008: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0004 AP 0.5725 AR 0.9000
Epoch 076 batch 00009: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6350 AR 0.8667
Epoch 076 batch 00010: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0002 AP 0.7135 AR 0.9800
Epoch 077 batch 00001: Loss 0.0020 Regression loss 0.0015 Classification loss 0.0005 AP 0.5851 AR 0.9350
Epoch 077 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6994 AR 0.9300
Epoch 077 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7127 AR 1.0000
Epoch 077 batch 00004: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.7221 AR 0.9050
Epoch 077 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6756 AR 0.9417
Epoch 077 batch 00006: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7433 AR 0.8667
Epoch 077 batch 00007: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.6142 AR 0.8250
Epoch 077 batch 00008: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6437 AR 0.8150
Epoch 077 batch 00009: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7292 AR 0.9000
Epoch 077 batch 00010: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6871 AR 0.9800
Epoch 078 batch 00001: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0005 AP 0.5871 AR 0.9000
Epoch 078 batch 00002: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.6464 AR 0.9750
Epoch 078 batch 00003: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.7519 AR 1.0000
Epoch 078 batch 00004: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.7150 AR 0.8167
Epoch 078 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6320 AR 0.8350
Epoch 078 batch 00006: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.7844 AR 0.9550
Epoch 078 batch 00007: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7002 AR 0.9350
Epoch 078 batch 00008: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6130 AR 0.8350
Epoch 078 batch 00009: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0002 AP 0.6675 AR 0.9000
Epoch 078 batch 00010: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6134 AR 0.9350
Epoch 079 batch 00001: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6187 AR 0.8350
Epoch 079 batch 00002: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.7650 AR 0.9800
Epoch 079 batch 00003: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7969 AR 1.0000
Epoch 079 batch 00004: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6223 AR 0.8667
Epoch 079 batch 00005: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0004 AP 0.6731 AR 0.8750
Epoch 079 batch 00006: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0004 AP 0.6908 AR 0.9800
Epoch 079 batch 00007: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.5871 AR 0.8050
Epoch 079 batch 00008: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.6458 AR 0.9600
Epoch 079 batch 00009: Loss 0.0025 Regression loss 0.0019 Classification loss 0.0006 AP 0.5631 AR 0.8000
Epoch 079 batch 00010: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0003 AP 0.6865 AR 0.9350
Epoch 080 batch 00001: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7431 AR 1.0000
Epoch 080 batch 00002: Loss 0.0021 Regression loss 0.0016 Classification loss 0.0005 AP 0.4740 AR 0.7750
Epoch 080 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6742 AR 0.9550
Epoch 080 batch 00004: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.7778 AR 0.9800
Epoch 080 batch 00005: Loss 0.0023 Regression loss 0.0018 Classification loss 0.0005 AP 0.6695 AR 0.9150
Epoch 080 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7194 AR 0.9600
Epoch 080 batch 00007: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.7121 AR 1.0000
Epoch 080 batch 00008: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.7717 AR 0.9000
Epoch 080 batch 00009: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.5781 AR 0.8083
Epoch 080 batch 00010: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.7014 AR 0.9300
Epoch 081 batch 00001: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6719 AR 0.9667
Epoch 081 batch 00002: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7598 AR 1.0000
Epoch 081 batch 00003: Loss 0.0030 Regression loss 0.0024 Classification loss 0.0005 AP 0.6792 AR 0.9800
Epoch 081 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6448 AR 0.8267
Epoch 081 batch 00005: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.5833 AR 0.8450
Epoch 081 batch 00006: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.6318 AR 0.8500
Epoch 081 batch 00007: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6283 AR 0.9400
Epoch 081 batch 00008: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7571 AR 0.9417
Epoch 081 batch 00009: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6859 AR 0.9550
Epoch 081 batch 00010: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.7906 AR 0.9000
Epoch 082 batch 00001: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0002 AP 0.6808 AR 0.9750
Epoch 082 batch 00002: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.6241 AR 0.9400
Epoch 082 batch 00003: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.6930 AR 0.9600
Epoch 082 batch 00004: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7183 AR 0.9300
Epoch 082 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6639 AR 0.8750
Epoch 082 batch 00006: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7088 AR 1.0000
Epoch 082 batch 00007: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.6919 AR 0.9600
Epoch 082 batch 00008: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.5964 AR 0.9000
Epoch 082 batch 00009: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6267 AR 0.9050
Epoch 082 batch 00010: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0004 AP 0.5931 AR 0.7717
Epoch 083 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7867 AR 1.0000
Epoch 083 batch 00002: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7380 AR 0.9550
Epoch 083 batch 00003: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.5314 AR 0.8150
Epoch 083 batch 00004: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.5717 AR 0.9600
Epoch 083 batch 00005: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7356 AR 1.0000
Epoch 083 batch 00006: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.7589 AR 0.9750
Epoch 083 batch 00007: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6356 AR 0.8750
Epoch 083 batch 00008: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6383 AR 0.8750
Epoch 083 batch 00009: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6784 AR 0.9550
Epoch 083 batch 00010: Loss 0.0035 Regression loss 0.0028 Classification loss 0.0007 AP 0.6517 AR 0.7300
Epoch 084 batch 00001: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7300 AR 0.9667
Epoch 084 batch 00002: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.6742 AR 0.9417
Epoch 084 batch 00003: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7538 AR 0.9550
Epoch 084 batch 00004: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6215 AR 0.8350
Epoch 084 batch 00005: Loss 0.0041 Regression loss 0.0038 Classification loss 0.0003 AP 0.6167 AR 0.8550
Epoch 084 batch 00006: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7129 AR 1.0000
Epoch 084 batch 00007: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.7847 AR 0.9800
Epoch 084 batch 00008: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0004 AP 0.5954 AR 0.8017
Epoch 084 batch 00009: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7067 AR 0.9167
Epoch 084 batch 00010: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6110 AR 0.8600
Epoch 085 batch 00001: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.7550 AR 0.8850
Epoch 085 batch 00002: Loss 0.0035 Regression loss 0.0031 Classification loss 0.0003 AP 0.7133 AR 0.9750
Epoch 085 batch 00003: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.7008 AR 0.9267
Epoch 085 batch 00004: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0002 AP 0.6342 AR 0.8500
Epoch 085 batch 00005: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.5775 AR 0.8717
Epoch 085 batch 00006: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5488 AR 0.7500
Epoch 085 batch 00007: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.6500 AR 0.8800
Epoch 085 batch 00008: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.7517 AR 0.8550
Epoch 085 batch 00009: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6723 AR 0.8400
Epoch 085 batch 00010: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6106 AR 0.9467
Epoch 086 batch 00001: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0004 AP 0.7431 AR 0.9100
Epoch 086 batch 00002: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6246 AR 0.8550
Epoch 086 batch 00003: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.7895 AR 0.9750
Epoch 086 batch 00004: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.7047 AR 0.8950
Epoch 086 batch 00005: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5767 AR 0.8000
Epoch 086 batch 00006: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7929 AR 0.9600
Epoch 086 batch 00007: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0004 AP 0.6858 AR 0.8750
Epoch 086 batch 00008: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.5783 AR 0.9000
Epoch 086 batch 00009: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6058 AR 0.8500
Epoch 086 batch 00010: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.5804 AR 0.8217
Epoch 087 batch 00001: Loss 0.0034 Regression loss 0.0030 Classification loss 0.0004 AP 0.6992 AR 0.9050
Epoch 087 batch 00002: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7681 AR 0.9467
Epoch 087 batch 00003: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0004 AP 0.7716 AR 0.9600
Epoch 087 batch 00004: Loss 0.0030 Regression loss 0.0028 Classification loss 0.0002 AP 0.6600 AR 0.9550
Epoch 087 batch 00005: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.5989 AR 0.9000
Epoch 087 batch 00006: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.6441 AR 0.8500
Epoch 087 batch 00007: Loss 0.0039 Regression loss 0.0036 Classification loss 0.0003 AP 0.6342 AR 0.9000
Epoch 087 batch 00008: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6225 AR 0.8667
Epoch 087 batch 00009: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.5644 AR 0.8300
Epoch 087 batch 00010: Loss 0.0047 Regression loss 0.0045 Classification loss 0.0003 AP 0.6527 AR 0.8750
Epoch 088 batch 00001: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.8017 AR 1.0000
Epoch 088 batch 00002: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.5123 AR 0.8917
Epoch 088 batch 00003: Loss 0.0053 Regression loss 0.0051 Classification loss 0.0002 AP 0.7725 AR 0.9800
Epoch 088 batch 00004: Loss 0.0031 Regression loss 0.0026 Classification loss 0.0005 AP 0.5181 AR 0.6917
Epoch 088 batch 00005: Loss 0.0036 Regression loss 0.0031 Classification loss 0.0005 AP 0.6246 AR 0.9150
Epoch 088 batch 00006: Loss 0.0044 Regression loss 0.0041 Classification loss 0.0003 AP 0.5470 AR 0.8017
Epoch 088 batch 00007: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0002 AP 0.6755 AR 0.9083
Epoch 088 batch 00008: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0005 AP 0.7350 AR 0.9400
Epoch 088 batch 00009: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.7075 AR 0.9500
Epoch 088 batch 00010: Loss 0.0027 Regression loss 0.0021 Classification loss 0.0006 AP 0.6350 AR 0.7433
Epoch 089 batch 00001: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0002 AP 0.7501 AR 0.9750
Epoch 089 batch 00002: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.5738 AR 0.8000
Epoch 089 batch 00003: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0005 AP 0.5830 AR 0.8467
Epoch 089 batch 00004: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0003 AP 0.7523 AR 0.9100
Epoch 089 batch 00005: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6967 AR 0.8800
Epoch 089 batch 00006: Loss 0.0030 Regression loss 0.0025 Classification loss 0.0005 AP 0.6433 AR 0.9000
Epoch 089 batch 00007: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0003 AP 0.6964 AR 0.8850
Epoch 089 batch 00008: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7238 AR 0.9800
Epoch 089 batch 00009: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.6336 AR 0.8550
Epoch 089 batch 00010: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0004 AP 0.6500 AR 0.9550
Epoch 090 batch 00001: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7013 AR 0.9750
Epoch 090 batch 00002: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7175 AR 0.8333
Epoch 090 batch 00003: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0003 AP 0.7100 AR 0.8417
Epoch 090 batch 00004: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0003 AP 0.8006 AR 0.9000
Epoch 090 batch 00005: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.5325 AR 0.8050
Epoch 090 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0004 AP 0.6810 AR 0.9600
Epoch 090 batch 00007: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7305 AR 1.0000
Epoch 090 batch 00008: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.7333 AR 0.9000
Epoch 090 batch 00009: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.6797 AR 0.9500
Epoch 090 batch 00010: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0004 AP 0.7181 AR 0.9550
Epoch 091 batch 00001: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7461 AR 0.9800
Epoch 091 batch 00002: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7264 AR 0.9417
Epoch 091 batch 00003: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.8036 AR 1.0000
Epoch 091 batch 00004: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0003 AP 0.7614 AR 0.9600
Epoch 091 batch 00005: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.5925 AR 0.8550
Epoch 091 batch 00006: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0003 AP 0.7055 AR 0.9550
Epoch 091 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6060 AR 0.9000
Epoch 091 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.6778 AR 0.9050
Epoch 091 batch 00009: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0004 AP 0.6347 AR 0.9000
Epoch 091 batch 00010: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.7083 AR 0.9350
Epoch 092 batch 00001: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7763 AR 0.9600
Epoch 092 batch 00002: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.6471 AR 0.9467
Epoch 092 batch 00003: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7838 AR 0.9550
Epoch 092 batch 00004: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0003 AP 0.5319 AR 0.7600
Epoch 092 batch 00005: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.4825 AR 0.7667
Epoch 092 batch 00006: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6933 AR 0.8750
Epoch 092 batch 00007: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0003 AP 0.7372 AR 0.9417
Epoch 092 batch 00008: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.5505 AR 0.8400
Epoch 092 batch 00009: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.8164 AR 0.9750
Epoch 092 batch 00010: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6683 AR 0.9750
Epoch 093 batch 00001: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.7567 AR 0.9417
Epoch 093 batch 00002: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.6237 AR 0.7950
Epoch 093 batch 00003: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7230 AR 0.9500
Epoch 093 batch 00004: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.8362 AR 1.0000
Epoch 093 batch 00005: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6122 AR 0.8550
Epoch 093 batch 00006: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.5501 AR 0.8300
Epoch 093 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7175 AR 0.9667
Epoch 093 batch 00008: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.7233 AR 0.9800
Epoch 093 batch 00009: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0004 AP 0.6489 AR 0.9550
Epoch 093 batch 00010: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.6472 AR 1.0000
Epoch 094 batch 00001: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0002 AP 0.7750 AR 1.0000
Epoch 094 batch 00002: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.5484 AR 0.8883
Epoch 094 batch 00003: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7078 AR 0.9350
Epoch 094 batch 00004: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.7489 AR 0.9000
Epoch 094 batch 00005: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7136 AR 0.8750
Epoch 094 batch 00006: Loss 0.0019 Regression loss 0.0014 Classification loss 0.0004 AP 0.6912 AR 0.8950
Epoch 094 batch 00007: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6505 AR 0.9500
Epoch 094 batch 00008: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6600 AR 0.8550
Epoch 094 batch 00009: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.5571 AR 0.7550
Epoch 094 batch 00010: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7275 AR 0.9550
Epoch 095 batch 00001: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0003 AP 0.7151 AR 0.9550
Epoch 095 batch 00002: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.5638 AR 0.7350
Epoch 095 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6855 AR 0.9750
Epoch 095 batch 00004: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0003 AP 0.7614 AR 1.0000
Epoch 095 batch 00005: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.7192 AR 0.9550
Epoch 095 batch 00006: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.6798 AR 0.9500
Epoch 095 batch 00007: Loss 0.0021 Regression loss 0.0016 Classification loss 0.0005 AP 0.7038 AR 0.8800
Epoch 095 batch 00008: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.6853 AR 0.9800
Epoch 095 batch 00009: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6276 AR 0.9267
Epoch 095 batch 00010: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6611 AR 0.8467
Epoch 096 batch 00001: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7558 AR 0.9500
Epoch 096 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7312 AR 1.0000
Epoch 096 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.4883 AR 0.7000
Epoch 096 batch 00004: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.6766 AR 0.9400
Epoch 096 batch 00005: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.8321 AR 0.9750
Epoch 096 batch 00006: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0003 AP 0.5827 AR 0.9083
Epoch 096 batch 00007: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0004 AP 0.7083 AR 1.0000
Epoch 096 batch 00008: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6944 AR 0.8600
Epoch 096 batch 00009: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6533 AR 0.9550
Epoch 096 batch 00010: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.7050 AR 0.9250
Epoch 097 batch 00001: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6588 AR 0.9000
Epoch 097 batch 00002: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.6873 AR 0.9750
Epoch 097 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7458 AR 0.9750
Epoch 097 batch 00004: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0004 AP 0.5583 AR 0.8000
Epoch 097 batch 00005: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0004 AP 0.7445 AR 0.9017
Epoch 097 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.8130 AR 1.0000
Epoch 097 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7100 AR 0.9500
Epoch 097 batch 00008: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.5508 AR 0.8800
Epoch 097 batch 00009: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0004 AP 0.6650 AR 0.8017
Epoch 097 batch 00010: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7808 AR 0.9800
Epoch 098 batch 00001: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7187 AR 0.9350
Epoch 098 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6450 AR 0.8750
Epoch 098 batch 00003: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.6825 AR 0.9667
Epoch 098 batch 00004: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.5348 AR 0.7667
Epoch 098 batch 00005: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7425 AR 0.9750
Epoch 098 batch 00006: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.7071 AR 1.0000
Epoch 098 batch 00007: Loss 0.0023 Regression loss 0.0017 Classification loss 0.0005 AP 0.5746 AR 0.8350
Epoch 098 batch 00008: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7721 AR 0.9600
Epoch 098 batch 00009: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.5206 AR 0.8500
Epoch 098 batch 00010: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7388 AR 0.9550
Epoch 099 batch 00001: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0003 AP 0.7425 AR 0.9267
Epoch 099 batch 00002: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7139 AR 1.0000
Epoch 099 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7344 AR 1.0000
Epoch 099 batch 00004: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.7608 AR 0.9350
Epoch 099 batch 00005: Loss 0.0023 Regression loss 0.0018 Classification loss 0.0004 AP 0.6727 AR 0.9550
Epoch 099 batch 00006: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6077 AR 0.8300
Epoch 099 batch 00007: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6492 AR 0.8967
Epoch 099 batch 00008: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.6348 AR 0.8500
Epoch 099 batch 00009: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.6392 AR 0.9000
Epoch 099 batch 00010: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.6196 AR 0.8417
Epoch 100 batch 00001: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.7148 AR 0.9267
Epoch 100 batch 00002: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7058 AR 0.9800
Epoch 100 batch 00003: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7209 AR 0.9467
Epoch 100 batch 00004: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.5854 AR 0.8100
Epoch 100 batch 00005: Loss 0.0021 Regression loss 0.0016 Classification loss 0.0005 AP 0.6508 AR 0.8800
Epoch 100 batch 00006: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7355 AR 0.9750
Epoch 100 batch 00007: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.7072 AR 0.9750
Epoch 100 batch 00008: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.5867 AR 0.7750
Epoch 100 batch 00009: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7378 AR 0.9550
Epoch 100 batch 00010: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0003 AP 0.7161 AR 0.9800
Epoch 101 batch 00001: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.5475 AR 0.8750
Epoch 101 batch 00002: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0003 AP 0.7550 AR 0.9550
Epoch 101 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6350 AR 0.8500
Epoch 101 batch 00004: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7933 AR 0.9800
Epoch 101 batch 00005: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.6242 AR 0.7600
Epoch 101 batch 00006: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6344 AR 0.8600
Epoch 101 batch 00007: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6963 AR 0.9600
Epoch 101 batch 00008: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0002 AP 0.5912 AR 0.9750
Epoch 101 batch 00009: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.7538 AR 0.9600
Epoch 101 batch 00010: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6971 AR 0.9417
Epoch 102 batch 00001: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.5073 AR 0.7300
Epoch 102 batch 00002: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0003 AP 0.7714 AR 1.0000
Epoch 102 batch 00003: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6688 AR 0.9667
Epoch 102 batch 00004: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.7202 AR 0.9550
Epoch 102 batch 00005: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7264 AR 0.9750
Epoch 102 batch 00006: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6655 AR 0.9150
Epoch 102 batch 00007: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6350 AR 0.7550
Epoch 102 batch 00008: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.5423 AR 0.8750
Epoch 102 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0003 AP 0.7321 AR 0.9300
Epoch 102 batch 00010: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.8025 AR 0.9500
Epoch 103 batch 00001: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.6722 AR 0.9217
Epoch 103 batch 00002: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.7122 AR 0.8800
Epoch 103 batch 00003: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6308 AR 0.8800
Epoch 103 batch 00004: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7278 AR 0.9300
Epoch 103 batch 00005: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0004 AP 0.4801 AR 0.7550
Epoch 103 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6350 AR 0.8967
Epoch 103 batch 00007: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.7017 AR 0.9500
Epoch 103 batch 00008: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.7561 AR 0.9550
Epoch 103 batch 00009: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6429 AR 0.9000
Epoch 103 batch 00010: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0003 AP 0.7267 AR 0.9750
Epoch 104 batch 00001: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0004 AP 0.6183 AR 0.7800
Epoch 104 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.6042 AR 0.8750
Epoch 104 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0004 AP 0.5938 AR 0.9350
Epoch 104 batch 00004: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.5517 AR 0.8550
Epoch 104 batch 00005: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.6755 AR 0.8800
Epoch 104 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5849 AR 0.9017
Epoch 104 batch 00007: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.8530 AR 0.9750
Epoch 104 batch 00008: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.6783 AR 0.9250
Epoch 104 batch 00009: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7348 AR 0.9550
Epoch 104 batch 00010: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0003 AP 0.6700 AR 0.9300
Epoch 105 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6645 AR 0.9500
Epoch 105 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6921 AR 0.8967
Epoch 105 batch 00003: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0003 AP 0.6661 AR 0.8467
Epoch 105 batch 00004: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.8267 AR 0.9750
Epoch 105 batch 00005: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.5476 AR 0.9550
Epoch 105 batch 00006: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.4592 AR 0.6800
Epoch 105 batch 00007: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6867 AR 0.8600
Epoch 105 batch 00008: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7169 AR 0.8800
Epoch 105 batch 00009: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7239 AR 0.9750
Epoch 105 batch 00010: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6725 AR 1.0000
Epoch 106 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6800 AR 0.8600
Epoch 106 batch 00002: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.6262 AR 0.8550
Epoch 106 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6636 AR 0.9800
Epoch 106 batch 00004: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6753 AR 0.9550
Epoch 106 batch 00005: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.7017 AR 0.9750
Epoch 106 batch 00006: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.7481 AR 0.9550
Epoch 106 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7017 AR 0.9217
Epoch 106 batch 00008: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7239 AR 0.8750
Epoch 106 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.6023 AR 0.9550
Epoch 106 batch 00010: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5989 AR 0.9250
Epoch 107 batch 00001: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6708 AR 0.8667
Epoch 107 batch 00002: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.7286 AR 0.9267
Epoch 107 batch 00003: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.7948 AR 1.0000
Epoch 107 batch 00004: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5036 AR 0.7300
Epoch 107 batch 00005: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7313 AR 0.9150
Epoch 107 batch 00006: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7175 AR 0.8917
Epoch 107 batch 00007: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.6517 AR 0.9467
Epoch 107 batch 00008: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0003 AP 0.5356 AR 0.8750
Epoch 107 batch 00009: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.5394 AR 0.8467
Epoch 107 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6717 AR 0.8750
Epoch 108 batch 00001: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0003 AP 0.5717 AR 0.8417
Epoch 108 batch 00002: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6855 AR 0.9000
Epoch 108 batch 00003: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6158 AR 0.9750
Epoch 108 batch 00004: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.6333 AR 0.9300
Epoch 108 batch 00005: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0004 AP 0.6469 AR 0.8417
Epoch 108 batch 00006: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.6314 AR 0.8500
Epoch 108 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7472 AR 0.9000
Epoch 108 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6326 AR 0.9600
Epoch 108 batch 00009: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.8138 AR 0.9600
Epoch 108 batch 00010: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7083 AR 0.9500
Epoch 109 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7917 AR 1.0000
Epoch 109 batch 00002: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0004 AP 0.6538 AR 0.8217
Epoch 109 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0004 AP 0.5733 AR 0.7300
Epoch 109 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7327 AR 1.0000
Epoch 109 batch 00005: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6594 AR 1.0000
Epoch 109 batch 00006: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0002 AP 0.7483 AR 0.9750
Epoch 109 batch 00007: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.5323 AR 0.8750
Epoch 109 batch 00008: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7508 AR 1.0000
Epoch 109 batch 00009: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6381 AR 0.8800
Epoch 109 batch 00010: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0005 AP 0.6268 AR 0.8350
Epoch 110 batch 00001: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.6450 AR 0.8550
Epoch 110 batch 00002: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0002 AP 0.6847 AR 0.9000
Epoch 110 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7633 AR 0.9800
Epoch 110 batch 00004: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0005 AP 0.7077 AR 0.9350
Epoch 110 batch 00005: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6653 AR 0.9350
Epoch 110 batch 00006: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.7820 AR 0.9750
Epoch 110 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6971 AR 1.0000
Epoch 110 batch 00008: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6326 AR 0.9350
Epoch 110 batch 00009: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0004 AP 0.7098 AR 0.9500
Epoch 110 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5919 AR 0.8667
Epoch 111 batch 00001: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.5350 AR 0.7850
Epoch 111 batch 00002: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0003 AP 0.6975 AR 1.0000
Epoch 111 batch 00003: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7387 AR 0.9400
Epoch 111 batch 00004: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.5921 AR 0.7750
Epoch 111 batch 00005: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.6651 AR 0.8800
Epoch 111 batch 00006: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.6707 AR 0.8083
Epoch 111 batch 00007: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6900 AR 0.9550
Epoch 111 batch 00008: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.5987 AR 0.8750
Epoch 111 batch 00009: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7338 AR 0.9667
Epoch 111 batch 00010: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7550 AR 0.9750
Epoch 112 batch 00001: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.6558 AR 0.9333
Epoch 112 batch 00002: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5661 AR 0.7600
Epoch 112 batch 00003: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0002 AP 0.7867 AR 0.9000
Epoch 112 batch 00004: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0004 AP 0.7214 AR 0.9750
Epoch 112 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.5788 AR 0.8500
Epoch 112 batch 00006: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.8392 AR 0.9800
Epoch 112 batch 00007: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.6889 AR 0.9800
Epoch 112 batch 00008: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0002 AP 0.5836 AR 0.8417
Epoch 112 batch 00009: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.6392 AR 0.9350
Epoch 112 batch 00010: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6113 AR 0.8350
Epoch 113 batch 00001: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.5750 AR 0.9217
Epoch 113 batch 00002: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.7000 AR 0.9100
Epoch 113 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0004 AP 0.6687 AR 0.8667
Epoch 113 batch 00004: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.6150 AR 0.8267
Epoch 113 batch 00005: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7794 AR 0.9350
Epoch 113 batch 00006: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7383 AR 0.9400
Epoch 113 batch 00007: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.5855 AR 0.8250
Epoch 113 batch 00008: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6635 AR 0.9500
Epoch 113 batch 00009: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7817 AR 0.9750
Epoch 113 batch 00010: Loss 0.0033 Regression loss 0.0028 Classification loss 0.0004 AP 0.4162 AR 0.7550
Epoch 114 batch 00001: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.8150 AR 0.9017
Epoch 114 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6306 AR 1.0000
Epoch 114 batch 00003: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0003 AP 0.6886 AR 0.8667
Epoch 114 batch 00004: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6413 AR 0.9750
Epoch 114 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.5278 AR 0.7350
Epoch 114 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6270 AR 0.9000
Epoch 114 batch 00007: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.5723 AR 0.7900
Epoch 114 batch 00008: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6755 AR 0.8800
Epoch 114 batch 00009: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0003 AP 0.7196 AR 0.9300
Epoch 114 batch 00010: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0002 AP 0.7100 AR 1.0000
Epoch 115 batch 00001: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7275 AR 0.9550
Epoch 115 batch 00002: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6588 AR 0.9600
Epoch 115 batch 00003: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0003 AP 0.6800 AR 0.9667
Epoch 115 batch 00004: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.6785 AR 0.8100
Epoch 115 batch 00005: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6931 AR 0.8550
Epoch 115 batch 00006: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0003 AP 0.8400 AR 0.9550
Epoch 115 batch 00007: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6850 AR 0.9083
Epoch 115 batch 00008: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6245 AR 0.8350
Epoch 115 batch 00009: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.5533 AR 0.8300
Epoch 115 batch 00010: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0004 AP 0.6853 AR 0.9133
Epoch 116 batch 00001: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.5350 AR 0.9300
Epoch 116 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.6044 AR 0.9000
Epoch 116 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6442 AR 0.8750
Epoch 116 batch 00004: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6750 AR 0.9500
Epoch 116 batch 00005: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7067 AR 0.8600
Epoch 116 batch 00006: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0004 AP 0.6988 AR 0.8550
Epoch 116 batch 00007: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.8131 AR 0.9550
Epoch 116 batch 00008: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0003 AP 0.6781 AR 0.9417
Epoch 116 batch 00009: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0001 AP 0.8167 AR 1.0000
Epoch 116 batch 00010: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7364 AR 0.9000
Epoch 117 batch 00001: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.5856 AR 0.8600
Epoch 117 batch 00002: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7777 AR 0.9800
Epoch 117 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.4941 AR 0.7883
Epoch 117 batch 00004: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.7373 AR 0.9750
Epoch 117 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7250 AR 0.9750
Epoch 117 batch 00006: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7538 AR 0.9800
Epoch 117 batch 00007: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.5958 AR 0.9333
Epoch 117 batch 00008: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0003 AP 0.7546 AR 1.0000
Epoch 117 batch 00009: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.7273 AR 0.9550
Epoch 117 batch 00010: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7003 AR 1.0000
Epoch 118 batch 00001: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7050 AR 0.9467
Epoch 118 batch 00002: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.7138 AR 0.9000
Epoch 118 batch 00003: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0004 AP 0.7283 AR 0.9750
Epoch 118 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6963 AR 0.9600
Epoch 118 batch 00005: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.5898 AR 0.7750
Epoch 118 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6839 AR 0.9750
Epoch 118 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6050 AR 0.8800
Epoch 118 batch 00008: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.6365 AR 0.9300
Epoch 118 batch 00009: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0005 AP 0.7467 AR 0.8850
Epoch 118 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.6927 AR 0.9667
Epoch 119 batch 00001: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0003 AP 0.6203 AR 0.8950
Epoch 119 batch 00002: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7598 AR 0.9800
Epoch 119 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6317 AR 0.9000
Epoch 119 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6656 AR 0.9417
Epoch 119 batch 00005: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6400 AR 0.9050
Epoch 119 batch 00006: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7939 AR 1.0000
Epoch 119 batch 00007: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6748 AR 0.8400
Epoch 119 batch 00008: Loss 0.0023 Regression loss 0.0022 Classification loss 0.0002 AP 0.7375 AR 1.0000
Epoch 119 batch 00009: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0002 AP 0.6764 AR 0.8750
Epoch 119 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7084 AR 0.9250
Epoch 120 batch 00001: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6870 AR 0.9750
Epoch 120 batch 00002: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6967 AR 0.8800
Epoch 120 batch 00003: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.5273 AR 0.7750
Epoch 120 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6805 AR 0.9300
Epoch 120 batch 00005: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6798 AR 0.8417
Epoch 120 batch 00006: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0003 AP 0.6908 AR 1.0000
Epoch 120 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.8606 AR 0.9800
Epoch 120 batch 00008: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5011 AR 0.8300
Epoch 120 batch 00009: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7892 AR 0.9300
Epoch 120 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6648 AR 0.9800
Epoch 121 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7158 AR 0.9750
Epoch 121 batch 00002: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.4870 AR 0.7550
Epoch 121 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.5752 AR 0.8300
Epoch 121 batch 00004: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6931 AR 0.9000
Epoch 121 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0004 AP 0.7733 AR 0.9600
Epoch 121 batch 00006: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6044 AR 0.8467
Epoch 121 batch 00007: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6867 AR 0.8417
Epoch 121 batch 00008: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5821 AR 0.8917
Epoch 121 batch 00009: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6333 AR 0.7967
Epoch 121 batch 00010: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0002 AP 0.8282 AR 0.9800
Epoch 122 batch 00001: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6444 AR 1.0000
Epoch 122 batch 00002: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7733 AR 1.0000
Epoch 122 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7202 AR 1.0000
Epoch 122 batch 00004: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.7167 AR 0.9050
Epoch 122 batch 00005: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0003 AP 0.7266 AR 0.9550
Epoch 122 batch 00006: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0003 AP 0.5565 AR 0.9467
Epoch 122 batch 00007: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.6944 AR 0.9350
Epoch 122 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7113 AR 0.9667
Epoch 122 batch 00009: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7081 AR 0.9100
Epoch 122 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6414 AR 0.9500
Epoch 123 batch 00001: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.7983 AR 0.9217
Epoch 123 batch 00002: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6414 AR 1.0000
Epoch 123 batch 00003: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5637 AR 0.8350
Epoch 123 batch 00004: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.5880 AR 0.8500
Epoch 123 batch 00005: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6361 AR 0.9300
Epoch 123 batch 00006: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7650 AR 1.0000
Epoch 123 batch 00007: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.6700 AR 0.9217
Epoch 123 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.6419 AR 0.9800
Epoch 123 batch 00009: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.7205 AR 0.9800
Epoch 123 batch 00010: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7750 AR 1.0000
Epoch 124 batch 00001: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0003 AP 0.6121 AR 0.8600
Epoch 124 batch 00002: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.7167 AR 0.9800
Epoch 124 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7858 AR 1.0000
Epoch 124 batch 00004: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.4746 AR 0.8167
Epoch 124 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6167 AR 0.9500
Epoch 124 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7398 AR 0.9750
Epoch 124 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.8072 AR 0.9500
Epoch 124 batch 00008: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6038 AR 0.8717
Epoch 124 batch 00009: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6860 AR 0.9000
Epoch 124 batch 00010: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0003 AP 0.5475 AR 0.7150
Epoch 125 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6280 AR 0.9800
Epoch 125 batch 00002: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7142 AR 0.8800
Epoch 125 batch 00003: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0003 AP 0.6572 AR 0.9267
Epoch 125 batch 00004: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.6113 AR 0.8550
Epoch 125 batch 00005: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.5674 AR 0.8800
Epoch 125 batch 00006: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.7308 AR 0.8750
Epoch 125 batch 00007: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7114 AR 0.9750
Epoch 125 batch 00008: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.8386 AR 0.9550
Epoch 125 batch 00009: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.5480 AR 0.7250
Epoch 125 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6270 AR 0.8500
Epoch 126 batch 00001: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7556 AR 1.0000
Epoch 126 batch 00002: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.5797 AR 0.8817
Epoch 126 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6200 AR 0.8550
Epoch 126 batch 00004: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.7529 AR 1.0000
Epoch 126 batch 00005: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.6167 AR 0.8500
Epoch 126 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.7838 AR 0.9000
Epoch 126 batch 00007: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0002 AP 0.7633 AR 0.9750
Epoch 126 batch 00008: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.5554 AR 0.9267
Epoch 126 batch 00009: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0003 AP 0.7483 AR 0.9017
Epoch 126 batch 00010: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0003 AP 0.7583 AR 0.9667
Epoch 127 batch 00001: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.6744 AR 0.8800
Epoch 127 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.5225 AR 0.7800
Epoch 127 batch 00003: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.7750 AR 0.9800
Epoch 127 batch 00004: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6313 AR 0.9000
Epoch 127 batch 00005: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0003 AP 0.6528 AR 0.9500
Epoch 127 batch 00006: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0003 AP 0.6221 AR 0.8550
Epoch 127 batch 00007: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7117 AR 0.8500
Epoch 127 batch 00008: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6820 AR 0.9000
Epoch 127 batch 00009: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.7483 AR 1.0000
Epoch 127 batch 00010: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7446 AR 0.9550
Epoch 128 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7667 AR 0.9750
Epoch 128 batch 00002: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6775 AR 0.8550
Epoch 128 batch 00003: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7247 AR 1.0000
Epoch 128 batch 00004: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0002 AP 0.7662 AR 0.9400
Epoch 128 batch 00005: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5786 AR 0.9000
Epoch 128 batch 00006: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6188 AR 0.9217
Epoch 128 batch 00007: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6863 AR 1.0000
Epoch 128 batch 00008: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.5497 AR 0.7217
Epoch 128 batch 00009: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.7139 AR 1.0000
Epoch 128 batch 00010: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6639 AR 0.8000
Epoch 129 batch 00001: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.6647 AR 0.9300
Epoch 129 batch 00002: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0003 AP 0.7714 AR 0.9800
Epoch 129 batch 00003: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7283 AR 0.9017
Epoch 129 batch 00004: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6321 AR 0.9000
Epoch 129 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7233 AR 0.8550
Epoch 129 batch 00006: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7614 AR 0.9550
Epoch 129 batch 00007: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7047 AR 0.9417
Epoch 129 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.5722 AR 0.8300
Epoch 129 batch 00009: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6267 AR 0.7750
Epoch 129 batch 00010: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.6981 AR 0.9000
Epoch 130 batch 00001: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6467 AR 0.8600
Epoch 130 batch 00002: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.5858 AR 0.8300
Epoch 130 batch 00003: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7817 AR 0.9600
Epoch 130 batch 00004: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.6392 AR 0.9550
Epoch 130 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.8167 AR 1.0000
Epoch 130 batch 00006: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5492 AR 0.7300
Epoch 130 batch 00007: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6403 AR 0.9417
Epoch 130 batch 00008: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6514 AR 0.9417
Epoch 130 batch 00009: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6617 AR 0.8467
Epoch 130 batch 00010: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7750 AR 0.9550
Epoch 131 batch 00001: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.6493 AR 0.8800
Epoch 131 batch 00002: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7856 AR 0.9800
Epoch 131 batch 00003: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.5789 AR 0.8667
Epoch 131 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7983 AR 0.9600
Epoch 131 batch 00005: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6286 AR 0.8500
Epoch 131 batch 00006: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7575 AR 0.9750
Epoch 131 batch 00007: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.5089 AR 0.7000
Epoch 131 batch 00008: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7750 AR 1.0000
Epoch 131 batch 00009: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0003 AP 0.5507 AR 0.8550
Epoch 131 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6502 AR 0.9800
Epoch 132 batch 00001: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7833 AR 1.0000
Epoch 132 batch 00002: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6176 AR 0.8400
Epoch 132 batch 00003: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.6571 AR 0.9467
Epoch 132 batch 00004: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0003 AP 0.6214 AR 0.9050
Epoch 132 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7721 AR 0.9750
Epoch 132 batch 00006: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.5733 AR 0.8800
Epoch 132 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6486 AR 0.8633
Epoch 132 batch 00008: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0004 AP 0.6822 AR 1.0000
Epoch 132 batch 00009: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7906 AR 1.0000
Epoch 132 batch 00010: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.6147 AR 0.8350
Epoch 133 batch 00001: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7270 AR 0.9800
Epoch 133 batch 00002: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.6889 AR 0.9600
Epoch 133 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.7587 AR 0.9500
Epoch 133 batch 00004: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6983 AR 0.9750
Epoch 133 batch 00005: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6596 AR 0.8500
Epoch 133 batch 00006: Loss 0.0023 Regression loss 0.0018 Classification loss 0.0004 AP 0.4989 AR 0.7100
Epoch 133 batch 00007: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0004 AP 0.7333 AR 0.9500
Epoch 133 batch 00008: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.6131 AR 0.8067
Epoch 133 batch 00009: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7650 AR 0.9750
Epoch 133 batch 00010: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0003 AP 0.7453 AR 1.0000
Epoch 134 batch 00001: Loss 0.0035 Regression loss 0.0031 Classification loss 0.0004 AP 0.4717 AR 0.6167
Epoch 134 batch 00002: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.8155 AR 0.9800
Epoch 134 batch 00003: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6531 AR 0.8717
Epoch 134 batch 00004: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.5343 AR 0.9167
Epoch 134 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.7125 AR 0.9600
Epoch 134 batch 00006: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.7492 AR 0.9750
Epoch 134 batch 00007: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6592 AR 0.8750
Epoch 134 batch 00008: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7048 AR 0.8800
Epoch 134 batch 00009: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6926 AR 0.9350
Epoch 134 batch 00010: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0003 AP 0.6881 AR 0.8550
Epoch 135 batch 00001: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7550 AR 1.0000
Epoch 135 batch 00002: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6050 AR 0.8500
Epoch 135 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7489 AR 0.9417
Epoch 135 batch 00004: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6396 AR 0.9467
Epoch 135 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6100 AR 0.9500
Epoch 135 batch 00006: Loss 0.0019 Regression loss 0.0014 Classification loss 0.0005 AP 0.7460 AR 0.9350
Epoch 135 batch 00007: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7528 AR 0.9467
Epoch 135 batch 00008: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0003 AP 0.5296 AR 0.8800
Epoch 135 batch 00009: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7471 AR 0.9750
Epoch 135 batch 00010: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7575 AR 0.9750
Epoch 136 batch 00001: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.5917 AR 0.9300
Epoch 136 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8198 AR 0.9750
Epoch 136 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6467 AR 0.9000
Epoch 136 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6069 AR 0.8400
Epoch 136 batch 00005: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7217 AR 0.9467
Epoch 136 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.5748 AR 0.9500
Epoch 136 batch 00007: Loss 0.0019 Regression loss 0.0014 Classification loss 0.0005 AP 0.6333 AR 0.7800
Epoch 136 batch 00008: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.6945 AR 0.8017
Epoch 136 batch 00009: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6444 AR 0.8600
Epoch 136 batch 00010: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7814 AR 1.0000
Epoch 137 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6664 AR 0.9017
Epoch 137 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6892 AR 0.9667
Epoch 137 batch 00003: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.5925 AR 0.7750
Epoch 137 batch 00004: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0002 AP 0.5855 AR 0.8750
Epoch 137 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6028 AR 0.9467
Epoch 137 batch 00006: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0004 AP 0.6247 AR 0.8350
Epoch 137 batch 00007: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7913 AR 0.9750
Epoch 137 batch 00008: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7252 AR 0.9600
Epoch 137 batch 00009: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6906 AR 0.9000
Epoch 137 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8039 AR 0.9750
Epoch 138 batch 00001: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.7050 AR 0.9500
Epoch 138 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.6133 AR 0.8417
Epoch 138 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5988 AR 0.8800
Epoch 138 batch 00004: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7380 AR 0.9800
Epoch 138 batch 00005: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.7292 AR 1.0000
Epoch 138 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6573 AR 0.8667
Epoch 138 batch 00007: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6508 AR 0.9217
Epoch 138 batch 00008: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7423 AR 0.8850
Epoch 138 batch 00009: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6673 AR 0.9250
Epoch 138 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5294 AR 0.7267
Epoch 139 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.6175 AR 0.8600
Epoch 139 batch 00002: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.7183 AR 0.8750
Epoch 139 batch 00003: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0003 AP 0.7462 AR 0.9267
Epoch 139 batch 00004: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.5951 AR 0.8750
Epoch 139 batch 00005: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0004 AP 0.6870 AR 0.9550
Epoch 139 batch 00006: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.6850 AR 0.9667
Epoch 139 batch 00007: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0002 AP 0.6236 AR 0.9250
Epoch 139 batch 00008: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6638 AR 0.8400
Epoch 139 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.6850 AR 0.9800
Epoch 139 batch 00010: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.8100 AR 0.9000
Epoch 140 batch 00001: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0003 AP 0.7098 AR 1.0000
Epoch 140 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6339 AR 0.9000
Epoch 140 batch 00003: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6350 AR 0.9350
Epoch 140 batch 00004: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5708 AR 0.8350
Epoch 140 batch 00005: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7617 AR 0.9600
Epoch 140 batch 00006: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0003 AP 0.7741 AR 0.9500
Epoch 140 batch 00007: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6796 AR 0.9750
Epoch 140 batch 00008: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6758 AR 0.9500
Epoch 140 batch 00009: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.5117 AR 0.7200
Epoch 140 batch 00010: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0003 AP 0.7283 AR 0.9550
Epoch 141 batch 00001: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7901 AR 0.9600
Epoch 141 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6681 AR 1.0000
Epoch 141 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7119 AR 0.9750
Epoch 141 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6864 AR 0.9417
Epoch 141 batch 00005: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7100 AR 1.0000
Epoch 141 batch 00006: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6364 AR 0.9000
Epoch 141 batch 00007: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.7850 AR 0.9300
Epoch 141 batch 00008: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7964 AR 0.9750
Epoch 141 batch 00009: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6281 AR 0.9550
Epoch 141 batch 00010: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.6717 AR 0.9300
Epoch 142 batch 00001: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.6406 AR 0.8717
Epoch 142 batch 00002: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6064 AR 0.8000
Epoch 142 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.8417 AR 1.0000
Epoch 142 batch 00004: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6898 AR 0.8500
Epoch 142 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7305 AR 0.9600
Epoch 142 batch 00006: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6328 AR 0.9350
Epoch 142 batch 00007: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.6700 AR 0.8683
Epoch 142 batch 00008: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6482 AR 0.8467
Epoch 142 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6383 AR 0.8750
Epoch 142 batch 00010: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6151 AR 1.0000
Epoch 143 batch 00001: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.6762 AR 1.0000
Epoch 143 batch 00002: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6967 AR 0.9800
Epoch 143 batch 00003: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0003 AP 0.7768 AR 0.9800
Epoch 143 batch 00004: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.6933 AR 0.9500
Epoch 143 batch 00005: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0002 AP 0.6819 AR 0.8550
Epoch 143 batch 00006: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6564 AR 0.8967
Epoch 143 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6057 AR 0.8550
Epoch 143 batch 00008: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7900 AR 0.9250
Epoch 143 batch 00009: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.6250 AR 0.9000
Epoch 143 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.7356 AR 0.9467
Epoch 144 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6671 AR 0.9750
Epoch 144 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6325 AR 0.8250
Epoch 144 batch 00003: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7963 AR 0.9300
Epoch 144 batch 00004: Loss 0.0016 Regression loss 0.0012 Classification loss 0.0003 AP 0.7558 AR 1.0000
Epoch 144 batch 00005: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0004 AP 0.6073 AR 0.8550
Epoch 144 batch 00006: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7633 AR 0.9000
Epoch 144 batch 00007: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0004 AP 0.5567 AR 0.8017
Epoch 144 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7078 AR 0.9800
Epoch 144 batch 00009: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7469 AR 1.0000
Epoch 144 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5965 AR 0.9000
Epoch 145 batch 00001: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6948 AR 0.9550
Epoch 145 batch 00002: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.5642 AR 0.8100
Epoch 145 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7005 AR 0.9600
Epoch 145 batch 00004: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6643 AR 0.9750
Epoch 145 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0003 AP 0.7242 AR 1.0000
Epoch 145 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6836 AR 0.9550
Epoch 145 batch 00007: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7955 AR 0.8800
Epoch 145 batch 00008: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7617 AR 0.9000
Epoch 145 batch 00009: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.7208 AR 0.9417
Epoch 145 batch 00010: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.5725 AR 0.9000
Epoch 146 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6688 AR 0.9000
Epoch 146 batch 00002: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6989 AR 0.8300
Epoch 146 batch 00003: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6125 AR 0.9000
Epoch 146 batch 00004: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6142 AR 0.7550
Epoch 146 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6270 AR 0.9667
Epoch 146 batch 00006: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.8205 AR 0.9800
Epoch 146 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7255 AR 0.9800
Epoch 146 batch 00008: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6396 AR 0.8917
Epoch 146 batch 00009: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6530 AR 0.9267
Epoch 146 batch 00010: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6034 AR 0.9217
Epoch 147 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7087 AR 0.9800
Epoch 147 batch 00002: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7767 AR 0.9467
Epoch 147 batch 00003: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6246 AR 0.8600
Epoch 147 batch 00004: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6333 AR 1.0000
Epoch 147 batch 00005: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0002 AP 0.8058 AR 0.9500
Epoch 147 batch 00006: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.5727 AR 0.9550
Epoch 147 batch 00007: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0003 AP 0.6755 AR 0.8550
Epoch 147 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6181 AR 0.8467
Epoch 147 batch 00009: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0002 AP 0.6522 AR 0.9000
Epoch 147 batch 00010: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6856 AR 0.9267
Epoch 148 batch 00001: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.7288 AR 0.9467
Epoch 148 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7314 AR 1.0000
Epoch 148 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7677 AR 0.9750
Epoch 148 batch 00004: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0004 AP 0.6605 AR 0.9600
Epoch 148 batch 00005: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.5844 AR 0.7800
Epoch 148 batch 00006: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.5642 AR 0.9417
Epoch 148 batch 00007: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.6996 AR 0.8850
Epoch 148 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.6921 AR 1.0000
Epoch 148 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6533 AR 0.8467
Epoch 148 batch 00010: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.8142 AR 0.9750
Epoch 149 batch 00001: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0003 AP 0.6920 AR 0.9550
Epoch 149 batch 00002: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6758 AR 0.9100
Epoch 149 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7517 AR 0.9550
Epoch 149 batch 00004: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0002 AP 0.6344 AR 0.8417
Epoch 149 batch 00005: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0003 AP 0.6778 AR 0.8717
Epoch 149 batch 00006: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6639 AR 0.8800
Epoch 149 batch 00007: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7017 AR 0.8750
Epoch 149 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7258 AR 0.9750
Epoch 149 batch 00009: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.6621 AR 0.9600
Epoch 149 batch 00010: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6371 AR 1.0000
Epoch 150 batch 00001: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6883 AR 0.8750
Epoch 150 batch 00002: Loss 0.0021 Regression loss 0.0015 Classification loss 0.0005 AP 0.6871 AR 0.9400
Epoch 150 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7558 AR 0.9550
Epoch 150 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6486 AR 0.9467
Epoch 150 batch 00005: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6476 AR 0.9000
Epoch 150 batch 00006: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.5532 AR 0.8750
Epoch 150 batch 00007: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.8144 AR 0.9800
Epoch 150 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6308 AR 0.8917
Epoch 150 batch 00009: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.7838 AR 0.9467
Epoch 150 batch 00010: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6008 AR 0.8883
Epoch 151 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.4800 AR 0.8000
Epoch 151 batch 00002: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0002 AP 0.7167 AR 0.9000
Epoch 151 batch 00003: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0003 AP 0.7156 AR 0.9800
Epoch 151 batch 00004: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.8464 AR 0.9750
Epoch 151 batch 00005: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0003 AP 0.6197 AR 0.8167
Epoch 151 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6235 AR 0.9000
Epoch 151 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6946 AR 0.9300
Epoch 151 batch 00008: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5589 AR 0.9167
Epoch 151 batch 00009: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7514 AR 0.9800
Epoch 151 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5730 AR 0.8100
Epoch 152 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7542 AR 1.0000
Epoch 152 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7395 AR 0.9500
Epoch 152 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6986 AR 0.9800
Epoch 152 batch 00004: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.6744 AR 0.9800
Epoch 152 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.6942 AR 0.8467
Epoch 152 batch 00006: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6114 AR 0.9250
Epoch 152 batch 00007: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6345 AR 0.8400
Epoch 152 batch 00008: Loss 0.0021 Regression loss 0.0016 Classification loss 0.0004 AP 0.6839 AR 0.8750
Epoch 152 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6583 AR 0.8000
Epoch 152 batch 00010: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.6206 AR 0.8800
Epoch 153 batch 00001: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.6605 AR 0.9800
Epoch 153 batch 00002: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6608 AR 0.9800
Epoch 153 batch 00003: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.5336 AR 0.7550
Epoch 153 batch 00004: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7333 AR 0.9800
Epoch 153 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8131 AR 1.0000
Epoch 153 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6600 AR 0.9417
Epoch 153 batch 00007: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7035 AR 0.9500
Epoch 153 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7570 AR 0.9667
Epoch 153 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0001 AP 0.6298 AR 0.9000
Epoch 153 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6458 AR 0.8000
Epoch 154 batch 00001: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6487 AR 0.8400
Epoch 154 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6152 AR 0.7750
Epoch 154 batch 00003: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6594 AR 0.8083
Epoch 154 batch 00004: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0004 AP 0.7342 AR 0.9800
Epoch 154 batch 00005: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.7689 AR 0.9800
Epoch 154 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6600 AR 1.0000
Epoch 154 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5598 AR 0.9667
Epoch 154 batch 00008: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.3964 AR 0.6800
Epoch 154 batch 00009: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0002 AP 0.7617 AR 0.9300
Epoch 154 batch 00010: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6677 AR 0.9750
Epoch 155 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.5814 AR 0.8600
Epoch 155 batch 00002: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6788 AR 0.9750
Epoch 155 batch 00003: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7733 AR 0.9550
Epoch 155 batch 00004: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7364 AR 0.9550
Epoch 155 batch 00005: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.8467 AR 1.0000
Epoch 155 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.5559 AR 0.9083
Epoch 155 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.6267 AR 0.8550
Epoch 155 batch 00008: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6114 AR 0.8667
Epoch 155 batch 00009: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0003 AP 0.7708 AR 1.0000
Epoch 155 batch 00010: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.5217 AR 0.7800
Epoch 156 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7389 AR 1.0000
Epoch 156 batch 00002: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.8127 AR 0.9800
Epoch 156 batch 00003: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6041 AR 0.8550
Epoch 156 batch 00004: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6617 AR 0.9217
Epoch 156 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7508 AR 0.9500
Epoch 156 batch 00006: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0001 AP 0.5405 AR 0.7467
Epoch 156 batch 00007: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.7105 AR 0.9800
Epoch 156 batch 00008: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.5894 AR 0.9000
Epoch 156 batch 00009: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.4671 AR 0.7667
Epoch 156 batch 00010: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0003 AP 0.7481 AR 0.9800
Epoch 157 batch 00001: Loss 0.0026 Regression loss 0.0025 Classification loss 0.0002 AP 0.5881 AR 0.8083
Epoch 157 batch 00002: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6183 AR 0.8500
Epoch 157 batch 00003: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.7028 AR 0.9600
Epoch 157 batch 00004: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6683 AR 0.7667
Epoch 157 batch 00005: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.6333 AR 0.8400
Epoch 157 batch 00006: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7588 AR 0.9800
Epoch 157 batch 00007: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.6489 AR 0.9500
Epoch 157 batch 00008: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0002 AP 0.7752 AR 1.0000
Epoch 157 batch 00009: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0003 AP 0.5591 AR 0.8600
Epoch 157 batch 00010: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0004 AP 0.6245 AR 0.8800
Epoch 158 batch 00001: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7383 AR 0.9000
Epoch 158 batch 00002: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.5309 AR 0.8750
Epoch 158 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7595 AR 0.9667
Epoch 158 batch 00004: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.8538 AR 0.9550
Epoch 158 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0003 AP 0.7844 AR 0.9550
Epoch 158 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8055 AR 0.9750
Epoch 158 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.5892 AR 0.8750
Epoch 158 batch 00008: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6710 AR 1.0000
Epoch 158 batch 00009: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.4888 AR 0.7800
Epoch 158 batch 00010: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6339 AR 0.9067
Epoch 159 batch 00001: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7717 AR 0.9500
Epoch 159 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6988 AR 1.0000
Epoch 159 batch 00003: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.6239 AR 0.9550
Epoch 159 batch 00004: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.6242 AR 0.9167
Epoch 159 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6537 AR 0.8617
Epoch 159 batch 00006: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.3613 AR 0.6100
Epoch 159 batch 00007: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0002 AP 0.6156 AR 0.8750
Epoch 159 batch 00008: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0004 AP 0.7833 AR 0.9417
Epoch 159 batch 00009: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7483 AR 0.9350
Epoch 159 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7683 AR 1.0000
Epoch 160 batch 00001: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0003 AP 0.6945 AR 0.8900
Epoch 160 batch 00002: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6312 AR 0.9750
Epoch 160 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7542 AR 0.9750
Epoch 160 batch 00004: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7869 AR 1.0000
Epoch 160 batch 00005: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0002 AP 0.7600 AR 0.9800
Epoch 160 batch 00006: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.5850 AR 0.8767
Epoch 160 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.5798 AR 0.7750
Epoch 160 batch 00008: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0003 AP 0.6225 AR 0.8467
Epoch 160 batch 00009: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7894 AR 0.9267
Epoch 160 batch 00010: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7261 AR 0.9750
Epoch 161 batch 00001: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.5848 AR 0.8817
Epoch 161 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.8542 AR 1.0000
Epoch 161 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7383 AR 0.9550
Epoch 161 batch 00004: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.5719 AR 0.9000
Epoch 161 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8133 AR 0.9500
Epoch 161 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7167 AR 0.9750
Epoch 161 batch 00007: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.5029 AR 0.7850
Epoch 161 batch 00008: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7467 AR 0.9667
Epoch 161 batch 00009: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.6675 AR 0.9000
Epoch 161 batch 00010: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6091 AR 0.9600
Epoch 162 batch 00001: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0003 AP 0.7044 AR 1.0000
Epoch 162 batch 00002: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.7043 AR 0.9400
Epoch 162 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7500 AR 1.0000
Epoch 162 batch 00004: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.8267 AR 0.9300
Epoch 162 batch 00005: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6288 AR 0.9350
Epoch 162 batch 00006: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.8333 AR 0.9800
Epoch 162 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.6567 AR 0.9800
Epoch 162 batch 00008: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.7333 AR 0.9000
Epoch 162 batch 00009: Loss 0.0043 Regression loss 0.0041 Classification loss 0.0002 AP 0.5213 AR 0.8000
Epoch 162 batch 00010: Loss 0.0045 Regression loss 0.0042 Classification loss 0.0002 AP 0.5567 AR 0.7483
Epoch 163 batch 00001: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.8850 AR 1.0000
Epoch 163 batch 00002: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.6850 AR 0.8800
Epoch 163 batch 00003: Loss 0.0044 Regression loss 0.0042 Classification loss 0.0002 AP 0.4154 AR 0.7767
Epoch 163 batch 00004: Loss 0.0039 Regression loss 0.0035 Classification loss 0.0003 AP 0.8056 AR 0.9000
Epoch 163 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5797 AR 0.7167
Epoch 163 batch 00006: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7512 AR 0.9400
Epoch 163 batch 00007: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.7108 AR 0.9600
Epoch 163 batch 00008: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.5731 AR 0.9350
Epoch 163 batch 00009: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6921 AR 0.9267
Epoch 163 batch 00010: Loss 0.0033 Regression loss 0.0030 Classification loss 0.0003 AP 0.6490 AR 0.9550
Epoch 164 batch 00001: Loss 0.0039 Regression loss 0.0036 Classification loss 0.0003 AP 0.6405 AR 0.8667
Epoch 164 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6483 AR 0.7550
Epoch 164 batch 00003: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.7917 AR 0.9000
Epoch 164 batch 00004: Loss 0.0045 Regression loss 0.0042 Classification loss 0.0002 AP 0.6383 AR 0.8750
Epoch 164 batch 00005: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0001 AP 0.7417 AR 0.9217
Epoch 164 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0004 AP 0.7142 AR 0.9550
Epoch 164 batch 00007: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0003 AP 0.6375 AR 0.8400
Epoch 164 batch 00008: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7083 AR 1.0000
Epoch 164 batch 00009: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0003 AP 0.6000 AR 0.9417
Epoch 164 batch 00010: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.6598 AR 0.9667
Epoch 165 batch 00001: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0003 AP 0.7090 AR 0.9417
Epoch 165 batch 00002: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.6450 AR 0.9217
Epoch 165 batch 00003: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7267 AR 0.8050
Epoch 165 batch 00004: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5625 AR 0.7800
Epoch 165 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6553 AR 1.0000
Epoch 165 batch 00006: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6792 AR 0.8750
Epoch 165 batch 00007: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.7683 AR 0.9750
Epoch 165 batch 00008: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0002 AP 0.6464 AR 0.9417
Epoch 165 batch 00009: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.7407 AR 0.8800
Epoch 165 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5468 AR 0.8800
Epoch 166 batch 00001: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0002 AP 0.7095 AR 0.9750
Epoch 166 batch 00002: Loss 0.0035 Regression loss 0.0032 Classification loss 0.0003 AP 0.7302 AR 0.8467
Epoch 166 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6416 AR 0.8550
Epoch 166 batch 00004: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0003 AP 0.6963 AR 0.9267
Epoch 166 batch 00005: Loss 0.0038 Regression loss 0.0036 Classification loss 0.0002 AP 0.7717 AR 1.0000
Epoch 166 batch 00006: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0002 AP 0.5633 AR 0.8350
Epoch 166 batch 00007: Loss 0.0019 Regression loss 0.0014 Classification loss 0.0005 AP 0.6500 AR 0.8750
Epoch 166 batch 00008: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.7567 AR 0.9800
Epoch 166 batch 00009: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.5720 AR 0.8350
Epoch 166 batch 00010: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0004 AP 0.6464 AR 0.9000
Epoch 167 batch 00001: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6867 AR 0.9550
Epoch 167 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7925 AR 0.9750
Epoch 167 batch 00003: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6477 AR 0.9667
Epoch 167 batch 00004: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0003 AP 0.7221 AR 0.8000
Epoch 167 batch 00005: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0006 AP 0.7375 AR 1.0000
Epoch 167 batch 00006: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.6026 AR 0.8350
Epoch 167 batch 00007: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0003 AP 0.6261 AR 0.9400
Epoch 167 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6571 AR 0.9800
Epoch 167 batch 00009: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.5683 AR 0.8800
Epoch 167 batch 00010: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0004 AP 0.7403 AR 0.9750
Epoch 168 batch 00001: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7498 AR 1.0000
Epoch 168 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.6950 AR 0.9800
Epoch 168 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6995 AR 1.0000
Epoch 168 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6713 AR 0.9800
Epoch 168 batch 00005: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.7475 AR 0.8500
Epoch 168 batch 00006: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7250 AR 0.8667
Epoch 168 batch 00007: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.5914 AR 0.8100
Epoch 168 batch 00008: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6426 AR 0.9667
Epoch 168 batch 00009: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.8072 AR 0.9667
Epoch 168 batch 00010: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.7187 AR 0.9267
Epoch 169 batch 00001: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0003 AP 0.7389 AR 0.8800
Epoch 169 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6067 AR 0.7467
Epoch 169 batch 00003: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0003 AP 0.7150 AR 0.9333
Epoch 169 batch 00004: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7238 AR 0.9150
Epoch 169 batch 00005: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6345 AR 0.9167
Epoch 169 batch 00006: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.6233 AR 0.8800
Epoch 169 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7831 AR 0.9550
Epoch 169 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6417 AR 0.8800
Epoch 169 batch 00009: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.5844 AR 0.8750
Epoch 169 batch 00010: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.6498 AR 1.0000
Epoch 170 batch 00001: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.6671 AR 0.8600
Epoch 170 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7505 AR 0.9800
Epoch 170 batch 00003: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6250 AR 0.9467
Epoch 170 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7700 AR 1.0000
Epoch 170 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7833 AR 1.0000
Epoch 170 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6818 AR 0.9550
Epoch 170 batch 00007: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6458 AR 0.9500
Epoch 170 batch 00008: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.5923 AR 0.8500
Epoch 170 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.7725 AR 1.0000
Epoch 170 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.6694 AR 0.8750
Epoch 171 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6128 AR 0.8550
Epoch 171 batch 00002: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6392 AR 0.9600
Epoch 171 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.6731 AR 0.9417
Epoch 171 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5753 AR 0.8550
Epoch 171 batch 00005: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7700 AR 0.9600
Epoch 171 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7608 AR 0.9750
Epoch 171 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6588 AR 0.8800
Epoch 171 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.5477 AR 0.8300
Epoch 171 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7883 AR 0.9800
Epoch 171 batch 00010: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7575 AR 0.9250
Epoch 172 batch 00001: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.7150 AR 0.9167
Epoch 172 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.6755 AR 1.0000
Epoch 172 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6920 AR 0.9000
Epoch 172 batch 00004: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8350 AR 1.0000
Epoch 172 batch 00005: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.5148 AR 0.8300
Epoch 172 batch 00006: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6935 AR 0.8600
Epoch 172 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.4750 AR 0.8000
Epoch 172 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7175 AR 0.9800
Epoch 172 batch 00009: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.7217 AR 0.9417
Epoch 172 batch 00010: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.7775 AR 0.9550
Epoch 173 batch 00001: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7008 AR 0.8550
Epoch 173 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6486 AR 0.8250
Epoch 173 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8600 AR 1.0000
Epoch 173 batch 00004: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.6638 AR 1.0000
Epoch 173 batch 00005: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.7489 AR 0.9667
Epoch 173 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7933 AR 1.0000
Epoch 173 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.5375 AR 0.7817
Epoch 173 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7048 AR 0.9550
Epoch 173 batch 00009: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6731 AR 0.9000
Epoch 173 batch 00010: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6725 AR 0.9800
Epoch 174 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6773 AR 0.9000
Epoch 174 batch 00002: Loss 0.0015 Regression loss 0.0011 Classification loss 0.0003 AP 0.6829 AR 0.9750
Epoch 174 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.6539 AR 0.9217
Epoch 174 batch 00004: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6060 AR 0.9467
Epoch 174 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.8021 AR 1.0000
Epoch 174 batch 00006: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6875 AR 1.0000
Epoch 174 batch 00007: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6917 AR 0.8000
Epoch 174 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8322 AR 0.9750
Epoch 174 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.7875 AR 0.9800
Epoch 174 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.5864 AR 0.9167
Epoch 175 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6892 AR 0.9750
Epoch 175 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0001 AP 0.6400 AR 0.7750
Epoch 175 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.5763 AR 0.8600
Epoch 175 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0003 AP 0.7600 AR 0.9250
Epoch 175 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7931 AR 0.9500
Epoch 175 batch 00006: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.6910 AR 0.9800
Epoch 175 batch 00007: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6283 AR 0.8750
Epoch 175 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6694 AR 0.9600
Epoch 175 batch 00009: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.5689 AR 0.8417
Epoch 175 batch 00010: Loss 0.0029 Regression loss 0.0023 Classification loss 0.0005 AP 0.7705 AR 0.9600
Epoch 176 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.7400 AR 0.9800
Epoch 176 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6931 AR 0.9550
Epoch 176 batch 00003: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.5900 AR 0.8667
Epoch 176 batch 00004: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.5848 AR 0.7550
Epoch 176 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.6933 AR 0.9667
Epoch 176 batch 00006: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7058 AR 0.9000
Epoch 176 batch 00007: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7307 AR 0.9350
Epoch 176 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6856 AR 0.9500
Epoch 176 batch 00009: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.7067 AR 0.9467
Epoch 176 batch 00010: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.6250 AR 0.8550
Epoch 177 batch 00001: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.7691 AR 0.9400
Epoch 177 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6389 AR 0.9217
Epoch 177 batch 00003: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.7533 AR 0.9550
Epoch 177 batch 00004: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0002 AP 0.6381 AR 0.8750
Epoch 177 batch 00005: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6650 AR 0.8750
Epoch 177 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7733 AR 1.0000
Epoch 177 batch 00007: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6375 AR 0.9667
Epoch 177 batch 00008: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7083 AR 0.9417
Epoch 177 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7842 AR 1.0000
Epoch 177 batch 00010: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.6877 AR 1.0000
Epoch 178 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0004 AP 0.7248 AR 0.9750
Epoch 178 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6394 AR 0.8667
Epoch 178 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.6663 AR 0.9467
Epoch 178 batch 00004: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6430 AR 0.8667
Epoch 178 batch 00005: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6073 AR 0.8733
Epoch 178 batch 00006: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.7139 AR 0.8550
Epoch 178 batch 00007: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.6639 AR 0.9550
Epoch 178 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7167 AR 0.9750
Epoch 178 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7248 AR 0.9750
Epoch 178 batch 00010: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6914 AR 0.8800
Epoch 179 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6671 AR 0.8667
Epoch 179 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7267 AR 0.9000
Epoch 179 batch 00003: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0003 AP 0.6055 AR 0.9000
Epoch 179 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7100 AR 0.9750
Epoch 179 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6233 AR 0.8600
Epoch 179 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.8283 AR 0.9800
Epoch 179 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.6672 AR 0.9350
Epoch 179 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.5851 AR 0.9133
Epoch 179 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7781 AR 0.9250
Epoch 179 batch 00010: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.4008 AR 0.6300
Epoch 180 batch 00001: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7050 AR 0.9800
Epoch 180 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6583 AR 0.8467
Epoch 180 batch 00003: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.8483 AR 0.9800
Epoch 180 batch 00004: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5789 AR 0.7800
Epoch 180 batch 00005: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5475 AR 0.8400
Epoch 180 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.5448 AR 0.9000
Epoch 180 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0003 AP 0.7792 AR 1.0000
Epoch 180 batch 00008: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.6989 AR 0.9467
Epoch 180 batch 00009: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6847 AR 0.9250
Epoch 180 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7433 AR 0.9217
Epoch 181 batch 00001: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7031 AR 0.9350
Epoch 181 batch 00002: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7175 AR 0.8800
Epoch 181 batch 00003: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.7208 AR 0.9350
Epoch 181 batch 00004: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6928 AR 0.9550
Epoch 181 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5599 AR 0.8800
Epoch 181 batch 00006: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5225 AR 0.7800
Epoch 181 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6470 AR 0.9417
Epoch 181 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.6433 AR 0.8267
Epoch 181 batch 00009: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0003 AP 0.7030 AR 0.8500
Epoch 181 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7014 AR 1.0000
Epoch 182 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7394 AR 0.9550
Epoch 182 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8064 AR 1.0000
Epoch 182 batch 00003: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0004 AP 0.6483 AR 0.9017
Epoch 182 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.8188 AR 0.9750
Epoch 182 batch 00005: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.6742 AR 0.9467
Epoch 182 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7683 AR 0.8467
Epoch 182 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6694 AR 0.9500
Epoch 182 batch 00008: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.5244 AR 0.8000
Epoch 182 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5917 AR 0.8667
Epoch 182 batch 00010: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6609 AR 0.9350
Epoch 183 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6272 AR 0.8350
Epoch 183 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5642 AR 0.9000
Epoch 183 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7067 AR 0.8500
Epoch 183 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0001 AP 0.6638 AR 0.8550
Epoch 183 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.8048 AR 1.0000
Epoch 183 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7398 AR 1.0000
Epoch 183 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6480 AR 0.9750
Epoch 183 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6514 AR 0.9350
Epoch 183 batch 00009: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.6641 AR 0.9467
Epoch 183 batch 00010: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7088 AR 0.8600
Epoch 184 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7233 AR 0.9500
Epoch 184 batch 00002: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.4925 AR 0.6850
Epoch 184 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6228 AR 0.9000
Epoch 184 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7828 AR 0.9550
Epoch 184 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.5671 AR 0.8467
Epoch 184 batch 00006: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.8594 AR 0.9550
Epoch 184 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7123 AR 0.9167
Epoch 184 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.5738 AR 0.9417
Epoch 184 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7133 AR 0.9500
Epoch 184 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7164 AR 0.9417
Epoch 185 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6883 AR 0.9267
Epoch 185 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7163 AR 0.9000
Epoch 185 batch 00003: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6156 AR 0.9550
Epoch 185 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5605 AR 0.9000
Epoch 185 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7083 AR 0.8750
Epoch 185 batch 00006: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.6314 AR 0.8500
Epoch 185 batch 00007: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7198 AR 0.8750
Epoch 185 batch 00008: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7363 AR 0.9300
Epoch 185 batch 00009: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6853 AR 0.9217
Epoch 185 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.6602 AR 0.9267
Epoch 186 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7514 AR 0.9667
Epoch 186 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7275 AR 0.9550
Epoch 186 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7997 AR 1.0000
Epoch 186 batch 00004: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0002 AP 0.4625 AR 0.6050
Epoch 186 batch 00005: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.6053 AR 0.9500
Epoch 186 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8252 AR 0.9800
Epoch 186 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.6006 AR 0.9217
Epoch 186 batch 00008: Loss 0.0016 Regression loss 0.0012 Classification loss 0.0004 AP 0.6667 AR 0.9400
Epoch 186 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7838 AR 0.9750
Epoch 186 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5761 AR 0.9217
Epoch 187 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7121 AR 0.9800
Epoch 187 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.4920 AR 0.8467
Epoch 187 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7183 AR 0.9267
Epoch 187 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6230 AR 0.9667
Epoch 187 batch 00005: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.7392 AR 0.9800
Epoch 187 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6827 AR 0.9750
Epoch 187 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7679 AR 0.8350
Epoch 187 batch 00008: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.8017 AR 0.8750
Epoch 187 batch 00009: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0004 AP 0.6511 AR 0.9350
Epoch 187 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.7617 AR 1.0000
Epoch 188 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6660 AR 1.0000
Epoch 188 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8136 AR 1.0000
Epoch 188 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6638 AR 0.9800
Epoch 188 batch 00004: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6081 AR 0.7567
Epoch 188 batch 00005: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6100 AR 0.9000
Epoch 188 batch 00006: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6956 AR 0.9500
Epoch 188 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7581 AR 0.9667
Epoch 188 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6664 AR 0.9750
Epoch 188 batch 00009: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6200 AR 0.8150
Epoch 188 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7500 AR 1.0000
Epoch 189 batch 00001: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6930 AR 0.8900
Epoch 189 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6114 AR 0.7750
Epoch 189 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0001 AP 0.6933 AR 1.0000
Epoch 189 batch 00004: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6921 AR 0.9667
Epoch 189 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0001 AP 0.7361 AR 0.9000
Epoch 189 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7396 AR 0.9350
Epoch 189 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8336 AR 1.0000
Epoch 189 batch 00008: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.6500 AR 0.9467
Epoch 189 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6472 AR 0.9500
Epoch 189 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6250 AR 0.8750
Epoch 190 batch 00001: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6427 AR 0.8400
Epoch 190 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6471 AR 0.9500
Epoch 190 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7531 AR 1.0000
Epoch 190 batch 00004: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.6556 AR 0.8250
Epoch 190 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7550 AR 1.0000
Epoch 190 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6394 AR 0.9333
Epoch 190 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6864 AR 0.8417
Epoch 190 batch 00008: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6953 AR 0.9400
Epoch 190 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6571 AR 0.8750
Epoch 190 batch 00010: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6871 AR 0.9800
Epoch 191 batch 00001: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.5783 AR 0.8800
Epoch 191 batch 00002: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7008 AR 0.8800
Epoch 191 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7833 AR 1.0000
Epoch 191 batch 00004: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7364 AR 0.9750
Epoch 191 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6986 AR 0.9100
Epoch 191 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.7633 AR 0.9800
Epoch 191 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.5806 AR 0.8550
Epoch 191 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.5644 AR 0.8500
Epoch 191 batch 00009: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6750 AR 0.9667
Epoch 191 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7605 AR 0.9750
Epoch 192 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6543 AR 0.9500
Epoch 192 batch 00002: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6811 AR 0.9217
Epoch 192 batch 00003: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0003 AP 0.8567 AR 1.0000
Epoch 192 batch 00004: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7489 AR 1.0000
Epoch 192 batch 00005: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0002 AP 0.7050 AR 0.9000
Epoch 192 batch 00006: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.5777 AR 0.8300
Epoch 192 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6430 AR 0.9600
Epoch 192 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6178 AR 0.7800
Epoch 192 batch 00009: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6651 AR 0.9600
Epoch 192 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7894 AR 1.0000
Epoch 193 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7158 AR 1.0000
Epoch 193 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6625 AR 0.8133
Epoch 193 batch 00003: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0004 AP 0.7298 AR 0.9750
Epoch 193 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7488 AR 1.0000
Epoch 193 batch 00005: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.4783 AR 0.8350
Epoch 193 batch 00006: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.7408 AR 0.9300
Epoch 193 batch 00007: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0003 AP 0.5904 AR 0.8500
Epoch 193 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0002 AP 0.8050 AR 0.9667
Epoch 193 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7370 AR 0.9500
Epoch 193 batch 00010: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7363 AR 0.8667
Epoch 194 batch 00001: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.7064 AR 0.8500
Epoch 194 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6372 AR 0.9550
Epoch 194 batch 00003: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7033 AR 0.9350
Epoch 194 batch 00004: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.6321 AR 0.8550
Epoch 194 batch 00005: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.5371 AR 0.8900
Epoch 194 batch 00006: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.7117 AR 0.9550
Epoch 194 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7217 AR 0.9300
Epoch 194 batch 00008: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0002 AP 0.7500 AR 0.9667
Epoch 194 batch 00009: Loss 0.0033 Regression loss 0.0030 Classification loss 0.0003 AP 0.6239 AR 0.9267
Epoch 194 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6333 AR 0.8133
Epoch 195 batch 00001: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7638 AR 0.9550
Epoch 195 batch 00002: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0002 AP 0.7519 AR 0.9800
Epoch 195 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6317 AR 0.8800
Epoch 195 batch 00004: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.6697 AR 0.9750
Epoch 195 batch 00005: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7438 AR 0.9800
Epoch 195 batch 00006: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6367 AR 0.7750
Epoch 195 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.6800 AR 0.9300
Epoch 195 batch 00008: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.5748 AR 0.9000
Epoch 195 batch 00009: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6122 AR 0.8750
Epoch 195 batch 00010: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0003 AP 0.6260 AR 0.7800
Epoch 196 batch 00001: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6614 AR 0.9800
Epoch 196 batch 00002: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6350 AR 0.8000
Epoch 196 batch 00003: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6972 AR 0.9300
Epoch 196 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6931 AR 0.9000
Epoch 196 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.6155 AR 0.9350
Epoch 196 batch 00006: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7481 AR 0.9000
Epoch 196 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6767 AR 0.9667
Epoch 196 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7492 AR 0.9300
Epoch 196 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6621 AR 0.9550
Epoch 196 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.7243 AR 0.9550
Epoch 197 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6683 AR 0.9250
Epoch 197 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7717 AR 0.9800
Epoch 197 batch 00003: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.7375 AR 1.0000
Epoch 197 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7447 AR 0.9600
Epoch 197 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7129 AR 0.9267
Epoch 197 batch 00006: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6002 AR 0.8217
Epoch 197 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7472 AR 0.9000
Epoch 197 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7016 AR 0.9600
Epoch 197 batch 00009: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6569 AR 0.8800
Epoch 197 batch 00010: Loss 0.0016 Regression loss 0.0012 Classification loss 0.0003 AP 0.5638 AR 0.8550
Epoch 198 batch 00001: Loss 0.0012 Regression loss 0.0009 Classification loss 0.0003 AP 0.7142 AR 1.0000
Epoch 198 batch 00002: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.5533 AR 1.0000
Epoch 198 batch 00003: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.7731 AR 0.9500
Epoch 198 batch 00004: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6744 AR 0.9800
Epoch 198 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0003 AP 0.6180 AR 0.9667
Epoch 198 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7341 AR 0.9000
Epoch 198 batch 00007: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.5817 AR 0.7267
Epoch 198 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6915 AR 0.9667
Epoch 198 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8021 AR 1.0000
Epoch 198 batch 00010: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7531 AR 0.9800
Epoch 199 batch 00001: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7676 AR 0.9550
Epoch 199 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5908 AR 0.9000
Epoch 199 batch 00003: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7275 AR 0.9600
Epoch 199 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.7350 AR 0.9750
Epoch 199 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.6903 AR 0.8800
Epoch 199 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.6840 AR 0.9000
Epoch 199 batch 00007: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.6600 AR 0.8667
Epoch 199 batch 00008: Loss 0.0015 Regression loss 0.0011 Classification loss 0.0003 AP 0.6341 AR 0.9467
Epoch 199 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6669 AR 0.9800
Epoch 199 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6350 AR 0.9167
Epoch 200 batch 00001: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7263 AR 0.9800
Epoch 200 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6733 AR 0.7667
Epoch 200 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6817 AR 1.0000
Epoch 200 batch 00004: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7030 AR 1.0000
Epoch 200 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6300 AR 0.8600
Epoch 200 batch 00006: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7425 AR 0.8800
Epoch 200 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7100 AR 0.8800
Epoch 200 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.6860 AR 0.8800
Epoch 200 batch 00009: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6123 AR 0.9167
Epoch 200 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6748 AR 0.9667
Epoch 201 batch 00001: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.5933 AR 0.7417
Epoch 201 batch 00002: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.6133 AR 0.8667
Epoch 201 batch 00003: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7075 AR 0.9467
Epoch 201 batch 00004: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7875 AR 0.9667
Epoch 201 batch 00005: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6911 AR 0.8800
Epoch 201 batch 00006: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.6603 AR 0.9300
Epoch 201 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0003 AP 0.6758 AR 0.9550
Epoch 201 batch 00008: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7767 AR 0.9800
Epoch 201 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6854 AR 0.8550
Epoch 201 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6506 AR 0.9667
Epoch 202 batch 00001: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6730 AR 0.8600
Epoch 202 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5542 AR 0.9500
Epoch 202 batch 00003: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6817 AR 0.8350
Epoch 202 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6798 AR 0.9600
Epoch 202 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0001 AP 0.7033 AR 0.8667
Epoch 202 batch 00006: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0003 AP 0.6121 AR 0.8217
Epoch 202 batch 00007: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6683 AR 0.9417
Epoch 202 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6653 AR 0.9800
Epoch 202 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6442 AR 0.8750
Epoch 202 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8488 AR 1.0000
Epoch 203 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7899 AR 0.9800
Epoch 203 batch 00002: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0003 AP 0.6667 AR 0.9750
Epoch 203 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7058 AR 0.9350
Epoch 203 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8600 AR 0.9750
Epoch 203 batch 00005: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.6783 AR 0.9267
Epoch 203 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5386 AR 0.8550
Epoch 203 batch 00007: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.5811 AR 0.8750
Epoch 203 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7739 AR 1.0000
Epoch 203 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5963 AR 0.8267
Epoch 203 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.6736 AR 0.9350
Epoch 204 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7433 AR 0.9750
Epoch 204 batch 00002: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.7512 AR 0.9750
Epoch 204 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6542 AR 0.9600
Epoch 204 batch 00004: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.7233 AR 0.9600
Epoch 204 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.5050 AR 0.7800
Epoch 204 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5672 AR 0.8550
Epoch 204 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7927 AR 1.0000
Epoch 204 batch 00008: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7458 AR 0.9500
Epoch 204 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6999 AR 0.9500
Epoch 204 batch 00010: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.5988 AR 0.9000
Epoch 205 batch 00001: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.6500 AR 0.8667
Epoch 205 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5433 AR 0.9000
Epoch 205 batch 00003: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6977 AR 0.9500
Epoch 205 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7503 AR 0.9550
Epoch 205 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6394 AR 0.9800
Epoch 205 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.5931 AR 0.7083
Epoch 205 batch 00007: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.8125 AR 0.9300
Epoch 205 batch 00008: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6550 AR 0.9750
Epoch 205 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5161 AR 0.7800
Epoch 205 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7066 AR 0.9300
Epoch 206 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7133 AR 0.8250
Epoch 206 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6664 AR 0.8550
Epoch 206 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7400 AR 0.9750
Epoch 206 batch 00004: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7486 AR 0.9467
Epoch 206 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7498 AR 0.9750
Epoch 206 batch 00006: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6011 AR 0.9300
Epoch 206 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6044 AR 1.0000
Epoch 206 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6136 AR 0.7750
Epoch 206 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0003 AP 0.6044 AR 0.8017
Epoch 206 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6839 AR 1.0000
Epoch 207 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.5375 AR 0.8133
Epoch 207 batch 00002: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7106 AR 0.8500
Epoch 207 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7683 AR 0.8800
Epoch 207 batch 00004: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6244 AR 0.9350
Epoch 207 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6336 AR 1.0000
Epoch 207 batch 00006: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6648 AR 0.9000
Epoch 207 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6854 AR 0.8600
Epoch 207 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.7625 AR 0.9550
Epoch 207 batch 00009: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6000 AR 0.7917
Epoch 207 batch 00010: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7267 AR 1.0000
Epoch 208 batch 00001: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6867 AR 1.0000
Epoch 208 batch 00002: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.6663 AR 0.8600
Epoch 208 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.7181 AR 1.0000
Epoch 208 batch 00004: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0002 AP 0.6589 AR 0.9000
Epoch 208 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.4508 AR 0.6150
Epoch 208 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7769 AR 0.9800
Epoch 208 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6975 AR 0.9500
Epoch 208 batch 00008: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.6509 AR 0.9550
Epoch 208 batch 00009: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0003 AP 0.7350 AR 0.9300
Epoch 208 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7736 AR 0.9467
Epoch 209 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6360 AR 0.8600
Epoch 209 batch 00002: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.6877 AR 0.9400
Epoch 209 batch 00003: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.5792 AR 0.9500
Epoch 209 batch 00004: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7008 AR 0.8750
Epoch 209 batch 00005: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.8750 AR 0.9550
Epoch 209 batch 00006: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.5456 AR 0.8350
Epoch 209 batch 00007: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.6120 AR 0.8000
Epoch 209 batch 00008: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.8350 AR 0.9550
Epoch 209 batch 00009: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0003 AP 0.6369 AR 0.8900
Epoch 209 batch 00010: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0002 AP 0.6663 AR 1.0000
Epoch 210 batch 00001: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.4544 AR 0.7550
Epoch 210 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6700 AR 0.8750
Epoch 210 batch 00003: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.7333 AR 0.9350
Epoch 210 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6245 AR 0.9400
Epoch 210 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7655 AR 1.0000
Epoch 210 batch 00006: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.7852 AR 0.9750
Epoch 210 batch 00007: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0002 AP 0.6500 AR 0.7167
Epoch 210 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6250 AR 0.9000
Epoch 210 batch 00009: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7230 AR 0.9800
Epoch 210 batch 00010: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.6202 AR 0.8733
Epoch 211 batch 00001: Loss 0.0032 Regression loss 0.0030 Classification loss 0.0002 AP 0.5921 AR 0.8800
Epoch 211 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6733 AR 0.9667
Epoch 211 batch 00003: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0002 AP 0.7133 AR 0.9300
Epoch 211 batch 00004: Loss 0.0039 Regression loss 0.0036 Classification loss 0.0003 AP 0.6541 AR 0.9467
Epoch 211 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8020 AR 0.9750
Epoch 211 batch 00006: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0003 AP 0.6486 AR 0.8750
Epoch 211 batch 00007: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7567 AR 0.9667
Epoch 211 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7614 AR 0.9750
Epoch 211 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0001 AP 0.6267 AR 0.8000
Epoch 211 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7523 AR 1.0000
Epoch 212 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7075 AR 0.9750
Epoch 212 batch 00002: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7694 AR 0.9800
Epoch 212 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.7081 AR 0.9417
Epoch 212 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5002 AR 0.6550
Epoch 212 batch 00005: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6111 AR 0.8800
Epoch 212 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7155 AR 0.9100
Epoch 212 batch 00007: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.5975 AR 0.8467
Epoch 212 batch 00008: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0002 AP 0.5867 AR 0.9000
Epoch 212 batch 00009: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.7338 AR 0.9800
Epoch 212 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7081 AR 0.9667
Epoch 213 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.5527 AR 0.6800
Epoch 213 batch 00002: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7858 AR 0.9800
Epoch 213 batch 00003: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6771 AR 0.9100
Epoch 213 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6548 AR 0.9017
Epoch 213 batch 00005: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.6822 AR 0.9750
Epoch 213 batch 00006: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.6050 AR 1.0000
Epoch 213 batch 00007: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0002 AP 0.7400 AR 0.9667
Epoch 213 batch 00008: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6631 AR 0.9417
Epoch 213 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8475 AR 0.9750
Epoch 213 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.6171 AR 0.8750
Epoch 214 batch 00001: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5819 AR 0.8600
Epoch 214 batch 00002: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6470 AR 0.9750
Epoch 214 batch 00003: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6578 AR 0.8267
Epoch 214 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7394 AR 0.9800
Epoch 214 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7671 AR 0.8967
Epoch 214 batch 00006: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.6898 AR 0.8750
Epoch 214 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.5650 AR 0.8750
Epoch 214 batch 00008: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6617 AR 1.0000
Epoch 214 batch 00009: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7336 AR 0.9667
Epoch 214 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6606 AR 0.9750
Epoch 215 batch 00001: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7517 AR 0.9550
Epoch 215 batch 00002: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.7516 AR 1.0000
Epoch 215 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7594 AR 0.9667
Epoch 215 batch 00004: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6656 AR 0.9417
Epoch 215 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7619 AR 0.8800
Epoch 215 batch 00006: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0001 AP 0.6025 AR 0.9417
Epoch 215 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7994 AR 0.9300
Epoch 215 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6849 AR 0.9600
Epoch 215 batch 00009: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6433 AR 0.9750
Epoch 215 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7272 AR 0.9550
Epoch 216 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5697 AR 0.8417
Epoch 216 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8300 AR 0.9417
Epoch 216 batch 00003: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6294 AR 0.8750
Epoch 216 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6761 AR 0.9150
Epoch 216 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.7622 AR 0.9800
Epoch 216 batch 00006: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.8433 AR 0.9750
Epoch 216 batch 00007: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6189 AR 0.8000
Epoch 216 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5752 AR 0.9600
Epoch 216 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6876 AR 0.9600
Epoch 216 batch 00010: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.5329 AR 0.8300
Epoch 217 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.8300 AR 0.9400
Epoch 217 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.5208 AR 0.9000
Epoch 217 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.5338 AR 0.8467
Epoch 217 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7472 AR 0.9550
Epoch 217 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6617 AR 0.8750
Epoch 217 batch 00006: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.7498 AR 0.9800
Epoch 217 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6821 AR 1.0000
Epoch 217 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7698 AR 1.0000
Epoch 217 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6242 AR 0.8150
Epoch 217 batch 00010: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6867 AR 0.9800
Epoch 218 batch 00001: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6947 AR 1.0000
Epoch 218 batch 00002: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.6983 AR 0.9750
Epoch 218 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6722 AR 0.9800
Epoch 218 batch 00004: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.7536 AR 0.9300
Epoch 218 batch 00005: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.5892 AR 0.8600
Epoch 218 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6725 AR 0.9550
Epoch 218 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7283 AR 0.9000
Epoch 218 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6900 AR 0.9000
Epoch 218 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.7202 AR 0.9667
Epoch 218 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7573 AR 0.9550
Epoch 219 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6008 AR 0.8400
Epoch 219 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6886 AR 0.9667
Epoch 219 batch 00003: Loss 0.0016 Regression loss 0.0012 Classification loss 0.0003 AP 0.5862 AR 0.8400
Epoch 219 batch 00004: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6972 AR 0.9750
Epoch 219 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.7083 AR 1.0000
Epoch 219 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7361 AR 1.0000
Epoch 219 batch 00007: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6689 AR 0.9500
Epoch 219 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0001 AP 0.6631 AR 0.8667
Epoch 219 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6967 AR 0.8800
Epoch 219 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8538 AR 1.0000
Epoch 220 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6196 AR 0.8417
Epoch 220 batch 00002: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7625 AR 0.9467
Epoch 220 batch 00003: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.6950 AR 0.9800
Epoch 220 batch 00004: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.5948 AR 0.8800
Epoch 220 batch 00005: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0002 AP 0.6808 AR 0.8800
Epoch 220 batch 00006: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.7150 AR 0.9550
Epoch 220 batch 00007: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.6833 AR 0.9800
Epoch 220 batch 00008: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.5933 AR 0.7750
Epoch 220 batch 00009: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7764 AR 0.8667
Epoch 220 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6544 AR 0.9550
Epoch 221 batch 00001: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0003 AP 0.4410 AR 0.7333
Epoch 221 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7820 AR 0.9350
Epoch 221 batch 00003: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6550 AR 0.9750
Epoch 221 batch 00004: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0002 AP 0.6908 AR 0.9500
Epoch 221 batch 00005: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.6239 AR 0.8550
Epoch 221 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6250 AR 0.9067
Epoch 221 batch 00007: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.6492 AR 0.7767
Epoch 221 batch 00008: Loss 0.0044 Regression loss 0.0042 Classification loss 0.0002 AP 0.6255 AR 0.8750
Epoch 221 batch 00009: Loss 0.0033 Regression loss 0.0031 Classification loss 0.0002 AP 0.6798 AR 0.8667
Epoch 221 batch 00010: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.5972 AR 0.8350
Epoch 222 batch 00001: Loss 0.0040 Regression loss 0.0036 Classification loss 0.0003 AP 0.7775 AR 0.9550
Epoch 222 batch 00002: Loss 0.0034 Regression loss 0.0032 Classification loss 0.0002 AP 0.6645 AR 0.9550
Epoch 222 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6564 AR 1.0000
Epoch 222 batch 00004: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7436 AR 0.8550
Epoch 222 batch 00005: Loss 0.0028 Regression loss 0.0027 Classification loss 0.0001 AP 0.3933 AR 0.6217
Epoch 222 batch 00006: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7262 AR 0.8917
Epoch 222 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7028 AR 0.9550
Epoch 222 batch 00008: Loss 0.0033 Regression loss 0.0030 Classification loss 0.0003 AP 0.5546 AR 1.0000
Epoch 222 batch 00009: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7383 AR 0.9000
Epoch 222 batch 00010: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7939 AR 0.9800
Epoch 223 batch 00001: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0002 AP 0.8392 AR 0.9500
Epoch 223 batch 00002: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0002 AP 0.6200 AR 0.9600
Epoch 223 batch 00003: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7717 AR 0.9800
Epoch 223 batch 00004: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6613 AR 0.9417
Epoch 223 batch 00005: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6664 AR 0.9667
Epoch 223 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7152 AR 0.9550
Epoch 223 batch 00007: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0003 AP 0.5891 AR 0.8800
Epoch 223 batch 00008: Loss 0.0043 Regression loss 0.0040 Classification loss 0.0003 AP 0.6233 AR 0.8100
Epoch 223 batch 00009: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.5475 AR 0.8250
Epoch 223 batch 00010: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6975 AR 0.9133
Epoch 224 batch 00001: Loss 0.0034 Regression loss 0.0033 Classification loss 0.0002 AP 0.7633 AR 0.8300
Epoch 224 batch 00002: Loss 0.0035 Regression loss 0.0031 Classification loss 0.0004 AP 0.5150 AR 0.6417
Epoch 224 batch 00003: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0003 AP 0.7653 AR 1.0000
Epoch 224 batch 00004: Loss 0.0033 Regression loss 0.0032 Classification loss 0.0002 AP 0.7917 AR 0.9800
Epoch 224 batch 00005: Loss 0.0034 Regression loss 0.0031 Classification loss 0.0002 AP 0.7071 AR 0.9600
Epoch 224 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.7339 AR 0.9667
Epoch 224 batch 00007: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.5780 AR 0.8800
Epoch 224 batch 00008: Loss 0.0037 Regression loss 0.0035 Classification loss 0.0002 AP 0.5025 AR 0.6583
Epoch 224 batch 00009: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6867 AR 0.9800
Epoch 224 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7025 AR 0.9750
Epoch 225 batch 00001: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0002 AP 0.5908 AR 0.8417
Epoch 225 batch 00002: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7613 AR 0.9800
Epoch 225 batch 00003: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7520 AR 1.0000
Epoch 225 batch 00004: Loss 0.0034 Regression loss 0.0031 Classification loss 0.0003 AP 0.6571 AR 0.9067
Epoch 225 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6236 AR 0.9300
Epoch 225 batch 00006: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7722 AR 0.9750
Epoch 225 batch 00007: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0002 AP 0.6200 AR 0.7917
Epoch 225 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7487 AR 0.8750
Epoch 225 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6133 AR 0.9000
Epoch 225 batch 00010: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6008 AR 0.8800
Epoch 226 batch 00001: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.6433 AR 1.0000
Epoch 226 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7549 AR 0.9800
Epoch 226 batch 00003: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7256 AR 0.9500
Epoch 226 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.8138 AR 0.9017
Epoch 226 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6358 AR 0.9000
Epoch 226 batch 00006: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5981 AR 0.8500
Epoch 226 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8125 AR 1.0000
Epoch 226 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5006 AR 0.7750
Epoch 226 batch 00009: Loss 0.0016 Regression loss 0.0012 Classification loss 0.0003 AP 0.6114 AR 0.8300
Epoch 226 batch 00010: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.7400 AR 0.9500
Epoch 227 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6908 AR 0.9800
Epoch 227 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.6252 AR 0.8750
Epoch 227 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7155 AR 0.9800
Epoch 227 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.6722 AR 1.0000
Epoch 227 batch 00005: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.9133 AR 1.0000
Epoch 227 batch 00006: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.5686 AR 0.8167
Epoch 227 batch 00007: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0004 AP 0.6495 AR 0.8050
Epoch 227 batch 00008: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7102 AR 0.9800
Epoch 227 batch 00009: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.7675 AR 0.9500
Epoch 227 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6942 AR 0.8967
Epoch 228 batch 00001: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.6606 AR 1.0000
Epoch 228 batch 00002: Loss 0.0017 Regression loss 0.0013 Classification loss 0.0004 AP 0.6881 AR 0.9100
Epoch 228 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7542 AR 0.9667
Epoch 228 batch 00004: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.7856 AR 0.9800
Epoch 228 batch 00005: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.5127 AR 0.6667
Epoch 228 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6767 AR 0.8550
Epoch 228 batch 00007: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.5994 AR 0.9300
Epoch 228 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6822 AR 0.9167
Epoch 228 batch 00009: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7958 AR 0.9750
Epoch 228 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6439 AR 0.8750
Epoch 229 batch 00001: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.7429 AR 0.9750
Epoch 229 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5578 AR 0.8350
Epoch 229 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6464 AR 0.9750
Epoch 229 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7517 AR 0.8750
Epoch 229 batch 00005: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0003 AP 0.6842 AR 0.9550
Epoch 229 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7617 AR 0.9750
Epoch 229 batch 00007: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7964 AR 1.0000
Epoch 229 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6817 AR 0.8750
Epoch 229 batch 00009: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6689 AR 0.9800
Epoch 229 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.7119 AR 0.9800
Epoch 230 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8198 AR 1.0000
Epoch 230 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6175 AR 0.9000
Epoch 230 batch 00003: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.7083 AR 0.8967
Epoch 230 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.8002 AR 1.0000
Epoch 230 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6464 AR 0.8800
Epoch 230 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6639 AR 0.9000
Epoch 230 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7733 AR 0.9750
Epoch 230 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0003 AP 0.7000 AR 0.9350
Epoch 230 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6072 AR 0.8750
Epoch 230 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7425 AR 1.0000
Epoch 231 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6431 AR 0.7800
Epoch 231 batch 00002: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7042 AR 1.0000
Epoch 231 batch 00003: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7583 AR 1.0000
Epoch 231 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6775 AR 0.9750
Epoch 231 batch 00005: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.6777 AR 0.8417
Epoch 231 batch 00006: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6872 AR 0.9600
Epoch 231 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7833 AR 0.9250
Epoch 231 batch 00008: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.7089 AR 1.0000
Epoch 231 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6787 AR 0.8933
Epoch 231 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6477 AR 0.9550
Epoch 232 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.5856 AR 0.8217
Epoch 232 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7288 AR 0.9500
Epoch 232 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6464 AR 0.9000
Epoch 232 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7483 AR 0.8867
Epoch 232 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7864 AR 1.0000
Epoch 232 batch 00006: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7905 AR 1.0000
Epoch 232 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7308 AR 0.9667
Epoch 232 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6630 AR 0.8800
Epoch 232 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0003 AP 0.5900 AR 0.9467
Epoch 232 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7024 AR 0.9550
Epoch 233 batch 00001: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7550 AR 0.9400
Epoch 233 batch 00002: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7052 AR 0.9800
Epoch 233 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6417 AR 0.8000
Epoch 233 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5467 AR 0.8550
Epoch 233 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6417 AR 0.9000
Epoch 233 batch 00006: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7256 AR 0.9500
Epoch 233 batch 00007: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0002 AP 0.6843 AR 0.9600
Epoch 233 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7267 AR 0.9250
Epoch 233 batch 00009: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.5913 AR 0.7800
Epoch 233 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6292 AR 0.8667
Epoch 234 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7217 AR 0.9600
Epoch 234 batch 00002: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.6645 AR 1.0000
Epoch 234 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8083 AR 0.9217
Epoch 234 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0003 AP 0.6000 AR 0.9000
Epoch 234 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0001 AP 0.8280 AR 0.9600
Epoch 234 batch 00006: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.7333 AR 0.9250
Epoch 234 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5403 AR 0.8800
Epoch 234 batch 00008: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.7083 AR 0.9300
Epoch 234 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6825 AR 0.9800
Epoch 234 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6580 AR 0.9600
Epoch 235 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5519 AR 0.8550
Epoch 235 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6199 AR 0.9000
Epoch 235 batch 00003: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.8067 AR 0.9750
Epoch 235 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.6792 AR 0.8967
Epoch 235 batch 00005: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7536 AR 0.9750
Epoch 235 batch 00006: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.6967 AR 0.8767
Epoch 235 batch 00007: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6649 AR 0.9800
Epoch 235 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7250 AR 0.9000
Epoch 235 batch 00009: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5167 AR 0.8600
Epoch 235 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5986 AR 0.8250
Epoch 236 batch 00001: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7750 AR 0.9750
Epoch 236 batch 00002: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0003 AP 0.6136 AR 0.8167
Epoch 236 batch 00003: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.4141 AR 0.7300
Epoch 236 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7964 AR 0.9750
Epoch 236 batch 00005: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.8333 AR 0.9750
Epoch 236 batch 00006: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.5664 AR 0.8267
Epoch 236 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7067 AR 0.9267
Epoch 236 batch 00008: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0003 AP 0.7144 AR 0.9217
Epoch 236 batch 00009: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0002 AP 0.6073 AR 0.8550
Epoch 236 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7442 AR 0.9167
Epoch 237 batch 00001: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.6556 AR 0.9750
Epoch 237 batch 00002: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0002 AP 0.4255 AR 0.6550
Epoch 237 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6836 AR 1.0000
Epoch 237 batch 00004: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.6854 AR 0.9750
Epoch 237 batch 00005: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.6755 AR 0.9550
Epoch 237 batch 00006: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7471 AR 0.9350
Epoch 237 batch 00007: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.7600 AR 0.8500
Epoch 237 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.5595 AR 0.7867
Epoch 237 batch 00009: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.8067 AR 0.9467
Epoch 237 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6717 AR 0.9550
Epoch 238 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5554 AR 0.8933
Epoch 238 batch 00002: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7106 AR 0.9750
Epoch 238 batch 00003: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0002 AP 0.8072 AR 0.9750
Epoch 238 batch 00004: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.6208 AR 0.8950
Epoch 238 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7414 AR 1.0000
Epoch 238 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7717 AR 0.9000
Epoch 238 batch 00007: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7639 AR 1.0000
Epoch 238 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6167 AR 1.0000
Epoch 238 batch 00009: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0002 AP 0.6617 AR 0.8750
Epoch 238 batch 00010: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6267 AR 0.8350
Epoch 239 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6460 AR 0.8667
Epoch 239 batch 00002: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7756 AR 1.0000
Epoch 239 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6205 AR 0.9600
Epoch 239 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.6356 AR 0.9800
Epoch 239 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6516 AR 0.9550
Epoch 239 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7139 AR 0.9800
Epoch 239 batch 00007: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.6850 AR 0.8717
Epoch 239 batch 00008: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0003 AP 0.7367 AR 0.9000
Epoch 239 batch 00009: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7400 AR 0.9350
Epoch 239 batch 00010: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.5633 AR 0.8300
Epoch 240 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7050 AR 0.9250
Epoch 240 batch 00002: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.7117 AR 0.9800
Epoch 240 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.4881 AR 0.8800
Epoch 240 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7404 AR 1.0000
Epoch 240 batch 00005: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0002 AP 0.7363 AR 0.9750
Epoch 240 batch 00006: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6571 AR 0.8300
Epoch 240 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7592 AR 0.9667
Epoch 240 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.7800 AR 0.9550
Epoch 240 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.5717 AR 0.9333
Epoch 240 batch 00010: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7625 AR 1.0000
Epoch 241 batch 00001: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6091 AR 0.8800
Epoch 241 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7010 AR 0.9800
Epoch 241 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8133 AR 0.9550
Epoch 241 batch 00004: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.5553 AR 0.8467
Epoch 241 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7072 AR 0.8500
Epoch 241 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7350 AR 1.0000
Epoch 241 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6764 AR 0.9667
Epoch 241 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7330 AR 0.9800
Epoch 241 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7750 AR 0.9600
Epoch 241 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6733 AR 1.0000
Epoch 242 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7317 AR 0.8750
Epoch 242 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8031 AR 0.9467
Epoch 242 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5738 AR 0.8217
Epoch 242 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.7833 AR 1.0000
Epoch 242 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.5806 AR 0.8000
Epoch 242 batch 00006: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0002 AP 0.5964 AR 0.8667
Epoch 242 batch 00007: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.6530 AR 1.0000
Epoch 242 batch 00008: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6239 AR 0.8550
Epoch 242 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6875 AR 1.0000
Epoch 242 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7433 AR 0.9000
Epoch 243 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7533 AR 0.9500
Epoch 243 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.7557 AR 0.9500
Epoch 243 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6425 AR 0.8400
Epoch 243 batch 00004: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7989 AR 0.9500
Epoch 243 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7100 AR 0.8500
Epoch 243 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6138 AR 0.7967
Epoch 243 batch 00007: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7021 AR 0.9800
Epoch 243 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7064 AR 1.0000
Epoch 243 batch 00009: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6494 AR 1.0000
Epoch 243 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6273 AR 0.9750
Epoch 244 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7317 AR 0.9750
Epoch 244 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6358 AR 0.9217
Epoch 244 batch 00003: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.8133 AR 0.9750
Epoch 244 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6683 AR 0.8500
Epoch 244 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.8267 AR 0.9467
Epoch 244 batch 00006: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.5481 AR 0.8667
Epoch 244 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6625 AR 0.9750
Epoch 244 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6134 AR 1.0000
Epoch 244 batch 00009: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6744 AR 0.8600
Epoch 244 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6735 AR 0.8550
Epoch 245 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6556 AR 0.9417
Epoch 245 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6883 AR 0.9800
Epoch 245 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.8375 AR 1.0000
Epoch 245 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7612 AR 0.9750
Epoch 245 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7206 AR 0.9750
Epoch 245 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5733 AR 0.8667
Epoch 245 batch 00007: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.7338 AR 0.9550
Epoch 245 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7236 AR 0.9800
Epoch 245 batch 00009: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6827 AR 0.9200
Epoch 245 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7833 AR 0.9750
Epoch 246 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.8550 AR 1.0000
Epoch 246 batch 00002: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.6962 AR 0.9667
Epoch 246 batch 00003: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.6397 AR 0.9550
Epoch 246 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7571 AR 0.9467
Epoch 246 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6850 AR 0.9750
Epoch 246 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6024 AR 0.8400
Epoch 246 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.5706 AR 0.8000
Epoch 246 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7338 AR 1.0000
Epoch 246 batch 00009: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.8450 AR 0.9467
Epoch 246 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6016 AR 0.8550
Epoch 247 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.6705 AR 0.8600
Epoch 247 batch 00002: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7322 AR 0.9000
Epoch 247 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6456 AR 0.9217
Epoch 247 batch 00004: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6717 AR 1.0000
Epoch 247 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6619 AR 0.8717
Epoch 247 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7061 AR 1.0000
Epoch 247 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7498 AR 0.9750
Epoch 247 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7092 AR 0.9000
Epoch 247 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7393 AR 0.9600
Epoch 247 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7483 AR 0.9467
Epoch 248 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5881 AR 0.8500
Epoch 248 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7383 AR 1.0000
Epoch 248 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6192 AR 0.9100
Epoch 248 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7547 AR 1.0000
Epoch 248 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7256 AR 0.9800
Epoch 248 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7233 AR 0.9550
Epoch 248 batch 00007: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7493 AR 0.9800
Epoch 248 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.8094 AR 0.9550
Epoch 248 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7345 AR 0.9750
Epoch 248 batch 00010: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6450 AR 0.8417
Epoch 249 batch 00001: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.6142 AR 0.8250
Epoch 249 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.5816 AR 0.8050
Epoch 249 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7108 AR 0.9800
Epoch 249 batch 00004: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0001 AP 0.7200 AR 1.0000
Epoch 249 batch 00005: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.6700 AR 0.8500
Epoch 249 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.8088 AR 0.9550
Epoch 249 batch 00007: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0002 AP 0.6980 AR 0.9800
Epoch 249 batch 00008: Loss 0.0032 Regression loss 0.0030 Classification loss 0.0002 AP 0.8144 AR 1.0000
Epoch 249 batch 00009: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.6038 AR 0.8550
Epoch 249 batch 00010: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.6689 AR 0.9600
Epoch 250 batch 00001: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7443 AR 0.8750
Epoch 250 batch 00002: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0001 AP 0.7217 AR 0.9000
Epoch 250 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6644 AR 0.9800
Epoch 250 batch 00004: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.6617 AR 0.9417
Epoch 250 batch 00005: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7914 AR 0.9750
Epoch 250 batch 00006: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5545 AR 0.9150
Epoch 250 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.5554 AR 0.8550
Epoch 250 batch 00008: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.8239 AR 0.9800
Epoch 250 batch 00009: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.4821 AR 0.8067
Epoch 250 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7038 AR 0.9000
Epoch 251 batch 00001: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7544 AR 1.0000
Epoch 251 batch 00002: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6667 AR 0.9400
Epoch 251 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.6181 AR 0.7800
Epoch 251 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7167 AR 0.9667
Epoch 251 batch 00005: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.6517 AR 0.9417
Epoch 251 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7023 AR 0.8750
Epoch 251 batch 00007: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7883 AR 0.9550
Epoch 251 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7566 AR 0.9800
Epoch 251 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6533 AR 0.9000
Epoch 251 batch 00010: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.7252 AR 0.9800
Epoch 252 batch 00001: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.6893 AR 0.9800
Epoch 252 batch 00002: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6808 AR 0.9000
Epoch 252 batch 00003: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7722 AR 0.9750
Epoch 252 batch 00004: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6867 AR 0.8550
Epoch 252 batch 00005: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6877 AR 0.9800
Epoch 252 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.6247 AR 0.9550
Epoch 252 batch 00007: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0001 AP 0.7992 AR 0.9350
Epoch 252 batch 00008: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7436 AR 0.9467
Epoch 252 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6121 AR 0.9000
Epoch 252 batch 00010: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6858 AR 0.8750
Epoch 253 batch 00001: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7033 AR 0.8967
Epoch 253 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6973 AR 0.9800
Epoch 253 batch 00003: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.7567 AR 0.9167
Epoch 253 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7581 AR 1.0000
Epoch 253 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6925 AR 0.9667
Epoch 253 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7000 AR 1.0000
Epoch 253 batch 00007: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7333 AR 0.8967
Epoch 253 batch 00008: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.5961 AR 0.9600
Epoch 253 batch 00009: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6267 AR 0.7600
Epoch 253 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0002 AP 0.6433 AR 0.8600
Epoch 254 batch 00001: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7189 AR 0.9550
Epoch 254 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7241 AR 0.9600
Epoch 254 batch 00003: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.8225 AR 0.9750
Epoch 254 batch 00004: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7431 AR 0.9750
Epoch 254 batch 00005: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6478 AR 0.9550
Epoch 254 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6646 AR 0.9800
Epoch 254 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6267 AR 1.0000
Epoch 254 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6680 AR 0.9467
Epoch 254 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8314 AR 0.9750
Epoch 254 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.8076 AR 0.9800
Epoch 255 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6752 AR 0.9800
Epoch 255 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6269 AR 0.9000
Epoch 255 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7438 AR 0.9467
Epoch 255 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7781 AR 0.9800
Epoch 255 batch 00005: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7000 AR 1.0000
Epoch 255 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7374 AR 0.9800
Epoch 255 batch 00007: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.6558 AR 0.9350
Epoch 255 batch 00008: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7633 AR 0.9550
Epoch 255 batch 00009: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6611 AR 0.8600
Epoch 255 batch 00010: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6503 AR 0.8500
Epoch 256 batch 00001: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.6011 AR 0.8550
Epoch 256 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6275 AR 0.8600
Epoch 256 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7767 AR 0.9800
Epoch 256 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6889 AR 0.9000
Epoch 256 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6650 AR 1.0000
Epoch 256 batch 00006: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7206 AR 0.8750
Epoch 256 batch 00007: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0002 AP 0.6405 AR 0.9750
Epoch 256 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6306 AR 0.8750
Epoch 256 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7698 AR 0.9667
Epoch 256 batch 00010: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7019 AR 0.9600
Epoch 257 batch 00001: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0003 AP 0.5363 AR 0.7800
Epoch 257 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7067 AR 0.9667
Epoch 257 batch 00003: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7671 AR 0.9800
Epoch 257 batch 00004: Loss 0.0012 Regression loss 0.0009 Classification loss 0.0002 AP 0.7012 AR 0.9667
Epoch 257 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6343 AR 0.9800
Epoch 257 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7267 AR 0.9750
Epoch 257 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.6206 AR 0.9000
Epoch 257 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6911 AR 0.9350
Epoch 257 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8198 AR 1.0000
Epoch 257 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7314 AR 0.9800
Epoch 258 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6805 AR 0.9267
Epoch 258 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7863 AR 0.9800
Epoch 258 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6681 AR 1.0000
Epoch 258 batch 00004: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6483 AR 0.8050
Epoch 258 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7488 AR 0.8750
Epoch 258 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7925 AR 0.9400
Epoch 258 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6971 AR 1.0000
Epoch 258 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6589 AR 1.0000
Epoch 258 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7667 AR 0.9417
Epoch 258 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6117 AR 0.9017
Epoch 259 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6822 AR 0.9600
Epoch 259 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8281 AR 1.0000
Epoch 259 batch 00003: Loss 0.0012 Regression loss 0.0009 Classification loss 0.0002 AP 0.7348 AR 0.8800
Epoch 259 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7041 AR 0.9800
Epoch 259 batch 00005: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7367 AR 1.0000
Epoch 259 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6943 AR 0.9800
Epoch 259 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6058 AR 0.9000
Epoch 259 batch 00008: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.6601 AR 0.8850
Epoch 259 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7406 AR 0.9500
Epoch 259 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7363 AR 1.0000
Epoch 260 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6567 AR 0.9350
Epoch 260 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6362 AR 0.9750
Epoch 260 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7883 AR 0.9750
Epoch 260 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7263 AR 0.9550
Epoch 260 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.7923 AR 1.0000
Epoch 260 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7367 AR 0.9600
Epoch 260 batch 00007: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7198 AR 0.9800
Epoch 260 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.8100 AR 0.9800
Epoch 260 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6722 AR 0.9167
Epoch 260 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6936 AR 0.9467
Epoch 261 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7112 AR 0.9667
Epoch 261 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6194 AR 0.8800
Epoch 261 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7642 AR 1.0000
Epoch 261 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7506 AR 1.0000
Epoch 261 batch 00005: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.7125 AR 0.9350
Epoch 261 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7042 AR 0.9667
Epoch 261 batch 00007: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7767 AR 0.9800
Epoch 261 batch 00008: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6893 AR 0.9750
Epoch 261 batch 00009: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7511 AR 0.9300
Epoch 261 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7194 AR 0.9467
Epoch 262 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.5889 AR 0.8500
Epoch 262 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6317 AR 0.8750
Epoch 262 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6939 AR 0.9267
Epoch 262 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7625 AR 1.0000
Epoch 262 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7296 AR 1.0000
Epoch 262 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7317 AR 1.0000
Epoch 262 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7048 AR 1.0000
Epoch 262 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.8633 AR 0.9800
Epoch 262 batch 00009: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6396 AR 0.8817
Epoch 262 batch 00010: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.6173 AR 0.8600
Epoch 263 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5822 AR 0.9750
Epoch 263 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6414 AR 0.9750
Epoch 263 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.8167 AR 1.0000
Epoch 263 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6419 AR 0.9750
Epoch 263 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7688 AR 0.9600
Epoch 263 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.8133 AR 0.9667
Epoch 263 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.7019 AR 0.9267
Epoch 263 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6194 AR 0.8800
Epoch 263 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.8255 AR 0.9550
Epoch 263 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7317 AR 1.0000
Epoch 264 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.6014 AR 0.8800
Epoch 264 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7705 AR 1.0000
Epoch 264 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8317 AR 0.9500
Epoch 264 batch 00004: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7862 AR 0.9800
Epoch 264 batch 00005: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0001 AP 0.6717 AR 0.9550
Epoch 264 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6872 AR 0.8800
Epoch 264 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6180 AR 0.8467
Epoch 264 batch 00008: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6196 AR 1.0000
Epoch 264 batch 00009: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.6600 AR 0.9600
Epoch 264 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7881 AR 1.0000
Epoch 265 batch 00001: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.8234 AR 1.0000
Epoch 265 batch 00002: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7493 AR 0.9600
Epoch 265 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6408 AR 0.9000
Epoch 265 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7083 AR 1.0000
Epoch 265 batch 00005: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7533 AR 0.9800
Epoch 265 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6651 AR 0.9350
Epoch 265 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7214 AR 0.9800
Epoch 265 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6471 AR 1.0000
Epoch 265 batch 00009: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.8000 AR 0.9550
Epoch 265 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6538 AR 0.8600
Epoch 266 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.5614 AR 0.8550
Epoch 266 batch 00002: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6767 AR 0.9750
Epoch 266 batch 00003: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6639 AR 0.8667
Epoch 266 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7417 AR 1.0000
Epoch 266 batch 00005: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7471 AR 0.9800
Epoch 266 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8433 AR 0.9800
Epoch 266 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6612 AR 0.9500
Epoch 266 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.6291 AR 0.9667
Epoch 266 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7642 AR 0.9800
Epoch 266 batch 00010: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0003 AP 0.6694 AR 0.7800
Epoch 267 batch 00001: Loss 0.0026 Regression loss 0.0025 Classification loss 0.0001 AP 0.6917 AR 0.9050
Epoch 267 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6842 AR 0.8750
Epoch 267 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7870 AR 0.9750
Epoch 267 batch 00004: Loss 0.0034 Regression loss 0.0032 Classification loss 0.0001 AP 0.6225 AR 0.8167
Epoch 267 batch 00005: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.7514 AR 0.9750
Epoch 267 batch 00006: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7083 AR 0.9267
Epoch 267 batch 00007: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0002 AP 0.7026 AR 0.9800
Epoch 267 batch 00008: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0002 AP 0.6417 AR 0.8250
Epoch 267 batch 00009: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.7208 AR 1.0000
Epoch 267 batch 00010: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0002 AP 0.6976 AR 0.9400
Epoch 268 batch 00001: Loss 0.0039 Regression loss 0.0037 Classification loss 0.0001 AP 0.6698 AR 0.8100
Epoch 268 batch 00002: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.8438 AR 0.9800
Epoch 268 batch 00003: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0003 AP 0.5804 AR 0.9000
Epoch 268 batch 00004: Loss 0.0035 Regression loss 0.0033 Classification loss 0.0002 AP 0.6806 AR 0.9800
Epoch 268 batch 00005: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0002 AP 0.5419 AR 0.7417
Epoch 268 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5771 AR 0.9750
Epoch 268 batch 00007: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.6381 AR 0.9100
Epoch 268 batch 00008: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0002 AP 0.7267 AR 0.8850
Epoch 268 batch 00009: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7178 AR 0.9000
Epoch 268 batch 00010: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0002 AP 0.6922 AR 0.9667
Epoch 269 batch 00001: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0002 AP 0.6357 AR 0.8350
Epoch 269 batch 00002: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.6548 AR 0.9800
Epoch 269 batch 00003: Loss 0.0032 Regression loss 0.0030 Classification loss 0.0002 AP 0.8183 AR 0.9300
Epoch 269 batch 00004: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0002 AP 0.5873 AR 0.8800
Epoch 269 batch 00005: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.6788 AR 0.9550
Epoch 269 batch 00006: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8338 AR 1.0000
Epoch 269 batch 00007: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6259 AR 0.9467
Epoch 269 batch 00008: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7533 AR 1.0000
Epoch 269 batch 00009: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6655 AR 0.9800
Epoch 269 batch 00010: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0002 AP 0.7664 AR 0.9750
Epoch 270 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7602 AR 0.9417
Epoch 270 batch 00002: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0002 AP 0.5580 AR 0.8467
Epoch 270 batch 00003: Loss 0.0037 Regression loss 0.0033 Classification loss 0.0003 AP 0.6395 AR 0.9750
Epoch 270 batch 00004: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.5842 AR 0.8350
Epoch 270 batch 00005: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0001 AP 0.7110 AR 1.0000
Epoch 270 batch 00006: Loss 0.0042 Regression loss 0.0040 Classification loss 0.0002 AP 0.7008 AR 0.9333
Epoch 270 batch 00007: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.8150 AR 1.0000
Epoch 270 batch 00008: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.7671 AR 0.9267
Epoch 270 batch 00009: Loss 0.0041 Regression loss 0.0038 Classification loss 0.0003 AP 0.6383 AR 0.8417
Epoch 270 batch 00010: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0002 AP 0.7750 AR 1.0000
Epoch 271 batch 00001: Loss 0.0060 Regression loss 0.0058 Classification loss 0.0003 AP 0.6842 AR 0.8517
Epoch 271 batch 00002: Loss 0.0072 Regression loss 0.0069 Classification loss 0.0003 AP 0.5267 AR 0.7300
Epoch 271 batch 00003: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.7844 AR 0.9800
Epoch 271 batch 00004: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.7702 AR 0.9417
Epoch 271 batch 00005: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0003 AP 0.5700 AR 0.8350
Epoch 271 batch 00006: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.6860 AR 0.9267
Epoch 271 batch 00007: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7350 AR 0.9750
Epoch 271 batch 00008: Loss 0.0050 Regression loss 0.0047 Classification loss 0.0003 AP 0.5305 AR 0.8167
Epoch 271 batch 00009: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.7172 AR 0.9300
Epoch 271 batch 00010: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6671 AR 0.9000
Epoch 272 batch 00001: Loss 0.0039 Regression loss 0.0036 Classification loss 0.0002 AP 0.5029 AR 0.8183
Epoch 272 batch 00002: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0003 AP 0.7000 AR 0.9167
Epoch 272 batch 00003: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.7355 AR 0.9100
Epoch 272 batch 00004: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0002 AP 0.7246 AR 0.9750
Epoch 272 batch 00005: Loss 0.0019 Regression loss 0.0015 Classification loss 0.0004 AP 0.6461 AR 0.9550
Epoch 272 batch 00006: Loss 0.0043 Regression loss 0.0040 Classification loss 0.0003 AP 0.6917 AR 0.8800
Epoch 272 batch 00007: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.5967 AR 0.8417
Epoch 272 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7293 AR 0.9800
Epoch 272 batch 00009: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0003 AP 0.8433 AR 1.0000
Epoch 272 batch 00010: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.7088 AR 0.9300
Epoch 273 batch 00001: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.7183 AR 0.9200
Epoch 273 batch 00002: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7039 AR 1.0000
Epoch 273 batch 00003: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.8055 AR 0.9800
Epoch 273 batch 00004: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.5933 AR 0.8967
Epoch 273 batch 00005: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6671 AR 0.9017
Epoch 273 batch 00006: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0002 AP 0.8522 AR 1.0000
Epoch 273 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0002 AP 0.6383 AR 0.9750
Epoch 273 batch 00008: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.4767 AR 0.6750
Epoch 273 batch 00009: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0002 AP 0.7583 AR 0.9000
Epoch 273 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7800 AR 0.9000
Epoch 274 batch 00001: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7225 AR 0.9800
Epoch 274 batch 00002: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6963 AR 1.0000
Epoch 274 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.8633 AR 1.0000
Epoch 274 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7603 AR 0.9750
Epoch 274 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7381 AR 0.9467
Epoch 274 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6489 AR 1.0000
Epoch 274 batch 00007: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7700 AR 0.9550
Epoch 274 batch 00008: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0002 AP 0.7092 AR 1.0000
Epoch 274 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7331 AR 0.9467
Epoch 274 batch 00010: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.5780 AR 0.9050
Epoch 275 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6708 AR 0.9000
Epoch 275 batch 00002: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.6436 AR 0.9600
Epoch 275 batch 00003: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.6837 AR 1.0000
Epoch 275 batch 00004: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.7217 AR 1.0000
Epoch 275 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.5781 AR 0.8250
Epoch 275 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.8314 AR 1.0000
Epoch 275 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6433 AR 0.8417
Epoch 275 batch 00008: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.6736 AR 0.9100
Epoch 275 batch 00009: Loss 0.0019 Regression loss 0.0014 Classification loss 0.0005 AP 0.7162 AR 0.9550
Epoch 275 batch 00010: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7805 AR 1.0000
Epoch 276 batch 00001: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.7871 AR 1.0000
Epoch 276 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6827 AR 1.0000
Epoch 276 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6944 AR 0.9750
Epoch 276 batch 00004: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0003 AP 0.7117 AR 0.9300
Epoch 276 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0001 AP 0.7550 AR 0.9750
Epoch 276 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.7222 AR 1.0000
Epoch 276 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.7871 AR 0.9550
Epoch 276 batch 00008: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0002 AP 0.7539 AR 0.9000
Epoch 276 batch 00009: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.7600 AR 0.9600
Epoch 276 batch 00010: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0003 AP 0.5844 AR 0.9217
Epoch 277 batch 00001: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7000 AR 0.9150
Epoch 277 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6695 AR 0.9500
Epoch 277 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5675 AR 0.9350
Epoch 277 batch 00004: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7567 AR 1.0000
Epoch 277 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7267 AR 0.9467
Epoch 277 batch 00006: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0004 AP 0.8155 AR 0.9800
Epoch 277 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7300 AR 0.8750
Epoch 277 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7438 AR 0.9750
Epoch 277 batch 00009: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.6578 AR 0.9133
Epoch 277 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7500 AR 0.9550
Epoch 278 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7231 AR 0.9800
Epoch 278 batch 00002: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.8117 AR 0.9550
Epoch 278 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6933 AR 0.8417
Epoch 278 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6117 AR 0.9750
Epoch 278 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6317 AR 0.7500
Epoch 278 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5772 AR 0.9067
Epoch 278 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7489 AR 1.0000
Epoch 278 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0003 AP 0.6485 AR 0.9800
Epoch 278 batch 00009: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.7875 AR 0.9750
Epoch 278 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7407 AR 0.9800
Epoch 279 batch 00001: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7183 AR 0.9417
Epoch 279 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7325 AR 0.8600
Epoch 279 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6314 AR 1.0000
Epoch 279 batch 00004: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0001 AP 0.7431 AR 0.9750
Epoch 279 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6076 AR 0.9067
Epoch 279 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6338 AR 0.9000
Epoch 279 batch 00007: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0002 AP 0.7690 AR 0.9333
Epoch 279 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6567 AR 0.8600
Epoch 279 batch 00009: Loss 0.0015 Regression loss 0.0011 Classification loss 0.0004 AP 0.7278 AR 0.9800
Epoch 279 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7288 AR 0.9750
Epoch 280 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7956 AR 1.0000
Epoch 280 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6905 AR 0.8600
Epoch 280 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.5950 AR 0.7833
Epoch 280 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.7310 AR 0.9100
Epoch 280 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6144 AR 0.9600
Epoch 280 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6342 AR 0.9250
Epoch 280 batch 00007: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.7267 AR 0.9467
Epoch 280 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7956 AR 1.0000
Epoch 280 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6900 AR 0.8167
Epoch 280 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7667 AR 0.9750
Epoch 281 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7117 AR 1.0000
Epoch 281 batch 00002: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7294 AR 0.9300
Epoch 281 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.7369 AR 0.9600
Epoch 281 batch 00004: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0002 AP 0.7017 AR 0.9750
Epoch 281 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6688 AR 1.0000
Epoch 281 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6367 AR 0.8083
Epoch 281 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6356 AR 0.9800
Epoch 281 batch 00008: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0001 AP 0.7726 AR 0.9550
Epoch 281 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6945 AR 0.8750
Epoch 281 batch 00010: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.7427 AR 0.9800
Epoch 282 batch 00001: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0001 AP 0.5941 AR 0.9000
Epoch 282 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6075 AR 0.9800
Epoch 282 batch 00003: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7794 AR 0.9600
Epoch 282 batch 00004: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.5781 AR 0.9000
Epoch 282 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6867 AR 0.9750
Epoch 282 batch 00006: Loss 0.0039 Regression loss 0.0035 Classification loss 0.0004 AP 0.8467 AR 0.8667
Epoch 282 batch 00007: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.6417 AR 0.8400
Epoch 282 batch 00008: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7700 AR 1.0000
Epoch 282 batch 00009: Loss 0.0037 Regression loss 0.0035 Classification loss 0.0002 AP 0.6631 AR 0.9550
Epoch 282 batch 00010: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.7280 AR 0.9800
Epoch 283 batch 00001: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.6667 AR 0.9000
Epoch 283 batch 00002: Loss 0.0030 Regression loss 0.0028 Classification loss 0.0002 AP 0.6070 AR 0.8150
Epoch 283 batch 00003: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7583 AR 1.0000
Epoch 283 batch 00004: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7110 AR 0.9500
Epoch 283 batch 00005: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.8050 AR 0.9550
Epoch 283 batch 00006: Loss 0.0021 Regression loss 0.0015 Classification loss 0.0006 AP 0.7255 AR 0.9350
Epoch 283 batch 00007: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6750 AR 0.8500
Epoch 283 batch 00008: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6967 AR 0.9800
Epoch 283 batch 00009: Loss 0.0027 Regression loss 0.0020 Classification loss 0.0007 AP 0.6813 AR 0.9050
Epoch 283 batch 00010: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7063 AR 0.9050
Epoch 284 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6460 AR 0.9200
Epoch 284 batch 00002: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7379 AR 0.9800
Epoch 284 batch 00003: Loss 0.0026 Regression loss 0.0018 Classification loss 0.0007 AP 0.6060 AR 0.9550
Epoch 284 batch 00004: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.6881 AR 0.8550
Epoch 284 batch 00005: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7061 AR 0.9500
Epoch 284 batch 00006: Loss 0.0015 Regression loss 0.0011 Classification loss 0.0004 AP 0.5886 AR 0.9667
Epoch 284 batch 00007: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.8050 AR 1.0000
Epoch 284 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6552 AR 1.0000
Epoch 284 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8058 AR 1.0000
Epoch 284 batch 00010: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6967 AR 0.9300
Epoch 285 batch 00001: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.4833 AR 0.8767
Epoch 285 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6925 AR 0.9000
Epoch 285 batch 00003: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7661 AR 0.9300
Epoch 285 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6906 AR 0.9800
Epoch 285 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7152 AR 0.9550
Epoch 285 batch 00006: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6937 AR 1.0000
Epoch 285 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0003 AP 0.8225 AR 0.9800
Epoch 285 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7006 AR 0.9000
Epoch 285 batch 00009: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.7114 AR 0.8250
Epoch 285 batch 00010: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7833 AR 0.9500
Epoch 286 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6638 AR 0.8833
Epoch 286 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8543 AR 0.9800
Epoch 286 batch 00003: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8177 AR 0.9800
Epoch 286 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8092 AR 0.9800
Epoch 286 batch 00005: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7831 AR 0.9150
Epoch 286 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5804 AR 0.8750
Epoch 286 batch 00007: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7225 AR 1.0000
Epoch 286 batch 00008: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0002 AP 0.6817 AR 0.9500
Epoch 286 batch 00009: Loss 0.0034 Regression loss 0.0032 Classification loss 0.0001 AP 0.6630 AR 0.9467
Epoch 286 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6142 AR 0.9000
Epoch 287 batch 00001: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6042 AR 0.8900
Epoch 287 batch 00002: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0003 AP 0.5116 AR 0.7350
Epoch 287 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7831 AR 0.9750
Epoch 287 batch 00004: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.6031 AR 0.8800
Epoch 287 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6680 AR 0.9350
Epoch 287 batch 00006: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7639 AR 1.0000
Epoch 287 batch 00007: Loss 0.0023 Regression loss 0.0022 Classification loss 0.0001 AP 0.7862 AR 0.9500
Epoch 287 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.8021 AR 1.0000
Epoch 287 batch 00009: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6188 AR 0.8300
Epoch 287 batch 00010: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6848 AR 0.8800
Epoch 288 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7471 AR 0.8600
Epoch 288 batch 00002: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8214 AR 1.0000
Epoch 288 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6689 AR 0.9750
Epoch 288 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6678 AR 0.9667
Epoch 288 batch 00005: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7214 AR 0.9750
Epoch 288 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7222 AR 1.0000
Epoch 288 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6995 AR 0.9500
Epoch 288 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.5321 AR 0.8400
Epoch 288 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7681 AR 0.9750
Epoch 288 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7217 AR 0.8550
Epoch 289 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6633 AR 0.8550
Epoch 289 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6521 AR 0.9333
Epoch 289 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6097 AR 0.8067
Epoch 289 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6761 AR 1.0000
Epoch 289 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6223 AR 0.8550
Epoch 289 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6450 AR 0.8750
Epoch 289 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7152 AR 0.9750
Epoch 289 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7729 AR 0.9800
Epoch 289 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7525 AR 1.0000
Epoch 289 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7522 AR 0.9750
Epoch 290 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6953 AR 0.9600
Epoch 290 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6267 AR 0.8917
Epoch 290 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6848 AR 0.9000
Epoch 290 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7372 AR 1.0000
Epoch 290 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7713 AR 0.9750
Epoch 290 batch 00006: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6942 AR 0.9150
Epoch 290 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6333 AR 0.9800
Epoch 290 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7210 AR 0.9800
Epoch 290 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6989 AR 0.9250
Epoch 290 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7367 AR 0.9000
Epoch 291 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7400 AR 0.8300
Epoch 291 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7073 AR 0.9550
Epoch 291 batch 00003: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.6732 AR 0.9800
Epoch 291 batch 00004: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.8017 AR 1.0000
Epoch 291 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6991 AR 0.9500
Epoch 291 batch 00006: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.5375 AR 0.7350
Epoch 291 batch 00007: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7094 AR 0.9550
Epoch 291 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6898 AR 0.9600
Epoch 291 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0003 AP 0.7289 AR 0.9800
Epoch 291 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8258 AR 0.9667
Epoch 292 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5900 AR 0.8800
Epoch 292 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6996 AR 0.9800
Epoch 292 batch 00003: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.7617 AR 1.0000
Epoch 292 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6067 AR 0.9000
Epoch 292 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8056 AR 1.0000
Epoch 292 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6494 AR 0.9600
Epoch 292 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7287 AR 0.9467
Epoch 292 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6417 AR 0.7750
Epoch 292 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7807 AR 0.9800
Epoch 292 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8167 AR 0.9750
Epoch 293 batch 00001: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.7163 AR 0.8217
Epoch 293 batch 00002: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7811 AR 0.9800
Epoch 293 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7571 AR 0.9300
Epoch 293 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7439 AR 0.8500
Epoch 293 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.5153 AR 0.9000
Epoch 293 batch 00006: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.8450 AR 1.0000
Epoch 293 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0003 AP 0.6073 AR 0.9750
Epoch 293 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.5947 AR 0.9750
Epoch 293 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6950 AR 0.9400
Epoch 293 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6498 AR 0.8500
Epoch 294 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5972 AR 0.8600
Epoch 294 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8056 AR 0.9667
Epoch 294 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7200 AR 0.9800
Epoch 294 batch 00004: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7538 AR 0.9500
Epoch 294 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7833 AR 0.9550
Epoch 294 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8183 AR 1.0000
Epoch 294 batch 00007: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.5792 AR 0.9467
Epoch 294 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6458 AR 0.9500
Epoch 294 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6725 AR 0.9000
Epoch 294 batch 00010: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.6063 AR 0.9800
Epoch 295 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5985 AR 0.9600
Epoch 295 batch 00002: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.5875 AR 0.8550
Epoch 295 batch 00003: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0002 AP 0.6417 AR 0.9350
Epoch 295 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7996 AR 1.0000
Epoch 295 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8036 AR 1.0000
Epoch 295 batch 00006: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7255 AR 0.9600
Epoch 295 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.5833 AR 0.8750
Epoch 295 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7308 AR 0.9750
Epoch 295 batch 00009: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.8267 AR 1.0000
Epoch 295 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.8017 AR 0.9300
Epoch 296 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.8037 AR 0.9600
Epoch 296 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7185 AR 1.0000
Epoch 296 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7017 AR 0.9500
Epoch 296 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6567 AR 0.8800
Epoch 296 batch 00005: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0002 AP 0.6014 AR 0.9350
Epoch 296 batch 00006: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7092 AR 0.9050
Epoch 296 batch 00007: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7038 AR 0.8467
Epoch 296 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7433 AR 0.9417
Epoch 296 batch 00009: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.7725 AR 0.9750
Epoch 296 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0003 AP 0.6314 AR 0.8250
Epoch 297 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8121 AR 0.9800
Epoch 297 batch 00002: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7617 AR 0.9667
Epoch 297 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6372 AR 0.8800
Epoch 297 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6817 AR 0.9750
Epoch 297 batch 00005: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6867 AR 0.9800
Epoch 297 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7117 AR 0.8750
Epoch 297 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5653 AR 0.8600
Epoch 297 batch 00008: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0001 AP 0.7152 AR 0.8667
Epoch 297 batch 00009: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.7183 AR 0.9800
Epoch 297 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6777 AR 1.0000
Epoch 298 batch 00001: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.5679 AR 0.8667
Epoch 298 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7433 AR 0.9250
Epoch 298 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7108 AR 0.9750
Epoch 298 batch 00004: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6583 AR 0.9550
Epoch 298 batch 00005: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7039 AR 0.9550
Epoch 298 batch 00006: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7555 AR 0.9017
Epoch 298 batch 00007: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.8000 AR 0.9750
Epoch 298 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6597 AR 1.0000
Epoch 298 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0001 AP 0.8681 AR 1.0000
Epoch 298 batch 00010: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7633 AR 0.9750
Epoch 299 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6750 AR 0.8100
Epoch 299 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7557 AR 0.9800
Epoch 299 batch 00003: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7164 AR 1.0000
Epoch 299 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5483 AR 0.7917
Epoch 299 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6267 AR 0.8600
Epoch 299 batch 00006: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.8342 AR 0.9800
Epoch 299 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.6792 AR 0.9500
Epoch 299 batch 00008: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7098 AR 0.9750
Epoch 299 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0001 AP 0.6728 AR 0.9750
Epoch 299 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.5800 AR 0.8000
Epoch 300 batch 00001: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.6031 AR 0.8000
Epoch 300 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6097 AR 0.9000
Epoch 300 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6255 AR 0.9550
Epoch 300 batch 00004: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0002 AP 0.7214 AR 0.9800
Epoch 300 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8284 AR 0.9800
Epoch 300 batch 00006: Loss 0.0025 Regression loss 0.0024 Classification loss 0.0001 AP 0.7838 AR 0.9750
Epoch 300 batch 00007: Loss 0.0029 Regression loss 0.0028 Classification loss 0.0001 AP 0.7208 AR 1.0000
Epoch 300 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7906 AR 0.9350
Epoch 300 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6742 AR 0.8900
Epoch 300 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7375 AR 0.9500
Epoch 301 batch 00001: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0003 AP 0.7487 AR 0.9550
Epoch 301 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.6867 AR 0.9217
Epoch 301 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7464 AR 0.8800
Epoch 301 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7708 AR 0.9750
Epoch 301 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7183 AR 0.8667
Epoch 301 batch 00006: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.5622 AR 0.8750
Epoch 301 batch 00007: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.6013 AR 0.8500
Epoch 301 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6581 AR 0.9250
Epoch 301 batch 00009: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6240 AR 1.0000
Epoch 301 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6538 AR 0.9600
Epoch 302 batch 00001: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.7135 AR 1.0000
Epoch 302 batch 00002: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.5900 AR 0.8300
Epoch 302 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7850 AR 0.9800
Epoch 302 batch 00004: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0002 AP 0.7595 AR 0.9750
Epoch 302 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7222 AR 0.8800
Epoch 302 batch 00006: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.6187 AR 0.8417
Epoch 302 batch 00007: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0002 AP 0.6628 AR 0.9300
Epoch 302 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7533 AR 0.9667
Epoch 302 batch 00009: Loss 0.0030 Regression loss 0.0028 Classification loss 0.0002 AP 0.6955 AR 0.8750
Epoch 302 batch 00010: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7058 AR 1.0000
Epoch 303 batch 00001: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7108 AR 0.9750
Epoch 303 batch 00002: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.5217 AR 0.8000
Epoch 303 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7714 AR 1.0000
Epoch 303 batch 00004: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8158 AR 1.0000
Epoch 303 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5802 AR 0.8467
Epoch 303 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6293 AR 0.9100
Epoch 303 batch 00007: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.6364 AR 0.8550
Epoch 303 batch 00008: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.7000 AR 0.9417
Epoch 303 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7308 AR 0.8800
Epoch 303 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7641 AR 1.0000
Epoch 304 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.6933 AR 0.8750
Epoch 304 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7033 AR 0.9550
Epoch 304 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7339 AR 0.9000
Epoch 304 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5714 AR 0.8750
Epoch 304 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0003 AP 0.6235 AR 0.8800
Epoch 304 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0003 AP 0.5709 AR 0.9467
Epoch 304 batch 00007: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7070 AR 0.9000
Epoch 304 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7019 AR 0.9400
Epoch 304 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6467 AR 0.8467
Epoch 304 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7808 AR 0.9750
Epoch 305 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8000 AR 0.8800
Epoch 305 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6639 AR 0.9300
Epoch 305 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5937 AR 0.8600
Epoch 305 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7092 AR 1.0000
Epoch 305 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6943 AR 0.9550
Epoch 305 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6338 AR 1.0000
Epoch 305 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7148 AR 0.9000
Epoch 305 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6667 AR 0.9000
Epoch 305 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7337 AR 0.8800
Epoch 305 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6736 AR 0.9300
Epoch 306 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7305 AR 0.9300
Epoch 306 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.5964 AR 1.0000
Epoch 306 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7921 AR 0.9750
Epoch 306 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7664 AR 0.9150
Epoch 306 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6113 AR 0.8467
Epoch 306 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7463 AR 1.0000
Epoch 306 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6021 AR 0.9800
Epoch 306 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6767 AR 0.9500
Epoch 306 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7380 AR 1.0000
Epoch 306 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7272 AR 0.8800
Epoch 307 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.8061 AR 1.0000
Epoch 307 batch 00002: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7421 AR 0.9350
Epoch 307 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7727 AR 0.9750
Epoch 307 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6667 AR 0.9800
Epoch 307 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7052 AR 0.9667
Epoch 307 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7558 AR 0.9750
Epoch 307 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6898 AR 1.0000
Epoch 307 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6927 AR 0.9667
Epoch 307 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6406 AR 0.9500
Epoch 307 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7228 AR 0.9800
Epoch 308 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6240 AR 0.9750
Epoch 308 batch 00002: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6708 AR 0.8750
Epoch 308 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.8581 AR 1.0000
Epoch 308 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6383 AR 1.0000
Epoch 308 batch 00005: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.7657 AR 0.9217
Epoch 308 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.6633 AR 0.8467
Epoch 308 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6750 AR 0.9100
Epoch 308 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7683 AR 1.0000
Epoch 308 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7458 AR 0.9750
Epoch 308 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0003 AP 0.6667 AR 0.8350
Epoch 309 batch 00001: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7206 AR 0.9500
Epoch 309 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.6048 AR 1.0000
Epoch 309 batch 00003: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7400 AR 1.0000
Epoch 309 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6006 AR 0.8350
Epoch 309 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8219 AR 0.9667
Epoch 309 batch 00006: Loss 0.0011 Regression loss 0.0008 Classification loss 0.0002 AP 0.7503 AR 0.9800
Epoch 309 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7467 AR 1.0000
Epoch 309 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7475 AR 1.0000
Epoch 309 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.8367 AR 0.9750
Epoch 309 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6782 AR 0.9800
Epoch 310 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6956 AR 0.9750
Epoch 310 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7581 AR 1.0000
Epoch 310 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6083 AR 0.8267
Epoch 310 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6249 AR 0.8467
Epoch 310 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7667 AR 0.9100
Epoch 310 batch 00006: Loss 0.0012 Regression loss 0.0009 Classification loss 0.0003 AP 0.8281 AR 0.9800
Epoch 310 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6667 AR 0.9750
Epoch 310 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7164 AR 0.9750
Epoch 310 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7669 AR 1.0000
Epoch 310 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7014 AR 1.0000
Epoch 311 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.5217 AR 0.8750
Epoch 311 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6704 AR 0.9750
Epoch 311 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.6699 AR 0.9100
Epoch 311 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7197 AR 0.9750
Epoch 311 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7992 AR 1.0000
Epoch 311 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7100 AR 1.0000
Epoch 311 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6713 AR 0.9267
Epoch 311 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7408 AR 0.9800
Epoch 311 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6948 AR 0.8600
Epoch 311 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8000 AR 0.9750
Epoch 312 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.6517 AR 0.9217
Epoch 312 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6983 AR 0.9250
Epoch 312 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6094 AR 0.7600
Epoch 312 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7367 AR 0.9500
Epoch 312 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8756 AR 1.0000
Epoch 312 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.5777 AR 0.8800
Epoch 312 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7158 AR 1.0000
Epoch 312 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8514 AR 1.0000
Epoch 312 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6756 AR 1.0000
Epoch 312 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.6080 AR 0.9000
Epoch 313 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.5821 AR 0.9000
Epoch 313 batch 00002: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7336 AR 0.9417
Epoch 313 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.5389 AR 0.8700
Epoch 313 batch 00004: Loss 0.0012 Regression loss 0.0009 Classification loss 0.0003 AP 0.7725 AR 0.9800
Epoch 313 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7119 AR 0.9800
Epoch 313 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7881 AR 0.9000
Epoch 313 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7295 AR 0.9750
Epoch 313 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7700 AR 1.0000
Epoch 313 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7114 AR 0.9750
Epoch 313 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7783 AR 0.9800
Epoch 314 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7371 AR 0.9800
Epoch 314 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7208 AR 1.0000
Epoch 314 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6471 AR 0.8500
Epoch 314 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.8138 AR 0.9417
Epoch 314 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7592 AR 0.9600
Epoch 314 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7314 AR 0.9500
Epoch 314 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7211 AR 0.9600
Epoch 314 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7248 AR 0.9667
Epoch 314 batch 00009: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.5556 AR 0.9000
Epoch 314 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6989 AR 1.0000
Epoch 315 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6550 AR 0.9250
Epoch 315 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8024 AR 0.9667
Epoch 315 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6208 AR 0.8400
Epoch 315 batch 00004: Loss 0.0012 Regression loss 0.0009 Classification loss 0.0002 AP 0.7171 AR 0.9800
Epoch 315 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7139 AR 0.9750
Epoch 315 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6810 AR 0.8350
Epoch 315 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7887 AR 1.0000
Epoch 315 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6058 AR 0.9000
Epoch 315 batch 00009: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7322 AR 0.9250
Epoch 315 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6600 AR 1.0000
Epoch 316 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0001 AP 0.7700 AR 0.9300
Epoch 316 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6976 AR 0.9467
Epoch 316 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7588 AR 0.9600
Epoch 316 batch 00004: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.6933 AR 0.9750
Epoch 316 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7992 AR 0.9800
Epoch 316 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5960 AR 0.9417
Epoch 316 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7731 AR 0.9500
Epoch 316 batch 00008: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.4839 AR 0.8000
Epoch 316 batch 00009: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.7129 AR 0.9000
Epoch 316 batch 00010: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.7705 AR 1.0000
Epoch 317 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7587 AR 1.0000
Epoch 317 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6950 AR 0.9200
Epoch 317 batch 00003: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.7183 AR 0.9550
Epoch 317 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.8033 AR 1.0000
Epoch 317 batch 00005: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.6583 AR 0.8750
Epoch 317 batch 00006: Loss 0.0025 Regression loss 0.0024 Classification loss 0.0002 AP 0.6446 AR 0.9600
Epoch 317 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.8136 AR 1.0000
Epoch 317 batch 00008: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6050 AR 0.8750
Epoch 317 batch 00009: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6683 AR 0.9750
Epoch 317 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.7933 AR 0.9300
Epoch 318 batch 00001: Loss 0.0035 Regression loss 0.0032 Classification loss 0.0002 AP 0.5924 AR 0.8550
Epoch 318 batch 00002: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0001 AP 0.8409 AR 0.9550
Epoch 318 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.7314 AR 0.9500
Epoch 318 batch 00004: Loss 0.0039 Regression loss 0.0037 Classification loss 0.0002 AP 0.6377 AR 0.9467
Epoch 318 batch 00005: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.7892 AR 0.9800
Epoch 318 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6484 AR 0.9000
Epoch 318 batch 00007: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0002 AP 0.7233 AR 0.9750
Epoch 318 batch 00008: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.7550 AR 0.9467
Epoch 318 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7749 AR 1.0000
Epoch 318 batch 00010: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0003 AP 0.5867 AR 0.8750
Epoch 319 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7625 AR 0.9350
Epoch 319 batch 00002: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0002 AP 0.7153 AR 0.9800
Epoch 319 batch 00003: Loss 0.0037 Regression loss 0.0034 Classification loss 0.0002 AP 0.6533 AR 0.8817
Epoch 319 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6489 AR 0.8750
Epoch 319 batch 00005: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8104 AR 1.0000
Epoch 319 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7151 AR 0.9600
Epoch 319 batch 00007: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6742 AR 0.8500
Epoch 319 batch 00008: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.7731 AR 0.9500
Epoch 319 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6833 AR 1.0000
Epoch 319 batch 00010: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.5810 AR 1.0000
Epoch 320 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8417 AR 0.9750
Epoch 320 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7642 AR 0.8600
Epoch 320 batch 00003: Loss 0.0024 Regression loss 0.0023 Classification loss 0.0001 AP 0.7181 AR 1.0000
Epoch 320 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5977 AR 0.9800
Epoch 320 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.7457 AR 0.9750
Epoch 320 batch 00006: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.5817 AR 0.7800
Epoch 320 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6307 AR 0.8217
Epoch 320 batch 00008: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.8248 AR 0.9800
Epoch 320 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0003 AP 0.7046 AR 0.9750
Epoch 320 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6558 AR 0.9750
Epoch 321 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.5362 AR 0.9083
Epoch 321 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.8348 AR 0.9800
Epoch 321 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7827 AR 0.9800
Epoch 321 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6900 AR 1.0000
Epoch 321 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7850 AR 0.9667
Epoch 321 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7450 AR 0.9750
Epoch 321 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6316 AR 0.8800
Epoch 321 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.6294 AR 0.8550
Epoch 321 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7230 AR 1.0000
Epoch 321 batch 00010: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.6180 AR 0.8100
Epoch 322 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6971 AR 0.9267
Epoch 322 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.6714 AR 0.9000
Epoch 322 batch 00003: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.5955 AR 0.7800
Epoch 322 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6722 AR 0.8800
Epoch 322 batch 00005: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.6592 AR 0.9800
Epoch 322 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7133 AR 0.8417
Epoch 322 batch 00007: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.6705 AR 0.9350
Epoch 322 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6717 AR 0.8500
Epoch 322 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6750 AR 0.9100
Epoch 322 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7171 AR 1.0000
Epoch 323 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7702 AR 0.9800
Epoch 323 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7229 AR 0.8500
Epoch 323 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7425 AR 0.9750
Epoch 323 batch 00004: Loss 0.0012 Regression loss 0.0009 Classification loss 0.0002 AP 0.5633 AR 0.8600
Epoch 323 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7267 AR 0.9750
Epoch 323 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7300 AR 0.9750
Epoch 323 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6778 AR 0.9750
Epoch 323 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7622 AR 1.0000
Epoch 323 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7983 AR 0.9800
Epoch 323 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6321 AR 0.9500
Epoch 324 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7910 AR 0.9600
Epoch 324 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7683 AR 0.9500
Epoch 324 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.7050 AR 0.8000
Epoch 324 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6957 AR 0.9467
Epoch 324 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6411 AR 0.9750
Epoch 324 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7523 AR 1.0000
Epoch 324 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6499 AR 0.9550
Epoch 324 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6205 AR 0.9300
Epoch 324 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.6933 AR 1.0000
Epoch 324 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8671 AR 0.9800
Epoch 325 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6117 AR 1.0000
Epoch 325 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7717 AR 0.9500
Epoch 325 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7236 AR 0.9200
Epoch 325 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0003 AP 0.6317 AR 0.8850
Epoch 325 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.5781 AR 0.9750
Epoch 325 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7913 AR 0.9467
Epoch 325 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7156 AR 0.8750
Epoch 325 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.9133 AR 1.0000
Epoch 325 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.5652 AR 0.9800
Epoch 325 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6219 AR 0.8800
Epoch 326 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7060 AR 0.9600
Epoch 326 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7156 AR 0.9417
Epoch 326 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.5614 AR 0.8350
Epoch 326 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.5848 AR 0.9550
Epoch 326 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8367 AR 0.9750
Epoch 326 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.8075 AR 0.9750
Epoch 326 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5492 AR 0.7000
Epoch 326 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6906 AR 1.0000
Epoch 326 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7364 AR 0.9750
Epoch 326 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7833 AR 0.9500
Epoch 327 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7513 AR 0.9017
Epoch 327 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7281 AR 0.9750
Epoch 327 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7950 AR 0.9800
Epoch 327 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7506 AR 1.0000
Epoch 327 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6114 AR 0.9500
Epoch 327 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6914 AR 0.9300
Epoch 327 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6793 AR 0.9800
Epoch 327 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7814 AR 1.0000
Epoch 327 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6505 AR 0.8800
Epoch 327 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6433 AR 0.9000
Epoch 328 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6964 AR 0.9500
Epoch 328 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7223 AR 0.9300
Epoch 328 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6933 AR 0.9750
Epoch 328 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.7181 AR 0.8550
Epoch 328 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.7464 AR 0.9333
Epoch 328 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.6800 AR 0.8417
Epoch 328 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.6704 AR 0.9800
Epoch 328 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6453 AR 0.9600
Epoch 328 batch 00009: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7717 AR 1.0000
Epoch 328 batch 00010: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.7025 AR 1.0000
Epoch 329 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.7375 AR 0.9800
Epoch 329 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7358 AR 1.0000
Epoch 329 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7703 AR 0.9417
Epoch 329 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6798 AR 1.0000
Epoch 329 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7517 AR 0.9750
Epoch 329 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7521 AR 0.9350
Epoch 329 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.6695 AR 0.9750
Epoch 329 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.6203 AR 0.8600
Epoch 329 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.7131 AR 0.9500
Epoch 329 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7502 AR 0.9800
Epoch 330 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6117 AR 0.8750
Epoch 330 batch 00002: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7460 AR 1.0000
Epoch 330 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7881 AR 0.9800
Epoch 330 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6383 AR 0.9100
Epoch 330 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6506 AR 0.9500
Epoch 330 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8133 AR 0.9800
Epoch 330 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7917 AR 1.0000
Epoch 330 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6044 AR 0.8750
Epoch 330 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7933 AR 0.9800
Epoch 330 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8017 AR 0.9750
Epoch 331 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.5620 AR 0.8500
Epoch 331 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7075 AR 0.8800
Epoch 331 batch 00003: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7089 AR 0.9250
Epoch 331 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6464 AR 1.0000
Epoch 331 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7019 AR 0.8967
Epoch 331 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7242 AR 0.9550
Epoch 331 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6950 AR 0.9000
Epoch 331 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.6460 AR 0.8217
Epoch 331 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7733 AR 0.9550
Epoch 331 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6910 AR 0.9133
Epoch 332 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6167 AR 0.8667
Epoch 332 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.5751 AR 0.8000
Epoch 332 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7220 AR 0.9350
Epoch 332 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7167 AR 0.9750
Epoch 332 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7354 AR 0.9550
Epoch 332 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6871 AR 0.9400
Epoch 332 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7317 AR 1.0000
Epoch 332 batch 00008: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7348 AR 0.9750
Epoch 332 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6567 AR 0.8750
Epoch 332 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.6963 AR 0.8550
Epoch 333 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7283 AR 0.9600
Epoch 333 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7188 AR 0.9550
Epoch 333 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7253 AR 0.9267
Epoch 333 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6172 AR 1.0000
Epoch 333 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.6771 AR 0.9000
Epoch 333 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7821 AR 0.9600
Epoch 333 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6958 AR 0.9667
Epoch 333 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7606 AR 0.9750
Epoch 333 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7496 AR 0.9800
Epoch 333 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6588 AR 0.8850
Epoch 334 batch 00001: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7075 AR 0.9500
Epoch 334 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6156 AR 1.0000
Epoch 334 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7154 AR 0.9500
Epoch 334 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.8025 AR 1.0000
Epoch 334 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6722 AR 0.8800
Epoch 334 batch 00006: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0001 AP 0.5981 AR 0.8750
Epoch 334 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6250 AR 0.9600
Epoch 334 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.8171 AR 0.9550
Epoch 334 batch 00009: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7676 AR 0.9600
Epoch 334 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7467 AR 0.9600
Epoch 335 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8302 AR 0.9800
Epoch 335 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7511 AR 0.8800
Epoch 335 batch 00003: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6329 AR 0.9000
Epoch 335 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.4625 AR 0.8400
Epoch 335 batch 00005: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7127 AR 0.9417
Epoch 335 batch 00006: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.8572 AR 1.0000
Epoch 335 batch 00007: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.5900 AR 0.8750
Epoch 335 batch 00008: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7300 AR 0.9467
Epoch 335 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7214 AR 0.9750
Epoch 335 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6686 AR 0.9600
Epoch 336 batch 00001: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.5694 AR 0.8550
Epoch 336 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7123 AR 1.0000
Epoch 336 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6733 AR 0.8800
Epoch 336 batch 00004: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7158 AR 1.0000
Epoch 336 batch 00005: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0001 AP 0.7520 AR 0.9600
Epoch 336 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.6100 AR 0.8100
Epoch 336 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7421 AR 0.9800
Epoch 336 batch 00008: Loss 0.0024 Regression loss 0.0023 Classification loss 0.0001 AP 0.7200 AR 0.9800
Epoch 336 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7488 AR 0.9750
Epoch 336 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7073 AR 0.9250
Epoch 337 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6229 AR 0.8967
Epoch 337 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6961 AR 0.9500
Epoch 337 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.4944 AR 0.7800
Epoch 337 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7961 AR 0.9600
Epoch 337 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6683 AR 1.0000
Epoch 337 batch 00006: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.6756 AR 1.0000
Epoch 337 batch 00007: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.8242 AR 0.9500
Epoch 337 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0001 AP 0.8067 AR 1.0000
Epoch 337 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6689 AR 0.9750
Epoch 337 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7150 AR 0.9750
Epoch 338 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6744 AR 1.0000
Epoch 338 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6133 AR 0.8750
Epoch 338 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6683 AR 0.9500
Epoch 338 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7156 AR 1.0000
Epoch 338 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7706 AR 0.9550
Epoch 338 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7270 AR 1.0000
Epoch 338 batch 00007: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.6856 AR 0.9800
Epoch 338 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7668 AR 0.9550
Epoch 338 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6862 AR 0.8750
Epoch 338 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7706 AR 0.9500
Epoch 339 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6992 AR 0.8750
Epoch 339 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6800 AR 1.0000
Epoch 339 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8314 AR 0.9750
Epoch 339 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6533 AR 0.9800
Epoch 339 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6674 AR 0.9067
Epoch 339 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7477 AR 0.9800
Epoch 339 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6151 AR 0.9000
Epoch 339 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6275 AR 0.9600
Epoch 339 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6881 AR 0.9000
Epoch 339 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8450 AR 0.9500
Epoch 340 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.6955 AR 0.9800
Epoch 340 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7818 AR 0.9550
Epoch 340 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.6437 AR 0.9800
Epoch 340 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7583 AR 1.0000
Epoch 340 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.8014 AR 0.9500
Epoch 340 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6911 AR 1.0000
Epoch 340 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6837 AR 0.9000
Epoch 340 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8317 AR 0.9800
Epoch 340 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.6113 AR 0.8700
Epoch 340 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6586 AR 1.0000
Epoch 341 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6561 AR 0.9800
Epoch 341 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7789 AR 0.9750
Epoch 341 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6687 AR 0.9750
Epoch 341 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8098 AR 0.9750
Epoch 341 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7750 AR 0.9300
Epoch 341 batch 00006: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.6592 AR 0.9667
Epoch 341 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7498 AR 0.9750
Epoch 341 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6714 AR 0.9350
Epoch 341 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7088 AR 0.9800
Epoch 341 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7142 AR 1.0000
Epoch 342 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7717 AR 0.9750
Epoch 342 batch 00002: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.5352 AR 0.8400
Epoch 342 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5181 AR 0.7750
Epoch 342 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7567 AR 0.9750
Epoch 342 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7431 AR 0.9350
Epoch 342 batch 00006: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.6750 AR 0.9750
Epoch 342 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6713 AR 1.0000
Epoch 342 batch 00008: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7606 AR 0.9350
Epoch 342 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7532 AR 0.9750
Epoch 342 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6711 AR 0.8917
Epoch 343 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7250 AR 0.9750
Epoch 343 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7570 AR 0.9500
Epoch 343 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.6644 AR 0.8750
Epoch 343 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7092 AR 0.9550
Epoch 343 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6667 AR 0.9000
Epoch 343 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7250 AR 0.9750
Epoch 343 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6472 AR 0.8667
Epoch 343 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7380 AR 1.0000
Epoch 343 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6414 AR 0.8800
Epoch 343 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6767 AR 1.0000
Epoch 344 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7217 AR 0.9750
Epoch 344 batch 00002: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7808 AR 0.9750
Epoch 344 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7188 AR 0.9467
Epoch 344 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5148 AR 0.8300
Epoch 344 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.8250 AR 1.0000
Epoch 344 batch 00006: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6608 AR 0.9000
Epoch 344 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7202 AR 1.0000
Epoch 344 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6983 AR 0.9500
Epoch 344 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6183 AR 0.7750
Epoch 344 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6725 AR 0.8550
Epoch 345 batch 00001: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7584 AR 0.9800
Epoch 345 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7238 AR 0.9800
Epoch 345 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6802 AR 0.9800
Epoch 345 batch 00004: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.6144 AR 0.8800
Epoch 345 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7838 AR 0.9550
Epoch 345 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.8617 AR 0.9750
Epoch 345 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7600 AR 0.9350
Epoch 345 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7553 AR 1.0000
Epoch 345 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.6552 AR 0.9417
Epoch 345 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6558 AR 1.0000
Epoch 346 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6573 AR 0.9750
Epoch 346 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6367 AR 0.9067
Epoch 346 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6681 AR 0.8550
Epoch 346 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6195 AR 0.9500
Epoch 346 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6802 AR 0.8667
Epoch 346 batch 00006: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6731 AR 0.9750
Epoch 346 batch 00007: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.9017 AR 0.9550
Epoch 346 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6700 AR 1.0000
Epoch 346 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7867 AR 1.0000
Epoch 346 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6613 AR 0.9800
Epoch 347 batch 00001: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.8149 AR 0.9600
Epoch 347 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.7525 AR 0.9800
Epoch 347 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7445 AR 0.9600
Epoch 347 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7094 AR 0.9000
Epoch 347 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6717 AR 0.8500
Epoch 347 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6462 AR 1.0000
Epoch 347 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7656 AR 1.0000
Epoch 347 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5678 AR 0.8800
Epoch 347 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5711 AR 0.9050
Epoch 347 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7617 AR 1.0000
Epoch 348 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8242 AR 0.9300
Epoch 348 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7317 AR 1.0000
Epoch 348 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7217 AR 0.9250
Epoch 348 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8183 AR 0.9750
Epoch 348 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7667 AR 0.9750
Epoch 348 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6552 AR 0.9600
Epoch 348 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7717 AR 1.0000
Epoch 348 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7562 AR 1.0000
Epoch 348 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7276 AR 1.0000
Epoch 348 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.5614 AR 0.8750
Epoch 349 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8550 AR 1.0000
Epoch 349 batch 00002: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6560 AR 1.0000
Epoch 349 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7589 AR 0.9750
Epoch 349 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.5500 AR 0.7950
Epoch 349 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6014 AR 0.8500
Epoch 349 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7867 AR 1.0000
Epoch 349 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7380 AR 0.8750
Epoch 349 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6188 AR 0.9550
Epoch 349 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7623 AR 0.9800
Epoch 349 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6775 AR 0.9467
Epoch 350 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7433 AR 1.0000
Epoch 350 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6603 AR 0.9500
Epoch 350 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8450 AR 0.9550
Epoch 350 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5921 AR 0.9050
Epoch 350 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8467 AR 1.0000
Epoch 350 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7292 AR 0.9600
Epoch 350 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6714 AR 0.8750
Epoch 350 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6673 AR 1.0000
Epoch 350 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6317 AR 0.8417
Epoch 350 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6844 AR 0.9467
Epoch 351 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6217 AR 0.9500
Epoch 351 batch 00002: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.8505 AR 0.9800
Epoch 351 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7056 AR 0.9750
Epoch 351 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6610 AR 0.8100
Epoch 351 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6598 AR 1.0000
Epoch 351 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6048 AR 0.9000
Epoch 351 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6792 AR 0.9000
Epoch 351 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7194 AR 0.9600
Epoch 351 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7583 AR 0.9750
Epoch 351 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6628 AR 0.9267
Epoch 352 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7175 AR 0.9800
Epoch 352 batch 00002: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7450 AR 1.0000
Epoch 352 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7414 AR 0.9300
Epoch 352 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7921 AR 0.9800
Epoch 352 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7145 AR 0.8750
Epoch 352 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5386 AR 0.8167
Epoch 352 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6838 AR 0.9750
Epoch 352 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6833 AR 0.9000
Epoch 352 batch 00009: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.7906 AR 1.0000
Epoch 352 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.6077 AR 0.9600
Epoch 353 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7964 AR 0.9350
Epoch 353 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6761 AR 0.9550
Epoch 353 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6631 AR 1.0000
Epoch 353 batch 00004: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.7519 AR 0.9217
Epoch 353 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7336 AR 0.9000
Epoch 353 batch 00006: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.5916 AR 0.9550
Epoch 353 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7017 AR 0.9750
Epoch 353 batch 00008: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6908 AR 0.9750
Epoch 353 batch 00009: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6500 AR 0.9000
Epoch 353 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7238 AR 0.9750
Epoch 354 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7967 AR 1.0000
Epoch 354 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7806 AR 0.9800
Epoch 354 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5806 AR 0.9000
Epoch 354 batch 00004: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7712 AR 0.9600
Epoch 354 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5900 AR 0.7500
Epoch 354 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6767 AR 1.0000
Epoch 354 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6233 AR 0.9800
Epoch 354 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8142 AR 0.9750
Epoch 354 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6700 AR 0.9500
Epoch 354 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6315 AR 0.9217
Epoch 355 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7745 AR 0.9667
Epoch 355 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6834 AR 0.9750
Epoch 355 batch 00003: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.7758 AR 0.9800
Epoch 355 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5538 AR 0.8400
Epoch 355 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.8164 AR 0.9750
Epoch 355 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6323 AR 0.9350
Epoch 355 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.5749 AR 0.8550
Epoch 355 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6775 AR 0.9000
Epoch 355 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8233 AR 1.0000
Epoch 355 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6762 AR 0.9000
Epoch 356 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6600 AR 0.9467
Epoch 356 batch 00002: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7083 AR 0.9800
Epoch 356 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5667 AR 0.8750
Epoch 356 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6891 AR 0.8600
Epoch 356 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6770 AR 0.9250
Epoch 356 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7067 AR 0.9000
Epoch 356 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6483 AR 0.9800
Epoch 356 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7381 AR 0.9750
Epoch 356 batch 00009: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7981 AR 0.9800
Epoch 356 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7700 AR 0.9750
Epoch 357 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6190 AR 0.8217
Epoch 357 batch 00002: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6250 AR 1.0000
Epoch 357 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6683 AR 0.9300
Epoch 357 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7430 AR 1.0000
Epoch 357 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6317 AR 0.8300
Epoch 357 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7978 AR 1.0000
Epoch 357 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7717 AR 0.9550
Epoch 357 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8239 AR 1.0000
Epoch 357 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7114 AR 1.0000
Epoch 357 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6763 AR 0.9550
Epoch 358 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7202 AR 0.9667
Epoch 358 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7189 AR 0.9500
Epoch 358 batch 00003: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.7175 AR 0.9500
Epoch 358 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6036 AR 0.8800
Epoch 358 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7117 AR 1.0000
Epoch 358 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7578 AR 0.9750
Epoch 358 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7236 AR 0.9350
Epoch 358 batch 00008: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7193 AR 0.8550
Epoch 358 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6464 AR 1.0000
Epoch 358 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7136 AR 0.9167
Epoch 359 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6716 AR 0.8800
Epoch 359 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7287 AR 0.9000
Epoch 359 batch 00003: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.5903 AR 0.9000
Epoch 359 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7714 AR 1.0000
Epoch 359 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.6650 AR 0.8467
Epoch 359 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7283 AR 0.9750
Epoch 359 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7648 AR 0.9500
Epoch 359 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6917 AR 1.0000
Epoch 359 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7139 AR 0.9550
Epoch 359 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.6655 AR 0.9800
Epoch 360 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5906 AR 0.8750
Epoch 360 batch 00002: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7398 AR 0.9300
Epoch 360 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7017 AR 1.0000
Epoch 360 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7717 AR 1.0000
Epoch 360 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6795 AR 0.9000
Epoch 360 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6452 AR 0.8467
Epoch 360 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6462 AR 0.8750
Epoch 360 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7475 AR 0.9750
Epoch 360 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7887 AR 0.9800
Epoch 360 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5925 AR 0.8750
Epoch 361 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.5512 AR 0.9250
Epoch 361 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7950 AR 1.0000
Epoch 361 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6364 AR 0.9300
Epoch 361 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7230 AR 0.9150
Epoch 361 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6960 AR 0.9800
Epoch 361 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6352 AR 0.8667
Epoch 361 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7472 AR 0.8750
Epoch 361 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8471 AR 1.0000
Epoch 361 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6839 AR 1.0000
Epoch 361 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7841 AR 1.0000
Epoch 362 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.8148 AR 0.9800
Epoch 362 batch 00002: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.5964 AR 0.9550
Epoch 362 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6278 AR 0.9050
Epoch 362 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7214 AR 0.9750
Epoch 362 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6445 AR 0.8417
Epoch 362 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7019 AR 0.8800
Epoch 362 batch 00007: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7267 AR 1.0000
Epoch 362 batch 00008: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6596 AR 0.9017
Epoch 362 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7621 AR 0.9500
Epoch 362 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6100 AR 0.8750
Epoch 363 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7178 AR 0.9550
Epoch 363 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6454 AR 0.8900
Epoch 363 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6263 AR 0.9750
Epoch 363 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6364 AR 0.8800
Epoch 363 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6595 AR 0.9750
Epoch 363 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7650 AR 0.9000
Epoch 363 batch 00007: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7892 AR 1.0000
Epoch 363 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7964 AR 0.9500
Epoch 363 batch 00009: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7467 AR 0.9750
Epoch 363 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7688 AR 0.9750
Epoch 364 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6600 AR 1.0000
Epoch 364 batch 00002: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.8650 AR 0.9750
Epoch 364 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5748 AR 0.8000
Epoch 364 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7764 AR 0.9500
Epoch 364 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6399 AR 0.8667
Epoch 364 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6889 AR 0.9300
Epoch 364 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7100 AR 0.9750
Epoch 364 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7391 AR 0.9800
Epoch 364 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7792 AR 0.9600
Epoch 364 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.6114 AR 0.8550
Epoch 365 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7594 AR 0.9350
Epoch 365 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7037 AR 0.9750
Epoch 365 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7131 AR 1.0000
Epoch 365 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.6225 AR 0.8500
Epoch 365 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7233 AR 0.8000
Epoch 365 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6525 AR 0.8650
Epoch 365 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0001 AP 0.7338 AR 0.9750
Epoch 365 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6881 AR 0.9750
Epoch 365 batch 00009: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6733 AR 0.9000
Epoch 365 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6344 AR 0.8667
Epoch 366 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7028 AR 0.9550
Epoch 366 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5956 AR 0.8750
Epoch 366 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6012 AR 0.8750
Epoch 366 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8375 AR 1.0000
Epoch 366 batch 00005: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6519 AR 0.9217
Epoch 366 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6995 AR 0.9000
Epoch 366 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7975 AR 1.0000
Epoch 366 batch 00008: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7438 AR 0.9800
Epoch 366 batch 00009: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6163 AR 0.8550
Epoch 366 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7433 AR 0.9300
Epoch 367 batch 00001: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7702 AR 0.9667
Epoch 367 batch 00002: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7220 AR 0.8750
Epoch 367 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.5362 AR 0.8217
Epoch 367 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6756 AR 0.9750
Epoch 367 batch 00005: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.6114 AR 0.8800
Epoch 367 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7298 AR 1.0000
Epoch 367 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6997 AR 0.9800
Epoch 367 batch 00008: Loss 0.0028 Regression loss 0.0027 Classification loss 0.0001 AP 0.7064 AR 0.9750
Epoch 367 batch 00009: Loss 0.0032 Regression loss 0.0031 Classification loss 0.0001 AP 0.6527 AR 0.9400
Epoch 367 batch 00010: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0002 AP 0.7693 AR 0.9750
Epoch 368 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6948 AR 0.9300
Epoch 368 batch 00002: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0002 AP 0.7733 AR 0.8800
Epoch 368 batch 00003: Loss 0.0036 Regression loss 0.0034 Classification loss 0.0002 AP 0.7917 AR 0.9217
Epoch 368 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.5759 AR 0.8817
Epoch 368 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.5181 AR 0.7800
Epoch 368 batch 00006: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0002 AP 0.6250 AR 0.8833
Epoch 368 batch 00007: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0001 AP 0.7369 AR 0.9667
Epoch 368 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6729 AR 0.9550
Epoch 368 batch 00009: Loss 0.0028 Regression loss 0.0027 Classification loss 0.0001 AP 0.8500 AR 1.0000
Epoch 368 batch 00010: Loss 0.0026 Regression loss 0.0025 Classification loss 0.0001 AP 0.7475 AR 0.9500
Epoch 369 batch 00001: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0001 AP 0.6814 AR 0.9800
Epoch 369 batch 00002: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.6978 AR 0.9750
Epoch 369 batch 00003: Loss 0.0030 Regression loss 0.0029 Classification loss 0.0001 AP 0.6110 AR 0.9500
Epoch 369 batch 00004: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6255 AR 0.7800
Epoch 369 batch 00005: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0003 AP 0.7081 AR 0.9050
Epoch 369 batch 00006: Loss 0.0030 Regression loss 0.0028 Classification loss 0.0002 AP 0.7448 AR 0.9750
Epoch 369 batch 00007: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0003 AP 0.6778 AR 0.9550
Epoch 369 batch 00008: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.7364 AR 0.9667
Epoch 369 batch 00009: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.7454 AR 0.8900
Epoch 369 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.8450 AR 1.0000
Epoch 370 batch 00001: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.7950 AR 0.9550
Epoch 370 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0004 AP 0.7388 AR 0.9217
Epoch 370 batch 00003: Loss 0.0019 Regression loss 0.0012 Classification loss 0.0007 AP 0.7781 AR 0.9550
Epoch 370 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0001 AP 0.7414 AR 1.0000
Epoch 370 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6317 AR 0.9000
Epoch 370 batch 00006: Loss 0.0024 Regression loss 0.0017 Classification loss 0.0007 AP 0.6773 AR 1.0000
Epoch 370 batch 00007: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0002 AP 0.6822 AR 0.8800
Epoch 370 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7414 AR 0.9417
Epoch 370 batch 00009: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.5738 AR 0.9750
Epoch 370 batch 00010: Loss 0.0019 Regression loss 0.0013 Classification loss 0.0005 AP 0.7508 AR 1.0000
Epoch 371 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6705 AR 0.9550
Epoch 371 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5694 AR 0.9800
Epoch 371 batch 00003: Loss 0.0023 Regression loss 0.0018 Classification loss 0.0004 AP 0.8575 AR 1.0000
Epoch 371 batch 00004: Loss 0.0022 Regression loss 0.0015 Classification loss 0.0007 AP 0.6781 AR 0.9000
Epoch 371 batch 00005: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6727 AR 0.9150
Epoch 371 batch 00006: Loss 0.0019 Regression loss 0.0010 Classification loss 0.0009 AP 0.7739 AR 0.9500
Epoch 371 batch 00007: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7281 AR 0.9750
Epoch 371 batch 00008: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7467 AR 1.0000
Epoch 371 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7433 AR 0.9550
Epoch 371 batch 00010: Loss 0.0020 Regression loss 0.0014 Classification loss 0.0006 AP 0.7628 AR 0.9217
Epoch 372 batch 00001: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0001 AP 0.7383 AR 1.0000
Epoch 372 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6236 AR 0.9550
Epoch 372 batch 00003: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.5532 AR 0.8600
Epoch 372 batch 00004: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6817 AR 0.8400
Epoch 372 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6983 AR 0.8750
Epoch 372 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7464 AR 0.8750
Epoch 372 batch 00007: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6883 AR 0.9800
Epoch 372 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7875 AR 0.9500
Epoch 372 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7114 AR 0.8500
Epoch 372 batch 00010: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7379 AR 1.0000
Epoch 373 batch 00001: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.7692 AR 1.0000
Epoch 373 batch 00002: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7617 AR 1.0000
Epoch 373 batch 00003: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.5667 AR 0.7800
Epoch 373 batch 00004: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0001 AP 0.7000 AR 0.9167
Epoch 373 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5583 AR 0.7750
Epoch 373 batch 00006: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7308 AR 0.9350
Epoch 373 batch 00007: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0001 AP 0.5881 AR 0.9000
Epoch 373 batch 00008: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.7261 AR 0.9600
Epoch 373 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7102 AR 0.9467
Epoch 373 batch 00010: Loss 0.0028 Regression loss 0.0027 Classification loss 0.0002 AP 0.6392 AR 0.8500
Epoch 374 batch 00001: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.6948 AR 1.0000
Epoch 374 batch 00002: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.8058 AR 0.9800
Epoch 374 batch 00003: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6869 AR 0.8267
Epoch 374 batch 00004: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7258 AR 0.9667
Epoch 374 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6758 AR 0.9000
Epoch 374 batch 00006: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.6392 AR 0.8600
Epoch 374 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7163 AR 1.0000
Epoch 374 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7250 AR 1.0000
Epoch 374 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6452 AR 0.9550
Epoch 374 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0001 AP 0.6239 AR 0.8550
Epoch 375 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7317 AR 0.9750
Epoch 375 batch 00002: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7519 AR 0.9133
Epoch 375 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7036 AR 0.9800
Epoch 375 batch 00004: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0001 AP 0.6352 AR 1.0000
Epoch 375 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.8033 AR 0.9500
Epoch 375 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8300 AR 1.0000
Epoch 375 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6694 AR 0.9600
Epoch 375 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6400 AR 0.9000
Epoch 375 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7306 AR 0.9000
Epoch 375 batch 00010: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6542 AR 0.9500
Epoch 376 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.8150 AR 1.0000
Epoch 376 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7050 AR 1.0000
Epoch 376 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8371 AR 0.9200
Epoch 376 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6721 AR 0.9300
Epoch 376 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6010 AR 1.0000
Epoch 376 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7945 AR 0.9750
Epoch 376 batch 00007: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7198 AR 0.9750
Epoch 376 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6820 AR 0.9600
Epoch 376 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6473 AR 0.9000
Epoch 376 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.8381 AR 0.9750
Epoch 377 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7398 AR 1.0000
Epoch 377 batch 00002: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6619 AR 0.8750
Epoch 377 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6822 AR 0.9750
Epoch 377 batch 00004: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7507 AR 0.9217
Epoch 377 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7917 AR 0.9350
Epoch 377 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7140 AR 0.9550
Epoch 377 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7467 AR 0.9000
Epoch 377 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8100 AR 0.9667
Epoch 377 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7531 AR 1.0000
Epoch 377 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.4967 AR 0.7967
Epoch 378 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7292 AR 0.9750
Epoch 378 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8967 AR 0.9750
Epoch 378 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6450 AR 0.8250
Epoch 378 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7031 AR 0.9217
Epoch 378 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6749 AR 0.9550
Epoch 378 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6417 AR 0.9667
Epoch 378 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7213 AR 0.9400
Epoch 378 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7206 AR 1.0000
Epoch 378 batch 00009: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6525 AR 0.9500
Epoch 378 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7156 AR 0.9800
Epoch 379 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.5845 AR 0.9050
Epoch 379 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7077 AR 0.9800
Epoch 379 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7171 AR 0.9550
Epoch 379 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7780 AR 1.0000
Epoch 379 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7238 AR 0.9000
Epoch 379 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6956 AR 1.0000
Epoch 379 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6320 AR 0.9800
Epoch 379 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8350 AR 0.9750
Epoch 379 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7427 AR 0.9167
Epoch 379 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7348 AR 1.0000
Epoch 380 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8056 AR 1.0000
Epoch 380 batch 00002: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.8508 AR 0.9800
Epoch 380 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6600 AR 0.9750
Epoch 380 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.7564 AR 0.9350
Epoch 380 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6845 AR 1.0000
Epoch 380 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7055 AR 0.9800
Epoch 380 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6063 AR 0.8683
Epoch 380 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7231 AR 1.0000
Epoch 380 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6358 AR 1.0000
Epoch 380 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7731 AR 0.9500
Epoch 381 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7492 AR 0.9500
Epoch 381 batch 00002: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7681 AR 0.9750
Epoch 381 batch 00003: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7767 AR 0.9800
Epoch 381 batch 00004: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.6598 AR 0.9000
Epoch 381 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7477 AR 0.9800
Epoch 381 batch 00006: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.6783 AR 0.8300
Epoch 381 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6602 AR 0.8800
Epoch 381 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.6454 AR 0.9750
Epoch 381 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7103 AR 1.0000
Epoch 381 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7989 AR 1.0000
Epoch 382 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7695 AR 1.0000
Epoch 382 batch 00002: Loss 0.0010 Regression loss 0.0007 Classification loss 0.0002 AP 0.6350 AR 0.9750
Epoch 382 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7367 AR 0.9000
Epoch 382 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5580 AR 0.9300
Epoch 382 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7191 AR 1.0000
Epoch 382 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6937 AR 0.9750
Epoch 382 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7600 AR 0.9800
Epoch 382 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.8067 AR 1.0000
Epoch 382 batch 00009: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.6219 AR 0.8667
Epoch 382 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8101 AR 0.9500
Epoch 383 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6413 AR 0.8800
Epoch 383 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7863 AR 0.9800
Epoch 383 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7300 AR 0.9800
Epoch 383 batch 00004: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6819 AR 0.9150
Epoch 383 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6977 AR 0.8667
Epoch 383 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6314 AR 0.8667
Epoch 383 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6700 AR 0.9550
Epoch 383 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7181 AR 0.9750
Epoch 383 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7192 AR 1.0000
Epoch 383 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7798 AR 0.9500
Epoch 384 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6508 AR 0.9667
Epoch 384 batch 00002: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7489 AR 0.9800
Epoch 384 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6750 AR 0.9550
Epoch 384 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7214 AR 0.9417
Epoch 384 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.5150 AR 0.8250
Epoch 384 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7400 AR 0.9000
Epoch 384 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6680 AR 0.9550
Epoch 384 batch 00008: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7225 AR 1.0000
Epoch 384 batch 00009: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7302 AR 0.8600
Epoch 384 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7822 AR 0.9750
Epoch 385 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7402 AR 0.9667
Epoch 385 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6478 AR 0.9800
Epoch 385 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6475 AR 0.8300
Epoch 385 batch 00004: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7252 AR 0.9550
Epoch 385 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7033 AR 0.9000
Epoch 385 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7242 AR 0.9550
Epoch 385 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8167 AR 1.0000
Epoch 385 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6871 AR 0.9800
Epoch 385 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5870 AR 0.9000
Epoch 385 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7658 AR 1.0000
Epoch 386 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7138 AR 0.9500
Epoch 386 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6192 AR 0.8750
Epoch 386 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.5954 AR 0.9217
Epoch 386 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8017 AR 0.9250
Epoch 386 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6084 AR 0.8750
Epoch 386 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7325 AR 0.8750
Epoch 386 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6172 AR 0.8550
Epoch 386 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7983 AR 0.9800
Epoch 386 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6217 AR 0.9667
Epoch 386 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7903 AR 0.9667
Epoch 387 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7550 AR 0.9417
Epoch 387 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.4983 AR 0.7500
Epoch 387 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.5858 AR 0.8050
Epoch 387 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7978 AR 0.9800
Epoch 387 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6952 AR 0.8667
Epoch 387 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7986 AR 1.0000
Epoch 387 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6651 AR 0.9417
Epoch 387 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6274 AR 0.9800
Epoch 387 batch 00009: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.8169 AR 0.9550
Epoch 387 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6653 AR 0.9550
Epoch 388 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6221 AR 0.9800
Epoch 388 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6971 AR 0.9800
Epoch 388 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7857 AR 0.9667
Epoch 388 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6911 AR 0.8550
Epoch 388 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8338 AR 0.9467
Epoch 388 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7952 AR 0.9550
Epoch 388 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7550 AR 1.0000
Epoch 388 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7079 AR 0.9667
Epoch 388 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.6312 AR 0.9750
Epoch 388 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6848 AR 0.9500
Epoch 389 batch 00001: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7739 AR 0.8750
Epoch 389 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6502 AR 0.9667
Epoch 389 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5967 AR 0.7850
Epoch 389 batch 00004: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.6898 AR 0.9417
Epoch 389 batch 00005: Loss 0.0022 Regression loss 0.0022 Classification loss 0.0001 AP 0.6725 AR 0.8750
Epoch 389 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8567 AR 1.0000
Epoch 389 batch 00007: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7169 AR 0.9750
Epoch 389 batch 00008: Loss 0.0032 Regression loss 0.0030 Classification loss 0.0001 AP 0.6308 AR 0.8500
Epoch 389 batch 00009: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0002 AP 0.6714 AR 0.9550
Epoch 389 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6083 AR 0.9217
Epoch 390 batch 00001: Loss 0.0023 Regression loss 0.0022 Classification loss 0.0001 AP 0.7363 AR 0.9750
Epoch 390 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7638 AR 0.9600
Epoch 390 batch 00003: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7088 AR 0.9000
Epoch 390 batch 00004: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0002 AP 0.6967 AR 0.9167
Epoch 390 batch 00005: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7692 AR 1.0000
Epoch 390 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7048 AR 0.9300
Epoch 390 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6306 AR 0.9100
Epoch 390 batch 00008: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0002 AP 0.6456 AR 0.9350
Epoch 390 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6681 AR 0.9467
Epoch 390 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7014 AR 0.8500
Epoch 391 batch 00001: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0001 AP 0.5388 AR 0.8600
Epoch 391 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6786 AR 0.8000
Epoch 391 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7422 AR 0.9550
Epoch 391 batch 00004: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.5616 AR 0.8800
Epoch 391 batch 00005: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0001 AP 0.8017 AR 0.9500
Epoch 391 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6772 AR 1.0000
Epoch 391 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.5881 AR 0.7800
Epoch 391 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7389 AR 0.9600
Epoch 391 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6792 AR 0.9417
Epoch 391 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5805 AR 0.8300
Epoch 392 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6664 AR 0.9750
Epoch 392 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.7264 AR 0.9600
Epoch 392 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7883 AR 0.9800
Epoch 392 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.6194 AR 0.9500
Epoch 392 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7233 AR 0.9550
Epoch 392 batch 00006: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6680 AR 0.8550
Epoch 392 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7025 AR 0.9467
Epoch 392 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6883 AR 0.9800
Epoch 392 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8181 AR 1.0000
Epoch 392 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8188 AR 0.9800
Epoch 393 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7525 AR 0.9550
Epoch 393 batch 00002: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.6279 AR 0.9750
Epoch 393 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7800 AR 0.9000
Epoch 393 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7079 AR 0.9417
Epoch 393 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7083 AR 0.9300
Epoch 393 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6205 AR 0.9500
Epoch 393 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7650 AR 1.0000
Epoch 393 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.6747 AR 0.9350
Epoch 393 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7005 AR 0.9800
Epoch 393 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7781 AR 0.9750
Epoch 394 batch 00001: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7538 AR 0.9750
Epoch 394 batch 00002: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6617 AR 0.9667
Epoch 394 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7103 AR 0.9750
Epoch 394 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7339 AR 0.9350
Epoch 394 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6555 AR 0.8550
Epoch 394 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6944 AR 1.0000
Epoch 394 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7044 AR 0.9800
Epoch 394 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7638 AR 0.9800
Epoch 394 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6535 AR 0.8400
Epoch 394 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7564 AR 0.9750
Epoch 395 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7433 AR 0.9750
Epoch 395 batch 00002: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.7192 AR 0.9000
Epoch 395 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6632 AR 0.9417
Epoch 395 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8352 AR 0.9600
Epoch 395 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5481 AR 0.8667
Epoch 395 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8139 AR 0.9500
Epoch 395 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7067 AR 0.9500
Epoch 395 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6622 AR 1.0000
Epoch 395 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6898 AR 0.8500
Epoch 395 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.6106 AR 0.9150
Epoch 396 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6458 AR 0.8750
Epoch 396 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7833 AR 0.9750
Epoch 396 batch 00003: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7367 AR 1.0000
Epoch 396 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.6410 AR 0.8400
Epoch 396 batch 00005: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.6217 AR 0.8750
Epoch 396 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7414 AR 0.9550
Epoch 396 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7000 AR 1.0000
Epoch 396 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6305 AR 0.9750
Epoch 396 batch 00009: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.8525 AR 0.9750
Epoch 396 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7386 AR 1.0000
Epoch 397 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7500 AR 0.9667
Epoch 397 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6355 AR 0.9500
Epoch 397 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7794 AR 0.9750
Epoch 397 batch 00004: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.5783 AR 0.8667
Epoch 397 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7283 AR 0.9100
Epoch 397 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7394 AR 0.9750
Epoch 397 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6933 AR 1.0000
Epoch 397 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6088 AR 0.8400
Epoch 397 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7525 AR 0.8933
Epoch 397 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7264 AR 0.9300
Epoch 398 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7642 AR 0.9750
Epoch 398 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7495 AR 0.9550
Epoch 398 batch 00003: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7333 AR 1.0000
Epoch 398 batch 00004: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.6269 AR 0.8417
Epoch 398 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6892 AR 0.9500
Epoch 398 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6158 AR 0.9000
Epoch 398 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.7830 AR 0.9400
Epoch 398 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7421 AR 0.9800
Epoch 398 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5735 AR 0.9750
Epoch 398 batch 00010: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7421 AR 0.9750
Epoch 399 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7360 AR 0.9000
Epoch 399 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5848 AR 0.8550
Epoch 399 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.5927 AR 0.9417
Epoch 399 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7900 AR 0.9550
Epoch 399 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7075 AR 1.0000
Epoch 399 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6128 AR 0.8800
Epoch 399 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7592 AR 1.0000
Epoch 399 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6667 AR 0.8750
Epoch 399 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7773 AR 0.9750
Epoch 399 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7348 AR 1.0000
Epoch 400 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7964 AR 0.9750
Epoch 400 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6781 AR 0.9100
Epoch 400 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7475 AR 0.9750
Epoch 400 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7496 AR 0.9467
Epoch 400 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7433 AR 0.9800
Epoch 400 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6767 AR 0.9550
Epoch 400 batch 00007: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0002 AP 0.7617 AR 1.0000
Epoch 400 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6610 AR 0.9500
Epoch 400 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7275 AR 0.9550
Epoch 400 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6656 AR 0.9417
Epoch 401 batch 00001: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.8850 AR 0.9750
Epoch 401 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6738 AR 1.0000
Epoch 401 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6988 AR 0.8667
Epoch 401 batch 00004: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0001 AP 0.7733 AR 1.0000
Epoch 401 batch 00005: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7409 AR 0.9467
Epoch 401 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6855 AR 0.9750
Epoch 401 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0001 AP 0.5849 AR 0.8350
Epoch 401 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6427 AR 0.8950
Epoch 401 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6656 AR 1.0000
Epoch 401 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.6273 AR 0.9050
Epoch 402 batch 00001: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.7286 AR 0.9000
Epoch 402 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7433 AR 0.9550
Epoch 402 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.7031 AR 0.9750
Epoch 402 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6225 AR 0.9000
Epoch 402 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8214 AR 0.9750
Epoch 402 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.5866 AR 0.8600
Epoch 402 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.5994 AR 0.8550
Epoch 402 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7138 AR 0.9800
Epoch 402 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6683 AR 0.9550
Epoch 402 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7750 AR 0.9667
Epoch 403 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7479 AR 0.9550
Epoch 403 batch 00002: Loss 0.0010 Regression loss 0.0007 Classification loss 0.0002 AP 0.7350 AR 0.9400
Epoch 403 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7000 AR 1.0000
Epoch 403 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7458 AR 1.0000
Epoch 403 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5706 AR 0.9500
Epoch 403 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7579 AR 0.9750
Epoch 403 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7773 AR 0.9667
Epoch 403 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7420 AR 0.9750
Epoch 403 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7847 AR 1.0000
Epoch 403 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.8050 AR 1.0000
Epoch 404 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.7389 AR 0.8750
Epoch 404 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6679 AR 0.8550
Epoch 404 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7400 AR 0.9750
Epoch 404 batch 00004: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0000 AP 0.8058 AR 1.0000
Epoch 404 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8112 AR 0.9750
Epoch 404 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6783 AR 1.0000
Epoch 404 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6199 AR 0.9217
Epoch 404 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6246 AR 1.0000
Epoch 404 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7358 AR 1.0000
Epoch 404 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7006 AR 0.9550
Epoch 405 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7338 AR 0.9217
Epoch 405 batch 00002: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.8267 AR 1.0000
Epoch 405 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7589 AR 0.9600
Epoch 405 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7455 AR 0.9600
Epoch 405 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6100 AR 0.9500
Epoch 405 batch 00006: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6988 AR 0.9250
Epoch 405 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.4780 AR 0.7000
Epoch 405 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7233 AR 0.9600
Epoch 405 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6404 AR 0.9150
Epoch 405 batch 00010: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6883 AR 1.0000
Epoch 406 batch 00001: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7881 AR 0.9550
Epoch 406 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.5739 AR 0.8750
Epoch 406 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7528 AR 1.0000
Epoch 406 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6671 AR 0.9550
Epoch 406 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6119 AR 0.7917
Epoch 406 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7108 AR 0.9150
Epoch 406 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7555 AR 1.0000
Epoch 406 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6850 AR 0.9750
Epoch 406 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7229 AR 0.9000
Epoch 406 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7502 AR 0.9800
Epoch 407 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7077 AR 1.0000
Epoch 407 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6500 AR 0.9417
Epoch 407 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.4786 AR 0.7267
Epoch 407 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7071 AR 0.9550
Epoch 407 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7505 AR 1.0000
Epoch 407 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7212 AR 0.9300
Epoch 407 batch 00007: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7314 AR 0.9750
Epoch 407 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6413 AR 0.8150
Epoch 407 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7500 AR 0.9000
Epoch 407 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6467 AR 0.8350
Epoch 408 batch 00001: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.6706 AR 1.0000
Epoch 408 batch 00002: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7389 AR 1.0000
Epoch 408 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.4814 AR 0.7250
Epoch 408 batch 00004: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.5686 AR 0.8550
Epoch 408 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6964 AR 0.7750
Epoch 408 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7217 AR 0.8500
Epoch 408 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6733 AR 0.8800
Epoch 408 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7358 AR 0.9800
Epoch 408 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6937 AR 0.9550
Epoch 408 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7956 AR 0.9667
Epoch 409 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7141 AR 1.0000
Epoch 409 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6733 AR 0.9050
Epoch 409 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7600 AR 1.0000
Epoch 409 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6875 AR 0.9350
Epoch 409 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.5781 AR 0.9000
Epoch 409 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6714 AR 0.8500
Epoch 409 batch 00007: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6381 AR 0.8417
Epoch 409 batch 00008: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7048 AR 0.9000
Epoch 409 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6686 AR 0.8100
Epoch 409 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8238 AR 0.9800
Epoch 410 batch 00001: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6792 AR 0.9300
Epoch 410 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6921 AR 0.9800
Epoch 410 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7125 AR 0.9000
Epoch 410 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6647 AR 0.9750
Epoch 410 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7592 AR 1.0000
Epoch 410 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7717 AR 0.9800
Epoch 410 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6798 AR 0.8500
Epoch 410 batch 00008: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6983 AR 0.9250
Epoch 410 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7072 AR 0.8750
Epoch 410 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6917 AR 0.9217
Epoch 411 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6888 AR 0.9750
Epoch 411 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7443 AR 0.9350
Epoch 411 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.5839 AR 0.7750
Epoch 411 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6727 AR 0.9417
Epoch 411 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7556 AR 0.8800
Epoch 411 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6905 AR 0.9800
Epoch 411 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6131 AR 0.9000
Epoch 411 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6008 AR 0.9267
Epoch 411 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6905 AR 0.9750
Epoch 411 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.8050 AR 0.9800
Epoch 412 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6113 AR 0.8550
Epoch 412 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6883 AR 0.9800
Epoch 412 batch 00003: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7264 AR 0.9750
Epoch 412 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6017 AR 0.9350
Epoch 412 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7572 AR 0.9550
Epoch 412 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6500 AR 0.9050
Epoch 412 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6775 AR 0.8667
Epoch 412 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7767 AR 0.9750
Epoch 412 batch 00009: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.8131 AR 0.9750
Epoch 412 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6833 AR 1.0000
Epoch 413 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7605 AR 0.9300
Epoch 413 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7369 AR 0.9600
Epoch 413 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8131 AR 1.0000
Epoch 413 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6921 AR 0.9000
Epoch 413 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7586 AR 0.9750
Epoch 413 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7261 AR 0.9550
Epoch 413 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6089 AR 0.9050
Epoch 413 batch 00008: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7386 AR 0.9417
Epoch 413 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5562 AR 0.8350
Epoch 413 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5933 AR 0.9417
Epoch 414 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6008 AR 0.9667
Epoch 414 batch 00002: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7602 AR 0.9467
Epoch 414 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7881 AR 1.0000
Epoch 414 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6308 AR 0.8667
Epoch 414 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7130 AR 0.9350
Epoch 414 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6230 AR 1.0000
Epoch 414 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7381 AR 1.0000
Epoch 414 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7806 AR 1.0000
Epoch 414 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.7181 AR 0.9000
Epoch 414 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7242 AR 0.9550
Epoch 415 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6629 AR 0.9350
Epoch 415 batch 00002: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.6923 AR 0.9000
Epoch 415 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6639 AR 1.0000
Epoch 415 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6695 AR 1.0000
Epoch 415 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7581 AR 0.9800
Epoch 415 batch 00006: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7039 AR 1.0000
Epoch 415 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8467 AR 0.9600
Epoch 415 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5242 AR 0.7250
Epoch 415 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7650 AR 0.8750
Epoch 415 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7351 AR 0.9750
Epoch 416 batch 00001: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.6825 AR 0.9800
Epoch 416 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6570 AR 0.8550
Epoch 416 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7702 AR 0.9667
Epoch 416 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6183 AR 0.8000
Epoch 416 batch 00005: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0001 AP 0.6850 AR 0.8800
Epoch 416 batch 00006: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0001 AP 0.7334 AR 0.9750
Epoch 416 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.7217 AR 0.9750
Epoch 416 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7355 AR 0.9500
Epoch 416 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6599 AR 0.9000
Epoch 416 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7495 AR 1.0000
Epoch 417 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6321 AR 0.7300
Epoch 417 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6500 AR 1.0000
Epoch 417 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6517 AR 0.9300
Epoch 417 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7125 AR 0.9750
Epoch 417 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6449 AR 0.9000
Epoch 417 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7383 AR 0.9800
Epoch 417 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7282 AR 0.9667
Epoch 417 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6989 AR 0.9800
Epoch 417 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8183 AR 1.0000
Epoch 417 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7877 AR 0.9400
Epoch 418 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7296 AR 0.9600
Epoch 418 batch 00002: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.6717 AR 0.9467
Epoch 418 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8148 AR 1.0000
Epoch 418 batch 00004: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6300 AR 0.9000
Epoch 418 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6145 AR 0.8750
Epoch 418 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7338 AR 0.9800
Epoch 418 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7350 AR 1.0000
Epoch 418 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5903 AR 0.9750
Epoch 418 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7552 AR 0.9800
Epoch 418 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.9050 AR 0.9800
Epoch 419 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6892 AR 0.9300
Epoch 419 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6548 AR 0.9800
Epoch 419 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8021 AR 0.9800
Epoch 419 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8164 AR 1.0000
Epoch 419 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.5695 AR 0.8300
Epoch 419 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7029 AR 0.9750
Epoch 419 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6475 AR 0.9417
Epoch 419 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7533 AR 1.0000
Epoch 419 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6827 AR 0.8800
Epoch 419 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7330 AR 0.9467
Epoch 420 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5662 AR 0.7750
Epoch 420 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7742 AR 0.9750
Epoch 420 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6908 AR 1.0000
Epoch 420 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7489 AR 0.9000
Epoch 420 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7025 AR 0.9800
Epoch 420 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8095 AR 1.0000
Epoch 420 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7532 AR 0.9300
Epoch 420 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6881 AR 0.9500
Epoch 420 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6367 AR 1.0000
Epoch 420 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6133 AR 0.8667
Epoch 421 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7655 AR 0.9800
Epoch 421 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5996 AR 0.9467
Epoch 421 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.8575 AR 0.9300
Epoch 421 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6598 AR 0.9250
Epoch 421 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6861 AR 0.8800
Epoch 421 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6230 AR 0.9600
Epoch 421 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8388 AR 0.9800
Epoch 421 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6977 AR 1.0000
Epoch 421 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6914 AR 0.9800
Epoch 421 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7300 AR 0.9000
Epoch 422 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6539 AR 0.9750
Epoch 422 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7798 AR 0.9750
Epoch 422 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6014 AR 0.8350
Epoch 422 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7054 AR 1.0000
Epoch 422 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7467 AR 0.9667
Epoch 422 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7589 AR 0.9350
Epoch 422 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6467 AR 0.9000
Epoch 422 batch 00008: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.6756 AR 0.8300
Epoch 422 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7101 AR 0.9800
Epoch 422 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7500 AR 0.9500
Epoch 423 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.5833 AR 0.9000
Epoch 423 batch 00002: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.6507 AR 0.9667
Epoch 423 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6525 AR 0.9800
Epoch 423 batch 00004: Loss 0.0012 Regression loss 0.0009 Classification loss 0.0003 AP 0.6284 AR 0.8500
Epoch 423 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6726 AR 0.8350
Epoch 423 batch 00006: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7031 AR 0.9500
Epoch 423 batch 00007: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.9071 AR 0.9800
Epoch 423 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7250 AR 0.9250
Epoch 423 batch 00009: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7171 AR 0.9800
Epoch 423 batch 00010: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7361 AR 0.9400
Epoch 424 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7700 AR 0.9800
Epoch 424 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5909 AR 0.9000
Epoch 424 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6361 AR 0.8750
Epoch 424 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7564 AR 0.9350
Epoch 424 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5981 AR 0.9000
Epoch 424 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7114 AR 0.9750
Epoch 424 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.6955 AR 1.0000
Epoch 424 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6922 AR 0.9500
Epoch 424 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7092 AR 0.9417
Epoch 424 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7014 AR 0.9500
Epoch 425 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6952 AR 1.0000
Epoch 425 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6658 AR 0.9467
Epoch 425 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6768 AR 0.9800
Epoch 425 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7625 AR 1.0000
Epoch 425 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8114 AR 0.9300
Epoch 425 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6921 AR 0.8800
Epoch 425 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7000 AR 0.9500
Epoch 425 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7489 AR 0.9000
Epoch 425 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6425 AR 0.9150
Epoch 425 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6093 AR 1.0000
Epoch 426 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7708 AR 1.0000
Epoch 426 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7714 AR 1.0000
Epoch 426 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7850 AR 1.0000
Epoch 426 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7800 AR 0.9750
Epoch 426 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7295 AR 1.0000
Epoch 426 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6906 AR 0.9750
Epoch 426 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5743 AR 0.9467
Epoch 426 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7517 AR 0.9667
Epoch 426 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6729 AR 0.9150
Epoch 426 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.5277 AR 0.7667
Epoch 427 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6845 AR 0.8750
Epoch 427 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7150 AR 0.9350
Epoch 427 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6039 AR 0.9500
Epoch 427 batch 00004: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.8148 AR 0.9667
Epoch 427 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6939 AR 1.0000
Epoch 427 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7514 AR 0.9000
Epoch 427 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7650 AR 0.9800
Epoch 427 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6213 AR 0.9750
Epoch 427 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6757 AR 0.9467
Epoch 427 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7502 AR 0.9600
Epoch 428 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.5875 AR 0.8267
Epoch 428 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6971 AR 0.9800
Epoch 428 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7250 AR 0.9300
Epoch 428 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5900 AR 0.8250
Epoch 428 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7481 AR 1.0000
Epoch 428 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6723 AR 0.9300
Epoch 428 batch 00007: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7971 AR 0.9800
Epoch 428 batch 00008: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.7625 AR 0.9750
Epoch 428 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6617 AR 0.8550
Epoch 428 batch 00010: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7183 AR 0.8600
Epoch 429 batch 00001: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0001 AP 0.7364 AR 0.8800
Epoch 429 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6770 AR 0.9250
Epoch 429 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6871 AR 1.0000
Epoch 429 batch 00004: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7418 AR 0.9800
Epoch 429 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0001 AP 0.6702 AR 0.9667
Epoch 429 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7289 AR 1.0000
Epoch 429 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6530 AR 0.8750
Epoch 429 batch 00008: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.7683 AR 0.9017
Epoch 429 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7152 AR 0.9550
Epoch 429 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6333 AR 0.9550
Epoch 430 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6158 AR 0.9000
Epoch 430 batch 00002: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6981 AR 0.8750
Epoch 430 batch 00003: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7300 AR 0.9800
Epoch 430 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8731 AR 1.0000
Epoch 430 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7744 AR 0.9600
Epoch 430 batch 00006: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7167 AR 0.9300
Epoch 430 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6402 AR 0.9667
Epoch 430 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6144 AR 0.8683
Epoch 430 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6456 AR 0.9667
Epoch 430 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7569 AR 0.9550
Epoch 431 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6927 AR 0.9467
Epoch 431 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6814 AR 0.9550
Epoch 431 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7475 AR 1.0000
Epoch 431 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7573 AR 1.0000
Epoch 431 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7338 AR 0.8550
Epoch 431 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6792 AR 1.0000
Epoch 431 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7542 AR 1.0000
Epoch 431 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7171 AR 1.0000
Epoch 431 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6639 AR 0.8750
Epoch 431 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6248 AR 0.9150
Epoch 432 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7433 AR 0.9750
Epoch 432 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6175 AR 0.8850
Epoch 432 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7933 AR 0.9750
Epoch 432 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6881 AR 0.9667
Epoch 432 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6313 AR 0.9200
Epoch 432 batch 00006: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7298 AR 0.9800
Epoch 432 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8225 AR 1.0000
Epoch 432 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6738 AR 0.9800
Epoch 432 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7186 AR 0.9467
Epoch 432 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8314 AR 1.0000
Epoch 433 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6656 AR 0.8500
Epoch 433 batch 00002: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.6542 AR 0.9750
Epoch 433 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8042 AR 1.0000
Epoch 433 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6244 AR 0.8800
Epoch 433 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6878 AR 0.9350
Epoch 433 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7100 AR 0.8800
Epoch 433 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6374 AR 1.0000
Epoch 433 batch 00008: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7889 AR 1.0000
Epoch 433 batch 00009: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6018 AR 0.9000
Epoch 433 batch 00010: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.8167 AR 1.0000
Epoch 434 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7767 AR 0.9800
Epoch 434 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7683 AR 1.0000
Epoch 434 batch 00003: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.6452 AR 0.9400
Epoch 434 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.5625 AR 0.8000
Epoch 434 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7052 AR 0.9750
Epoch 434 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5983 AR 0.8167
Epoch 434 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6995 AR 0.9050
Epoch 434 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6167 AR 0.9750
Epoch 434 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7333 AR 0.9750
Epoch 434 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8338 AR 1.0000
Epoch 435 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6667 AR 1.0000
Epoch 435 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8400 AR 1.0000
Epoch 435 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7464 AR 1.0000
Epoch 435 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6910 AR 1.0000
Epoch 435 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7171 AR 0.9600
Epoch 435 batch 00006: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7475 AR 0.9400
Epoch 435 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6928 AR 1.0000
Epoch 435 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7150 AR 0.9250
Epoch 435 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7529 AR 1.0000
Epoch 435 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6713 AR 0.9750
Epoch 436 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6348 AR 0.9800
Epoch 436 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7503 AR 0.9800
Epoch 436 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5773 AR 0.8000
Epoch 436 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7493 AR 0.8300
Epoch 436 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7781 AR 1.0000
Epoch 436 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7104 AR 0.9100
Epoch 436 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7326 AR 0.9750
Epoch 436 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6508 AR 1.0000
Epoch 436 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7567 AR 1.0000
Epoch 436 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6197 AR 0.9250
Epoch 437 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6232 AR 0.9350
Epoch 437 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6465 AR 1.0000
Epoch 437 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7267 AR 0.9400
Epoch 437 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7405 AR 0.9000
Epoch 437 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6788 AR 0.8800
Epoch 437 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6648 AR 0.9467
Epoch 437 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6017 AR 0.9550
Epoch 437 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7450 AR 0.8800
Epoch 437 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8106 AR 1.0000
Epoch 437 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7361 AR 0.9417
Epoch 438 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6363 AR 0.9667
Epoch 438 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7410 AR 1.0000
Epoch 438 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7067 AR 1.0000
Epoch 438 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6007 AR 0.8900
Epoch 438 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6483 AR 0.9150
Epoch 438 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7950 AR 0.9800
Epoch 438 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7833 AR 0.9500
Epoch 438 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7300 AR 0.8750
Epoch 438 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7689 AR 1.0000
Epoch 438 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7767 AR 0.9750
Epoch 439 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6592 AR 0.9467
Epoch 439 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7621 AR 0.9800
Epoch 439 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8046 AR 1.0000
Epoch 439 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7787 AR 0.9800
Epoch 439 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6931 AR 0.9250
Epoch 439 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6330 AR 0.8150
Epoch 439 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6522 AR 0.9750
Epoch 439 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5700 AR 0.8750
Epoch 439 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7198 AR 0.9467
Epoch 439 batch 00010: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7517 AR 0.9250
Epoch 440 batch 00001: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6071 AR 0.8917
Epoch 440 batch 00002: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.7939 AR 0.9350
Epoch 440 batch 00003: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6406 AR 1.0000
Epoch 440 batch 00004: Loss 0.0023 Regression loss 0.0022 Classification loss 0.0001 AP 0.6542 AR 0.8800
Epoch 440 batch 00005: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7164 AR 0.9150
Epoch 440 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6752 AR 0.9500
Epoch 440 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7422 AR 0.9750
Epoch 440 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6592 AR 1.0000
Epoch 440 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6383 AR 0.9000
Epoch 440 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7310 AR 0.9800
Epoch 441 batch 00001: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.5670 AR 0.8750
Epoch 441 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6842 AR 0.9750
Epoch 441 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7306 AR 1.0000
Epoch 441 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7488 AR 0.9800
Epoch 441 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5991 AR 0.8500
Epoch 441 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8100 AR 1.0000
Epoch 441 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7772 AR 0.9467
Epoch 441 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6599 AR 1.0000
Epoch 441 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.6839 AR 1.0000
Epoch 441 batch 00010: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0001 AP 0.7939 AR 0.9000
Epoch 442 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6878 AR 0.8750
Epoch 442 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7450 AR 0.9217
Epoch 442 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7538 AR 0.9750
Epoch 442 batch 00004: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7398 AR 0.9750
Epoch 442 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7617 AR 0.9500
Epoch 442 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6094 AR 0.9800
Epoch 442 batch 00007: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.6933 AR 0.8800
Epoch 442 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6105 AR 0.9350
Epoch 442 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7321 AR 0.9750
Epoch 442 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6633 AR 0.7800
Epoch 443 batch 00001: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6967 AR 0.8267
Epoch 443 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6733 AR 0.8750
Epoch 443 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6739 AR 1.0000
Epoch 443 batch 00004: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.6879 AR 1.0000
Epoch 443 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6683 AR 1.0000
Epoch 443 batch 00006: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6363 AR 0.9667
Epoch 443 batch 00007: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.5772 AR 0.7717
Epoch 443 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6471 AR 0.8900
Epoch 443 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7348 AR 0.9000
Epoch 443 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7192 AR 0.8750
Epoch 444 batch 00001: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.5598 AR 0.8217
Epoch 444 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5788 AR 0.8600
Epoch 444 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7238 AR 0.8800
Epoch 444 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7212 AR 0.9550
Epoch 444 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6778 AR 0.9000
Epoch 444 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7417 AR 0.9500
Epoch 444 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7850 AR 1.0000
Epoch 444 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6117 AR 0.9000
Epoch 444 batch 00009: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7413 AR 0.9667
Epoch 444 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6421 AR 1.0000
Epoch 445 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7633 AR 0.9400
Epoch 445 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5986 AR 0.8417
Epoch 445 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6750 AR 1.0000
Epoch 445 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7583 AR 0.9550
Epoch 445 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7817 AR 0.9750
Epoch 445 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7225 AR 0.9800
Epoch 445 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6697 AR 1.0000
Epoch 445 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7040 AR 0.9100
Epoch 445 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8060 AR 0.9800
Epoch 445 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5867 AR 0.8250
Epoch 446 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7428 AR 0.9150
Epoch 446 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.7538 AR 1.0000
Epoch 446 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6787 AR 0.9750
Epoch 446 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5789 AR 1.0000
Epoch 446 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7900 AR 1.0000
Epoch 446 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6638 AR 0.8667
Epoch 446 batch 00007: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7036 AR 0.9750
Epoch 446 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.5464 AR 0.8350
Epoch 446 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6433 AR 0.9667
Epoch 446 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8906 AR 0.9800
Epoch 447 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6096 AR 0.9350
Epoch 447 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.5933 AR 0.9000
Epoch 447 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7900 AR 0.9800
Epoch 447 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6675 AR 0.9750
Epoch 447 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7677 AR 0.9000
Epoch 447 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7353 AR 0.9800
Epoch 447 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6983 AR 0.8500
Epoch 447 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5833 AR 0.8800
Epoch 447 batch 00009: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.6802 AR 0.9800
Epoch 447 batch 00010: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.8439 AR 0.9750
Epoch 448 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5345 AR 0.8000
Epoch 448 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7192 AR 0.8417
Epoch 448 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7933 AR 0.9750
Epoch 448 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6033 AR 0.9800
Epoch 448 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6522 AR 0.8250
Epoch 448 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7179 AR 1.0000
Epoch 448 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.5777 AR 0.8467
Epoch 448 batch 00008: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7159 AR 0.9500
Epoch 448 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7208 AR 0.9750
Epoch 448 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7721 AR 0.9800
Epoch 449 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6267 AR 0.8800
Epoch 449 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.6856 AR 0.9217
Epoch 449 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7900 AR 1.0000
Epoch 449 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6617 AR 0.9500
Epoch 449 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6936 AR 0.9467
Epoch 449 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5725 AR 0.9750
Epoch 449 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7696 AR 0.9300
Epoch 449 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7314 AR 0.9500
Epoch 449 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7219 AR 0.9300
Epoch 449 batch 00010: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.8600 AR 1.0000
Epoch 450 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.8133 AR 0.9600
Epoch 450 batch 00002: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7814 AR 1.0000
Epoch 450 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7431 AR 1.0000
Epoch 450 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6239 AR 0.8850
Epoch 450 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6317 AR 0.8750
Epoch 450 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6666 AR 1.0000
Epoch 450 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6939 AR 0.8600
Epoch 450 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6839 AR 1.0000
Epoch 450 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6657 AR 0.8017
Epoch 450 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7021 AR 0.9500
Epoch 451 batch 00001: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0001 AP 0.7395 AR 1.0000
Epoch 451 batch 00002: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0001 AP 0.7521 AR 1.0000
Epoch 451 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7127 AR 1.0000
Epoch 451 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7381 AR 0.9500
Epoch 451 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.5729 AR 0.7800
Epoch 451 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6942 AR 1.0000
Epoch 451 batch 00007: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.5958 AR 0.7050
Epoch 451 batch 00008: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.6728 AR 1.0000
Epoch 451 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6433 AR 0.8800
Epoch 451 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7038 AR 0.9350
Epoch 452 batch 00001: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.6348 AR 0.8800
Epoch 452 batch 00002: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7012 AR 0.8467
Epoch 452 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6850 AR 0.9750
Epoch 452 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6537 AR 0.9750
Epoch 452 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.7850 AR 1.0000
Epoch 452 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7243 AR 0.9750
Epoch 452 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6775 AR 0.9000
Epoch 452 batch 00008: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.7025 AR 0.9600
Epoch 452 batch 00009: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0001 AP 0.7733 AR 0.9750
Epoch 452 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.8050 AR 1.0000
Epoch 453 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7008 AR 0.8950
Epoch 453 batch 00002: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7842 AR 0.9750
Epoch 453 batch 00003: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.6814 AR 0.9250
Epoch 453 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6433 AR 0.9000
Epoch 453 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7029 AR 1.0000
Epoch 453 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6621 AR 0.9550
Epoch 453 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.6517 AR 0.8750
Epoch 453 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7456 AR 1.0000
Epoch 453 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5970 AR 0.9217
Epoch 453 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7892 AR 1.0000
Epoch 454 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7314 AR 0.9750
Epoch 454 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5702 AR 0.8667
Epoch 454 batch 00003: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8771 AR 0.9600
Epoch 454 batch 00004: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6283 AR 0.9750
Epoch 454 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7425 AR 0.9550
Epoch 454 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6500 AR 1.0000
Epoch 454 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7081 AR 1.0000
Epoch 454 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7239 AR 1.0000
Epoch 454 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7556 AR 0.9750
Epoch 454 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6958 AR 0.9000
Epoch 455 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.4933 AR 0.6667
Epoch 455 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7730 AR 0.9400
Epoch 455 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6989 AR 1.0000
Epoch 455 batch 00004: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8206 AR 0.9750
Epoch 455 batch 00005: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.7981 AR 0.9667
Epoch 455 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6738 AR 0.9267
Epoch 455 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7483 AR 1.0000
Epoch 455 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0001 AP 0.5611 AR 0.8350
Epoch 455 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8146 AR 0.9800
Epoch 455 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6667 AR 1.0000
Epoch 456 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7106 AR 0.9667
Epoch 456 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6483 AR 0.8750
Epoch 456 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6005 AR 0.9400
Epoch 456 batch 00004: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7317 AR 0.9400
Epoch 456 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7283 AR 0.9500
Epoch 456 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6781 AR 0.9000
Epoch 456 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8450 AR 0.9750
Epoch 456 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6712 AR 0.9667
Epoch 456 batch 00009: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6429 AR 1.0000
Epoch 456 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7844 AR 0.9467
Epoch 457 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7060 AR 0.9467
Epoch 457 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7495 AR 0.9800
Epoch 457 batch 00003: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7696 AR 0.9150
Epoch 457 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6800 AR 0.8800
Epoch 457 batch 00005: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.6450 AR 0.8917
Epoch 457 batch 00006: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7029 AR 1.0000
Epoch 457 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6663 AR 0.9800
Epoch 457 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6183 AR 1.0000
Epoch 457 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.7233 AR 0.9750
Epoch 457 batch 00010: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7642 AR 1.0000
Epoch 458 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.5690 AR 0.8550
Epoch 458 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7917 AR 0.9800
Epoch 458 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6039 AR 0.9000
Epoch 458 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7660 AR 0.9467
Epoch 458 batch 00005: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7967 AR 1.0000
Epoch 458 batch 00006: Loss 0.0014 Regression loss 0.0014 Classification loss 0.0001 AP 0.7000 AR 0.9417
Epoch 458 batch 00007: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.8617 AR 0.9550
Epoch 458 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6350 AR 0.9667
Epoch 458 batch 00009: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.6760 AR 0.9667
Epoch 458 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7173 AR 0.9800
Epoch 459 batch 00001: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7725 AR 0.9750
Epoch 459 batch 00002: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.7000 AR 0.9550
Epoch 459 batch 00003: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0002 AP 0.6755 AR 0.9550
Epoch 459 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7945 AR 0.9350
Epoch 459 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7520 AR 1.0000
Epoch 459 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7358 AR 0.9800
Epoch 459 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8298 AR 1.0000
Epoch 459 batch 00008: Loss 0.0024 Regression loss 0.0023 Classification loss 0.0001 AP 0.6951 AR 0.9750
Epoch 459 batch 00009: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.6274 AR 1.0000
Epoch 459 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7406 AR 0.9350
Epoch 460 batch 00001: Loss 0.0020 Regression loss 0.0020 Classification loss 0.0001 AP 0.7988 AR 1.0000
Epoch 460 batch 00002: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0002 AP 0.7781 AR 1.0000
Epoch 460 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7781 AR 1.0000
Epoch 460 batch 00004: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0001 AP 0.8181 AR 1.0000
Epoch 460 batch 00005: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6767 AR 1.0000
Epoch 460 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6264 AR 0.9667
Epoch 460 batch 00007: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.6745 AR 0.9017
Epoch 460 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6342 AR 0.8800
Epoch 460 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7436 AR 0.9800
Epoch 460 batch 00010: Loss 0.0023 Regression loss 0.0022 Classification loss 0.0001 AP 0.6960 AR 0.9300
Epoch 461 batch 00001: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8087 AR 0.9750
Epoch 461 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6633 AR 0.9467
Epoch 461 batch 00003: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.7228 AR 1.0000
Epoch 461 batch 00004: Loss 0.0024 Regression loss 0.0023 Classification loss 0.0001 AP 0.8500 AR 0.9500
Epoch 461 batch 00005: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.6405 AR 0.9800
Epoch 461 batch 00006: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6748 AR 0.9750
Epoch 461 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7314 AR 0.9150
Epoch 461 batch 00008: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.7763 AR 0.9800
Epoch 461 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5978 AR 0.8800
Epoch 461 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6301 AR 1.0000
Epoch 462 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7381 AR 1.0000
Epoch 462 batch 00002: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6064 AR 0.9350
Epoch 462 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5852 AR 0.7417
Epoch 462 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7667 AR 0.9800
Epoch 462 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7898 AR 0.9750
Epoch 462 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8542 AR 0.9750
Epoch 462 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6489 AR 0.9000
Epoch 462 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7867 AR 0.9350
Epoch 462 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7256 AR 1.0000
Epoch 462 batch 00010: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6106 AR 1.0000
Epoch 463 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6070 AR 0.8500
Epoch 463 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7708 AR 0.9750
Epoch 463 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.6950 AR 0.8300
Epoch 463 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7719 AR 0.9800
Epoch 463 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7900 AR 1.0000
Epoch 463 batch 00006: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7723 AR 0.9750
Epoch 463 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6633 AR 0.8750
Epoch 463 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7216 AR 0.9800
Epoch 463 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6499 AR 0.8817
Epoch 463 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6667 AR 1.0000
Epoch 464 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6917 AR 1.0000
Epoch 464 batch 00002: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.5822 AR 0.8600
Epoch 464 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.8531 AR 1.0000
Epoch 464 batch 00004: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7150 AR 0.9500
Epoch 464 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7064 AR 0.9750
Epoch 464 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7317 AR 0.9500
Epoch 464 batch 00007: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.8017 AR 1.0000
Epoch 464 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7748 AR 0.9750
Epoch 464 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6529 AR 0.9550
Epoch 464 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6917 AR 0.9667
Epoch 465 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6953 AR 1.0000
Epoch 465 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6589 AR 1.0000
Epoch 465 batch 00003: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7450 AR 0.8750
Epoch 465 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7572 AR 0.9750
Epoch 465 batch 00005: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7157 AR 0.9467
Epoch 465 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7522 AR 0.9750
Epoch 465 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7864 AR 1.0000
Epoch 465 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7600 AR 0.9800
Epoch 465 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6275 AR 0.8300
Epoch 465 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6448 AR 0.9500
Epoch 466 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7928 AR 0.9800
Epoch 466 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6655 AR 0.9300
Epoch 466 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7189 AR 0.9600
Epoch 466 batch 00004: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8431 AR 1.0000
Epoch 466 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7687 AR 1.0000
Epoch 466 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7433 AR 0.9750
Epoch 466 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6300 AR 0.9300
Epoch 466 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7584 AR 0.9750
Epoch 466 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5290 AR 0.8467
Epoch 466 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7431 AR 0.8800
Epoch 467 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6317 AR 0.9467
Epoch 467 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8171 AR 0.9200
Epoch 467 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6837 AR 0.9300
Epoch 467 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8231 AR 1.0000
Epoch 467 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7683 AR 0.9800
Epoch 467 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7467 AR 1.0000
Epoch 467 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5917 AR 0.9000
Epoch 467 batch 00008: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6350 AR 0.8750
Epoch 467 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6806 AR 0.8667
Epoch 467 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7267 AR 1.0000
Epoch 468 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6970 AR 1.0000
Epoch 468 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6733 AR 0.8917
Epoch 468 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7392 AR 0.9800
Epoch 468 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6417 AR 0.9350
Epoch 468 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6983 AR 0.9500
Epoch 468 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5817 AR 0.8750
Epoch 468 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7850 AR 0.9800
Epoch 468 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7913 AR 0.9800
Epoch 468 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7583 AR 1.0000
Epoch 468 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8133 AR 0.9800
Epoch 469 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7417 AR 0.9000
Epoch 469 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6631 AR 0.9000
Epoch 469 batch 00003: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6611 AR 0.9800
Epoch 469 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7433 AR 1.0000
Epoch 469 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5955 AR 0.8800
Epoch 469 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6804 AR 0.9500
Epoch 469 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8333 AR 1.0000
Epoch 469 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6061 AR 0.9350
Epoch 469 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7608 AR 0.9750
Epoch 469 batch 00010: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.8222 AR 0.9800
Epoch 470 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6983 AR 1.0000
Epoch 470 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6388 AR 0.8300
Epoch 470 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7472 AR 1.0000
Epoch 470 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6600 AR 0.9350
Epoch 470 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7333 AR 0.9417
Epoch 470 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6404 AR 0.8800
Epoch 470 batch 00007: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7286 AR 0.9800
Epoch 470 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7086 AR 1.0000
Epoch 470 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8517 AR 0.9800
Epoch 470 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6414 AR 0.8600
Epoch 471 batch 00001: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6814 AR 0.9750
Epoch 471 batch 00002: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7300 AR 0.9550
Epoch 471 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7005 AR 0.8600
Epoch 471 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7624 AR 0.9350
Epoch 471 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6930 AR 0.9800
Epoch 471 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6563 AR 0.9217
Epoch 471 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7781 AR 1.0000
Epoch 471 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6567 AR 0.8750
Epoch 471 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7031 AR 0.9667
Epoch 471 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6333 AR 0.8750
Epoch 472 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6422 AR 0.9750
Epoch 472 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8548 AR 1.0000
Epoch 472 batch 00003: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7131 AR 0.9017
Epoch 472 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6389 AR 1.0000
Epoch 472 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8013 AR 1.0000
Epoch 472 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7571 AR 1.0000
Epoch 472 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.7000 AR 0.9600
Epoch 472 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6883 AR 0.9417
Epoch 472 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7336 AR 0.9800
Epoch 472 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6092 AR 0.8467
Epoch 473 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7222 AR 0.9000
Epoch 473 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7042 AR 1.0000
Epoch 473 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6883 AR 0.9500
Epoch 473 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7100 AR 0.8550
Epoch 473 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6643 AR 0.8500
Epoch 473 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7506 AR 1.0000
Epoch 473 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6767 AR 0.9750
Epoch 473 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7216 AR 0.9467
Epoch 473 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6452 AR 0.9800
Epoch 473 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8114 AR 0.9750
Epoch 474 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7850 AR 1.0000
Epoch 474 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7969 AR 0.9600
Epoch 474 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6105 AR 0.9467
Epoch 474 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7267 AR 0.8750
Epoch 474 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6143 AR 0.9150
Epoch 474 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6697 AR 0.9750
Epoch 474 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7310 AR 0.8550
Epoch 474 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7786 AR 0.9750
Epoch 474 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6333 AR 0.9750
Epoch 474 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7845 AR 1.0000
Epoch 475 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7008 AR 0.9750
Epoch 475 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7000 AR 0.9500
Epoch 475 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8088 AR 1.0000
Epoch 475 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6874 AR 0.9550
Epoch 475 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7964 AR 0.9000
Epoch 475 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6226 AR 0.9000
Epoch 475 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7181 AR 0.9750
Epoch 475 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7165 AR 0.9800
Epoch 475 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6950 AR 0.9800
Epoch 475 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7483 AR 0.9400
Epoch 476 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6314 AR 0.9750
Epoch 476 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7942 AR 0.9300
Epoch 476 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5813 AR 0.7900
Epoch 476 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8417 AR 1.0000
Epoch 476 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6136 AR 0.9217
Epoch 476 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6139 AR 0.8667
Epoch 476 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7250 AR 1.0000
Epoch 476 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7006 AR 0.9600
Epoch 476 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8467 AR 1.0000
Epoch 476 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7018 AR 1.0000
Epoch 477 batch 00001: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8114 AR 0.9800
Epoch 477 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5780 AR 0.8800
Epoch 477 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7171 AR 0.9800
Epoch 477 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6553 AR 1.0000
Epoch 477 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5552 AR 0.8150
Epoch 477 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7772 AR 1.0000
Epoch 477 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5776 AR 0.9000
Epoch 477 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7967 AR 0.9750
Epoch 477 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7975 AR 0.9750
Epoch 477 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7267 AR 0.8800
Epoch 478 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8214 AR 1.0000
Epoch 478 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7800 AR 1.0000
Epoch 478 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7346 AR 0.9600
Epoch 478 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7774 AR 0.9600
Epoch 478 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6267 AR 0.9750
Epoch 478 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6900 AR 0.9750
Epoch 478 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6427 AR 0.9333
Epoch 478 batch 00008: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7267 AR 1.0000
Epoch 478 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7244 AR 0.9100
Epoch 478 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6089 AR 0.9000
Epoch 479 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8003 AR 0.9750
Epoch 479 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6350 AR 0.8550
Epoch 479 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7455 AR 0.9750
Epoch 479 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6481 AR 1.0000
Epoch 479 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6698 AR 0.8800
Epoch 479 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7013 AR 0.9000
Epoch 479 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6800 AR 1.0000
Epoch 479 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7678 AR 0.9017
Epoch 479 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5650 AR 0.8467
Epoch 479 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6729 AR 1.0000
Epoch 480 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5884 AR 0.8417
Epoch 480 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7067 AR 0.9750
Epoch 480 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8214 AR 1.0000
Epoch 480 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6013 AR 0.9750
Epoch 480 batch 00005: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7753 AR 0.9750
Epoch 480 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7289 AR 0.9600
Epoch 480 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8560 AR 0.9417
Epoch 480 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7233 AR 1.0000
Epoch 480 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6695 AR 0.9467
Epoch 480 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7100 AR 0.9550
Epoch 481 batch 00001: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8098 AR 0.9750
Epoch 481 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6808 AR 0.9417
Epoch 481 batch 00003: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7775 AR 0.9550
Epoch 481 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5542 AR 0.7600
Epoch 481 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8150 AR 0.9750
Epoch 481 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6072 AR 1.0000
Epoch 481 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7498 AR 0.9800
Epoch 481 batch 00008: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6583 AR 0.9000
Epoch 481 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7781 AR 0.9500
Epoch 481 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7192 AR 1.0000
Epoch 482 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6456 AR 0.8767
Epoch 482 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6158 AR 0.9550
Epoch 482 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7452 AR 0.9000
Epoch 482 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7771 AR 0.9800
Epoch 482 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7123 AR 0.9500
Epoch 482 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6712 AR 0.9550
Epoch 482 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8100 AR 1.0000
Epoch 482 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6433 AR 0.8800
Epoch 482 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6838 AR 0.9333
Epoch 482 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7716 AR 0.9800
Epoch 483 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6793 AR 0.9800
Epoch 483 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7450 AR 0.9750
Epoch 483 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7550 AR 0.9800
Epoch 483 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6520 AR 0.9000
Epoch 483 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6175 AR 1.0000
Epoch 483 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6588 AR 0.8167
Epoch 483 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6363 AR 0.9150
Epoch 483 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6021 AR 0.8550
Epoch 483 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7206 AR 0.9667
Epoch 483 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8583 AR 1.0000
Epoch 484 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6464 AR 0.9750
Epoch 484 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5956 AR 0.8300
Epoch 484 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6238 AR 0.8800
Epoch 484 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8667 AR 1.0000
Epoch 484 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6525 AR 0.8600
Epoch 484 batch 00006: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.6692 AR 1.0000
Epoch 484 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7183 AR 0.9500
Epoch 484 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6577 AR 0.8667
Epoch 484 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8014 AR 0.9550
Epoch 484 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6363 AR 0.9217
Epoch 485 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6292 AR 1.0000
Epoch 485 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6767 AR 0.9800
Epoch 485 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7160 AR 1.0000
Epoch 485 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6681 AR 0.8417
Epoch 485 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7741 AR 1.0000
Epoch 485 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6800 AR 0.8400
Epoch 485 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7400 AR 0.8750
Epoch 485 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6717 AR 1.0000
Epoch 485 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7886 AR 0.9350
Epoch 485 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7471 AR 0.9550
Epoch 486 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7283 AR 0.9750
Epoch 486 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6783 AR 0.9750
Epoch 486 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6689 AR 1.0000
Epoch 486 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7694 AR 0.9100
Epoch 486 batch 00005: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7917 AR 1.0000
Epoch 486 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6990 AR 0.9467
Epoch 486 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7488 AR 0.9250
Epoch 486 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6634 AR 0.9300
Epoch 486 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6900 AR 0.9550
Epoch 486 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8225 AR 0.8750
Epoch 487 batch 00001: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6938 AR 0.9550
Epoch 487 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7796 AR 0.9800
Epoch 487 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7872 AR 0.9750
Epoch 487 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6905 AR 0.9667
Epoch 487 batch 00005: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.7605 AR 0.8900
Epoch 487 batch 00006: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6878 AR 0.9300
Epoch 487 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6877 AR 0.9467
Epoch 487 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6517 AR 0.9250
Epoch 487 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.6384 AR 0.9550
Epoch 487 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.8150 AR 1.0000
Epoch 488 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6986 AR 0.9667
Epoch 488 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5975 AR 0.9000
Epoch 488 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7517 AR 0.9750
Epoch 488 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7781 AR 0.9550
Epoch 488 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6281 AR 0.9750
Epoch 488 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6752 AR 0.9750
Epoch 488 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5813 AR 0.8800
Epoch 488 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7383 AR 0.9250
Epoch 488 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7389 AR 0.8550
Epoch 488 batch 00010: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.8314 AR 0.9667
Epoch 489 batch 00001: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0001 AP 0.6814 AR 0.9000
Epoch 489 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6938 AR 0.8800
Epoch 489 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6856 AR 0.9100
Epoch 489 batch 00004: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.7608 AR 0.9800
Epoch 489 batch 00005: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.7348 AR 0.8750
Epoch 489 batch 00006: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.5097 AR 0.7750
Epoch 489 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6800 AR 0.9667
Epoch 489 batch 00008: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7175 AR 0.9550
Epoch 489 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6367 AR 0.9000
Epoch 489 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7625 AR 0.9750
Epoch 490 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7092 AR 1.0000
Epoch 490 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7567 AR 0.8800
Epoch 490 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7133 AR 0.9750
Epoch 490 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7631 AR 1.0000
Epoch 490 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7575 AR 1.0000
Epoch 490 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6572 AR 0.9750
Epoch 490 batch 00007: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7245 AR 0.9500
Epoch 490 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7862 AR 0.9667
Epoch 490 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6468 AR 0.9400
Epoch 490 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6883 AR 0.9750
Epoch 491 batch 00001: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.8067 AR 0.9800
Epoch 491 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8292 AR 0.9500
Epoch 491 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6595 AR 0.9750
Epoch 491 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6308 AR 0.8850
Epoch 491 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6689 AR 0.8500
Epoch 491 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6671 AR 0.9600
Epoch 491 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7233 AR 1.0000
Epoch 491 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7550 AR 0.9600
Epoch 491 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6717 AR 0.9083
Epoch 491 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6780 AR 0.9600
Epoch 492 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6269 AR 0.8417
Epoch 492 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7783 AR 0.9500
Epoch 492 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6831 AR 1.0000
Epoch 492 batch 00004: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7848 AR 0.9800
Epoch 492 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7460 AR 0.9800
Epoch 492 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.7411 AR 0.9750
Epoch 492 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7138 AR 0.9550
Epoch 492 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7630 AR 0.9800
Epoch 492 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7525 AR 0.9800
Epoch 492 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6759 AR 0.9800
Epoch 493 batch 00001: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7283 AR 0.9250
Epoch 493 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6871 AR 0.9800
Epoch 493 batch 00003: Loss 0.0012 Regression loss 0.0009 Classification loss 0.0003 AP 0.7278 AR 0.9800
Epoch 493 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7112 AR 0.9500
Epoch 493 batch 00005: Loss 0.0018 Regression loss 0.0012 Classification loss 0.0006 AP 0.7669 AR 0.9800
Epoch 493 batch 00006: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.8131 AR 0.9800
Epoch 493 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5684 AR 0.9000
Epoch 493 batch 00008: Loss 0.0009 Regression loss 0.0006 Classification loss 0.0003 AP 0.6536 AR 0.9000
Epoch 493 batch 00009: Loss 0.0020 Regression loss 0.0015 Classification loss 0.0005 AP 0.8467 AR 0.9800
Epoch 493 batch 00010: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7500 AR 0.9550
Epoch 494 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7417 AR 0.9750
Epoch 494 batch 00002: Loss 0.0018 Regression loss 0.0013 Classification loss 0.0005 AP 0.6233 AR 0.9000
Epoch 494 batch 00003: Loss 0.0021 Regression loss 0.0015 Classification loss 0.0006 AP 0.5368 AR 0.9800
Epoch 494 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.8348 AR 0.9600
Epoch 494 batch 00005: Loss 0.0113 Regression loss 0.0016 Classification loss 0.0098 AP 0.7005 AR 0.8300
Epoch 494 batch 00006: Loss 0.2039 Regression loss 0.0047 Classification loss 0.1992 AP 0.4233 AR 0.7067
Epoch 494 batch 00007: Loss 0.6923 Regression loss 0.0253 Classification loss 0.6671 AP 0.3010 AR 0.2667
Epoch 494 batch 00008: Loss 0.3986 Regression loss 0.0219 Classification loss 0.3767 AP 0.1993 AR 0.2550
Epoch 494 batch 00009: Loss 0.4273 Regression loss 0.0169 Classification loss 0.4103 AP 0.0463 AR 0.1667
Epoch 494 batch 00010: Loss 0.2665 Regression loss 0.0397 Classification loss 0.2268 AP 0.0125 AR 0.0250
Epoch 495 batch 00001: Loss 0.3540 Regression loss 0.0383 Classification loss 0.3157 AP 0.0268 AR 0.0450
Epoch 495 batch 00002: Loss 0.2365 Regression loss 0.0321 Classification loss 0.2044 AP 0.0667 AR 0.1333
Epoch 495 batch 00003: Loss 0.1470 Regression loss 0.0753 Classification loss 0.0717 AP 0.0000 AR 0.0000
Epoch 495 batch 00004: Loss 0.2085 Regression loss 0.0680 Classification loss 0.1405 AP 0.0000 AR 0.0000
Epoch 495 batch 00005: Loss 0.1482 Regression loss 0.0402 Classification loss 0.1080 AP 0.0810 AR 0.1333
Epoch 495 batch 00006: Loss 0.1633 Regression loss 0.0373 Classification loss 0.1260 AP 0.1222 AR 0.2083
Epoch 495 batch 00007: Loss 0.1845 Regression loss 0.0455 Classification loss 0.1390 AP 0.1222 AR 0.0400
Epoch 495 batch 00008: Loss 0.2051 Regression loss 0.0575 Classification loss 0.1476 AP 0.0083 AR 0.0200
Epoch 495 batch 00009: Loss 0.1906 Regression loss 0.0399 Classification loss 0.1506 AP 0.0744 AR 0.1733
Epoch 495 batch 00010: Loss 0.1139 Regression loss 0.0368 Classification loss 0.0771 AP 0.2261 AR 0.3867
Epoch 496 batch 00001: Loss 0.0621 Regression loss 0.0428 Classification loss 0.0192 AP 0.0417 AR 0.0783
Epoch 496 batch 00002: Loss 0.0564 Regression loss 0.0316 Classification loss 0.0248 AP 0.1790 AR 0.4033
Epoch 496 batch 00003: Loss 0.0430 Regression loss 0.0294 Classification loss 0.0136 AP 0.1202 AR 0.2133
Epoch 496 batch 00004: Loss 0.0733 Regression loss 0.0334 Classification loss 0.0399 AP 0.0100 AR 0.0200
Epoch 496 batch 00005: Loss 0.0957 Regression loss 0.0279 Classification loss 0.0678 AP 0.0942 AR 0.2000
Epoch 496 batch 00006: Loss 0.1006 Regression loss 0.0277 Classification loss 0.0729 AP 0.1192 AR 0.2983
Epoch 496 batch 00007: Loss 0.1358 Regression loss 0.0302 Classification loss 0.1056 AP 0.1387 AR 0.2983
Epoch 496 batch 00008: Loss 0.0706 Regression loss 0.0308 Classification loss 0.0398 AP 0.2059 AR 0.3400
Epoch 496 batch 00009: Loss 0.0793 Regression loss 0.0228 Classification loss 0.0565 AP 0.3217 AR 0.7167
Epoch 496 batch 00010: Loss 0.0325 Regression loss 0.0242 Classification loss 0.0083 AP 0.3020 AR 0.4367
Epoch 497 batch 00001: Loss 0.0509 Regression loss 0.0143 Classification loss 0.0367 AP 0.2719 AR 0.4350
Epoch 497 batch 00002: Loss 0.0460 Regression loss 0.0170 Classification loss 0.0290 AP 0.3731 AR 0.5500
Epoch 497 batch 00003: Loss 0.0641 Regression loss 0.0287 Classification loss 0.0354 AP 0.2808 AR 0.4033
Epoch 497 batch 00004: Loss 0.0446 Regression loss 0.0195 Classification loss 0.0252 AP 0.1656 AR 0.2467
Epoch 497 batch 00005: Loss 0.0540 Regression loss 0.0195 Classification loss 0.0344 AP 0.2658 AR 0.3683
Epoch 497 batch 00006: Loss 0.0289 Regression loss 0.0192 Classification loss 0.0097 AP 0.2490 AR 0.3967
Epoch 497 batch 00007: Loss 0.0269 Regression loss 0.0189 Classification loss 0.0080 AP 0.2586 AR 0.4583
Epoch 497 batch 00008: Loss 0.0307 Regression loss 0.0145 Classification loss 0.0162 AP 0.3143 AR 0.5750
Epoch 497 batch 00009: Loss 0.0439 Regression loss 0.0183 Classification loss 0.0257 AP 0.1587 AR 0.4083
Epoch 497 batch 00010: Loss 0.0399 Regression loss 0.0199 Classification loss 0.0200 AP 0.1908 AR 0.4100
Epoch 498 batch 00001: Loss 0.0307 Regression loss 0.0142 Classification loss 0.0165 AP 0.2626 AR 0.4250
Epoch 498 batch 00002: Loss 0.0534 Regression loss 0.0147 Classification loss 0.0387 AP 0.5212 AR 0.7150
Epoch 498 batch 00003: Loss 0.0423 Regression loss 0.0162 Classification loss 0.0261 AP 0.4043 AR 0.6583
Epoch 498 batch 00004: Loss 0.0219 Regression loss 0.0139 Classification loss 0.0080 AP 0.3586 AR 0.6217
Epoch 498 batch 00005: Loss 0.0193 Regression loss 0.0122 Classification loss 0.0071 AP 0.4752 AR 0.7717
Epoch 498 batch 00006: Loss 0.0291 Regression loss 0.0149 Classification loss 0.0141 AP 0.4226 AR 0.6217
Epoch 498 batch 00007: Loss 0.0180 Regression loss 0.0132 Classification loss 0.0048 AP 0.5046 AR 0.7150
Epoch 498 batch 00008: Loss 0.0199 Regression loss 0.0139 Classification loss 0.0061 AP 0.4542 AR 0.6117
Epoch 498 batch 00009: Loss 0.0156 Regression loss 0.0115 Classification loss 0.0041 AP 0.3679 AR 0.6000
Epoch 498 batch 00010: Loss 0.0215 Regression loss 0.0141 Classification loss 0.0073 AP 0.4242 AR 0.7467
Epoch 499 batch 00001: Loss 0.0193 Regression loss 0.0134 Classification loss 0.0058 AP 0.4022 AR 0.7467
Epoch 499 batch 00002: Loss 0.0178 Regression loss 0.0135 Classification loss 0.0043 AP 0.4778 AR 0.6817
Epoch 499 batch 00003: Loss 0.0149 Regression loss 0.0122 Classification loss 0.0027 AP 0.4869 AR 0.6433
Epoch 499 batch 00004: Loss 0.0176 Regression loss 0.0132 Classification loss 0.0045 AP 0.6778 AR 0.7800
Epoch 499 batch 00005: Loss 0.0140 Regression loss 0.0100 Classification loss 0.0040 AP 0.4508 AR 0.7500
Epoch 499 batch 00006: Loss 0.0146 Regression loss 0.0112 Classification loss 0.0033 AP 0.1854 AR 0.3517
Epoch 499 batch 00007: Loss 0.0247 Regression loss 0.0118 Classification loss 0.0128 AP 0.3009 AR 0.5483
Epoch 499 batch 00008: Loss 0.0119 Regression loss 0.0085 Classification loss 0.0035 AP 0.5271 AR 0.7250
Epoch 499 batch 00009: Loss 0.0116 Regression loss 0.0095 Classification loss 0.0021 AP 0.6092 AR 0.8967
Epoch 499 batch 00010: Loss 0.0146 Regression loss 0.0122 Classification loss 0.0025 AP 0.6780 AR 0.8700
Epoch 500 batch 00001: Loss 0.0148 Regression loss 0.0095 Classification loss 0.0053 AP 0.4660 AR 0.6350
Epoch 500 batch 00002: Loss 0.0120 Regression loss 0.0098 Classification loss 0.0022 AP 0.5540 AR 0.8400
Epoch 500 batch 00003: Loss 0.0154 Regression loss 0.0106 Classification loss 0.0048 AP 0.4046 AR 0.6433
Epoch 500 batch 00004: Loss 0.0105 Regression loss 0.0080 Classification loss 0.0026 AP 0.4650 AR 0.7400
Epoch 500 batch 00005: Loss 0.0128 Regression loss 0.0102 Classification loss 0.0025 AP 0.4460 AR 0.7633
Epoch 500 batch 00006: Loss 0.0122 Regression loss 0.0102 Classification loss 0.0021 AP 0.4748 AR 0.7967
Epoch 500 batch 00007: Loss 0.0109 Regression loss 0.0091 Classification loss 0.0018 AP 0.5417 AR 0.8300
Epoch 500 batch 00008: Loss 0.0123 Regression loss 0.0105 Classification loss 0.0019 AP 0.5625 AR 0.7417
Epoch 500 batch 00009: Loss 0.0109 Regression loss 0.0097 Classification loss 0.0012 AP 0.5100 AR 0.7500
Epoch 500 batch 00010: Loss 0.0103 Regression loss 0.0089 Classification loss 0.0015 AP 0.4408 AR 0.6600
Epoch 501 batch 00001: Loss 0.0096 Regression loss 0.0087 Classification loss 0.0008 AP 0.6229 AR 0.7333
Epoch 501 batch 00002: Loss 0.0113 Regression loss 0.0088 Classification loss 0.0025 AP 0.4714 AR 0.7383
Epoch 501 batch 00003: Loss 0.0118 Regression loss 0.0087 Classification loss 0.0031 AP 0.4854 AR 0.7683
Epoch 501 batch 00004: Loss 0.0098 Regression loss 0.0085 Classification loss 0.0012 AP 0.4942 AR 0.6867
Epoch 501 batch 00005: Loss 0.0117 Regression loss 0.0099 Classification loss 0.0018 AP 0.3808 AR 0.7000
Epoch 501 batch 00006: Loss 0.0113 Regression loss 0.0092 Classification loss 0.0021 AP 0.6267 AR 0.7750
Epoch 501 batch 00007: Loss 0.0116 Regression loss 0.0088 Classification loss 0.0028 AP 0.5848 AR 0.7833
Epoch 501 batch 00008: Loss 0.0128 Regression loss 0.0117 Classification loss 0.0011 AP 0.6494 AR 0.8467
Epoch 501 batch 00009: Loss 0.0095 Regression loss 0.0076 Classification loss 0.0019 AP 0.4695 AR 0.6917
Epoch 501 batch 00010: Loss 0.0110 Regression loss 0.0098 Classification loss 0.0012 AP 0.4569 AR 0.6317
Epoch 502 batch 00001: Loss 0.0093 Regression loss 0.0077 Classification loss 0.0016 AP 0.4333 AR 0.7467
Epoch 502 batch 00002: Loss 0.0092 Regression loss 0.0081 Classification loss 0.0011 AP 0.6133 AR 0.9167
Epoch 502 batch 00003: Loss 0.0098 Regression loss 0.0085 Classification loss 0.0013 AP 0.5083 AR 0.5867
Epoch 502 batch 00004: Loss 0.0099 Regression loss 0.0084 Classification loss 0.0015 AP 0.3457 AR 0.5150
Epoch 502 batch 00005: Loss 0.0101 Regression loss 0.0074 Classification loss 0.0027 AP 0.7458 AR 0.9050
Epoch 502 batch 00006: Loss 0.0082 Regression loss 0.0072 Classification loss 0.0009 AP 0.5494 AR 0.7600
Epoch 502 batch 00007: Loss 0.0085 Regression loss 0.0068 Classification loss 0.0017 AP 0.5881 AR 0.7400
Epoch 502 batch 00008: Loss 0.0084 Regression loss 0.0074 Classification loss 0.0010 AP 0.6233 AR 0.8400
Epoch 502 batch 00009: Loss 0.0086 Regression loss 0.0077 Classification loss 0.0009 AP 0.6237 AR 0.8417
Epoch 502 batch 00010: Loss 0.0096 Regression loss 0.0081 Classification loss 0.0015 AP 0.5356 AR 0.7500
Epoch 503 batch 00001: Loss 0.0081 Regression loss 0.0070 Classification loss 0.0011 AP 0.6521 AR 0.9300
Epoch 503 batch 00002: Loss 0.0088 Regression loss 0.0067 Classification loss 0.0021 AP 0.7338 AR 0.9800
Epoch 503 batch 00003: Loss 0.0080 Regression loss 0.0070 Classification loss 0.0010 AP 0.4392 AR 0.6533
Epoch 503 batch 00004: Loss 0.0074 Regression loss 0.0069 Classification loss 0.0005 AP 0.4908 AR 0.7317
Epoch 503 batch 00005: Loss 0.0078 Regression loss 0.0069 Classification loss 0.0009 AP 0.6151 AR 0.7600
Epoch 503 batch 00006: Loss 0.0087 Regression loss 0.0076 Classification loss 0.0011 AP 0.7786 AR 0.9167
Epoch 503 batch 00007: Loss 0.0074 Regression loss 0.0059 Classification loss 0.0016 AP 0.5155 AR 0.7050
Epoch 503 batch 00008: Loss 0.0094 Regression loss 0.0081 Classification loss 0.0013 AP 0.5262 AR 0.6917
Epoch 503 batch 00009: Loss 0.0078 Regression loss 0.0067 Classification loss 0.0011 AP 0.5139 AR 0.7800
Epoch 503 batch 00010: Loss 0.0075 Regression loss 0.0058 Classification loss 0.0018 AP 0.7500 AR 0.8933
Epoch 504 batch 00001: Loss 0.0073 Regression loss 0.0058 Classification loss 0.0014 AP 0.6544 AR 0.8883
Epoch 504 batch 00002: Loss 0.0078 Regression loss 0.0066 Classification loss 0.0012 AP 0.6450 AR 0.8300
Epoch 504 batch 00003: Loss 0.0075 Regression loss 0.0066 Classification loss 0.0008 AP 0.4408 AR 0.6883
Epoch 504 batch 00004: Loss 0.0079 Regression loss 0.0067 Classification loss 0.0012 AP 0.4114 AR 0.5417
Epoch 504 batch 00005: Loss 0.0057 Regression loss 0.0051 Classification loss 0.0006 AP 0.6546 AR 0.8800
Epoch 504 batch 00006: Loss 0.0071 Regression loss 0.0060 Classification loss 0.0011 AP 0.6214 AR 0.8750
Epoch 504 batch 00007: Loss 0.0068 Regression loss 0.0057 Classification loss 0.0012 AP 0.5071 AR 0.7600
Epoch 504 batch 00008: Loss 0.0071 Regression loss 0.0060 Classification loss 0.0012 AP 0.5600 AR 0.8800
Epoch 504 batch 00009: Loss 0.0077 Regression loss 0.0064 Classification loss 0.0013 AP 0.6780 AR 0.8933
Epoch 504 batch 00010: Loss 0.0063 Regression loss 0.0055 Classification loss 0.0008 AP 0.6600 AR 0.7667
Epoch 505 batch 00001: Loss 0.0069 Regression loss 0.0057 Classification loss 0.0012 AP 0.6767 AR 0.8167
Epoch 505 batch 00002: Loss 0.0065 Regression loss 0.0054 Classification loss 0.0011 AP 0.6467 AR 0.8600
Epoch 505 batch 00003: Loss 0.0073 Regression loss 0.0061 Classification loss 0.0012 AP 0.7583 AR 0.8417
Epoch 505 batch 00004: Loss 0.0054 Regression loss 0.0046 Classification loss 0.0008 AP 0.5831 AR 0.7950
Epoch 505 batch 00005: Loss 0.0075 Regression loss 0.0069 Classification loss 0.0007 AP 0.5733 AR 0.9167
Epoch 505 batch 00006: Loss 0.0058 Regression loss 0.0053 Classification loss 0.0004 AP 0.5814 AR 0.7750
Epoch 505 batch 00007: Loss 0.0068 Regression loss 0.0055 Classification loss 0.0012 AP 0.5467 AR 0.8133
Epoch 505 batch 00008: Loss 0.0073 Regression loss 0.0064 Classification loss 0.0009 AP 0.4143 AR 0.6767
Epoch 505 batch 00009: Loss 0.0066 Regression loss 0.0056 Classification loss 0.0011 AP 0.6747 AR 0.9000
Epoch 505 batch 00010: Loss 0.0068 Regression loss 0.0057 Classification loss 0.0011 AP 0.5781 AR 0.8500
Epoch 506 batch 00001: Loss 0.0060 Regression loss 0.0045 Classification loss 0.0015 AP 0.5800 AR 0.7850
Epoch 506 batch 00002: Loss 0.0057 Regression loss 0.0053 Classification loss 0.0004 AP 0.7317 AR 0.9500
Epoch 506 batch 00003: Loss 0.0057 Regression loss 0.0049 Classification loss 0.0008 AP 0.7881 AR 0.9467
Epoch 506 batch 00004: Loss 0.0061 Regression loss 0.0056 Classification loss 0.0005 AP 0.7064 AR 0.9150
Epoch 506 batch 00005: Loss 0.0065 Regression loss 0.0052 Classification loss 0.0013 AP 0.6725 AR 0.8633
Epoch 506 batch 00006: Loss 0.0070 Regression loss 0.0060 Classification loss 0.0010 AP 0.5919 AR 0.9550
Epoch 506 batch 00007: Loss 0.0061 Regression loss 0.0049 Classification loss 0.0011 AP 0.4940 AR 0.7250
Epoch 506 batch 00008: Loss 0.0055 Regression loss 0.0049 Classification loss 0.0006 AP 0.5983 AR 0.8833
Epoch 506 batch 00009: Loss 0.0071 Regression loss 0.0061 Classification loss 0.0010 AP 0.6417 AR 0.8500
Epoch 506 batch 00010: Loss 0.0061 Regression loss 0.0051 Classification loss 0.0009 AP 0.6683 AR 0.8917
Epoch 507 batch 00001: Loss 0.0059 Regression loss 0.0045 Classification loss 0.0014 AP 0.7883 AR 0.8933
Epoch 507 batch 00002: Loss 0.0053 Regression loss 0.0047 Classification loss 0.0006 AP 0.5755 AR 0.7667
Epoch 507 batch 00003: Loss 0.0055 Regression loss 0.0045 Classification loss 0.0009 AP 0.6792 AR 0.9417
Epoch 507 batch 00004: Loss 0.0063 Regression loss 0.0056 Classification loss 0.0007 AP 0.5717 AR 0.9417
Epoch 507 batch 00005: Loss 0.0060 Regression loss 0.0054 Classification loss 0.0006 AP 0.6588 AR 0.9467
Epoch 507 batch 00006: Loss 0.0060 Regression loss 0.0053 Classification loss 0.0007 AP 0.7002 AR 0.8667
Epoch 507 batch 00007: Loss 0.0049 Regression loss 0.0042 Classification loss 0.0007 AP 0.7711 AR 0.9100
Epoch 507 batch 00008: Loss 0.0073 Regression loss 0.0063 Classification loss 0.0009 AP 0.5769 AR 0.9100
Epoch 507 batch 00009: Loss 0.0061 Regression loss 0.0053 Classification loss 0.0008 AP 0.4488 AR 0.6800
Epoch 507 batch 00010: Loss 0.0053 Regression loss 0.0046 Classification loss 0.0007 AP 0.7567 AR 0.9217
Epoch 508 batch 00001: Loss 0.0061 Regression loss 0.0051 Classification loss 0.0010 AP 0.5367 AR 0.7500
Epoch 508 batch 00002: Loss 0.0057 Regression loss 0.0046 Classification loss 0.0011 AP 0.7093 AR 0.9200
Epoch 508 batch 00003: Loss 0.0057 Regression loss 0.0050 Classification loss 0.0007 AP 0.6083 AR 0.8200
Epoch 508 batch 00004: Loss 0.0057 Regression loss 0.0053 Classification loss 0.0004 AP 0.5731 AR 0.8917
Epoch 508 batch 00005: Loss 0.0056 Regression loss 0.0049 Classification loss 0.0007 AP 0.6683 AR 0.8350
Epoch 508 batch 00006: Loss 0.0071 Regression loss 0.0059 Classification loss 0.0011 AP 0.6562 AR 0.7717
Epoch 508 batch 00007: Loss 0.0051 Regression loss 0.0043 Classification loss 0.0008 AP 0.6836 AR 0.9000
Epoch 508 batch 00008: Loss 0.0059 Regression loss 0.0050 Classification loss 0.0009 AP 0.5501 AR 0.7550
Epoch 508 batch 00009: Loss 0.0045 Regression loss 0.0040 Classification loss 0.0004 AP 0.6655 AR 0.7967
Epoch 508 batch 00010: Loss 0.0061 Regression loss 0.0055 Classification loss 0.0006 AP 0.6167 AR 0.8217
Epoch 509 batch 00001: Loss 0.0056 Regression loss 0.0049 Classification loss 0.0007 AP 0.5763 AR 0.8550
Epoch 509 batch 00002: Loss 0.0058 Regression loss 0.0048 Classification loss 0.0010 AP 0.4822 AR 0.7250
Epoch 509 batch 00003: Loss 0.0053 Regression loss 0.0046 Classification loss 0.0007 AP 0.6950 AR 0.9583
Epoch 509 batch 00004: Loss 0.0070 Regression loss 0.0057 Classification loss 0.0013 AP 0.6317 AR 0.7333
Epoch 509 batch 00005: Loss 0.0056 Regression loss 0.0050 Classification loss 0.0005 AP 0.6548 AR 0.8550
Epoch 509 batch 00006: Loss 0.0059 Regression loss 0.0051 Classification loss 0.0008 AP 0.6133 AR 0.8167
Epoch 509 batch 00007: Loss 0.0057 Regression loss 0.0052 Classification loss 0.0005 AP 0.6662 AR 0.9250
Epoch 509 batch 00008: Loss 0.0056 Regression loss 0.0049 Classification loss 0.0007 AP 0.7564 AR 0.9250
Epoch 509 batch 00009: Loss 0.0046 Regression loss 0.0039 Classification loss 0.0007 AP 0.6190 AR 0.9167
Epoch 509 batch 00010: Loss 0.0065 Regression loss 0.0056 Classification loss 0.0009 AP 0.4762 AR 0.5900
Epoch 510 batch 00001: Loss 0.0050 Regression loss 0.0044 Classification loss 0.0006 AP 0.6042 AR 0.9017
Epoch 510 batch 00002: Loss 0.0070 Regression loss 0.0060 Classification loss 0.0010 AP 0.6869 AR 0.9000
Epoch 510 batch 00003: Loss 0.0057 Regression loss 0.0050 Classification loss 0.0007 AP 0.5219 AR 0.7500
Epoch 510 batch 00004: Loss 0.0054 Regression loss 0.0046 Classification loss 0.0008 AP 0.6050 AR 0.8250
Epoch 510 batch 00005: Loss 0.0045 Regression loss 0.0041 Classification loss 0.0004 AP 0.7395 AR 0.9300
Epoch 510 batch 00006: Loss 0.0058 Regression loss 0.0052 Classification loss 0.0006 AP 0.7250 AR 0.8550
Epoch 510 batch 00007: Loss 0.0053 Regression loss 0.0045 Classification loss 0.0007 AP 0.6375 AR 0.8917
Epoch 510 batch 00008: Loss 0.0059 Regression loss 0.0051 Classification loss 0.0008 AP 0.6625 AR 0.9500
Epoch 510 batch 00009: Loss 0.0047 Regression loss 0.0042 Classification loss 0.0005 AP 0.7117 AR 0.8967
Epoch 510 batch 00010: Loss 0.0059 Regression loss 0.0051 Classification loss 0.0008 AP 0.6381 AR 0.8000
Epoch 511 batch 00001: Loss 0.0049 Regression loss 0.0041 Classification loss 0.0009 AP 0.6037 AR 0.8950
Epoch 511 batch 00002: Loss 0.0046 Regression loss 0.0039 Classification loss 0.0006 AP 0.6271 AR 0.8550
Epoch 511 batch 00003: Loss 0.0044 Regression loss 0.0039 Classification loss 0.0005 AP 0.7800 AR 1.0000
Epoch 511 batch 00004: Loss 0.0054 Regression loss 0.0046 Classification loss 0.0009 AP 0.7867 AR 0.9150
Epoch 511 batch 00005: Loss 0.0051 Regression loss 0.0045 Classification loss 0.0006 AP 0.7183 AR 0.9250
Epoch 511 batch 00006: Loss 0.0050 Regression loss 0.0042 Classification loss 0.0008 AP 0.5562 AR 0.8467
Epoch 511 batch 00007: Loss 0.0054 Regression loss 0.0048 Classification loss 0.0006 AP 0.7238 AR 0.9550
Epoch 511 batch 00008: Loss 0.0049 Regression loss 0.0044 Classification loss 0.0005 AP 0.7564 AR 0.9500
Epoch 511 batch 00009: Loss 0.0043 Regression loss 0.0039 Classification loss 0.0004 AP 0.6238 AR 0.7967
Epoch 511 batch 00010: Loss 0.0061 Regression loss 0.0054 Classification loss 0.0007 AP 0.4133 AR 0.6500
Epoch 512 batch 00001: Loss 0.0042 Regression loss 0.0037 Classification loss 0.0005 AP 0.8931 AR 1.0000
Epoch 512 batch 00002: Loss 0.0047 Regression loss 0.0039 Classification loss 0.0008 AP 0.5771 AR 0.7667
Epoch 512 batch 00003: Loss 0.0048 Regression loss 0.0040 Classification loss 0.0008 AP 0.5183 AR 0.6583
Epoch 512 batch 00004: Loss 0.0049 Regression loss 0.0041 Classification loss 0.0008 AP 0.6617 AR 0.9067
Epoch 512 batch 00005: Loss 0.0048 Regression loss 0.0040 Classification loss 0.0008 AP 0.6317 AR 0.8917
Epoch 512 batch 00006: Loss 0.0047 Regression loss 0.0042 Classification loss 0.0006 AP 0.6183 AR 0.9417
Epoch 512 batch 00007: Loss 0.0048 Regression loss 0.0044 Classification loss 0.0004 AP 0.8300 AR 0.9000
Epoch 512 batch 00008: Loss 0.0042 Regression loss 0.0036 Classification loss 0.0006 AP 0.7488 AR 0.9500
Epoch 512 batch 00009: Loss 0.0042 Regression loss 0.0036 Classification loss 0.0006 AP 0.6064 AR 0.8967
Epoch 512 batch 00010: Loss 0.0047 Regression loss 0.0043 Classification loss 0.0004 AP 0.6533 AR 0.9550
Epoch 513 batch 00001: Loss 0.0044 Regression loss 0.0041 Classification loss 0.0003 AP 0.7688 AR 0.9800
Epoch 513 batch 00002: Loss 0.0042 Regression loss 0.0035 Classification loss 0.0007 AP 0.7829 AR 0.9750
Epoch 513 batch 00003: Loss 0.0044 Regression loss 0.0035 Classification loss 0.0009 AP 0.6050 AR 0.7850
Epoch 513 batch 00004: Loss 0.0047 Regression loss 0.0041 Classification loss 0.0007 AP 0.5739 AR 0.7667
Epoch 513 batch 00005: Loss 0.0044 Regression loss 0.0039 Classification loss 0.0005 AP 0.7092 AR 0.9750
Epoch 513 batch 00006: Loss 0.0046 Regression loss 0.0038 Classification loss 0.0008 AP 0.6786 AR 0.9800
Epoch 513 batch 00007: Loss 0.0039 Regression loss 0.0036 Classification loss 0.0003 AP 0.6802 AR 0.9500
Epoch 513 batch 00008: Loss 0.0044 Regression loss 0.0041 Classification loss 0.0004 AP 0.6533 AR 0.9250
Epoch 513 batch 00009: Loss 0.0049 Regression loss 0.0040 Classification loss 0.0009 AP 0.5788 AR 0.8333
Epoch 513 batch 00010: Loss 0.0043 Regression loss 0.0036 Classification loss 0.0007 AP 0.7961 AR 0.9200
Epoch 514 batch 00001: Loss 0.0042 Regression loss 0.0036 Classification loss 0.0006 AP 0.7500 AR 0.9800
Epoch 514 batch 00002: Loss 0.0038 Regression loss 0.0034 Classification loss 0.0005 AP 0.6771 AR 0.9417
Epoch 514 batch 00003: Loss 0.0047 Regression loss 0.0041 Classification loss 0.0006 AP 0.7914 AR 1.0000
Epoch 514 batch 00004: Loss 0.0037 Regression loss 0.0032 Classification loss 0.0005 AP 0.7092 AR 0.9250
Epoch 514 batch 00005: Loss 0.0036 Regression loss 0.0030 Classification loss 0.0006 AP 0.6538 AR 0.7850
Epoch 514 batch 00006: Loss 0.0048 Regression loss 0.0040 Classification loss 0.0008 AP 0.7350 AR 0.9100
Epoch 514 batch 00007: Loss 0.0043 Regression loss 0.0036 Classification loss 0.0007 AP 0.6253 AR 0.8550
Epoch 514 batch 00008: Loss 0.0049 Regression loss 0.0042 Classification loss 0.0007 AP 0.5767 AR 0.7417
Epoch 514 batch 00009: Loss 0.0035 Regression loss 0.0031 Classification loss 0.0003 AP 0.6080 AR 0.8500
Epoch 514 batch 00010: Loss 0.0049 Regression loss 0.0043 Classification loss 0.0006 AP 0.6017 AR 0.8750
Epoch 515 batch 00001: Loss 0.0047 Regression loss 0.0038 Classification loss 0.0009 AP 0.6895 AR 0.9017
Epoch 515 batch 00002: Loss 0.0040 Regression loss 0.0034 Classification loss 0.0006 AP 0.7383 AR 0.9750
Epoch 515 batch 00003: Loss 0.0045 Regression loss 0.0041 Classification loss 0.0004 AP 0.6267 AR 0.9467
Epoch 515 batch 00004: Loss 0.0037 Regression loss 0.0033 Classification loss 0.0004 AP 0.7233 AR 0.9250
Epoch 515 batch 00005: Loss 0.0042 Regression loss 0.0036 Classification loss 0.0006 AP 0.7921 AR 0.9550
Epoch 515 batch 00006: Loss 0.0047 Regression loss 0.0042 Classification loss 0.0006 AP 0.5610 AR 0.8250
Epoch 515 batch 00007: Loss 0.0037 Regression loss 0.0032 Classification loss 0.0005 AP 0.7076 AR 1.0000
Epoch 515 batch 00008: Loss 0.0041 Regression loss 0.0034 Classification loss 0.0006 AP 0.6489 AR 0.9667
Epoch 515 batch 00009: Loss 0.0039 Regression loss 0.0033 Classification loss 0.0006 AP 0.6948 AR 0.9550
Epoch 515 batch 00010: Loss 0.0038 Regression loss 0.0033 Classification loss 0.0004 AP 0.6613 AR 0.8800
Epoch 516 batch 00001: Loss 0.0040 Regression loss 0.0035 Classification loss 0.0004 AP 0.7067 AR 1.0000
Epoch 516 batch 00002: Loss 0.0040 Regression loss 0.0034 Classification loss 0.0006 AP 0.7761 AR 1.0000
Epoch 516 batch 00003: Loss 0.0038 Regression loss 0.0034 Classification loss 0.0004 AP 0.5552 AR 0.7700
Epoch 516 batch 00004: Loss 0.0041 Regression loss 0.0033 Classification loss 0.0008 AP 0.6817 AR 0.8900
Epoch 516 batch 00005: Loss 0.0038 Regression loss 0.0034 Classification loss 0.0004 AP 0.6762 AR 0.8550
Epoch 516 batch 00006: Loss 0.0045 Regression loss 0.0036 Classification loss 0.0009 AP 0.7100 AR 0.8500
Epoch 516 batch 00007: Loss 0.0044 Regression loss 0.0039 Classification loss 0.0005 AP 0.7044 AR 0.8717
Epoch 516 batch 00008: Loss 0.0036 Regression loss 0.0032 Classification loss 0.0004 AP 0.6138 AR 0.9100
Epoch 516 batch 00009: Loss 0.0052 Regression loss 0.0047 Classification loss 0.0005 AP 0.7628 AR 0.9800
Epoch 516 batch 00010: Loss 0.0045 Regression loss 0.0042 Classification loss 0.0003 AP 0.5000 AR 0.7550
Epoch 517 batch 00001: Loss 0.0042 Regression loss 0.0039 Classification loss 0.0003 AP 0.7000 AR 0.9800
Epoch 517 batch 00002: Loss 0.0039 Regression loss 0.0034 Classification loss 0.0004 AP 0.6612 AR 0.9667
Epoch 517 batch 00003: Loss 0.0039 Regression loss 0.0032 Classification loss 0.0006 AP 0.7300 AR 0.9217
Epoch 517 batch 00004: Loss 0.0047 Regression loss 0.0042 Classification loss 0.0005 AP 0.6788 AR 0.8300
Epoch 517 batch 00005: Loss 0.0046 Regression loss 0.0040 Classification loss 0.0007 AP 0.8250 AR 0.9417
Epoch 517 batch 00006: Loss 0.0048 Regression loss 0.0039 Classification loss 0.0009 AP 0.6338 AR 0.9600
Epoch 517 batch 00007: Loss 0.0041 Regression loss 0.0037 Classification loss 0.0004 AP 0.5645 AR 0.8550
Epoch 517 batch 00008: Loss 0.0037 Regression loss 0.0032 Classification loss 0.0006 AP 0.6394 AR 0.8467
Epoch 517 batch 00009: Loss 0.0040 Regression loss 0.0035 Classification loss 0.0005 AP 0.7767 AR 0.9600
Epoch 517 batch 00010: Loss 0.0037 Regression loss 0.0033 Classification loss 0.0004 AP 0.7140 AR 0.9250
Epoch 518 batch 00001: Loss 0.0041 Regression loss 0.0034 Classification loss 0.0007 AP 0.7467 AR 0.8967
Epoch 518 batch 00002: Loss 0.0042 Regression loss 0.0036 Classification loss 0.0006 AP 0.5750 AR 0.8333
Epoch 518 batch 00003: Loss 0.0048 Regression loss 0.0041 Classification loss 0.0007 AP 0.6464 AR 0.9167
Epoch 518 batch 00004: Loss 0.0052 Regression loss 0.0048 Classification loss 0.0003 AP 0.6583 AR 0.8300
Epoch 518 batch 00005: Loss 0.0039 Regression loss 0.0032 Classification loss 0.0007 AP 0.7200 AR 0.8600
Epoch 518 batch 00006: Loss 0.0036 Regression loss 0.0033 Classification loss 0.0004 AP 0.5867 AR 0.8800
Epoch 518 batch 00007: Loss 0.0032 Regression loss 0.0026 Classification loss 0.0006 AP 0.6376 AR 0.8667
Epoch 518 batch 00008: Loss 0.0036 Regression loss 0.0034 Classification loss 0.0003 AP 0.6850 AR 0.8000
Epoch 518 batch 00009: Loss 0.0039 Regression loss 0.0035 Classification loss 0.0005 AP 0.6389 AR 0.9500
Epoch 518 batch 00010: Loss 0.0037 Regression loss 0.0032 Classification loss 0.0005 AP 0.7967 AR 0.9467
Epoch 519 batch 00001: Loss 0.0042 Regression loss 0.0037 Classification loss 0.0005 AP 0.7417 AR 0.9250
Epoch 519 batch 00002: Loss 0.0036 Regression loss 0.0031 Classification loss 0.0005 AP 0.6122 AR 0.9000
Epoch 519 batch 00003: Loss 0.0036 Regression loss 0.0031 Classification loss 0.0005 AP 0.5919 AR 0.8350
Epoch 519 batch 00004: Loss 0.0037 Regression loss 0.0032 Classification loss 0.0005 AP 0.6619 AR 0.9500
Epoch 519 batch 00005: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.7000 AR 0.9500
Epoch 519 batch 00006: Loss 0.0038 Regression loss 0.0034 Classification loss 0.0004 AP 0.6833 AR 1.0000
Epoch 519 batch 00007: Loss 0.0036 Regression loss 0.0032 Classification loss 0.0004 AP 0.7267 AR 0.9467
Epoch 519 batch 00008: Loss 0.0039 Regression loss 0.0037 Classification loss 0.0003 AP 0.7933 AR 0.9500
Epoch 519 batch 00009: Loss 0.0042 Regression loss 0.0033 Classification loss 0.0008 AP 0.5833 AR 0.7650
Epoch 519 batch 00010: Loss 0.0034 Regression loss 0.0029 Classification loss 0.0004 AP 0.7451 AR 0.9750
Epoch 520 batch 00001: Loss 0.0034 Regression loss 0.0030 Classification loss 0.0003 AP 0.7288 AR 0.9550
Epoch 520 batch 00002: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.6252 AR 0.8600
Epoch 520 batch 00003: Loss 0.0037 Regression loss 0.0031 Classification loss 0.0005 AP 0.6967 AR 0.8517
Epoch 520 batch 00004: Loss 0.0037 Regression loss 0.0033 Classification loss 0.0004 AP 0.6167 AR 0.9000
Epoch 520 batch 00005: Loss 0.0040 Regression loss 0.0033 Classification loss 0.0006 AP 0.7667 AR 0.9800
Epoch 520 batch 00006: Loss 0.0033 Regression loss 0.0028 Classification loss 0.0005 AP 0.7314 AR 0.9500
Epoch 520 batch 00007: Loss 0.0046 Regression loss 0.0042 Classification loss 0.0004 AP 0.7072 AR 0.8750
Epoch 520 batch 00008: Loss 0.0043 Regression loss 0.0037 Classification loss 0.0006 AP 0.6829 AR 0.9600
Epoch 520 batch 00009: Loss 0.0042 Regression loss 0.0037 Classification loss 0.0005 AP 0.6017 AR 1.0000
Epoch 520 batch 00010: Loss 0.0035 Regression loss 0.0032 Classification loss 0.0003 AP 0.7012 AR 0.8967
Epoch 521 batch 00001: Loss 0.0034 Regression loss 0.0030 Classification loss 0.0004 AP 0.7310 AR 0.9000
Epoch 521 batch 00002: Loss 0.0046 Regression loss 0.0040 Classification loss 0.0006 AP 0.6871 AR 0.9600
Epoch 521 batch 00003: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0004 AP 0.6308 AR 0.8100
Epoch 521 batch 00004: Loss 0.0038 Regression loss 0.0032 Classification loss 0.0006 AP 0.6517 AR 0.9017
Epoch 521 batch 00005: Loss 0.0036 Regression loss 0.0034 Classification loss 0.0002 AP 0.8017 AR 1.0000
Epoch 521 batch 00006: Loss 0.0040 Regression loss 0.0036 Classification loss 0.0004 AP 0.5817 AR 0.8550
Epoch 521 batch 00007: Loss 0.0034 Regression loss 0.0029 Classification loss 0.0004 AP 0.6521 AR 1.0000
Epoch 521 batch 00008: Loss 0.0042 Regression loss 0.0038 Classification loss 0.0004 AP 0.6333 AR 0.9000
Epoch 521 batch 00009: Loss 0.0042 Regression loss 0.0035 Classification loss 0.0007 AP 0.7350 AR 0.9500
Epoch 521 batch 00010: Loss 0.0048 Regression loss 0.0044 Classification loss 0.0003 AP 0.7792 AR 0.9500
Epoch 522 batch 00001: Loss 0.0035 Regression loss 0.0031 Classification loss 0.0004 AP 0.6744 AR 0.8800
Epoch 522 batch 00002: Loss 0.0046 Regression loss 0.0043 Classification loss 0.0004 AP 0.5867 AR 0.6667
Epoch 522 batch 00003: Loss 0.0053 Regression loss 0.0045 Classification loss 0.0008 AP 0.5067 AR 0.7167
Epoch 522 batch 00004: Loss 0.0041 Regression loss 0.0039 Classification loss 0.0002 AP 0.6567 AR 0.9050
Epoch 522 batch 00005: Loss 0.0062 Regression loss 0.0055 Classification loss 0.0007 AP 0.6379 AR 0.7417
Epoch 522 batch 00006: Loss 0.0038 Regression loss 0.0032 Classification loss 0.0006 AP 0.7483 AR 0.9467
Epoch 522 batch 00007: Loss 0.0067 Regression loss 0.0064 Classification loss 0.0003 AP 0.5554 AR 0.8250
Epoch 522 batch 00008: Loss 0.0036 Regression loss 0.0030 Classification loss 0.0005 AP 0.6644 AR 0.9500
Epoch 522 batch 00009: Loss 0.0056 Regression loss 0.0053 Classification loss 0.0004 AP 0.7883 AR 0.9750
Epoch 522 batch 00010: Loss 0.0057 Regression loss 0.0051 Classification loss 0.0005 AP 0.6458 AR 0.9300
Epoch 523 batch 00001: Loss 0.0045 Regression loss 0.0042 Classification loss 0.0002 AP 0.7317 AR 0.8917
Epoch 523 batch 00002: Loss 0.0066 Regression loss 0.0062 Classification loss 0.0004 AP 0.7421 AR 0.8317
Epoch 523 batch 00003: Loss 0.0035 Regression loss 0.0031 Classification loss 0.0004 AP 0.6548 AR 0.9667
Epoch 523 batch 00004: Loss 0.0056 Regression loss 0.0053 Classification loss 0.0003 AP 0.7483 AR 0.9150
Epoch 523 batch 00005: Loss 0.0041 Regression loss 0.0035 Classification loss 0.0006 AP 0.6238 AR 0.9350
Epoch 523 batch 00006: Loss 0.0043 Regression loss 0.0037 Classification loss 0.0006 AP 0.6183 AR 0.7850
Epoch 523 batch 00007: Loss 0.0044 Regression loss 0.0038 Classification loss 0.0006 AP 0.4828 AR 0.7467
Epoch 523 batch 00008: Loss 0.0034 Regression loss 0.0028 Classification loss 0.0006 AP 0.6250 AR 0.9350
Epoch 523 batch 00009: Loss 0.0044 Regression loss 0.0040 Classification loss 0.0004 AP 0.8000 AR 0.9150
Epoch 523 batch 00010: Loss 0.0043 Regression loss 0.0038 Classification loss 0.0005 AP 0.6822 AR 0.9750
Epoch 524 batch 00001: Loss 0.0040 Regression loss 0.0036 Classification loss 0.0005 AP 0.5920 AR 0.8167
Epoch 524 batch 00002: Loss 0.0039 Regression loss 0.0033 Classification loss 0.0006 AP 0.7050 AR 0.8667
Epoch 524 batch 00003: Loss 0.0036 Regression loss 0.0032 Classification loss 0.0005 AP 0.7433 AR 1.0000
Epoch 524 batch 00004: Loss 0.0035 Regression loss 0.0029 Classification loss 0.0006 AP 0.7833 AR 1.0000
Epoch 524 batch 00005: Loss 0.0030 Regression loss 0.0028 Classification loss 0.0002 AP 0.7731 AR 0.9800
Epoch 524 batch 00006: Loss 0.0034 Regression loss 0.0030 Classification loss 0.0004 AP 0.6981 AR 0.8300
Epoch 524 batch 00007: Loss 0.0032 Regression loss 0.0025 Classification loss 0.0007 AP 0.7183 AR 0.9100
Epoch 524 batch 00008: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0002 AP 0.5850 AR 0.8550
Epoch 524 batch 00009: Loss 0.0033 Regression loss 0.0029 Classification loss 0.0004 AP 0.6267 AR 0.9133
Epoch 524 batch 00010: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0004 AP 0.7139 AR 0.9750
Epoch 525 batch 00001: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0003 AP 0.7392 AR 0.9800
Epoch 525 batch 00002: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.8017 AR 0.9550
Epoch 525 batch 00003: Loss 0.0032 Regression loss 0.0025 Classification loss 0.0007 AP 0.7645 AR 0.9550
Epoch 525 batch 00004: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.8656 AR 0.9800
Epoch 525 batch 00005: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0003 AP 0.6160 AR 0.9050
Epoch 525 batch 00006: Loss 0.0035 Regression loss 0.0030 Classification loss 0.0006 AP 0.7708 AR 0.9400
Epoch 525 batch 00007: Loss 0.0033 Regression loss 0.0028 Classification loss 0.0005 AP 0.6592 AR 0.9667
Epoch 525 batch 00008: Loss 0.0036 Regression loss 0.0031 Classification loss 0.0005 AP 0.7117 AR 0.9800
Epoch 525 batch 00009: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.6633 AR 0.7833
Epoch 525 batch 00010: Loss 0.0037 Regression loss 0.0032 Classification loss 0.0004 AP 0.6133 AR 0.9750
Epoch 526 batch 00001: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.7886 AR 0.9750
Epoch 526 batch 00002: Loss 0.0032 Regression loss 0.0027 Classification loss 0.0004 AP 0.6867 AR 0.9250
Epoch 526 batch 00003: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0003 AP 0.8200 AR 1.0000
Epoch 526 batch 00004: Loss 0.0037 Regression loss 0.0032 Classification loss 0.0005 AP 0.6071 AR 0.9400
Epoch 526 batch 00005: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0004 AP 0.6800 AR 0.9300
Epoch 526 batch 00006: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.8633 AR 1.0000
Epoch 526 batch 00007: Loss 0.0032 Regression loss 0.0027 Classification loss 0.0004 AP 0.7589 AR 0.9250
Epoch 526 batch 00008: Loss 0.0033 Regression loss 0.0030 Classification loss 0.0003 AP 0.7355 AR 0.9750
Epoch 526 batch 00009: Loss 0.0032 Regression loss 0.0026 Classification loss 0.0006 AP 0.6433 AR 0.9150
Epoch 526 batch 00010: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0004 AP 0.5744 AR 0.7917
Epoch 527 batch 00001: Loss 0.0036 Regression loss 0.0033 Classification loss 0.0003 AP 0.6488 AR 0.7950
Epoch 527 batch 00002: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0004 AP 0.7917 AR 1.0000
Epoch 527 batch 00003: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.8517 AR 0.9667
Epoch 527 batch 00004: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.5883 AR 0.8467
Epoch 527 batch 00005: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0004 AP 0.6840 AR 0.9550
Epoch 527 batch 00006: Loss 0.0033 Regression loss 0.0028 Classification loss 0.0005 AP 0.6942 AR 0.9000
Epoch 527 batch 00007: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0004 AP 0.7338 AR 0.9800
Epoch 527 batch 00008: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7650 AR 0.9667
Epoch 527 batch 00009: Loss 0.0033 Regression loss 0.0028 Classification loss 0.0006 AP 0.6672 AR 0.8850
Epoch 527 batch 00010: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0003 AP 0.6242 AR 0.8050
Epoch 528 batch 00001: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6639 AR 0.9550
Epoch 528 batch 00002: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0003 AP 0.7783 AR 1.0000
Epoch 528 batch 00003: Loss 0.0037 Regression loss 0.0033 Classification loss 0.0004 AP 0.7522 AR 0.9017
Epoch 528 batch 00004: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0003 AP 0.6763 AR 1.0000
Epoch 528 batch 00005: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.8014 AR 1.0000
Epoch 528 batch 00006: Loss 0.0032 Regression loss 0.0026 Classification loss 0.0006 AP 0.6950 AR 0.9500
Epoch 528 batch 00007: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.6933 AR 0.9250
Epoch 528 batch 00008: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.8764 AR 0.9600
Epoch 528 batch 00009: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.6639 AR 0.9667
Epoch 528 batch 00010: Loss 0.0036 Regression loss 0.0032 Classification loss 0.0004 AP 0.6667 AR 0.9000
Epoch 529 batch 00001: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.7667 AR 0.9550
Epoch 529 batch 00002: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0004 AP 0.7100 AR 0.9417
Epoch 529 batch 00003: Loss 0.0030 Regression loss 0.0025 Classification loss 0.0004 AP 0.7458 AR 0.9500
Epoch 529 batch 00004: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0005 AP 0.7021 AR 0.9600
Epoch 529 batch 00005: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.7700 AR 0.9500
Epoch 529 batch 00006: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6705 AR 0.8300
Epoch 529 batch 00007: Loss 0.0035 Regression loss 0.0031 Classification loss 0.0004 AP 0.6489 AR 0.8583
Epoch 529 batch 00008: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7695 AR 0.9417
Epoch 529 batch 00009: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.7700 AR 0.9800
Epoch 529 batch 00010: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0002 AP 0.5692 AR 0.8550
Epoch 530 batch 00001: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0005 AP 0.6813 AR 0.9200
Epoch 530 batch 00002: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.5612 AR 0.9417
Epoch 530 batch 00003: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.7022 AR 0.9500
Epoch 530 batch 00004: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.8583 AR 0.9500
Epoch 530 batch 00005: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.8700 AR 0.9550
Epoch 530 batch 00006: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7431 AR 1.0000
Epoch 530 batch 00007: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.8005 AR 1.0000
Epoch 530 batch 00008: Loss 0.0034 Regression loss 0.0031 Classification loss 0.0002 AP 0.6336 AR 0.8267
Epoch 530 batch 00009: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.7233 AR 1.0000
Epoch 530 batch 00010: Loss 0.0030 Regression loss 0.0025 Classification loss 0.0005 AP 0.6392 AR 0.9550
Epoch 531 batch 00001: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.7331 AR 0.9083
Epoch 531 batch 00002: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.6364 AR 0.9000
Epoch 531 batch 00003: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0005 AP 0.8094 AR 0.9800
Epoch 531 batch 00004: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0002 AP 0.7300 AR 1.0000
Epoch 531 batch 00005: Loss 0.0031 Regression loss 0.0026 Classification loss 0.0005 AP 0.6267 AR 0.9050
Epoch 531 batch 00006: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.8386 AR 0.9500
Epoch 531 batch 00007: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6283 AR 0.8800
Epoch 531 batch 00008: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.7808 AR 0.9800
Epoch 531 batch 00009: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0002 AP 0.7305 AR 0.9750
Epoch 531 batch 00010: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.7350 AR 0.9750
Epoch 532 batch 00001: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6408 AR 0.8967
Epoch 532 batch 00002: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6119 AR 0.8300
Epoch 532 batch 00003: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7481 AR 0.9750
Epoch 532 batch 00004: Loss 0.0033 Regression loss 0.0029 Classification loss 0.0004 AP 0.7548 AR 0.9600
Epoch 532 batch 00005: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7622 AR 1.0000
Epoch 532 batch 00006: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.7516 AR 0.9500
Epoch 532 batch 00007: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0003 AP 0.5814 AR 0.8750
Epoch 532 batch 00008: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.6767 AR 0.8750
Epoch 532 batch 00009: Loss 0.0036 Regression loss 0.0033 Classification loss 0.0003 AP 0.6683 AR 0.8917
Epoch 532 batch 00010: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7933 AR 0.9267
Epoch 533 batch 00001: Loss 0.0030 Regression loss 0.0028 Classification loss 0.0002 AP 0.7710 AR 0.9750
Epoch 533 batch 00002: Loss 0.0028 Regression loss 0.0026 Classification loss 0.0002 AP 0.6783 AR 0.9250
Epoch 533 batch 00003: Loss 0.0029 Regression loss 0.0023 Classification loss 0.0006 AP 0.7148 AR 0.9467
Epoch 533 batch 00004: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.8167 AR 0.9467
Epoch 533 batch 00005: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6488 AR 0.9550
Epoch 533 batch 00006: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0004 AP 0.6977 AR 0.9750
Epoch 533 batch 00007: Loss 0.0032 Regression loss 0.0030 Classification loss 0.0002 AP 0.6289 AR 0.8567
Epoch 533 batch 00008: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.6967 AR 0.9750
Epoch 533 batch 00009: Loss 0.0034 Regression loss 0.0030 Classification loss 0.0004 AP 0.7283 AR 0.9050
Epoch 533 batch 00010: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6422 AR 0.8800
Epoch 534 batch 00001: Loss 0.0033 Regression loss 0.0031 Classification loss 0.0002 AP 0.6395 AR 0.8350
Epoch 534 batch 00002: Loss 0.0023 Regression loss 0.0022 Classification loss 0.0002 AP 0.8433 AR 1.0000
Epoch 534 batch 00003: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0003 AP 0.8167 AR 0.9550
Epoch 534 batch 00004: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.6952 AR 0.9400
Epoch 534 batch 00005: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.7356 AR 0.9667
Epoch 534 batch 00006: Loss 0.0038 Regression loss 0.0035 Classification loss 0.0003 AP 0.8200 AR 1.0000
Epoch 534 batch 00007: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.6408 AR 0.8767
Epoch 534 batch 00008: Loss 0.0039 Regression loss 0.0034 Classification loss 0.0005 AP 0.6867 AR 0.8567
Epoch 534 batch 00009: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.7400 AR 1.0000
Epoch 534 batch 00010: Loss 0.0033 Regression loss 0.0028 Classification loss 0.0005 AP 0.5240 AR 0.8717
Epoch 535 batch 00001: Loss 0.0034 Regression loss 0.0029 Classification loss 0.0005 AP 0.7600 AR 0.9467
Epoch 535 batch 00002: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0002 AP 0.7538 AR 0.9500
Epoch 535 batch 00003: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0003 AP 0.6614 AR 0.9000
Epoch 535 batch 00004: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.8200 AR 1.0000
Epoch 535 batch 00005: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.7167 AR 1.0000
Epoch 535 batch 00006: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.7597 AR 0.9467
Epoch 535 batch 00007: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0002 AP 0.7936 AR 0.9750
Epoch 535 batch 00008: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.6867 AR 0.9750
Epoch 535 batch 00009: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6369 AR 1.0000
Epoch 535 batch 00010: Loss 0.0030 Regression loss 0.0024 Classification loss 0.0006 AP 0.6512 AR 0.8150
Epoch 536 batch 00001: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6800 AR 1.0000
Epoch 536 batch 00002: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0005 AP 0.7433 AR 1.0000
Epoch 536 batch 00003: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6958 AR 0.9167
Epoch 536 batch 00004: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.6902 AR 0.9500
Epoch 536 batch 00005: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.8664 AR 0.9550
Epoch 536 batch 00006: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7533 AR 0.9800
Epoch 536 batch 00007: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0002 AP 0.8348 AR 0.9800
Epoch 536 batch 00008: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.6862 AR 0.8750
Epoch 536 batch 00009: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5705 AR 0.8550
Epoch 536 batch 00010: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.6126 AR 0.8617
Epoch 537 batch 00001: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.5839 AR 0.9217
Epoch 537 batch 00002: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.6780 AR 0.9100
Epoch 537 batch 00003: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.8733 AR 1.0000
Epoch 537 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0002 AP 0.8192 AR 0.9550
Epoch 537 batch 00005: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.8044 AR 1.0000
Epoch 537 batch 00006: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.6550 AR 0.8467
Epoch 537 batch 00007: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7100 AR 0.9417
Epoch 537 batch 00008: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0002 AP 0.6712 AR 0.9500
Epoch 537 batch 00009: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0005 AP 0.6924 AR 0.8600
Epoch 537 batch 00010: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.7333 AR 0.9500
Epoch 538 batch 00001: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0002 AP 0.7383 AR 0.9667
Epoch 538 batch 00002: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0004 AP 0.7471 AR 0.9800
Epoch 538 batch 00003: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0004 AP 0.6421 AR 0.8350
Epoch 538 batch 00004: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0003 AP 0.6243 AR 0.8300
Epoch 538 batch 00005: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0004 AP 0.8117 AR 0.9550
Epoch 538 batch 00006: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7359 AR 0.9800
Epoch 538 batch 00007: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0002 AP 0.7522 AR 0.9217
Epoch 538 batch 00008: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0002 AP 0.7233 AR 0.9417
Epoch 538 batch 00009: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.6423 AR 0.9800
Epoch 538 batch 00010: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.7533 AR 0.9500
Epoch 539 batch 00001: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0002 AP 0.7755 AR 1.0000
Epoch 539 batch 00002: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7762 AR 0.9500
Epoch 539 batch 00003: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6717 AR 0.8417
Epoch 539 batch 00004: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.8475 AR 0.9750
Epoch 539 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.5922 AR 0.8500
Epoch 539 batch 00006: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.5945 AR 0.9550
Epoch 539 batch 00007: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0004 AP 0.6511 AR 0.9100
Epoch 539 batch 00008: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7186 AR 0.9400
Epoch 539 batch 00009: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.7650 AR 0.9800
Epoch 539 batch 00010: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.6538 AR 0.7800
Epoch 540 batch 00001: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7681 AR 0.9800
Epoch 540 batch 00002: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7098 AR 0.9500
Epoch 540 batch 00003: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0002 AP 0.7617 AR 0.9500
Epoch 540 batch 00004: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7471 AR 0.9800
Epoch 540 batch 00005: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0002 AP 0.8100 AR 1.0000
Epoch 540 batch 00006: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0002 AP 0.6955 AR 0.9750
Epoch 540 batch 00007: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.8152 AR 0.9550
Epoch 540 batch 00008: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.6521 AR 0.8950
Epoch 540 batch 00009: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.7283 AR 0.9417
Epoch 540 batch 00010: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6842 AR 0.8600
Epoch 541 batch 00001: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.6683 AR 0.8267
Epoch 541 batch 00002: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.6910 AR 0.9750
Epoch 541 batch 00003: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0002 AP 0.7333 AR 0.9800
Epoch 541 batch 00004: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0003 AP 0.6453 AR 0.8667
Epoch 541 batch 00005: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7733 AR 0.9300
Epoch 541 batch 00006: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.8164 AR 1.0000
Epoch 541 batch 00007: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7408 AR 0.9750
Epoch 541 batch 00008: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.7639 AR 0.9250
Epoch 541 batch 00009: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6733 AR 0.9800
Epoch 541 batch 00010: Loss 0.0022 Regression loss 0.0017 Classification loss 0.0005 AP 0.7767 AR 0.9750
Epoch 542 batch 00001: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0004 AP 0.7156 AR 1.0000
Epoch 542 batch 00002: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0002 AP 0.6733 AR 0.8550
Epoch 542 batch 00003: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.8322 AR 1.0000
Epoch 542 batch 00004: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7960 AR 0.9400
Epoch 542 batch 00005: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.7233 AR 0.8750
Epoch 542 batch 00006: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.6883 AR 0.8500
Epoch 542 batch 00007: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6919 AR 1.0000
Epoch 542 batch 00008: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6708 AR 0.9250
Epoch 542 batch 00009: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0002 AP 0.6381 AR 0.9467
Epoch 542 batch 00010: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7383 AR 1.0000
Epoch 543 batch 00001: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7321 AR 0.9750
Epoch 543 batch 00002: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.7512 AR 0.9750
Epoch 543 batch 00003: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.6971 AR 0.9800
Epoch 543 batch 00004: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0002 AP 0.7029 AR 0.8600
Epoch 543 batch 00005: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.8633 AR 0.9800
Epoch 543 batch 00006: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.6316 AR 0.9467
Epoch 543 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.8350 AR 0.9467
Epoch 543 batch 00008: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6914 AR 0.9667
Epoch 543 batch 00009: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7821 AR 1.0000
Epoch 543 batch 00010: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0005 AP 0.6572 AR 0.9800
Epoch 544 batch 00001: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7356 AR 1.0000
Epoch 544 batch 00002: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7398 AR 0.9550
Epoch 544 batch 00003: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.8250 AR 0.9800
Epoch 544 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7056 AR 0.9750
Epoch 544 batch 00005: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7355 AR 0.9667
Epoch 544 batch 00006: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7439 AR 0.9417
Epoch 544 batch 00007: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.7300 AR 0.9800
Epoch 544 batch 00008: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.6942 AR 0.8250
Epoch 544 batch 00009: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0003 AP 0.7567 AR 0.9800
Epoch 544 batch 00010: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6810 AR 0.9750
Epoch 545 batch 00001: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0002 AP 0.7628 AR 0.9500
Epoch 545 batch 00002: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7910 AR 0.9600
Epoch 545 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7233 AR 0.9500
Epoch 545 batch 00004: Loss 0.0023 Regression loss 0.0018 Classification loss 0.0004 AP 0.6533 AR 0.7633
Epoch 545 batch 00005: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.7771 AR 0.9750
Epoch 545 batch 00006: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0002 AP 0.6983 AR 1.0000
Epoch 545 batch 00007: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6444 AR 1.0000
Epoch 545 batch 00008: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7742 AR 1.0000
Epoch 545 batch 00009: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7623 AR 0.9500
Epoch 545 batch 00010: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.8331 AR 0.9800
Epoch 546 batch 00001: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0003 AP 0.8076 AR 0.9750
Epoch 546 batch 00002: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0004 AP 0.6526 AR 0.8500
Epoch 546 batch 00003: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0003 AP 0.6683 AR 0.9217
Epoch 546 batch 00004: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6538 AR 0.9500
Epoch 546 batch 00005: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6639 AR 0.8800
Epoch 546 batch 00006: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.7517 AR 0.9800
Epoch 546 batch 00007: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7088 AR 0.9800
Epoch 546 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7423 AR 0.9800
Epoch 546 batch 00009: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0003 AP 0.7589 AR 0.9750
Epoch 546 batch 00010: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.7817 AR 0.9800
Epoch 547 batch 00001: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0002 AP 0.7152 AR 0.9667
Epoch 547 batch 00002: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0003 AP 0.7338 AR 1.0000
Epoch 547 batch 00003: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.8192 AR 1.0000
Epoch 547 batch 00004: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.6300 AR 1.0000
Epoch 547 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7183 AR 0.9550
Epoch 547 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7081 AR 0.9400
Epoch 547 batch 00007: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7617 AR 0.9350
Epoch 547 batch 00008: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6871 AR 0.9750
Epoch 547 batch 00009: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.8081 AR 0.9050
Epoch 547 batch 00010: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0002 AP 0.8000 AR 0.9667
Epoch 548 batch 00001: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0003 AP 0.7887 AR 0.9750
Epoch 548 batch 00002: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7239 AR 0.9750
Epoch 548 batch 00003: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0003 AP 0.6583 AR 0.9600
Epoch 548 batch 00004: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.6769 AR 0.9667
Epoch 548 batch 00005: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.6467 AR 0.8500
Epoch 548 batch 00006: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0003 AP 0.7755 AR 0.9750
Epoch 548 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6502 AR 0.9000
Epoch 548 batch 00008: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.7196 AR 0.9467
Epoch 548 batch 00009: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0003 AP 0.7564 AR 0.9800
Epoch 548 batch 00010: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0002 AP 0.8067 AR 1.0000
Epoch 549 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7796 AR 1.0000
Epoch 549 batch 00002: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.7421 AR 0.9217
Epoch 549 batch 00003: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6364 AR 0.9000
Epoch 549 batch 00004: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0004 AP 0.5772 AR 0.9800
Epoch 549 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7625 AR 0.9750
Epoch 549 batch 00006: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7764 AR 0.9800
Epoch 549 batch 00007: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6800 AR 0.9300
Epoch 549 batch 00008: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.8213 AR 1.0000
Epoch 549 batch 00009: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7717 AR 1.0000
Epoch 549 batch 00010: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.7361 AR 0.9300
Epoch 550 batch 00001: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7261 AR 0.9350
Epoch 550 batch 00002: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0003 AP 0.7958 AR 0.9000
Epoch 550 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.8192 AR 0.9550
Epoch 550 batch 00004: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7433 AR 0.9800
Epoch 550 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.6767 AR 0.9550
Epoch 550 batch 00006: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7150 AR 0.9750
Epoch 550 batch 00007: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7038 AR 1.0000
Epoch 550 batch 00008: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.8264 AR 1.0000
Epoch 550 batch 00009: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.5483 AR 0.8667
Epoch 550 batch 00010: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0002 AP 0.6725 AR 0.9000
Epoch 551 batch 00001: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0003 AP 0.6067 AR 0.7750
Epoch 551 batch 00002: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.6722 AR 0.9100
Epoch 551 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7237 AR 0.9050
Epoch 551 batch 00004: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7548 AR 0.9800
Epoch 551 batch 00005: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0002 AP 0.7092 AR 0.9550
Epoch 551 batch 00006: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6439 AR 1.0000
Epoch 551 batch 00007: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7475 AR 0.9750
Epoch 551 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.8300 AR 1.0000
Epoch 551 batch 00009: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.6783 AR 0.9167
Epoch 551 batch 00010: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7826 AR 1.0000
Epoch 552 batch 00001: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6883 AR 0.9800
Epoch 552 batch 00002: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7564 AR 0.9000
Epoch 552 batch 00003: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0002 AP 0.7356 AR 1.0000
Epoch 552 batch 00004: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0003 AP 0.7471 AR 0.9800
Epoch 552 batch 00005: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0002 AP 0.6700 AR 0.9750
Epoch 552 batch 00006: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8458 AR 1.0000
Epoch 552 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7405 AR 0.9800
Epoch 552 batch 00008: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7031 AR 0.9800
Epoch 552 batch 00009: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0002 AP 0.6329 AR 0.9300
Epoch 552 batch 00010: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7333 AR 0.9750
Epoch 553 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6808 AR 0.8600
Epoch 553 batch 00002: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0004 AP 0.7042 AR 0.9500
Epoch 553 batch 00003: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.6808 AR 1.0000
Epoch 553 batch 00004: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.8300 AR 1.0000
Epoch 553 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7831 AR 1.0000
Epoch 553 batch 00006: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6683 AR 0.8750
Epoch 553 batch 00007: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7095 AR 0.9350
Epoch 553 batch 00008: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0002 AP 0.6958 AR 0.9667
Epoch 553 batch 00009: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6508 AR 0.8350
Epoch 553 batch 00010: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7071 AR 0.9750
Epoch 554 batch 00001: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0001 AP 0.6731 AR 0.9750
Epoch 554 batch 00002: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.8481 AR 1.0000
Epoch 554 batch 00003: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0003 AP 0.7442 AR 1.0000
Epoch 554 batch 00004: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7567 AR 0.9000
Epoch 554 batch 00005: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.7417 AR 0.9800
Epoch 554 batch 00006: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.6231 AR 0.9333
Epoch 554 batch 00007: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0003 AP 0.5983 AR 0.8350
Epoch 554 batch 00008: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.8356 AR 0.9750
Epoch 554 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0003 AP 0.6717 AR 0.9800
Epoch 554 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7644 AR 0.9400
Epoch 555 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7800 AR 0.9667
Epoch 555 batch 00002: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7108 AR 0.9400
Epoch 555 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6655 AR 0.9417
Epoch 555 batch 00004: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0001 AP 0.6383 AR 0.8750
Epoch 555 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7175 AR 0.9500
Epoch 555 batch 00006: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.8175 AR 0.9800
Epoch 555 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7633 AR 0.9800
Epoch 555 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7614 AR 1.0000
Epoch 555 batch 00009: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7667 AR 0.9300
Epoch 555 batch 00010: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0002 AP 0.6925 AR 0.9667
Epoch 556 batch 00001: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6500 AR 0.8650
Epoch 556 batch 00002: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.8500 AR 0.9750
Epoch 556 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7750 AR 1.0000
Epoch 556 batch 00004: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6347 AR 1.0000
Epoch 556 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7833 AR 0.8800
Epoch 556 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.6705 AR 0.9800
Epoch 556 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7582 AR 0.9750
Epoch 556 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7370 AR 1.0000
Epoch 556 batch 00009: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0001 AP 0.6964 AR 0.9750
Epoch 556 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7850 AR 1.0000
Epoch 557 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8150 AR 1.0000
Epoch 557 batch 00002: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.6771 AR 0.9000
Epoch 557 batch 00003: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.7300 AR 0.9550
Epoch 557 batch 00004: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0004 AP 0.7775 AR 0.9550
Epoch 557 batch 00005: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7392 AR 1.0000
Epoch 557 batch 00006: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0003 AP 0.7371 AR 0.9400
Epoch 557 batch 00007: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0002 AP 0.6664 AR 0.9250
Epoch 557 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7150 AR 1.0000
Epoch 557 batch 00009: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7480 AR 1.0000
Epoch 557 batch 00010: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7867 AR 1.0000
Epoch 558 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7419 AR 1.0000
Epoch 558 batch 00002: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.6781 AR 0.9750
Epoch 558 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7305 AR 0.9417
Epoch 558 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6646 AR 0.9300
Epoch 558 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6838 AR 0.9300
Epoch 558 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7083 AR 1.0000
Epoch 558 batch 00007: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7258 AR 0.9800
Epoch 558 batch 00008: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7900 AR 0.9500
Epoch 558 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.8267 AR 0.9800
Epoch 558 batch 00010: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7600 AR 0.9800
Epoch 559 batch 00001: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0002 AP 0.7021 AR 0.9600
Epoch 559 batch 00002: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.8800 AR 1.0000
Epoch 559 batch 00003: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.6333 AR 0.9000
Epoch 559 batch 00004: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.6729 AR 0.8750
Epoch 559 batch 00005: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6406 AR 0.9550
Epoch 559 batch 00006: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.8071 AR 0.9750
Epoch 559 batch 00007: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6983 AR 1.0000
Epoch 559 batch 00008: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7522 AR 0.9800
Epoch 559 batch 00009: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.7467 AR 0.9300
Epoch 559 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7763 AR 1.0000
Epoch 560 batch 00001: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.8283 AR 0.9800
Epoch 560 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7881 AR 0.9800
Epoch 560 batch 00003: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.6242 AR 0.8750
Epoch 560 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6636 AR 1.0000
Epoch 560 batch 00005: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7950 AR 1.0000
Epoch 560 batch 00006: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0003 AP 0.6855 AR 0.9350
Epoch 560 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6073 AR 0.9000
Epoch 560 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6688 AR 0.9667
Epoch 560 batch 00009: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7311 AR 1.0000
Epoch 560 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8817 AR 0.9750
Epoch 561 batch 00001: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7305 AR 0.9550
Epoch 561 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7156 AR 1.0000
Epoch 561 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7558 AR 0.9550
Epoch 561 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7533 AR 0.9300
Epoch 561 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8348 AR 0.9800
Epoch 561 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7244 AR 0.9750
Epoch 561 batch 00007: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7019 AR 1.0000
Epoch 561 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6817 AR 0.9000
Epoch 561 batch 00009: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6325 AR 0.9750
Epoch 561 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7403 AR 0.9800
Epoch 562 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0003 AP 0.6798 AR 0.9800
Epoch 562 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.8355 AR 0.9500
Epoch 562 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.7453 AR 0.9800
Epoch 562 batch 00004: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.7742 AR 0.9550
Epoch 562 batch 00005: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.6280 AR 0.8750
Epoch 562 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7642 AR 0.9750
Epoch 562 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7337 AR 1.0000
Epoch 562 batch 00008: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.6733 AR 1.0000
Epoch 562 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6978 AR 0.9550
Epoch 562 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6317 AR 0.8500
Epoch 563 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6696 AR 0.9300
Epoch 563 batch 00002: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7167 AR 0.9750
Epoch 563 batch 00003: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6510 AR 0.9250
Epoch 563 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7248 AR 0.9800
Epoch 563 batch 00005: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8558 AR 0.9600
Epoch 563 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6219 AR 0.7600
Epoch 563 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.8100 AR 1.0000
Epoch 563 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6955 AR 0.9500
Epoch 563 batch 00009: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7972 AR 1.0000
Epoch 563 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0001 AP 0.7067 AR 0.9550
Epoch 564 batch 00001: Loss 0.0013 Regression loss 0.0010 Classification loss 0.0003 AP 0.8283 AR 1.0000
Epoch 564 batch 00002: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8288 AR 0.9800
Epoch 564 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8344 AR 0.9300
Epoch 564 batch 00004: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.5433 AR 0.8750
Epoch 564 batch 00005: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.6683 AR 0.9800
Epoch 564 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7763 AR 0.9550
Epoch 564 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6070 AR 0.9250
Epoch 564 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.7339 AR 0.9500
Epoch 564 batch 00009: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.7621 AR 0.8800
Epoch 564 batch 00010: Loss 0.0014 Regression loss 0.0014 Classification loss 0.0001 AP 0.7150 AR 0.9667
Epoch 565 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.7290 AR 0.9550
Epoch 565 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.6450 AR 0.9467
Epoch 565 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6667 AR 0.9550
Epoch 565 batch 00004: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.8717 AR 0.9800
Epoch 565 batch 00005: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.8881 AR 0.9300
Epoch 565 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6800 AR 0.9000
Epoch 565 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6637 AR 0.9750
Epoch 565 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7013 AR 0.9800
Epoch 565 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7805 AR 1.0000
Epoch 565 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6017 AR 0.9000
Epoch 566 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8388 AR 1.0000
Epoch 566 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7933 AR 0.9800
Epoch 566 batch 00003: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.6438 AR 0.9500
Epoch 566 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6644 AR 0.9350
Epoch 566 batch 00005: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.6196 AR 0.9000
Epoch 566 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.6150 AR 0.8500
Epoch 566 batch 00007: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7031 AR 0.9000
Epoch 566 batch 00008: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.7617 AR 0.9800
Epoch 566 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7295 AR 0.9667
Epoch 566 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8567 AR 0.9800
Epoch 567 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7981 AR 1.0000
Epoch 567 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8483 AR 0.9600
Epoch 567 batch 00003: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6341 AR 0.9550
Epoch 567 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8400 AR 0.9550
Epoch 567 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.6662 AR 0.9550
Epoch 567 batch 00006: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6497 AR 0.9600
Epoch 567 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.7544 AR 1.0000
Epoch 567 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6692 AR 0.8500
Epoch 567 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8208 AR 1.0000
Epoch 567 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0003 AP 0.6783 AR 1.0000
Epoch 568 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5850 AR 0.9350
Epoch 568 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7111 AR 1.0000
Epoch 568 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8033 AR 0.9550
Epoch 568 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6233 AR 0.8800
Epoch 568 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6833 AR 0.9100
Epoch 568 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7158 AR 0.8917
Epoch 568 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8650 AR 0.9750
Epoch 568 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.7350 AR 0.9750
Epoch 568 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6264 AR 1.0000
Epoch 568 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7705 AR 0.9000
Epoch 569 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6864 AR 1.0000
Epoch 569 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7506 AR 1.0000
Epoch 569 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5933 AR 0.8750
Epoch 569 batch 00004: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6933 AR 0.9200
Epoch 569 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7464 AR 0.9250
Epoch 569 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7254 AR 0.9500
Epoch 569 batch 00007: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6871 AR 0.9550
Epoch 569 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.8033 AR 0.9600
Epoch 569 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6625 AR 0.9750
Epoch 569 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7458 AR 0.9500
Epoch 570 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.5700 AR 1.0000
Epoch 570 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7075 AR 0.9500
Epoch 570 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7147 AR 1.0000
Epoch 570 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.7189 AR 1.0000
Epoch 570 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7567 AR 0.9667
Epoch 570 batch 00006: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.8683 AR 0.9600
Epoch 570 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6729 AR 0.9600
Epoch 570 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6614 AR 0.8750
Epoch 570 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7360 AR 0.9750
Epoch 570 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8850 AR 1.0000
Epoch 571 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7500 AR 0.9600
Epoch 571 batch 00002: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7367 AR 0.9550
Epoch 571 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6792 AR 0.9167
Epoch 571 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.8617 AR 1.0000
Epoch 571 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.7125 AR 0.9150
Epoch 571 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6986 AR 1.0000
Epoch 571 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7517 AR 0.9550
Epoch 571 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6956 AR 0.9500
Epoch 571 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7271 AR 0.9600
Epoch 571 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7681 AR 1.0000
Epoch 572 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8098 AR 1.0000
Epoch 572 batch 00002: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.6967 AR 0.9750
Epoch 572 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6850 AR 0.8917
Epoch 572 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8078 AR 0.9000
Epoch 572 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7267 AR 0.9550
Epoch 572 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7872 AR 0.9600
Epoch 572 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6255 AR 0.9000
Epoch 572 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6650 AR 0.9350
Epoch 572 batch 00009: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7365 AR 0.9800
Epoch 572 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6698 AR 0.9350
Epoch 573 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.5535 AR 0.8250
Epoch 573 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.8283 AR 1.0000
Epoch 573 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6767 AR 1.0000
Epoch 573 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6633 AR 0.9550
Epoch 573 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7225 AR 1.0000
Epoch 573 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8500 AR 0.9500
Epoch 573 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7514 AR 0.9600
Epoch 573 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6006 AR 0.9467
Epoch 573 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.8421 AR 0.9550
Epoch 573 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6783 AR 0.8550
Epoch 574 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6867 AR 0.9550
Epoch 574 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6693 AR 1.0000
Epoch 574 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8338 AR 0.9800
Epoch 574 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7458 AR 1.0000
Epoch 574 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6414 AR 1.0000
Epoch 574 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6808 AR 0.8750
Epoch 574 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7371 AR 1.0000
Epoch 574 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7350 AR 0.8750
Epoch 574 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7400 AR 0.9750
Epoch 574 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7600 AR 0.8800
Epoch 575 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7203 AR 0.9750
Epoch 575 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8131 AR 0.9800
Epoch 575 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7292 AR 0.9000
Epoch 575 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.6900 AR 0.9500
Epoch 575 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7667 AR 0.9500
Epoch 575 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8055 AR 0.9800
Epoch 575 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7031 AR 0.9800
Epoch 575 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.5833 AR 0.9000
Epoch 575 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.5825 AR 0.8350
Epoch 575 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7321 AR 1.0000
Epoch 576 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7539 AR 0.9600
Epoch 576 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7770 AR 0.9750
Epoch 576 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6498 AR 0.8550
Epoch 576 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5717 AR 0.9300
Epoch 576 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8350 AR 1.0000
Epoch 576 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7550 AR 0.9500
Epoch 576 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6321 AR 0.8300
Epoch 576 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8517 AR 1.0000
Epoch 576 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7136 AR 1.0000
Epoch 576 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7435 AR 1.0000
Epoch 577 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6194 AR 0.9300
Epoch 577 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5989 AR 0.8800
Epoch 577 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6438 AR 0.9350
Epoch 577 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.8933 AR 1.0000
Epoch 577 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7400 AR 0.9550
Epoch 577 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.5114 AR 0.7500
Epoch 577 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.8308 AR 1.0000
Epoch 577 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7349 AR 0.9750
Epoch 577 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8281 AR 0.9800
Epoch 577 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7467 AR 1.0000
Epoch 578 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8033 AR 1.0000
Epoch 578 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7067 AR 0.9000
Epoch 578 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6827 AR 0.9600
Epoch 578 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6587 AR 0.9467
Epoch 578 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.8550 AR 0.9750
Epoch 578 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7106 AR 0.9500
Epoch 578 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.8017 AR 1.0000
Epoch 578 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6448 AR 0.9300
Epoch 578 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6817 AR 0.8800
Epoch 578 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6319 AR 0.7750
Epoch 579 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6798 AR 0.9500
Epoch 579 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7083 AR 0.9500
Epoch 579 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6450 AR 0.7350
Epoch 579 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7316 AR 0.9600
Epoch 579 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6542 AR 1.0000
Epoch 579 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8471 AR 0.9550
Epoch 579 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7837 AR 0.9400
Epoch 579 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6967 AR 0.9000
Epoch 579 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.5405 AR 0.8000
Epoch 579 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7205 AR 0.9800
Epoch 580 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6700 AR 0.9350
Epoch 580 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6544 AR 0.9750
Epoch 580 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7483 AR 0.9750
Epoch 580 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.8650 AR 0.9550
Epoch 580 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6633 AR 0.9667
Epoch 580 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7158 AR 1.0000
Epoch 580 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7917 AR 0.9100
Epoch 580 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.5505 AR 0.8550
Epoch 580 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6994 AR 1.0000
Epoch 580 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7014 AR 0.8000
Epoch 581 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7671 AR 0.9750
Epoch 581 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7850 AR 0.9500
Epoch 581 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7292 AR 0.9667
Epoch 581 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6958 AR 0.9750
Epoch 581 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.5939 AR 0.7600
Epoch 581 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7361 AR 0.9350
Epoch 581 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6271 AR 1.0000
Epoch 581 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7917 AR 0.9400
Epoch 581 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7064 AR 0.9000
Epoch 581 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.5839 AR 0.9000
Epoch 582 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6367 AR 0.8467
Epoch 582 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7600 AR 0.9800
Epoch 582 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7039 AR 1.0000
Epoch 582 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.8281 AR 0.9800
Epoch 582 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7900 AR 0.9800
Epoch 582 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8017 AR 0.9500
Epoch 582 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6737 AR 0.9500
Epoch 582 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6347 AR 0.8750
Epoch 582 batch 00009: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7158 AR 1.0000
Epoch 582 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8192 AR 0.9600
Epoch 583 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7958 AR 0.9750
Epoch 583 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7567 AR 0.9600
Epoch 583 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6489 AR 0.9800
Epoch 583 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6550 AR 0.8500
Epoch 583 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7767 AR 0.9800
Epoch 583 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8131 AR 1.0000
Epoch 583 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6119 AR 0.8550
Epoch 583 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5767 AR 0.9800
Epoch 583 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7926 AR 0.9300
Epoch 583 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7400 AR 0.9550
Epoch 584 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7905 AR 1.0000
Epoch 584 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6655 AR 0.9600
Epoch 584 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6153 AR 0.9400
Epoch 584 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6929 AR 1.0000
Epoch 584 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7892 AR 1.0000
Epoch 584 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7656 AR 0.9800
Epoch 584 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7617 AR 1.0000
Epoch 584 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8250 AR 0.9800
Epoch 584 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.8550 AR 0.9750
Epoch 584 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5525 AR 0.8750
Epoch 585 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6283 AR 0.8750
Epoch 585 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8217 AR 0.9333
Epoch 585 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7391 AR 1.0000
Epoch 585 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7094 AR 0.9500
Epoch 585 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6946 AR 0.8800
Epoch 585 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7022 AR 1.0000
Epoch 585 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.8275 AR 0.9350
Epoch 585 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7108 AR 0.9750
Epoch 585 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7088 AR 0.9350
Epoch 585 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8550 AR 1.0000
Epoch 586 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7933 AR 1.0000
Epoch 586 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8000 AR 1.0000
Epoch 586 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.7733 AR 0.9250
Epoch 586 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6523 AR 0.8600
Epoch 586 batch 00005: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7650 AR 0.9800
Epoch 586 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6872 AR 0.9750
Epoch 586 batch 00007: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7000 AR 0.8800
Epoch 586 batch 00008: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7039 AR 1.0000
Epoch 586 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6145 AR 0.8750
Epoch 586 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7023 AR 0.9550
Epoch 587 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7871 AR 1.0000
Epoch 587 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7500 AR 0.8800
Epoch 587 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6417 AR 0.9000
Epoch 587 batch 00004: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8675 AR 1.0000
Epoch 587 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6253 AR 0.9250
Epoch 587 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7133 AR 1.0000
Epoch 587 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7498 AR 1.0000
Epoch 587 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7150 AR 0.9300
Epoch 587 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6808 AR 0.9000
Epoch 587 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0003 AP 0.6900 AR 0.9800
Epoch 588 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8348 AR 0.9800
Epoch 588 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7433 AR 0.8750
Epoch 588 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6950 AR 0.9500
Epoch 588 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8333 AR 0.9750
Epoch 588 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0003 AP 0.6758 AR 0.9800
Epoch 588 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7672 AR 0.9800
Epoch 588 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6555 AR 0.8250
Epoch 588 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7920 AR 1.0000
Epoch 588 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6421 AR 0.9467
Epoch 588 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6521 AR 0.9600
Epoch 589 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7022 AR 0.9000
Epoch 589 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.8708 AR 0.9750
Epoch 589 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7217 AR 0.9467
Epoch 589 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.5417 AR 0.8550
Epoch 589 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5675 AR 0.7500
Epoch 589 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7750 AR 1.0000
Epoch 589 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6983 AR 0.9500
Epoch 589 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7498 AR 0.9167
Epoch 589 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6206 AR 0.9150
Epoch 589 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.8129 AR 0.9800
Epoch 590 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7356 AR 0.9550
Epoch 590 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7025 AR 0.9417
Epoch 590 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7195 AR 0.9500
Epoch 590 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7317 AR 0.9500
Epoch 590 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7036 AR 0.9000
Epoch 590 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.6850 AR 0.8750
Epoch 590 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7556 AR 0.9600
Epoch 590 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8314 AR 1.0000
Epoch 590 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7000 AR 0.9750
Epoch 590 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6288 AR 0.9550
Epoch 591 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7750 AR 0.9800
Epoch 591 batch 00002: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7650 AR 0.8950
Epoch 591 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7050 AR 0.8750
Epoch 591 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7683 AR 1.0000
Epoch 591 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6721 AR 0.9250
Epoch 591 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7683 AR 0.9800
Epoch 591 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7842 AR 1.0000
Epoch 591 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7341 AR 0.9050
Epoch 591 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6064 AR 0.7750
Epoch 591 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6905 AR 1.0000
Epoch 592 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5917 AR 0.9000
Epoch 592 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6367 AR 0.9000
Epoch 592 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7300 AR 0.9350
Epoch 592 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6204 AR 0.8550
Epoch 592 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6698 AR 1.0000
Epoch 592 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7267 AR 0.8817
Epoch 592 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7289 AR 0.9800
Epoch 592 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7483 AR 0.9000
Epoch 592 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7139 AR 0.9000
Epoch 592 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7688 AR 0.8717
Epoch 593 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7575 AR 0.9750
Epoch 593 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6898 AR 0.8417
Epoch 593 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7060 AR 0.9550
Epoch 593 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7664 AR 0.9750
Epoch 593 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.5567 AR 0.8350
Epoch 593 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.8050 AR 0.9600
Epoch 593 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7517 AR 0.9000
Epoch 593 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7475 AR 0.9600
Epoch 593 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7892 AR 0.9750
Epoch 593 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6921 AR 1.0000
Epoch 594 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6983 AR 0.8750
Epoch 594 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8083 AR 0.9050
Epoch 594 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7817 AR 1.0000
Epoch 594 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6697 AR 0.9750
Epoch 594 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6445 AR 0.9017
Epoch 594 batch 00006: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7505 AR 1.0000
Epoch 594 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6764 AR 0.8750
Epoch 594 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6217 AR 0.9800
Epoch 594 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6949 AR 0.9600
Epoch 594 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8145 AR 0.9800
Epoch 595 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6771 AR 0.9750
Epoch 595 batch 00002: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.5581 AR 0.8300
Epoch 595 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7414 AR 0.9800
Epoch 595 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7084 AR 0.9350
Epoch 595 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8272 AR 0.9417
Epoch 595 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0003 AP 0.6464 AR 0.8800
Epoch 595 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6812 AR 0.9500
Epoch 595 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6742 AR 1.0000
Epoch 595 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7267 AR 0.9550
Epoch 595 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.7717 AR 0.8800
Epoch 596 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6650 AR 0.7600
Epoch 596 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7171 AR 0.9800
Epoch 596 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6392 AR 0.8467
Epoch 596 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6672 AR 0.9550
Epoch 596 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8481 AR 1.0000
Epoch 596 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7248 AR 0.9750
Epoch 596 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7300 AR 0.9800
Epoch 596 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6722 AR 0.9750
Epoch 596 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6891 AR 0.9500
Epoch 596 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6988 AR 0.9750
Epoch 597 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6283 AR 0.8800
Epoch 597 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6481 AR 0.9000
Epoch 597 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6183 AR 0.8800
Epoch 597 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8128 AR 0.9500
Epoch 597 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6983 AR 0.9750
Epoch 597 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7653 AR 0.9750
Epoch 597 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7035 AR 0.9300
Epoch 597 batch 00008: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7071 AR 0.9600
Epoch 597 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6743 AR 0.8750
Epoch 597 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7923 AR 0.9750
Epoch 598 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7138 AR 0.9300
Epoch 598 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7033 AR 1.0000
Epoch 598 batch 00003: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7081 AR 0.8500
Epoch 598 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7836 AR 0.9800
Epoch 598 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6826 AR 0.9750
Epoch 598 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7933 AR 0.9550
Epoch 598 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7370 AR 0.9800
Epoch 598 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8210 AR 0.9800
Epoch 598 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6550 AR 0.9750
Epoch 598 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7100 AR 0.9500
Epoch 599 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6725 AR 0.8300
Epoch 599 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6906 AR 0.9300
Epoch 599 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6900 AR 1.0000
Epoch 599 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7061 AR 1.0000
Epoch 599 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7767 AR 0.9800
Epoch 599 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7386 AR 0.9500
Epoch 599 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7931 AR 1.0000
Epoch 599 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7017 AR 0.9500
Epoch 599 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7564 AR 0.9600
Epoch 599 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8145 AR 0.9500
Epoch 600 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7583 AR 0.9750
Epoch 600 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7440 AR 0.9600
Epoch 600 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7850 AR 0.9550
Epoch 600 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7792 AR 0.9500
Epoch 600 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6526 AR 0.8817
Epoch 600 batch 00006: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7333 AR 0.9250
Epoch 600 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5933 AR 0.9250
Epoch 600 batch 00008: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7314 AR 1.0000
Epoch 600 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6458 AR 0.8800
Epoch 600 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7364 AR 1.0000
Epoch 601 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7400 AR 1.0000
Epoch 601 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6771 AR 0.9750
Epoch 601 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6550 AR 1.0000
Epoch 601 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7425 AR 0.9500
Epoch 601 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8583 AR 1.0000
Epoch 601 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8156 AR 0.9800
Epoch 601 batch 00007: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7450 AR 0.9017
Epoch 601 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7276 AR 0.9750
Epoch 601 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7406 AR 0.9000
Epoch 601 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6825 AR 0.9217
Epoch 602 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8083 AR 0.9800
Epoch 602 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6250 AR 0.9750
Epoch 602 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7817 AR 0.9750
Epoch 602 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7000 AR 0.9333
Epoch 602 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7192 AR 1.0000
Epoch 602 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7733 AR 0.8800
Epoch 602 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7556 AR 1.0000
Epoch 602 batch 00008: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6831 AR 0.9050
Epoch 602 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7528 AR 0.9050
Epoch 602 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8114 AR 0.9467
Epoch 603 batch 00001: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7588 AR 0.9467
Epoch 603 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7892 AR 1.0000
Epoch 603 batch 00003: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7105 AR 0.9150
Epoch 603 batch 00004: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6817 AR 0.9750
Epoch 603 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5623 AR 0.8600
Epoch 603 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7483 AR 0.9750
Epoch 603 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8393 AR 0.9550
Epoch 603 batch 00008: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7167 AR 0.9800
Epoch 603 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6056 AR 0.9250
Epoch 603 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7521 AR 0.9750
Epoch 604 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6817 AR 0.9300
Epoch 604 batch 00002: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7583 AR 0.9350
Epoch 604 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7392 AR 0.9750
Epoch 604 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6755 AR 0.9750
Epoch 604 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6722 AR 0.9000
Epoch 604 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7906 AR 0.9600
Epoch 604 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7354 AR 0.9600
Epoch 604 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7567 AR 1.0000
Epoch 604 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7933 AR 0.9550
Epoch 604 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6645 AR 0.8500
Epoch 605 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7788 AR 0.9750
Epoch 605 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7717 AR 1.0000
Epoch 605 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7308 AR 1.0000
Epoch 605 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6721 AR 0.9467
Epoch 605 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6133 AR 0.7800
Epoch 605 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7642 AR 1.0000
Epoch 605 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6485 AR 0.9467
Epoch 605 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7700 AR 1.0000
Epoch 605 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7031 AR 0.9350
Epoch 605 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.8338 AR 0.9350
Epoch 606 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5619 AR 0.8600
Epoch 606 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7350 AR 0.9250
Epoch 606 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7481 AR 1.0000
Epoch 606 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7075 AR 1.0000
Epoch 606 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8400 AR 1.0000
Epoch 606 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7917 AR 0.9750
Epoch 606 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8198 AR 0.9750
Epoch 606 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5860 AR 0.7967
Epoch 606 batch 00009: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6317 AR 0.8750
Epoch 606 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7308 AR 0.9400
Epoch 607 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6955 AR 0.9800
Epoch 607 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8058 AR 0.9800
Epoch 607 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7348 AR 0.9600
Epoch 607 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7217 AR 1.0000
Epoch 607 batch 00005: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6735 AR 0.8750
Epoch 607 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7864 AR 1.0000
Epoch 607 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7381 AR 0.9500
Epoch 607 batch 00008: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6717 AR 0.9267
Epoch 607 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7150 AR 0.9000
Epoch 607 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7317 AR 0.9550
Epoch 608 batch 00001: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7067 AR 0.9350
Epoch 608 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7225 AR 0.9550
Epoch 608 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6345 AR 0.8750
Epoch 608 batch 00004: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6721 AR 0.9300
Epoch 608 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7864 AR 0.9800
Epoch 608 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7625 AR 0.9800
Epoch 608 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7433 AR 0.9750
Epoch 608 batch 00008: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.8317 AR 0.9550
Epoch 608 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6200 AR 0.9467
Epoch 608 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7219 AR 1.0000
Epoch 609 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8088 AR 1.0000
Epoch 609 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6726 AR 0.9100
Epoch 609 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6533 AR 0.8717
Epoch 609 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8064 AR 0.9750
Epoch 609 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5458 AR 0.8417
Epoch 609 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7228 AR 1.0000
Epoch 609 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7442 AR 0.9800
Epoch 609 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7971 AR 0.9550
Epoch 609 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6992 AR 1.0000
Epoch 609 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7183 AR 0.9300
Epoch 610 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5516 AR 0.8550
Epoch 610 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7817 AR 0.9750
Epoch 610 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6964 AR 0.9750
Epoch 610 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6721 AR 0.9150
Epoch 610 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7289 AR 0.9250
Epoch 610 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7746 AR 1.0000
Epoch 610 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7448 AR 0.9800
Epoch 610 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8192 AR 1.0000
Epoch 610 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7314 AR 0.9000
Epoch 610 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6958 AR 0.9800
Epoch 611 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7633 AR 0.9750
Epoch 611 batch 00002: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.8025 AR 1.0000
Epoch 611 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6567 AR 0.9400
Epoch 611 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7283 AR 0.9750
Epoch 611 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6877 AR 0.9750
Epoch 611 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8133 AR 1.0000
Epoch 611 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6781 AR 0.8217
Epoch 611 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6958 AR 0.9000
Epoch 611 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6680 AR 0.8850
Epoch 611 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8056 AR 0.9750
Epoch 612 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7814 AR 0.9600
Epoch 612 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7898 AR 1.0000
Epoch 612 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.8034 AR 0.9600
Epoch 612 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.6905 AR 0.9550
Epoch 612 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5783 AR 0.9750
Epoch 612 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7183 AR 0.9000
Epoch 612 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6958 AR 0.9500
Epoch 612 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7964 AR 0.9800
Epoch 612 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7566 AR 1.0000
Epoch 612 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7238 AR 0.9750
Epoch 613 batch 00001: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6900 AR 0.8667
Epoch 613 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6400 AR 1.0000
Epoch 613 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7431 AR 1.0000
Epoch 613 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7088 AR 0.9600
Epoch 613 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7971 AR 0.9550
Epoch 613 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8236 AR 0.9500
Epoch 613 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6333 AR 0.9400
Epoch 613 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7917 AR 0.9667
Epoch 613 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7202 AR 1.0000
Epoch 613 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7846 AR 0.9800
Epoch 614 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7472 AR 0.9600
Epoch 614 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8205 AR 0.9667
Epoch 614 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7060 AR 0.9800
Epoch 614 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7883 AR 0.9500
Epoch 614 batch 00005: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6683 AR 0.8800
Epoch 614 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7750 AR 0.9750
Epoch 614 batch 00007: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6981 AR 0.9550
Epoch 614 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6644 AR 0.9000
Epoch 614 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5767 AR 0.9467
Epoch 614 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6719 AR 1.0000
Epoch 615 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6614 AR 0.9267
Epoch 615 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6817 AR 0.9750
Epoch 615 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7988 AR 0.9800
Epoch 615 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8192 AR 0.9667
Epoch 615 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5850 AR 0.9800
Epoch 615 batch 00006: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.7617 AR 0.9300
Epoch 615 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8175 AR 0.9800
Epoch 615 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7533 AR 0.8750
Epoch 615 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6923 AR 1.0000
Epoch 615 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6883 AR 1.0000
Epoch 616 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7003 AR 0.9550
Epoch 616 batch 00002: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.7083 AR 0.9550
Epoch 616 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6629 AR 0.9750
Epoch 616 batch 00004: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7442 AR 0.9417
Epoch 616 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5493 AR 0.8000
Epoch 616 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7448 AR 0.9350
Epoch 616 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6798 AR 0.9550
Epoch 616 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.9050 AR 0.9667
Epoch 616 batch 00009: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8221 AR 0.9750
Epoch 616 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6317 AR 0.9000
Epoch 617 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7676 AR 0.9550
Epoch 617 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7467 AR 0.8883
Epoch 617 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6371 AR 0.9017
Epoch 617 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5456 AR 0.9000
Epoch 617 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7500 AR 0.9800
Epoch 617 batch 00006: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7933 AR 1.0000
Epoch 617 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6225 AR 0.7750
Epoch 617 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7433 AR 1.0000
Epoch 617 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.7480 AR 0.9500
Epoch 617 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8464 AR 1.0000
Epoch 618 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7671 AR 0.9750
Epoch 618 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7598 AR 0.9550
Epoch 618 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7548 AR 0.9667
Epoch 618 batch 00004: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7167 AR 1.0000
Epoch 618 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6889 AR 0.9550
Epoch 618 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7581 AR 1.0000
Epoch 618 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8717 AR 0.9500
Epoch 618 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5619 AR 0.9800
Epoch 618 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7210 AR 0.8967
Epoch 618 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7008 AR 0.9300
Epoch 619 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6753 AR 1.0000
Epoch 619 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7517 AR 0.9750
Epoch 619 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7788 AR 1.0000
Epoch 619 batch 00004: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7111 AR 0.9800
Epoch 619 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8038 AR 0.9800
Epoch 619 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.6231 AR 0.9000
Epoch 619 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7517 AR 0.9800
Epoch 619 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7879 AR 0.9300
Epoch 619 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7955 AR 1.0000
Epoch 619 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6783 AR 0.9250
Epoch 620 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6867 AR 0.9167
Epoch 620 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6708 AR 0.9550
Epoch 620 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7598 AR 0.9550
Epoch 620 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7663 AR 1.0000
Epoch 620 batch 00005: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7683 AR 0.9800
Epoch 620 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6825 AR 0.9800
Epoch 620 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6605 AR 0.8267
Epoch 620 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6189 AR 0.9500
Epoch 620 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8098 AR 0.9500
Epoch 620 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7638 AR 0.9550
Epoch 621 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7667 AR 1.0000
Epoch 621 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8764 AR 0.9800
Epoch 621 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7750 AR 1.0000
Epoch 621 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7200 AR 0.9050
Epoch 621 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6743 AR 0.9750
Epoch 621 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6228 AR 0.8550
Epoch 621 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7233 AR 0.9550
Epoch 621 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6589 AR 0.9000
Epoch 621 batch 00009: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8283 AR 0.9750
Epoch 621 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6127 AR 0.9800
Epoch 622 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8217 AR 0.9750
Epoch 622 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6396 AR 0.8633
Epoch 622 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7550 AR 0.9750
Epoch 622 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7292 AR 0.9750
Epoch 622 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7187 AR 0.9467
Epoch 622 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7321 AR 0.9600
Epoch 622 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6855 AR 0.9000
Epoch 622 batch 00008: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7300 AR 1.0000
Epoch 622 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7117 AR 0.9750
Epoch 622 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7113 AR 1.0000
Epoch 623 batch 00001: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6679 AR 1.0000
Epoch 623 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7505 AR 1.0000
Epoch 623 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7327 AR 0.9550
Epoch 623 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6975 AR 0.9500
Epoch 623 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6013 AR 0.8417
Epoch 623 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7067 AR 0.9800
Epoch 623 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7076 AR 0.9750
Epoch 623 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6939 AR 0.9750
Epoch 623 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8423 AR 0.9800
Epoch 623 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8433 AR 0.9500
Epoch 624 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8292 AR 1.0000
Epoch 624 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7177 AR 1.0000
Epoch 624 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.8267 AR 1.0000
Epoch 624 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5317 AR 0.7167
Epoch 624 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6956 AR 1.0000
Epoch 624 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6713 AR 0.9500
Epoch 624 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7621 AR 0.9550
Epoch 624 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7389 AR 1.0000
Epoch 624 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6371 AR 0.9300
Epoch 624 batch 00010: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.7560 AR 0.9050
Epoch 625 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6971 AR 0.9000
Epoch 625 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7771 AR 0.9133
Epoch 625 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6947 AR 0.9750
Epoch 625 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8600 AR 0.9550
Epoch 625 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7300 AR 0.9750
Epoch 625 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7164 AR 0.9600
Epoch 625 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6591 AR 0.9000
Epoch 625 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6573 AR 1.0000
Epoch 625 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6089 AR 0.9500
Epoch 625 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.7375 AR 1.0000
Epoch 626 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7530 AR 0.9300
Epoch 626 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6850 AR 0.9500
Epoch 626 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7198 AR 0.9800
Epoch 626 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8917 AR 1.0000
Epoch 626 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6859 AR 0.9500
Epoch 626 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6538 AR 0.9750
Epoch 626 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8325 AR 0.9750
Epoch 626 batch 00008: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6389 AR 1.0000
Epoch 626 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7889 AR 1.0000
Epoch 626 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6858 AR 0.8617
Epoch 627 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6789 AR 0.9267
Epoch 627 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7431 AR 1.0000
Epoch 627 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7476 AR 0.9550
Epoch 627 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8183 AR 0.9500
Epoch 627 batch 00005: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7342 AR 0.9800
Epoch 627 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6655 AR 0.9500
Epoch 627 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6450 AR 0.9167
Epoch 627 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7521 AR 0.8550
Epoch 627 batch 00009: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6922 AR 0.9550
Epoch 627 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7169 AR 0.9800
Epoch 628 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6167 AR 1.0000
Epoch 628 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7448 AR 0.9800
Epoch 628 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7872 AR 0.9750
Epoch 628 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7392 AR 0.9467
Epoch 628 batch 00005: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7038 AR 0.9050
Epoch 628 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7422 AR 0.9750
Epoch 628 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6927 AR 1.0000
Epoch 628 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7027 AR 0.9467
Epoch 628 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7200 AR 0.9250
Epoch 628 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8517 AR 0.9750
Epoch 629 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7092 AR 0.9000
Epoch 629 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7433 AR 0.9750
Epoch 629 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7700 AR 0.9250
Epoch 629 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7331 AR 1.0000
Epoch 629 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7417 AR 0.9300
Epoch 629 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6620 AR 1.0000
Epoch 629 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6921 AR 1.0000
Epoch 629 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6892 AR 0.9400
Epoch 629 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7655 AR 0.9800
Epoch 629 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6589 AR 0.8750
Epoch 630 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7317 AR 0.9600
Epoch 630 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7100 AR 0.8667
Epoch 630 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6781 AR 1.0000
Epoch 630 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7967 AR 0.9750
Epoch 630 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7256 AR 0.9300
Epoch 630 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6592 AR 0.8300
Epoch 630 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6337 AR 0.8750
Epoch 630 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6523 AR 0.9050
Epoch 630 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7067 AR 0.9750
Epoch 630 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7867 AR 0.9750
Epoch 631 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6689 AR 0.9750
Epoch 631 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6328 AR 0.9500
Epoch 631 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8400 AR 0.9750
Epoch 631 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7645 AR 0.9417
Epoch 631 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7189 AR 0.9600
Epoch 631 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8030 AR 0.9800
Epoch 631 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6583 AR 0.9250
Epoch 631 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6850 AR 0.9800
Epoch 631 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7833 AR 0.9500
Epoch 631 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7371 AR 0.9500
Epoch 632 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7006 AR 0.9800
Epoch 632 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7700 AR 1.0000
Epoch 632 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7617 AR 0.9150
Epoch 632 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8292 AR 1.0000
Epoch 632 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7083 AR 1.0000
Epoch 632 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5631 AR 0.8750
Epoch 632 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7655 AR 1.0000
Epoch 632 batch 00008: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7883 AR 1.0000
Epoch 632 batch 00009: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7319 AR 0.9550
Epoch 632 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6948 AR 0.9250
Epoch 633 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5675 AR 0.9000
Epoch 633 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7505 AR 0.9550
Epoch 633 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8692 AR 1.0000
Epoch 633 batch 00004: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7434 AR 1.0000
Epoch 633 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6883 AR 0.9500
Epoch 633 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6922 AR 0.9500
Epoch 633 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7550 AR 0.9750
Epoch 633 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7727 AR 1.0000
Epoch 633 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7961 AR 0.9800
Epoch 633 batch 00010: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0002 AP 0.5983 AR 0.9300
Epoch 634 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7960 AR 1.0000
Epoch 634 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7548 AR 0.9500
Epoch 634 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7683 AR 0.9600
Epoch 634 batch 00004: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7317 AR 0.9500
Epoch 634 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6625 AR 0.9500
Epoch 634 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7381 AR 1.0000
Epoch 634 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7371 AR 0.9500
Epoch 634 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7162 AR 1.0000
Epoch 634 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7130 AR 0.9800
Epoch 634 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7255 AR 0.9467
Epoch 635 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6951 AR 0.9150
Epoch 635 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7267 AR 0.9500
Epoch 635 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7822 AR 1.0000
Epoch 635 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6176 AR 0.8583
Epoch 635 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6764 AR 0.8500
Epoch 635 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7721 AR 0.9750
Epoch 635 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8125 AR 0.9750
Epoch 635 batch 00008: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7702 AR 0.9600
Epoch 635 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5767 AR 1.0000
Epoch 635 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6975 AR 0.8800
Epoch 636 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7172 AR 0.9800
Epoch 636 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7775 AR 1.0000
Epoch 636 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7537 AR 0.9500
Epoch 636 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.9071 AR 1.0000
Epoch 636 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6292 AR 0.8750
Epoch 636 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6949 AR 1.0000
Epoch 636 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6592 AR 0.9550
Epoch 636 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7955 AR 1.0000
Epoch 636 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7017 AR 0.9667
Epoch 636 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6787 AR 0.9500
Epoch 637 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7267 AR 0.9750
Epoch 637 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6967 AR 0.9550
Epoch 637 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7439 AR 1.0000
Epoch 637 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8022 AR 0.9500
Epoch 637 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8200 AR 0.9600
Epoch 637 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5308 AR 0.7750
Epoch 637 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7528 AR 1.0000
Epoch 637 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7831 AR 0.9250
Epoch 637 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7353 AR 1.0000
Epoch 637 batch 00010: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.6566 AR 0.9267
Epoch 638 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7294 AR 1.0000
Epoch 638 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8388 AR 0.9800
Epoch 638 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8264 AR 1.0000
Epoch 638 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6819 AR 0.9500
Epoch 638 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5948 AR 0.6967
Epoch 638 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6875 AR 0.8667
Epoch 638 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7783 AR 0.9550
Epoch 638 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7743 AR 0.9550
Epoch 638 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6680 AR 1.0000
Epoch 638 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6364 AR 0.9750
Epoch 639 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6060 AR 0.9350
Epoch 639 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6939 AR 1.0000
Epoch 639 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6444 AR 0.9250
Epoch 639 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7420 AR 0.8800
Epoch 639 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7167 AR 0.9000
Epoch 639 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7733 AR 1.0000
Epoch 639 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7517 AR 1.0000
Epoch 639 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6805 AR 0.8550
Epoch 639 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7142 AR 0.9400
Epoch 639 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8005 AR 0.9750
Epoch 640 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6547 AR 0.8667
Epoch 640 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5850 AR 0.9000
Epoch 640 batch 00003: Loss 0.0015 Regression loss 0.0015 Classification loss 0.0001 AP 0.8750 AR 1.0000
Epoch 640 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7711 AR 0.9350
Epoch 640 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7560 AR 0.9750
Epoch 640 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7419 AR 0.9017
Epoch 640 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6514 AR 0.8750
Epoch 640 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7250 AR 0.9000
Epoch 640 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6820 AR 0.9750
Epoch 640 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6222 AR 0.9500
Epoch 641 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7272 AR 1.0000
Epoch 641 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7876 AR 1.0000
Epoch 641 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7003 AR 0.9300
Epoch 641 batch 00004: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7983 AR 0.9550
Epoch 641 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6905 AR 0.9550
Epoch 641 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8364 AR 1.0000
Epoch 641 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7475 AR 0.9667
Epoch 641 batch 00008: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7167 AR 0.9667
Epoch 641 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7789 AR 1.0000
Epoch 641 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5976 AR 0.9800
Epoch 642 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7433 AR 0.9500
Epoch 642 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5550 AR 0.8500
Epoch 642 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7167 AR 0.8500
Epoch 642 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7488 AR 0.9500
Epoch 642 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6771 AR 0.9800
Epoch 642 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7084 AR 0.8750
Epoch 642 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6030 AR 0.8633
Epoch 642 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7273 AR 0.9750
Epoch 642 batch 00009: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.8044 AR 0.9550
Epoch 642 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7717 AR 0.9800
Epoch 643 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6364 AR 0.9800
Epoch 643 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8072 AR 0.9750
Epoch 643 batch 00003: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.8336 AR 0.9550
Epoch 643 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7517 AR 0.9800
Epoch 643 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6762 AR 0.9250
Epoch 643 batch 00006: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7783 AR 0.9750
Epoch 643 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6683 AR 0.8250
Epoch 643 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7639 AR 1.0000
Epoch 643 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6367 AR 0.8750
Epoch 643 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6730 AR 0.9550
Epoch 644 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7445 AR 0.9550
Epoch 644 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6693 AR 0.8550
Epoch 644 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7431 AR 1.0000
Epoch 644 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6814 AR 1.0000
Epoch 644 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7156 AR 0.9000
Epoch 644 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7672 AR 1.0000
Epoch 644 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7142 AR 0.9500
Epoch 644 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7455 AR 1.0000
Epoch 644 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7245 AR 1.0000
Epoch 644 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8921 AR 0.9800
Epoch 645 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7683 AR 0.9750
Epoch 645 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7635 AR 1.0000
Epoch 645 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7008 AR 0.9417
Epoch 645 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7692 AR 0.9600
Epoch 645 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6789 AR 1.0000
Epoch 645 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6406 AR 0.8500
Epoch 645 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8414 AR 0.9750
Epoch 645 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7231 AR 0.9750
Epoch 645 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7620 AR 1.0000
Epoch 645 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7138 AR 0.9500
Epoch 646 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6856 AR 0.9500
Epoch 646 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7639 AR 1.0000
Epoch 646 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8156 AR 0.9800
Epoch 646 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6327 AR 0.9000
Epoch 646 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6817 AR 0.9300
Epoch 646 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6583 AR 0.8417
Epoch 646 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6689 AR 0.9250
Epoch 646 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7367 AR 0.9167
Epoch 646 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7838 AR 0.9800
Epoch 646 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7238 AR 0.9500
Epoch 647 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6548 AR 0.9000
Epoch 647 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7842 AR 1.0000
Epoch 647 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8037 AR 0.9800
Epoch 647 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6917 AR 0.9250
Epoch 647 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7350 AR 0.9000
Epoch 647 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7055 AR 1.0000
Epoch 647 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7689 AR 0.9750
Epoch 647 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7113 AR 0.9800
Epoch 647 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6766 AR 0.9800
Epoch 647 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6421 AR 0.7550
Epoch 648 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6339 AR 0.9417
Epoch 648 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6403 AR 0.9667
Epoch 648 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7472 AR 1.0000
Epoch 648 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6138 AR 0.9550
Epoch 648 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8181 AR 1.0000
Epoch 648 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8250 AR 1.0000
Epoch 648 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7167 AR 1.0000
Epoch 648 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6721 AR 0.8550
Epoch 648 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7439 AR 0.9500
Epoch 648 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8933 AR 1.0000
Epoch 649 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6439 AR 0.9000
Epoch 649 batch 00002: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.5302 AR 0.7100
Epoch 649 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7567 AR 0.9500
Epoch 649 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7100 AR 0.9550
Epoch 649 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7433 AR 0.9750
Epoch 649 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8130 AR 0.9500
Epoch 649 batch 00007: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.5881 AR 0.9000
Epoch 649 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7000 AR 1.0000
Epoch 649 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.8421 AR 0.9750
Epoch 649 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7322 AR 0.9467
Epoch 650 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6217 AR 0.8750
Epoch 650 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6130 AR 0.9300
Epoch 650 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7398 AR 1.0000
Epoch 650 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8070 AR 0.9417
Epoch 650 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6755 AR 1.0000
Epoch 650 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6947 AR 1.0000
Epoch 650 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7642 AR 0.9500
Epoch 650 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7231 AR 0.9300
Epoch 650 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7383 AR 0.8800
Epoch 650 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7625 AR 0.9167
Epoch 651 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7967 AR 0.9000
Epoch 651 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6933 AR 0.9750
Epoch 651 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7233 AR 0.8717
Epoch 651 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7380 AR 1.0000
Epoch 651 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7608 AR 0.9600
Epoch 651 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7056 AR 0.8750
Epoch 651 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6433 AR 1.0000
Epoch 651 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6303 AR 0.9300
Epoch 651 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5517 AR 0.7750
Epoch 651 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7638 AR 0.9750
Epoch 652 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6506 AR 0.9750
Epoch 652 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8014 AR 0.9750
Epoch 652 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7931 AR 1.0000
Epoch 652 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8050 AR 0.9667
Epoch 652 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7114 AR 0.9500
Epoch 652 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6896 AR 0.9550
Epoch 652 batch 00007: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7271 AR 0.9550
Epoch 652 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8092 AR 1.0000
Epoch 652 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7738 AR 0.9800
Epoch 652 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5481 AR 0.7750
Epoch 653 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6572 AR 0.9417
Epoch 653 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7002 AR 0.9750
Epoch 653 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6221 AR 0.8750
Epoch 653 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7184 AR 1.0000
Epoch 653 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6367 AR 0.8050
Epoch 653 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8583 AR 1.0000
Epoch 653 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6800 AR 0.9500
Epoch 653 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6958 AR 0.9000
Epoch 653 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7698 AR 1.0000
Epoch 653 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7450 AR 0.8767
Epoch 654 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6830 AR 0.9417
Epoch 654 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7388 AR 0.9800
Epoch 654 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6900 AR 0.8750
Epoch 654 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7729 AR 0.9750
Epoch 654 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8083 AR 1.0000
Epoch 654 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6683 AR 0.9750
Epoch 654 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7639 AR 0.9800
Epoch 654 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7517 AR 0.9800
Epoch 654 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6767 AR 0.7750
Epoch 654 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6870 AR 1.0000
Epoch 655 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6894 AR 1.0000
Epoch 655 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6808 AR 0.9000
Epoch 655 batch 00003: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.6656 AR 0.8550
Epoch 655 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8817 AR 1.0000
Epoch 655 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6533 AR 0.9750
Epoch 655 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6353 AR 0.7750
Epoch 655 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6433 AR 0.9750
Epoch 655 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6218 AR 0.8500
Epoch 655 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7290 AR 0.9800
Epoch 655 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8017 AR 0.9550
Epoch 656 batch 00001: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7772 AR 0.9800
Epoch 656 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8650 AR 0.9750
Epoch 656 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7338 AR 0.9750
Epoch 656 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8017 AR 1.0000
Epoch 656 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7183 AR 0.9250
Epoch 656 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6663 AR 0.9500
Epoch 656 batch 00007: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7339 AR 0.9750
Epoch 656 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6147 AR 0.9000
Epoch 656 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5112 AR 0.8417
Epoch 656 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7721 AR 0.9550
Epoch 657 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8156 AR 1.0000
Epoch 657 batch 00002: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.6192 AR 0.9050
Epoch 657 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6456 AR 0.9250
Epoch 657 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6289 AR 0.9500
Epoch 657 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8421 AR 0.9800
Epoch 657 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8720 AR 1.0000
Epoch 657 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6983 AR 0.9000
Epoch 657 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7998 AR 0.9550
Epoch 657 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6845 AR 0.9417
Epoch 657 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7117 AR 0.9550
Epoch 658 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7817 AR 0.9550
Epoch 658 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6873 AR 0.9417
Epoch 658 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7298 AR 1.0000
Epoch 658 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6883 AR 0.9500
Epoch 658 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7138 AR 0.9550
Epoch 658 batch 00006: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.8358 AR 0.9800
Epoch 658 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7317 AR 1.0000
Epoch 658 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6782 AR 0.8167
Epoch 658 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7497 AR 0.9750
Epoch 658 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6910 AR 0.9550
Epoch 659 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6317 AR 0.9600
Epoch 659 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7055 AR 0.9550
Epoch 659 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7364 AR 0.9250
Epoch 659 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6848 AR 0.9550
Epoch 659 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7763 AR 0.9550
Epoch 659 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7196 AR 0.9500
Epoch 659 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6756 AR 0.8467
Epoch 659 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5930 AR 0.7800
Epoch 659 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8505 AR 0.9417
Epoch 659 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6617 AR 0.8500
Epoch 660 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7436 AR 0.9267
Epoch 660 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7433 AR 0.9800
Epoch 660 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8125 AR 0.9750
Epoch 660 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6360 AR 1.0000
Epoch 660 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7879 AR 0.9667
Epoch 660 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7183 AR 0.9800
Epoch 660 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7206 AR 0.9500
Epoch 660 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6447 AR 0.8500
Epoch 660 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7130 AR 0.8850
Epoch 660 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6475 AR 0.8833
Epoch 661 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7706 AR 0.9500
Epoch 661 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7900 AR 1.0000
Epoch 661 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6921 AR 0.9550
Epoch 661 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7444 AR 0.9800
Epoch 661 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6922 AR 0.9000
Epoch 661 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6702 AR 0.9600
Epoch 661 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7338 AR 0.9550
Epoch 661 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6458 AR 0.8000
Epoch 661 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7564 AR 0.8750
Epoch 661 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7348 AR 1.0000
Epoch 662 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7131 AR 0.9750
Epoch 662 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7900 AR 0.9800
Epoch 662 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7192 AR 0.8800
Epoch 662 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7452 AR 1.0000
Epoch 662 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6655 AR 0.9217
Epoch 662 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6347 AR 0.9500
Epoch 662 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7260 AR 1.0000
Epoch 662 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8196 AR 1.0000
Epoch 662 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6981 AR 1.0000
Epoch 662 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7314 AR 0.8250
Epoch 663 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6248 AR 0.9500
Epoch 663 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7336 AR 0.9800
Epoch 663 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6830 AR 0.9000
Epoch 663 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6695 AR 0.9000
Epoch 663 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6783 AR 0.9500
Epoch 663 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7226 AR 0.9300
Epoch 663 batch 00007: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.8372 AR 0.9300
Epoch 663 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7733 AR 1.0000
Epoch 663 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7488 AR 0.9550
Epoch 663 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7835 AR 0.9800
Epoch 664 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7095 AR 0.9550
Epoch 664 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7514 AR 0.9550
Epoch 664 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7821 AR 0.9550
Epoch 664 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6208 AR 0.8667
Epoch 664 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8117 AR 0.9667
Epoch 664 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7156 AR 1.0000
Epoch 664 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7558 AR 0.9800
Epoch 664 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7646 AR 0.9800
Epoch 664 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7110 AR 0.8300
Epoch 664 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5788 AR 0.9050
Epoch 665 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8967 AR 0.9800
Epoch 665 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6833 AR 0.9500
Epoch 665 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7716 AR 1.0000
Epoch 665 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6419 AR 1.0000
Epoch 665 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6686 AR 0.9100
Epoch 665 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6589 AR 0.9000
Epoch 665 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7155 AR 0.9500
Epoch 665 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7067 AR 1.0000
Epoch 665 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7838 AR 0.9300
Epoch 665 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7250 AR 1.0000
Epoch 666 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6861 AR 0.9550
Epoch 666 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8321 AR 0.9500
Epoch 666 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6489 AR 0.8667
Epoch 666 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5981 AR 0.9150
Epoch 666 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7658 AR 0.9750
Epoch 666 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6118 AR 0.9500
Epoch 666 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7383 AR 0.9667
Epoch 666 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8664 AR 0.9550
Epoch 666 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8292 AR 1.0000
Epoch 666 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8383 AR 1.0000
Epoch 667 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7397 AR 1.0000
Epoch 667 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7331 AR 0.8850
Epoch 667 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7224 AR 0.9750
Epoch 667 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7533 AR 0.9667
Epoch 667 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6973 AR 0.9750
Epoch 667 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7744 AR 0.9300
Epoch 667 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8033 AR 0.9750
Epoch 667 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6117 AR 0.8667
Epoch 667 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6492 AR 0.8750
Epoch 667 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6927 AR 0.9600
Epoch 668 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7689 AR 0.9550
Epoch 668 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6449 AR 0.9467
Epoch 668 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7100 AR 0.9250
Epoch 668 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8100 AR 0.9800
Epoch 668 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8457 AR 0.9800
Epoch 668 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6423 AR 0.9000
Epoch 668 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7805 AR 0.9300
Epoch 668 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6933 AR 0.8750
Epoch 668 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6392 AR 0.9800
Epoch 668 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6058 AR 0.8500
Epoch 669 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8233 AR 0.9750
Epoch 669 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6781 AR 0.9000
Epoch 669 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7292 AR 0.9750
Epoch 669 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8495 AR 0.9600
Epoch 669 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7536 AR 0.9800
Epoch 669 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7410 AR 0.9300
Epoch 669 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7038 AR 0.9667
Epoch 669 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0002 AP 0.6050 AR 0.8300
Epoch 669 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6098 AR 0.7800
Epoch 669 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.5508 AR 0.8250
Epoch 670 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6946 AR 0.9800
Epoch 670 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8103 AR 1.0000
Epoch 670 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7970 AR 1.0000
Epoch 670 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8250 AR 0.9750
Epoch 670 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7228 AR 1.0000
Epoch 670 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6388 AR 0.9000
Epoch 670 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6933 AR 0.9800
Epoch 670 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7538 AR 0.9500
Epoch 670 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7705 AR 0.9800
Epoch 670 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7517 AR 0.9500
Epoch 671 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7478 AR 0.9417
Epoch 671 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7583 AR 0.9500
Epoch 671 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6788 AR 0.9350
Epoch 671 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8625 AR 1.0000
Epoch 671 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7425 AR 0.9750
Epoch 671 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6255 AR 0.9500
Epoch 671 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7071 AR 0.9800
Epoch 671 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7269 AR 0.9400
Epoch 671 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6317 AR 0.8000
Epoch 671 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7292 AR 0.9750
Epoch 672 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6042 AR 0.9300
Epoch 672 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8833 AR 1.0000
Epoch 672 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8464 AR 0.9750
Epoch 672 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7767 AR 0.9600
Epoch 672 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5938 AR 0.9500
Epoch 672 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8650 AR 1.0000
Epoch 672 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6514 AR 0.9417
Epoch 672 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7536 AR 0.9500
Epoch 672 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6615 AR 0.9800
Epoch 672 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7758 AR 1.0000
Epoch 673 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5331 AR 0.7000
Epoch 673 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7531 AR 0.9800
Epoch 673 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7594 AR 1.0000
Epoch 673 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6172 AR 0.8350
Epoch 673 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7050 AR 0.9750
Epoch 673 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7175 AR 0.9300
Epoch 673 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7875 AR 0.9500
Epoch 673 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6871 AR 0.9550
Epoch 673 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5630 AR 0.8750
Epoch 673 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8881 AR 1.0000
Epoch 674 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7452 AR 0.9800
Epoch 674 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7100 AR 1.0000
Epoch 674 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6939 AR 0.9800
Epoch 674 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6400 AR 1.0000
Epoch 674 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8155 AR 0.9750
Epoch 674 batch 00006: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0002 AP 0.5880 AR 0.9000
Epoch 674 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7600 AR 0.9250
Epoch 674 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8050 AR 0.9167
Epoch 674 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7467 AR 0.8467
Epoch 674 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6588 AR 0.9300
Epoch 675 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8500 AR 0.9750
Epoch 675 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7433 AR 0.9800
Epoch 675 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7237 AR 1.0000
Epoch 675 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7037 AR 0.9750
Epoch 675 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7933 AR 1.0000
Epoch 675 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6492 AR 0.9250
Epoch 675 batch 00007: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7373 AR 0.9800
Epoch 675 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5567 AR 0.7500
Epoch 675 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6616 AR 0.9550
Epoch 675 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7388 AR 0.8600
Epoch 676 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7100 AR 0.9667
Epoch 676 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7967 AR 0.9550
Epoch 676 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7341 AR 1.0000
Epoch 676 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7448 AR 1.0000
Epoch 676 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7764 AR 0.9500
Epoch 676 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6302 AR 0.8800
Epoch 676 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8325 AR 0.9800
Epoch 676 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7505 AR 0.9750
Epoch 676 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6496 AR 0.9800
Epoch 676 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6971 AR 0.9550
Epoch 677 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6428 AR 0.9017
Epoch 677 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7194 AR 0.9800
Epoch 677 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6383 AR 0.8550
Epoch 677 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7475 AR 0.9800
Epoch 677 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8314 AR 0.9500
Epoch 677 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6338 AR 0.9800
Epoch 677 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8608 AR 1.0000
Epoch 677 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6983 AR 0.9750
Epoch 677 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7692 AR 0.9750
Epoch 677 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6925 AR 1.0000
Epoch 678 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7060 AR 0.9050
Epoch 678 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6781 AR 0.9800
Epoch 678 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7564 AR 0.8750
Epoch 678 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8550 AR 0.9800
Epoch 678 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7171 AR 0.9550
Epoch 678 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6519 AR 0.9550
Epoch 678 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7467 AR 1.0000
Epoch 678 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7350 AR 0.9667
Epoch 678 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6763 AR 0.9000
Epoch 678 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6542 AR 0.9000
Epoch 679 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6950 AR 1.0000
Epoch 679 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6588 AR 0.9800
Epoch 679 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7067 AR 0.8800
Epoch 679 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7275 AR 0.8750
Epoch 679 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7383 AR 0.9050
Epoch 679 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8119 AR 0.9800
Epoch 679 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7792 AR 0.9750
Epoch 679 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6694 AR 0.9800
Epoch 679 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7948 AR 0.9750
Epoch 679 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6362 AR 0.8500
Epoch 680 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7448 AR 0.9750
Epoch 680 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7550 AR 0.9800
Epoch 680 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7592 AR 1.0000
Epoch 680 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6709 AR 1.0000
Epoch 680 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8017 AR 0.9500
Epoch 680 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6769 AR 1.0000
Epoch 680 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8455 AR 0.9300
Epoch 680 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7520 AR 0.9550
Epoch 680 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6350 AR 0.8800
Epoch 680 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6283 AR 0.8750
Epoch 681 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5817 AR 0.8300
Epoch 681 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6419 AR 0.9800
Epoch 681 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8200 AR 1.0000
Epoch 681 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8321 AR 0.9550
Epoch 681 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6552 AR 0.8500
Epoch 681 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7800 AR 0.9800
Epoch 681 batch 00007: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.6933 AR 0.8800
Epoch 681 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7022 AR 0.9500
Epoch 681 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7477 AR 0.9550
Epoch 681 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7122 AR 0.9467
Epoch 682 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6694 AR 0.9250
Epoch 682 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7601 AR 0.8950
Epoch 682 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8155 AR 1.0000
Epoch 682 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6817 AR 0.8667
Epoch 682 batch 00005: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.6350 AR 0.9000
Epoch 682 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8221 AR 0.9750
Epoch 682 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7108 AR 0.9000
Epoch 682 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5802 AR 0.8600
Epoch 682 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6769 AR 0.9167
Epoch 682 batch 00010: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7261 AR 0.9800
Epoch 683 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7396 AR 0.9550
Epoch 683 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6477 AR 0.8800
Epoch 683 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6619 AR 0.9000
Epoch 683 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6817 AR 0.8133
Epoch 683 batch 00005: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7360 AR 1.0000
Epoch 683 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7739 AR 1.0000
Epoch 683 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8267 AR 1.0000
Epoch 683 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6864 AR 0.9550
Epoch 683 batch 00009: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7721 AR 0.8850
Epoch 683 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7517 AR 0.9750
Epoch 684 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6908 AR 0.9750
Epoch 684 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6875 AR 0.9750
Epoch 684 batch 00003: Loss 0.0015 Regression loss 0.0015 Classification loss 0.0001 AP 0.7933 AR 0.9667
Epoch 684 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7198 AR 0.9600
Epoch 684 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8330 AR 1.0000
Epoch 684 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6319 AR 0.9000
Epoch 684 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8037 AR 0.9750
Epoch 684 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7538 AR 0.9600
Epoch 684 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8100 AR 0.9800
Epoch 684 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7239 AR 0.9750
Epoch 685 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7381 AR 1.0000
Epoch 685 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6866 AR 0.9550
Epoch 685 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8564 AR 1.0000
Epoch 685 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6294 AR 0.7800
Epoch 685 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6800 AR 0.9750
Epoch 685 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6267 AR 0.7300
Epoch 685 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7198 AR 1.0000
Epoch 685 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8122 AR 1.0000
Epoch 685 batch 00009: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7417 AR 0.9800
Epoch 685 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6675 AR 0.9750
Epoch 686 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6953 AR 0.9550
Epoch 686 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7550 AR 0.9667
Epoch 686 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6180 AR 0.8800
Epoch 686 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7655 AR 1.0000
Epoch 686 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7117 AR 0.9000
Epoch 686 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5948 AR 0.8300
Epoch 686 batch 00007: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7581 AR 0.9550
Epoch 686 batch 00008: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7987 AR 0.9800
Epoch 686 batch 00009: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7269 AR 0.9550
Epoch 686 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7355 AR 1.0000
Epoch 687 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7833 AR 1.0000
Epoch 687 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7333 AR 0.9750
Epoch 687 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7372 AR 0.9800
Epoch 687 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6233 AR 0.9000
Epoch 687 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7855 AR 0.9300
Epoch 687 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6207 AR 0.9667
Epoch 687 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8781 AR 0.9800
Epoch 687 batch 00008: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.6781 AR 0.9050
Epoch 687 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6168 AR 0.8550
Epoch 687 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7788 AR 1.0000
Epoch 688 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7330 AR 0.9800
Epoch 688 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8033 AR 1.0000
Epoch 688 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6845 AR 0.9750
Epoch 688 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7043 AR 0.9800
Epoch 688 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6772 AR 0.8800
Epoch 688 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7683 AR 1.0000
Epoch 688 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5633 AR 0.9100
Epoch 688 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7169 AR 0.9417
Epoch 688 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8405 AR 0.9800
Epoch 688 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8633 AR 0.9800
Epoch 689 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8806 AR 1.0000
Epoch 689 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8267 AR 1.0000
Epoch 689 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6621 AR 0.9200
Epoch 689 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6102 AR 0.8667
Epoch 689 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6500 AR 0.9000
Epoch 689 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6400 AR 0.8400
Epoch 689 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.4989 AR 0.8600
Epoch 689 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7261 AR 0.9550
Epoch 689 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7950 AR 0.9750
Epoch 689 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7267 AR 0.9500
Epoch 690 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7633 AR 1.0000
Epoch 690 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6948 AR 0.8800
Epoch 690 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6817 AR 0.8750
Epoch 690 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7561 AR 0.9800
Epoch 690 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6276 AR 0.9167
Epoch 690 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5996 AR 0.7967
Epoch 690 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6389 AR 0.9750
Epoch 690 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8496 AR 1.0000
Epoch 690 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6750 AR 1.0000
Epoch 690 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7062 AR 0.8817
Epoch 691 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8183 AR 0.9550
Epoch 691 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6569 AR 0.9750
Epoch 691 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6755 AR 0.8500
Epoch 691 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7714 AR 0.9000
Epoch 691 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7133 AR 0.9667
Epoch 691 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7206 AR 0.9550
Epoch 691 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7172 AR 0.9600
Epoch 691 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6321 AR 0.9050
Epoch 691 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6008 AR 0.8000
Epoch 691 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7998 AR 1.0000
Epoch 692 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7275 AR 1.0000
Epoch 692 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7064 AR 1.0000
Epoch 692 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7892 AR 0.9800
Epoch 692 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7417 AR 0.9550
Epoch 692 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6281 AR 0.9217
Epoch 692 batch 00006: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0002 AP 0.7583 AR 0.8800
Epoch 692 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6386 AR 0.9750
Epoch 692 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7621 AR 0.9800
Epoch 692 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8069 AR 0.9800
Epoch 692 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5467 AR 0.7667
Epoch 693 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8767 AR 1.0000
Epoch 693 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7842 AR 0.9750
Epoch 693 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6726 AR 0.9100
Epoch 693 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7981 AR 0.9800
Epoch 693 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7167 AR 1.0000
Epoch 693 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7264 AR 0.9800
Epoch 693 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6055 AR 0.7833
Epoch 693 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6433 AR 0.9250
Epoch 693 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6380 AR 0.8883
Epoch 693 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7005 AR 0.9550
Epoch 694 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7031 AR 0.9800
Epoch 694 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6506 AR 0.9417
Epoch 694 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7683 AR 1.0000
Epoch 694 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6535 AR 0.8600
Epoch 694 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7339 AR 0.9000
Epoch 694 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7655 AR 1.0000
Epoch 694 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7263 AR 0.9667
Epoch 694 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7825 AR 0.9750
Epoch 694 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5733 AR 0.8800
Epoch 694 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7647 AR 0.9550
Epoch 695 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6583 AR 1.0000
Epoch 695 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7461 AR 0.9750
Epoch 695 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8028 AR 0.9800
Epoch 695 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8292 AR 1.0000
Epoch 695 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6783 AR 0.9000
Epoch 695 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7600 AR 0.9800
Epoch 695 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7833 AR 0.9000
Epoch 695 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6422 AR 0.9550
Epoch 695 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7480 AR 0.9800
Epoch 695 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7183 AR 0.9417
Epoch 696 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6668 AR 0.9800
Epoch 696 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7281 AR 1.0000
Epoch 696 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7544 AR 0.9800
Epoch 696 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7900 AR 1.0000
Epoch 696 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7380 AR 0.9350
Epoch 696 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7481 AR 0.9800
Epoch 696 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7441 AR 1.0000
Epoch 696 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.5742 AR 0.8250
Epoch 696 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8881 AR 1.0000
Epoch 696 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6067 AR 0.8000
Epoch 697 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7255 AR 0.9550
Epoch 697 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6251 AR 0.9167
Epoch 697 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7081 AR 0.9000
Epoch 697 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7958 AR 1.0000
Epoch 697 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6505 AR 1.0000
Epoch 697 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7361 AR 0.9750
Epoch 697 batch 00007: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6833 AR 0.8500
Epoch 697 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8417 AR 0.9800
Epoch 697 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7789 AR 0.9800
Epoch 697 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7289 AR 0.9550
Epoch 698 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7488 AR 0.9667
Epoch 698 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6561 AR 0.8550
Epoch 698 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7600 AR 0.9600
Epoch 698 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6856 AR 0.9000
Epoch 698 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6573 AR 0.8967
Epoch 698 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6533 AR 0.9750
Epoch 698 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.9000 AR 0.9750
Epoch 698 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7031 AR 1.0000
Epoch 698 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6905 AR 0.9000
Epoch 698 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6618 AR 0.9300
Epoch 699 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7006 AR 0.8833
Epoch 699 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6319 AR 0.9750
Epoch 699 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5648 AR 0.9750
Epoch 699 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8221 AR 0.9300
Epoch 699 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6667 AR 0.8750
Epoch 699 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7099 AR 0.9600
Epoch 699 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7300 AR 0.7800
Epoch 699 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7238 AR 1.0000
Epoch 699 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7817 AR 0.9750
Epoch 699 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7085 AR 0.9600
Epoch 700 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7525 AR 0.8800
Epoch 700 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6283 AR 0.8550
Epoch 700 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7203 AR 1.0000
Epoch 700 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7621 AR 0.9600
Epoch 700 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7613 AR 1.0000
Epoch 700 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7093 AR 0.9300
Epoch 700 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7030 AR 0.9750
Epoch 700 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6250 AR 0.9667
Epoch 700 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7321 AR 0.9050
Epoch 700 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7256 AR 1.0000
Epoch 701 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7304 AR 0.9600
Epoch 701 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7380 AR 0.9750
Epoch 701 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7142 AR 0.9750
Epoch 701 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7731 AR 1.0000
Epoch 701 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6456 AR 0.7750
Epoch 701 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8633 AR 0.9667
Epoch 701 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6979 AR 0.9750
Epoch 701 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7246 AR 0.9800
Epoch 701 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5700 AR 0.9000
Epoch 701 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6370 AR 0.8550
Epoch 702 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7775 AR 0.9000
Epoch 702 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6793 AR 0.8600
Epoch 702 batch 00003: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6864 AR 0.9000
Epoch 702 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7362 AR 0.9667
Epoch 702 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6048 AR 0.9667
Epoch 702 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6287 AR 0.9000
Epoch 702 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7581 AR 0.9550
Epoch 702 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5772 AR 0.8750
Epoch 702 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7083 AR 1.0000
Epoch 702 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.9238 AR 0.9800
Epoch 703 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8250 AR 0.9750
Epoch 703 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6542 AR 0.8000
Epoch 703 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7633 AR 1.0000
Epoch 703 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7050 AR 0.9350
Epoch 703 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7197 AR 1.0000
Epoch 703 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6656 AR 0.9500
Epoch 703 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6935 AR 1.0000
Epoch 703 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6831 AR 0.9600
Epoch 703 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7314 AR 0.9550
Epoch 703 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7731 AR 1.0000
Epoch 704 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7883 AR 0.9800
Epoch 704 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6595 AR 1.0000
Epoch 704 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7521 AR 0.9300
Epoch 704 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7163 AR 0.9800
Epoch 704 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8375 AR 1.0000
Epoch 704 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6564 AR 0.8750
Epoch 704 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6581 AR 0.9000
Epoch 704 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6700 AR 1.0000
Epoch 704 batch 00009: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7452 AR 0.9250
Epoch 704 batch 00010: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.6841 AR 0.8467
Epoch 705 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8883 AR 1.0000
Epoch 705 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7089 AR 0.9800
Epoch 705 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6925 AR 0.9667
Epoch 705 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7822 AR 1.0000
Epoch 705 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7000 AR 0.9000
Epoch 705 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6852 AR 0.8550
Epoch 705 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6667 AR 0.9750
Epoch 705 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7600 AR 0.9800
Epoch 705 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6946 AR 0.9550
Epoch 705 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6817 AR 0.9000
Epoch 706 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6496 AR 0.8800
Epoch 706 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6780 AR 0.9417
Epoch 706 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6938 AR 1.0000
Epoch 706 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8000 AR 0.9750
Epoch 706 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6717 AR 0.9800
Epoch 706 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6357 AR 0.8800
Epoch 706 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8711 AR 0.9800
Epoch 706 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7725 AR 0.9500
Epoch 706 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7761 AR 0.9250
Epoch 706 batch 00010: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7098 AR 0.9600
Epoch 707 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6551 AR 0.9350
Epoch 707 batch 00002: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.9267 AR 0.9750
Epoch 707 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7811 AR 1.0000
Epoch 707 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7767 AR 0.9750
Epoch 707 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6142 AR 0.9000
Epoch 707 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6906 AR 0.8800
Epoch 707 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7889 AR 1.0000
Epoch 707 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5860 AR 0.8833
Epoch 707 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6905 AR 0.9500
Epoch 707 batch 00010: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.6455 AR 0.8650
Epoch 708 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7706 AR 1.0000
Epoch 708 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7475 AR 0.9750
Epoch 708 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7250 AR 0.9400
Epoch 708 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8022 AR 0.9750
Epoch 708 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6622 AR 0.8800
Epoch 708 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6261 AR 0.9550
Epoch 708 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7713 AR 1.0000
Epoch 708 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7500 AR 0.9500
Epoch 708 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6700 AR 0.9500
Epoch 708 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7531 AR 0.8667
Epoch 709 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7595 AR 0.9500
Epoch 709 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7456 AR 1.0000
Epoch 709 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6083 AR 0.8417
Epoch 709 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.8225 AR 0.9750
Epoch 709 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7167 AR 0.9267
Epoch 709 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6720 AR 0.9750
Epoch 709 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7488 AR 0.9800
Epoch 709 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6425 AR 0.9000
Epoch 709 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6016 AR 0.8350
Epoch 709 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8003 AR 1.0000
Epoch 710 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6613 AR 0.9467
Epoch 710 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6983 AR 1.0000
Epoch 710 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7696 AR 0.9550
Epoch 710 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7175 AR 0.9550
Epoch 710 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8400 AR 0.9750
Epoch 710 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8150 AR 0.9800
Epoch 710 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6233 AR 0.8000
Epoch 710 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6561 AR 0.7883
Epoch 710 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7064 AR 0.9500
Epoch 710 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6005 AR 1.0000
Epoch 711 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6962 AR 0.9800
Epoch 711 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6418 AR 0.8150
Epoch 711 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7217 AR 0.9800
Epoch 711 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7428 AR 0.9550
Epoch 711 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8333 AR 0.9750
Epoch 711 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6781 AR 0.9417
Epoch 711 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7292 AR 0.9500
Epoch 711 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7171 AR 0.9500
Epoch 711 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6981 AR 0.8800
Epoch 711 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7131 AR 1.0000
Epoch 712 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7317 AR 1.0000
Epoch 712 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6414 AR 0.8750
Epoch 712 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.6233 AR 0.8750
Epoch 712 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7022 AR 0.9100
Epoch 712 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7567 AR 1.0000
Epoch 712 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6806 AR 0.9800
Epoch 712 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7348 AR 0.9417
Epoch 712 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7267 AR 0.9000
Epoch 712 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7364 AR 0.9300
Epoch 712 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6905 AR 0.8800
Epoch 713 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6208 AR 0.8750
Epoch 713 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7506 AR 0.9750
Epoch 713 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7667 AR 0.9800
Epoch 713 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7405 AR 0.9750
Epoch 713 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7333 AR 0.9417
Epoch 713 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7571 AR 0.9550
Epoch 713 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7314 AR 1.0000
Epoch 713 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7438 AR 0.9600
Epoch 713 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7399 AR 0.9600
Epoch 713 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7361 AR 0.9800
Epoch 714 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7756 AR 0.9550
Epoch 714 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6233 AR 0.8350
Epoch 714 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7350 AR 0.9250
Epoch 714 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7458 AR 0.9750
Epoch 714 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7533 AR 0.9750
Epoch 714 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7179 AR 0.9800
Epoch 714 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7150 AR 0.9300
Epoch 714 batch 00008: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.5296 AR 0.7333
Epoch 714 batch 00009: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8006 AR 0.9417
Epoch 714 batch 00010: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6353 AR 1.0000
Epoch 715 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7838 AR 0.9750
Epoch 715 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7867 AR 0.9800
Epoch 715 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7671 AR 1.0000
Epoch 715 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7250 AR 0.9800
Epoch 715 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7322 AR 0.9667
Epoch 715 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6455 AR 0.9500
Epoch 715 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6679 AR 0.8750
Epoch 715 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7256 AR 0.9550
Epoch 715 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7253 AR 0.9300
Epoch 715 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7783 AR 0.9800
Epoch 716 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7546 AR 0.9750
Epoch 716 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7425 AR 0.9000
Epoch 716 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8459 AR 0.9800
Epoch 716 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7567 AR 0.9750
Epoch 716 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6750 AR 1.0000
Epoch 716 batch 00006: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8100 AR 0.9500
Epoch 716 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7567 AR 0.9750
Epoch 716 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6500 AR 0.9417
Epoch 716 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7031 AR 0.9550
Epoch 716 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6625 AR 0.9400
Epoch 717 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7394 AR 0.9600
Epoch 717 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6771 AR 0.9667
Epoch 717 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6939 AR 0.8800
Epoch 717 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7863 AR 0.9667
Epoch 717 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7378 AR 0.9467
Epoch 717 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7467 AR 1.0000
Epoch 717 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7781 AR 0.9600
Epoch 717 batch 00008: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6883 AR 0.9550
Epoch 717 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6517 AR 0.8750
Epoch 717 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6400 AR 0.8500
Epoch 718 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8458 AR 1.0000
Epoch 718 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7310 AR 0.9600
Epoch 718 batch 00003: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6925 AR 0.8600
Epoch 718 batch 00004: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0001 AP 0.7000 AR 1.0000
Epoch 718 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6388 AR 0.8967
Epoch 718 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7631 AR 0.9750
Epoch 718 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6694 AR 0.9167
Epoch 718 batch 00008: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6906 AR 0.9550
Epoch 718 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6398 AR 0.9000
Epoch 718 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8417 AR 0.9750
Epoch 719 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6871 AR 0.9000
Epoch 719 batch 00002: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6964 AR 0.9750
Epoch 719 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5433 AR 0.7250
Epoch 719 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6917 AR 1.0000
Epoch 719 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7675 AR 1.0000
Epoch 719 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7662 AR 0.9550
Epoch 719 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.8148 AR 1.0000
Epoch 719 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7841 AR 1.0000
Epoch 719 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7117 AR 0.9800
Epoch 719 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7800 AR 1.0000
Epoch 720 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7433 AR 0.9550
Epoch 720 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7881 AR 1.0000
Epoch 720 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8356 AR 1.0000
Epoch 720 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5871 AR 0.8600
Epoch 720 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7594 AR 0.9800
Epoch 720 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5743 AR 0.9050
Epoch 720 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6835 AR 1.0000
Epoch 720 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7300 AR 0.9550
Epoch 720 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7450 AR 0.9500
Epoch 720 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7651 AR 0.9750
Epoch 721 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7260 AR 0.9250
Epoch 721 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7383 AR 0.9500
Epoch 721 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7081 AR 0.9300
Epoch 721 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8164 AR 1.0000
Epoch 721 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7283 AR 0.9333
Epoch 721 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7467 AR 0.9000
Epoch 721 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7277 AR 0.9550
Epoch 721 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6983 AR 0.9600
Epoch 721 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7025 AR 0.9800
Epoch 721 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7472 AR 0.9750
Epoch 722 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7667 AR 0.9267
Epoch 722 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7950 AR 0.9800
Epoch 722 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6850 AR 0.8750
Epoch 722 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6500 AR 0.8650
Epoch 722 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7367 AR 0.9750
Epoch 722 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6675 AR 0.9500
Epoch 722 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7371 AR 0.9667
Epoch 722 batch 00008: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.7131 AR 0.9000
Epoch 722 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6945 AR 0.9600
Epoch 722 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6995 AR 1.0000
Epoch 723 batch 00001: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7017 AR 0.9500
Epoch 723 batch 00002: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.6998 AR 0.9800
Epoch 723 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8667 AR 0.9800
Epoch 723 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7183 AR 0.9750
Epoch 723 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7007 AR 0.9800
Epoch 723 batch 00006: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.8437 AR 1.0000
Epoch 723 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7971 AR 0.9800
Epoch 723 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7182 AR 0.9750
Epoch 723 batch 00009: Loss 0.0016 Regression loss 0.0016 Classification loss 0.0001 AP 0.6933 AR 0.9250
Epoch 723 batch 00010: Loss 0.0024 Regression loss 0.0023 Classification loss 0.0001 AP 0.6183 AR 0.8967
Epoch 724 batch 00001: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0001 AP 0.8348 AR 0.9750
Epoch 724 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7044 AR 0.8800
Epoch 724 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7617 AR 0.9750
Epoch 724 batch 00004: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7400 AR 0.9467
Epoch 724 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6435 AR 0.9600
Epoch 724 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7205 AR 1.0000
Epoch 724 batch 00007: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.6996 AR 0.9600
Epoch 724 batch 00008: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7280 AR 0.9300
Epoch 724 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.8197 AR 1.0000
Epoch 724 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6638 AR 0.9250
Epoch 725 batch 00001: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.7117 AR 0.9000
Epoch 725 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7850 AR 1.0000
Epoch 725 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7595 AR 0.9300
Epoch 725 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6983 AR 0.9750
Epoch 725 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7106 AR 0.9100
Epoch 725 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8328 AR 1.0000
Epoch 725 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6458 AR 0.9800
Epoch 725 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6100 AR 0.9333
Epoch 725 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7225 AR 0.8800
Epoch 725 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8167 AR 0.9800
Epoch 726 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8321 AR 0.9750
Epoch 726 batch 00002: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.8452 AR 1.0000
Epoch 726 batch 00003: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6921 AR 0.8800
Epoch 726 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7161 AR 0.9667
Epoch 726 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7028 AR 0.9800
Epoch 726 batch 00006: Loss 0.0017 Regression loss 0.0017 Classification loss 0.0001 AP 0.7345 AR 1.0000
Epoch 726 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6667 AR 0.9250
Epoch 726 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6676 AR 0.9150
Epoch 726 batch 00009: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7298 AR 0.9350
Epoch 726 batch 00010: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0001 AP 0.6728 AR 0.9750
Epoch 727 batch 00001: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.6719 AR 0.9800
Epoch 727 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6705 AR 0.9400
Epoch 727 batch 00003: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6271 AR 0.9500
Epoch 727 batch 00004: Loss 0.0024 Regression loss 0.0023 Classification loss 0.0001 AP 0.7396 AR 0.9550
Epoch 727 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7281 AR 0.9333
Epoch 727 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7438 AR 0.9550
Epoch 727 batch 00007: Loss 0.0026 Regression loss 0.0025 Classification loss 0.0001 AP 0.7500 AR 1.0000
Epoch 727 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7881 AR 0.9500
Epoch 727 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7738 AR 0.9750
Epoch 727 batch 00010: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.8067 AR 0.9800
Epoch 728 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7467 AR 0.8900
Epoch 728 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6133 AR 0.9000
Epoch 728 batch 00003: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.7721 AR 1.0000
Epoch 728 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7017 AR 0.9217
Epoch 728 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6896 AR 0.9750
Epoch 728 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7546 AR 0.9550
Epoch 728 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7067 AR 0.9350
Epoch 728 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8167 AR 1.0000
Epoch 728 batch 00009: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6967 AR 0.9800
Epoch 728 batch 00010: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0001 AP 0.7583 AR 0.9417
Epoch 729 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8417 AR 1.0000
Epoch 729 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6525 AR 0.8600
Epoch 729 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7408 AR 0.9750
Epoch 729 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6576 AR 0.9300
Epoch 729 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7425 AR 0.9800
Epoch 729 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7175 AR 0.8800
Epoch 729 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7321 AR 0.9750
Epoch 729 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7417 AR 0.9600
Epoch 729 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6848 AR 0.9800
Epoch 729 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8072 AR 1.0000
Epoch 730 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7642 AR 0.9550
Epoch 730 batch 00002: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7317 AR 0.8717
Epoch 730 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8131 AR 1.0000
Epoch 730 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6664 AR 0.9750
Epoch 730 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6583 AR 0.9800
Epoch 730 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6677 AR 0.8800
Epoch 730 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7295 AR 0.9750
Epoch 730 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7046 AR 0.8800
Epoch 730 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7094 AR 1.0000
Epoch 730 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8100 AR 0.9550
Epoch 731 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6955 AR 0.9500
Epoch 731 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6189 AR 0.8133
Epoch 731 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5710 AR 0.7750
Epoch 731 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7380 AR 0.9750
Epoch 731 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7258 AR 0.9100
Epoch 731 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7131 AR 1.0000
Epoch 731 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7958 AR 1.0000
Epoch 731 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6953 AR 0.9600
Epoch 731 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7383 AR 0.9000
Epoch 731 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8133 AR 1.0000
Epoch 732 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7639 AR 0.9467
Epoch 732 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6458 AR 0.9750
Epoch 732 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7355 AR 0.9217
Epoch 732 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8067 AR 0.9500
Epoch 732 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6171 AR 0.8000
Epoch 732 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.8121 AR 1.0000
Epoch 732 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6683 AR 0.8550
Epoch 732 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6961 AR 0.9800
Epoch 732 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7475 AR 1.0000
Epoch 732 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7083 AR 0.9800
Epoch 733 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7603 AR 0.9750
Epoch 733 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6694 AR 0.9300
Epoch 733 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7567 AR 0.8600
Epoch 733 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5642 AR 0.8500
Epoch 733 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6721 AR 0.9550
Epoch 733 batch 00006: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8800 AR 1.0000
Epoch 733 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5893 AR 0.9267
Epoch 733 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7546 AR 0.9667
Epoch 733 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6983 AR 1.0000
Epoch 733 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.8267 AR 0.9750
Epoch 734 batch 00001: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7442 AR 0.9800
Epoch 734 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7844 AR 1.0000
Epoch 734 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6996 AR 0.9800
Epoch 734 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.8064 AR 0.9000
Epoch 734 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6526 AR 0.9800
Epoch 734 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7000 AR 0.9550
Epoch 734 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6988 AR 0.9500
Epoch 734 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7889 AR 1.0000
Epoch 734 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6250 AR 0.9000
Epoch 734 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6992 AR 0.9150
Epoch 735 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7497 AR 0.9800
Epoch 735 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6406 AR 0.9000
Epoch 735 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6783 AR 0.8800
Epoch 735 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.8117 AR 1.0000
Epoch 735 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7305 AR 0.9600
Epoch 735 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6733 AR 1.0000
Epoch 735 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7814 AR 1.0000
Epoch 735 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6685 AR 1.0000
Epoch 735 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8881 AR 0.9750
Epoch 735 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.5948 AR 0.7350
Epoch 736 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6914 AR 0.9333
Epoch 736 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7537 AR 0.9500
Epoch 736 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7667 AR 0.9550
Epoch 736 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6945 AR 0.9550
Epoch 736 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7800 AR 1.0000
Epoch 736 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7271 AR 1.0000
Epoch 736 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6628 AR 1.0000
Epoch 736 batch 00008: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7683 AR 1.0000
Epoch 736 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7517 AR 0.9750
Epoch 736 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7576 AR 0.8800
Epoch 737 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6625 AR 0.9750
Epoch 737 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6172 AR 0.8417
Epoch 737 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7943 AR 0.9800
Epoch 737 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6106 AR 0.9667
Epoch 737 batch 00005: Loss 0.0014 Regression loss 0.0014 Classification loss 0.0001 AP 0.7492 AR 0.9000
Epoch 737 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7189 AR 0.9550
Epoch 737 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8600 AR 1.0000
Epoch 737 batch 00008: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.8417 AR 1.0000
Epoch 737 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6859 AR 0.9300
Epoch 737 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6564 AR 0.9800
Epoch 738 batch 00001: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0001 AP 0.7363 AR 1.0000
Epoch 738 batch 00002: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.5600 AR 0.9300
Epoch 738 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7148 AR 1.0000
Epoch 738 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7572 AR 0.9750
Epoch 738 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.5483 AR 0.8400
Epoch 738 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8383 AR 0.9500
Epoch 738 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5917 AR 0.9667
Epoch 738 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7200 AR 0.8750
Epoch 738 batch 00009: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.7333 AR 0.8750
Epoch 738 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7202 AR 0.9350
Epoch 739 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7300 AR 0.9000
Epoch 739 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7705 AR 0.9800
Epoch 739 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7571 AR 0.9600
Epoch 739 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7542 AR 0.9000
Epoch 739 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7069 AR 0.9550
Epoch 739 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7125 AR 0.9800
Epoch 739 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6722 AR 0.8667
Epoch 739 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6817 AR 0.9600
Epoch 739 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7067 AR 1.0000
Epoch 739 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6930 AR 0.9350
Epoch 740 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7717 AR 0.9800
Epoch 740 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6333 AR 0.8500
Epoch 740 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7372 AR 1.0000
Epoch 740 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7796 AR 1.0000
Epoch 740 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7661 AR 0.9350
Epoch 740 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7200 AR 0.9667
Epoch 740 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8033 AR 0.9800
Epoch 740 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7068 AR 0.9600
Epoch 740 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5202 AR 0.8417
Epoch 740 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6933 AR 0.9750
Epoch 741 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7227 AR 1.0000
Epoch 741 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7233 AR 0.8800
Epoch 741 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7345 AR 1.0000
Epoch 741 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7310 AR 0.9800
Epoch 741 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7017 AR 0.8550
Epoch 741 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8867 AR 0.9800
Epoch 741 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6671 AR 0.8750
Epoch 741 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6333 AR 0.9167
Epoch 741 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6433 AR 0.9600
Epoch 741 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7038 AR 0.9800
Epoch 742 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7627 AR 0.9750
Epoch 742 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6446 AR 1.0000
Epoch 742 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6871 AR 0.8933
Epoch 742 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7881 AR 0.9750
Epoch 742 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6100 AR 0.8750
Epoch 742 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6778 AR 0.9400
Epoch 742 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8000 AR 0.9300
Epoch 742 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7538 AR 0.9800
Epoch 742 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7680 AR 1.0000
Epoch 742 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7406 AR 0.9750
Epoch 743 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7067 AR 0.9000
Epoch 743 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6860 AR 0.9300
Epoch 743 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6136 AR 0.9000
Epoch 743 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7767 AR 0.9800
Epoch 743 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8546 AR 1.0000
Epoch 743 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6967 AR 1.0000
Epoch 743 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7395 AR 0.9500
Epoch 743 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7000 AR 1.0000
Epoch 743 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6443 AR 0.9267
Epoch 743 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6017 AR 0.7550
Epoch 744 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6465 AR 0.9600
Epoch 744 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7183 AR 0.9167
Epoch 744 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7058 AR 0.9300
Epoch 744 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8105 AR 0.9500
Epoch 744 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6892 AR 0.8600
Epoch 744 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6414 AR 0.9667
Epoch 744 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6239 AR 0.8800
Epoch 744 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6875 AR 0.8750
Epoch 744 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7750 AR 0.9500
Epoch 744 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7646 AR 0.9800
Epoch 745 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6225 AR 0.9550
Epoch 745 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7071 AR 0.8500
Epoch 745 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7448 AR 0.9550
Epoch 745 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7722 AR 0.9333
Epoch 745 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7250 AR 0.9800
Epoch 745 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6735 AR 1.0000
Epoch 745 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6744 AR 0.8800
Epoch 745 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7133 AR 0.7900
Epoch 745 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8350 AR 1.0000
Epoch 745 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6942 AR 0.9550
Epoch 746 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7021 AR 0.9400
Epoch 746 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6771 AR 0.9050
Epoch 746 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7656 AR 1.0000
Epoch 746 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7200 AR 0.8750
Epoch 746 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7075 AR 0.9417
Epoch 746 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6231 AR 0.8750
Epoch 746 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7950 AR 0.9600
Epoch 746 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7961 AR 1.0000
Epoch 746 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5752 AR 1.0000
Epoch 746 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8567 AR 0.9550
Epoch 747 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6863 AR 0.9267
Epoch 747 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7483 AR 0.9250
Epoch 747 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7755 AR 0.9800
Epoch 747 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7333 AR 0.9800
Epoch 747 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7221 AR 1.0000
Epoch 747 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7008 AR 0.9750
Epoch 747 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7006 AR 0.9800
Epoch 747 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6272 AR 0.9600
Epoch 747 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8606 AR 1.0000
Epoch 747 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8183 AR 0.9750
Epoch 748 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7775 AR 0.9750
Epoch 748 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7005 AR 0.8467
Epoch 748 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6614 AR 0.9050
Epoch 748 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6963 AR 1.0000
Epoch 748 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6636 AR 0.9750
Epoch 748 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7783 AR 0.9500
Epoch 748 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6667 AR 0.9000
Epoch 748 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6600 AR 0.8800
Epoch 748 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6169 AR 0.9467
Epoch 748 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8705 AR 0.9800
Epoch 749 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7383 AR 0.8500
Epoch 749 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7075 AR 0.9000
Epoch 749 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5819 AR 0.8600
Epoch 749 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6887 AR 0.9800
Epoch 749 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8450 AR 0.9750
Epoch 749 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8083 AR 0.9500
Epoch 749 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6342 AR 0.9000
Epoch 749 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7067 AR 0.9300
Epoch 749 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7614 AR 0.9800
Epoch 749 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6514 AR 0.9300
Epoch 750 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7392 AR 0.8750
Epoch 750 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6867 AR 0.9667
Epoch 750 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6817 AR 0.9500
Epoch 750 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5958 AR 0.9350
Epoch 750 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7122 AR 0.8800
Epoch 750 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6468 AR 0.9750
Epoch 750 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7300 AR 0.8800
Epoch 750 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8571 AR 0.9550
Epoch 750 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7850 AR 0.9800
Epoch 750 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7498 AR 1.0000
Epoch 751 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7433 AR 0.8550
Epoch 751 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6581 AR 0.9250
Epoch 751 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7238 AR 0.9800
Epoch 751 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6564 AR 1.0000
Epoch 751 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7792 AR 1.0000
Epoch 751 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7405 AR 0.8800
Epoch 751 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7605 AR 0.9550
Epoch 751 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6467 AR 0.9000
Epoch 751 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7710 AR 0.9800
Epoch 751 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6917 AR 0.9350
Epoch 752 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7435 AR 0.9167
Epoch 752 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7883 AR 0.9550
Epoch 752 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6605 AR 0.9750
Epoch 752 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6528 AR 0.9350
Epoch 752 batch 00005: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6967 AR 0.9800
Epoch 752 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6981 AR 0.9000
Epoch 752 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6556 AR 0.8467
Epoch 752 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7292 AR 1.0000
Epoch 752 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7650 AR 0.9417
Epoch 752 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7667 AR 1.0000
Epoch 753 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8058 AR 1.0000
Epoch 753 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6767 AR 0.8750
Epoch 753 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6547 AR 0.9400
Epoch 753 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7039 AR 1.0000
Epoch 753 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6944 AR 0.9500
Epoch 753 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7352 AR 0.8400
Epoch 753 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5163 AR 0.9000
Epoch 753 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7650 AR 0.9167
Epoch 753 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7350 AR 0.9000
Epoch 753 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7967 AR 1.0000
Epoch 754 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7347 AR 0.9800
Epoch 754 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7650 AR 0.9800
Epoch 754 batch 00003: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7920 AR 1.0000
Epoch 754 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.5836 AR 0.8500
Epoch 754 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5797 AR 0.9500
Epoch 754 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7514 AR 1.0000
Epoch 754 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7575 AR 0.9167
Epoch 754 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7875 AR 0.9467
Epoch 754 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6821 AR 0.9000
Epoch 754 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8255 AR 1.0000
Epoch 755 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5400 AR 0.8550
Epoch 755 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7042 AR 0.9417
Epoch 755 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6666 AR 0.9750
Epoch 755 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7800 AR 0.9400
Epoch 755 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7279 AR 0.9000
Epoch 755 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7655 AR 0.9800
Epoch 755 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7300 AR 0.9500
Epoch 755 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7717 AR 1.0000
Epoch 755 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7276 AR 1.0000
Epoch 755 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7334 AR 0.9800
Epoch 756 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6842 AR 0.9500
Epoch 756 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7361 AR 0.9600
Epoch 756 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6439 AR 0.9333
Epoch 756 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6783 AR 0.9550
Epoch 756 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6883 AR 1.0000
Epoch 756 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8621 AR 0.9750
Epoch 756 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8083 AR 0.8800
Epoch 756 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7775 AR 0.9750
Epoch 756 batch 00009: Loss 0.0006 Regression loss 0.0004 Classification loss 0.0001 AP 0.6522 AR 0.9350
Epoch 756 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6943 AR 0.9300
Epoch 757 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7306 AR 0.9800
Epoch 757 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7825 AR 1.0000
Epoch 757 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6668 AR 0.8800
Epoch 757 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6948 AR 0.9083
Epoch 757 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7688 AR 0.9667
Epoch 757 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7100 AR 0.9000
Epoch 757 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7700 AR 1.0000
Epoch 757 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6867 AR 0.9800
Epoch 757 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5855 AR 0.7800
Epoch 757 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7467 AR 0.9550
Epoch 758 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5250 AR 0.8000
Epoch 758 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6808 AR 0.9350
Epoch 758 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8363 AR 1.0000
Epoch 758 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7728 AR 0.9550
Epoch 758 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8008 AR 0.9800
Epoch 758 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7392 AR 0.9417
Epoch 758 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6206 AR 1.0000
Epoch 758 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7023 AR 1.0000
Epoch 758 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6317 AR 0.8500
Epoch 758 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8021 AR 0.9550
Epoch 759 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6852 AR 0.9800
Epoch 759 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7846 AR 0.9550
Epoch 759 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7258 AR 1.0000
Epoch 759 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7988 AR 0.9750
Epoch 759 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7283 AR 0.9333
Epoch 759 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6933 AR 0.8800
Epoch 759 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7792 AR 1.0000
Epoch 759 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6356 AR 0.8800
Epoch 759 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6650 AR 0.9467
Epoch 759 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6676 AR 0.8800
Epoch 760 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6970 AR 0.9600
Epoch 760 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8958 AR 1.0000
Epoch 760 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7912 AR 0.9250
Epoch 760 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6064 AR 0.8500
Epoch 760 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7363 AR 0.9000
Epoch 760 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7578 AR 1.0000
Epoch 760 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6827 AR 0.9600
Epoch 760 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5717 AR 0.9083
Epoch 760 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6733 AR 0.9500
Epoch 760 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6675 AR 0.9000
Epoch 761 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7898 AR 1.0000
Epoch 761 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7467 AR 1.0000
Epoch 761 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7417 AR 0.9600
Epoch 761 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7842 AR 0.9333
Epoch 761 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7642 AR 0.9250
Epoch 761 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6071 AR 0.8000
Epoch 761 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7119 AR 0.9750
Epoch 761 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6692 AR 1.0000
Epoch 761 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6675 AR 0.8400
Epoch 761 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6172 AR 0.9150
Epoch 762 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7058 AR 0.9100
Epoch 762 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6422 AR 0.8800
Epoch 762 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5798 AR 0.8350
Epoch 762 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7533 AR 0.9800
Epoch 762 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8050 AR 1.0000
Epoch 762 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7183 AR 1.0000
Epoch 762 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8596 AR 1.0000
Epoch 762 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7476 AR 0.9500
Epoch 762 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6935 AR 0.9800
Epoch 762 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6200 AR 0.8800
Epoch 763 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6875 AR 0.9000
Epoch 763 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6473 AR 0.8250
Epoch 763 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7383 AR 0.8500
Epoch 763 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6286 AR 0.9550
Epoch 763 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7681 AR 1.0000
Epoch 763 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7105 AR 0.9800
Epoch 763 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7267 AR 1.0000
Epoch 763 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7078 AR 0.8800
Epoch 763 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6671 AR 0.9017
Epoch 763 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8089 AR 0.9750
Epoch 764 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6919 AR 0.9800
Epoch 764 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8317 AR 0.9800
Epoch 764 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6006 AR 0.8300
Epoch 764 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7029 AR 0.9300
Epoch 764 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6689 AR 1.0000
Epoch 764 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7596 AR 0.9800
Epoch 764 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8981 AR 0.9800
Epoch 764 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6517 AR 0.8750
Epoch 764 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6814 AR 0.9750
Epoch 764 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6167 AR 0.8333
Epoch 765 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7900 AR 0.9750
Epoch 765 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7189 AR 1.0000
Epoch 765 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6483 AR 0.9400
Epoch 765 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6463 AR 0.8000
Epoch 765 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7456 AR 0.9800
Epoch 765 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7517 AR 0.9667
Epoch 765 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6894 AR 0.8600
Epoch 765 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7405 AR 1.0000
Epoch 765 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7733 AR 1.0000
Epoch 765 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7433 AR 0.9000
Epoch 766 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7250 AR 0.8667
Epoch 766 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5769 AR 0.7750
Epoch 766 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6831 AR 1.0000
Epoch 766 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6071 AR 0.9800
Epoch 766 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7938 AR 0.9550
Epoch 766 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6292 AR 0.9000
Epoch 766 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7217 AR 0.9550
Epoch 766 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7988 AR 0.8550
Epoch 766 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7373 AR 0.9600
Epoch 766 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6663 AR 0.9550
Epoch 767 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7127 AR 0.9467
Epoch 767 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6750 AR 0.9750
Epoch 767 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6288 AR 0.8333
Epoch 767 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8578 AR 0.9800
Epoch 767 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6542 AR 0.9000
Epoch 767 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7330 AR 1.0000
Epoch 767 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6400 AR 0.8500
Epoch 767 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7947 AR 0.9800
Epoch 767 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7200 AR 0.9800
Epoch 767 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7517 AR 0.9550
Epoch 768 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6817 AR 1.0000
Epoch 768 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7169 AR 0.9750
Epoch 768 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6942 AR 0.9600
Epoch 768 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6913 AR 0.9500
Epoch 768 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5739 AR 0.7750
Epoch 768 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5533 AR 0.8050
Epoch 768 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7733 AR 0.9083
Epoch 768 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8067 AR 0.9800
Epoch 768 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7020 AR 0.9000
Epoch 768 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8030 AR 1.0000
Epoch 769 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5552 AR 0.8667
Epoch 769 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7567 AR 0.9500
Epoch 769 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7650 AR 0.9133
Epoch 769 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7008 AR 0.9250
Epoch 769 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6708 AR 0.9350
Epoch 769 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6267 AR 0.8800
Epoch 769 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8183 AR 1.0000
Epoch 769 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6391 AR 1.0000
Epoch 769 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7244 AR 0.8600
Epoch 769 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6700 AR 0.8500
Epoch 770 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6208 AR 0.7800
Epoch 770 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7467 AR 1.0000
Epoch 770 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7423 AR 1.0000
Epoch 770 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8189 AR 1.0000
Epoch 770 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6845 AR 0.9217
Epoch 770 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6858 AR 0.9550
Epoch 770 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6946 AR 1.0000
Epoch 770 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7462 AR 0.8550
Epoch 770 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7347 AR 0.9750
Epoch 770 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7983 AR 1.0000
Epoch 771 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7821 AR 1.0000
Epoch 771 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6869 AR 0.9800
Epoch 771 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7664 AR 0.9300
Epoch 771 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6324 AR 0.8550
Epoch 771 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6571 AR 0.8250
Epoch 771 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7525 AR 1.0000
Epoch 771 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6464 AR 0.9333
Epoch 771 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7356 AR 0.9800
Epoch 771 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7083 AR 0.9000
Epoch 771 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7667 AR 0.9800
Epoch 772 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6743 AR 0.9550
Epoch 772 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7558 AR 0.9083
Epoch 772 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7100 AR 0.9800
Epoch 772 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7105 AR 1.0000
Epoch 772 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7847 AR 1.0000
Epoch 772 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8100 AR 0.9467
Epoch 772 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8092 AR 0.9750
Epoch 772 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7467 AR 0.9550
Epoch 772 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5655 AR 0.8067
Epoch 772 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6170 AR 0.8500
Epoch 773 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6749 AR 0.9000
Epoch 773 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5931 AR 0.8000
Epoch 773 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6853 AR 0.9000
Epoch 773 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6350 AR 0.8800
Epoch 773 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6938 AR 0.9467
Epoch 773 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7005 AR 0.9350
Epoch 773 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6600 AR 1.0000
Epoch 773 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8067 AR 0.9300
Epoch 773 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7583 AR 0.9083
Epoch 773 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7333 AR 0.9750
Epoch 774 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8188 AR 1.0000
Epoch 774 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6677 AR 0.9300
Epoch 774 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7202 AR 1.0000
Epoch 774 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8308 AR 1.0000
Epoch 774 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8072 AR 1.0000
Epoch 774 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8181 AR 0.9000
Epoch 774 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5905 AR 0.9133
Epoch 774 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6605 AR 0.9467
Epoch 774 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7400 AR 0.9100
Epoch 774 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6942 AR 0.9800
Epoch 775 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7300 AR 0.8800
Epoch 775 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8117 AR 0.9500
Epoch 775 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7383 AR 1.0000
Epoch 775 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7287 AR 0.9800
Epoch 775 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7158 AR 0.9250
Epoch 775 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7283 AR 0.9400
Epoch 775 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8321 AR 0.9750
Epoch 775 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6742 AR 0.9333
Epoch 775 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.3648 AR 0.7000
Epoch 775 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7322 AR 0.9750
Epoch 776 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7818 AR 1.0000
Epoch 776 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6656 AR 1.0000
Epoch 776 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6356 AR 0.9750
Epoch 776 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7352 AR 0.9550
Epoch 776 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7933 AR 0.9667
Epoch 776 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6849 AR 0.8800
Epoch 776 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6958 AR 0.9800
Epoch 776 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6764 AR 0.7800
Epoch 776 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7600 AR 0.9750
Epoch 776 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7547 AR 0.9750
Epoch 777 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7018 AR 0.9800
Epoch 777 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7933 AR 0.9550
Epoch 777 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7733 AR 0.9750
Epoch 777 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6005 AR 0.8600
Epoch 777 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6417 AR 0.9050
Epoch 777 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8200 AR 1.0000
Epoch 777 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7505 AR 1.0000
Epoch 777 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6871 AR 0.9800
Epoch 777 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7556 AR 1.0000
Epoch 777 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7514 AR 0.9467
Epoch 778 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6948 AR 0.9550
Epoch 778 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8050 AR 1.0000
Epoch 778 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8250 AR 0.9100
Epoch 778 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6141 AR 0.8600
Epoch 778 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6286 AR 0.9333
Epoch 778 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7505 AR 1.0000
Epoch 778 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7308 AR 1.0000
Epoch 778 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7175 AR 0.8000
Epoch 778 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6971 AR 0.9550
Epoch 778 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6856 AR 1.0000
Epoch 779 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8306 AR 1.0000
Epoch 779 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7690 AR 0.9550
Epoch 779 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8017 AR 1.0000
Epoch 779 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5694 AR 0.9100
Epoch 779 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6833 AR 0.9417
Epoch 779 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7067 AR 0.9550
Epoch 779 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7517 AR 0.9550
Epoch 779 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.6905 AR 0.9467
Epoch 779 batch 00009: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7217 AR 0.9000
Epoch 779 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6744 AR 1.0000
Epoch 780 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6200 AR 1.0000
Epoch 780 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7733 AR 0.9800
Epoch 780 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7958 AR 0.9417
Epoch 780 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7838 AR 1.0000
Epoch 780 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7050 AR 0.9467
Epoch 780 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6322 AR 0.7417
Epoch 780 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7589 AR 0.9750
Epoch 780 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7172 AR 1.0000
Epoch 780 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7050 AR 0.9800
Epoch 780 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7408 AR 0.9467
Epoch 781 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6485 AR 0.8600
Epoch 781 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6817 AR 0.8750
Epoch 781 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.6975 AR 0.9500
Epoch 781 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7338 AR 0.9333
Epoch 781 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6878 AR 0.8550
Epoch 781 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8767 AR 1.0000
Epoch 781 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7681 AR 1.0000
Epoch 781 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6905 AR 0.9350
Epoch 781 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6310 AR 0.9300
Epoch 781 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7613 AR 1.0000
Epoch 782 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.9175 AR 0.9800
Epoch 782 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6361 AR 0.8467
Epoch 782 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6821 AR 0.9750
Epoch 782 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7433 AR 0.8600
Epoch 782 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6031 AR 0.8750
Epoch 782 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6075 AR 0.9500
Epoch 782 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7500 AR 1.0000
Epoch 782 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7512 AR 0.9250
Epoch 782 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6914 AR 0.9050
Epoch 782 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5855 AR 0.8967
Epoch 783 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7255 AR 0.9267
Epoch 783 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8114 AR 0.9800
Epoch 783 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8113 AR 1.0000
Epoch 783 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6395 AR 0.9750
Epoch 783 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.8075 AR 0.9750
Epoch 783 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8183 AR 0.9750
Epoch 783 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8233 AR 1.0000
Epoch 783 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6222 AR 0.9500
Epoch 783 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7245 AR 0.9500
Epoch 783 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6033 AR 0.8250
Epoch 784 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6586 AR 0.8600
Epoch 784 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6995 AR 0.8633
Epoch 784 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6608 AR 0.9050
Epoch 784 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7148 AR 0.9667
Epoch 784 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7764 AR 0.9750
Epoch 784 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6764 AR 0.9500
Epoch 784 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7794 AR 0.9800
Epoch 784 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7450 AR 1.0000
Epoch 784 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7763 AR 1.0000
Epoch 784 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5975 AR 0.9000
Epoch 785 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6563 AR 1.0000
Epoch 785 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7100 AR 0.9467
Epoch 785 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6892 AR 0.8750
Epoch 785 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7517 AR 0.9550
Epoch 785 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5996 AR 0.7400
Epoch 785 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7408 AR 0.9500
Epoch 785 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7614 AR 0.9500
Epoch 785 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6585 AR 0.9333
Epoch 785 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7363 AR 0.9550
Epoch 785 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7572 AR 0.9800
Epoch 786 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8433 AR 1.0000
Epoch 786 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8717 AR 1.0000
Epoch 786 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5130 AR 0.8550
Epoch 786 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6444 AR 0.8383
Epoch 786 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7339 AR 0.9000
Epoch 786 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6475 AR 0.9000
Epoch 786 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8292 AR 0.9750
Epoch 786 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6398 AR 0.9550
Epoch 786 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5233 AR 0.8417
Epoch 786 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6871 AR 0.9300
Epoch 787 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6606 AR 1.0000
Epoch 787 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7839 AR 0.9000
Epoch 787 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6350 AR 0.9417
Epoch 787 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7772 AR 0.9750
Epoch 787 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8067 AR 0.9800
Epoch 787 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8217 AR 0.9800
Epoch 787 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7425 AR 0.9750
Epoch 787 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7967 AR 1.0000
Epoch 787 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7964 AR 0.9750
Epoch 787 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5705 AR 0.8933
Epoch 788 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.7036 AR 0.9800
Epoch 788 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7865 AR 0.9800
Epoch 788 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7172 AR 0.9350
Epoch 788 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7100 AR 1.0000
Epoch 788 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6931 AR 0.9750
Epoch 788 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8162 AR 0.9750
Epoch 788 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7939 AR 1.0000
Epoch 788 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8194 AR 0.9750
Epoch 788 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.6083 AR 0.9000
Epoch 788 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7625 AR 0.9417
Epoch 789 batch 00001: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0000 AP 0.6156 AR 0.8750
Epoch 789 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7072 AR 1.0000
Epoch 789 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7625 AR 0.9417
Epoch 789 batch 00004: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0001 AP 0.7280 AR 0.8800
Epoch 789 batch 00005: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.7033 AR 0.9750
Epoch 789 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7117 AR 0.9750
Epoch 789 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8398 AR 0.9800
Epoch 789 batch 00008: Loss 0.0025 Regression loss 0.0024 Classification loss 0.0001 AP 0.7571 AR 0.9467
Epoch 789 batch 00009: Loss 0.0026 Regression loss 0.0026 Classification loss 0.0001 AP 0.6207 AR 0.8700
Epoch 789 batch 00010: Loss 0.0018 Regression loss 0.0018 Classification loss 0.0000 AP 0.8192 AR 1.0000
Epoch 790 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6654 AR 0.9750
Epoch 790 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6073 AR 0.9250
Epoch 790 batch 00003: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8067 AR 0.9000
Epoch 790 batch 00004: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0001 AP 0.8317 AR 1.0000
Epoch 790 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6917 AR 0.9600
Epoch 790 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.5717 AR 0.9000
Epoch 790 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7829 AR 0.8750
Epoch 790 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6169 AR 0.9750
Epoch 790 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.8096 AR 0.9550
Epoch 790 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8003 AR 1.0000
Epoch 791 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7575 AR 0.9400
Epoch 791 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7950 AR 0.9333
Epoch 791 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7198 AR 0.9350
Epoch 791 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6414 AR 0.9000
Epoch 791 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8083 AR 1.0000
Epoch 791 batch 00006: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.6906 AR 0.8250
Epoch 791 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7306 AR 1.0000
Epoch 791 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7166 AR 0.9500
Epoch 791 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6055 AR 0.9800
Epoch 791 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8030 AR 1.0000
Epoch 792 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6517 AR 0.9750
Epoch 792 batch 00002: Loss 0.0016 Regression loss 0.0016 Classification loss 0.0001 AP 0.7883 AR 1.0000
Epoch 792 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7196 AR 0.9800
Epoch 792 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6981 AR 0.9800
Epoch 792 batch 00005: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.8180 AR 0.9750
Epoch 792 batch 00006: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.5710 AR 0.8000
Epoch 792 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6671 AR 0.9500
Epoch 792 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7375 AR 0.9800
Epoch 792 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7185 AR 0.9200
Epoch 792 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7917 AR 0.9750
Epoch 793 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7351 AR 0.9750
Epoch 793 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7005 AR 0.9800
Epoch 793 batch 00003: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.7298 AR 0.9500
Epoch 793 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7145 AR 1.0000
Epoch 793 batch 00005: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6894 AR 0.9000
Epoch 793 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7233 AR 0.9750
Epoch 793 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7225 AR 0.8750
Epoch 793 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7105 AR 0.9600
Epoch 793 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6448 AR 0.8467
Epoch 793 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7867 AR 0.9300
Epoch 794 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6710 AR 0.9467
Epoch 794 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7506 AR 0.9800
Epoch 794 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6100 AR 0.8000
Epoch 794 batch 00004: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.5478 AR 0.9600
Epoch 794 batch 00005: Loss 0.0027 Regression loss 0.0026 Classification loss 0.0001 AP 0.7573 AR 0.9667
Epoch 794 batch 00006: Loss 0.0017 Regression loss 0.0017 Classification loss 0.0000 AP 0.7989 AR 1.0000
Epoch 794 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8217 AR 1.0000
Epoch 794 batch 00008: Loss 0.0026 Regression loss 0.0025 Classification loss 0.0001 AP 0.7538 AR 0.9500
Epoch 794 batch 00009: Loss 0.0041 Regression loss 0.0040 Classification loss 0.0001 AP 0.7229 AR 0.9150
Epoch 794 batch 00010: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7714 AR 0.9667
Epoch 795 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6567 AR 0.9467
Epoch 795 batch 00002: Loss 0.0031 Regression loss 0.0031 Classification loss 0.0001 AP 0.6289 AR 0.9250
Epoch 795 batch 00003: Loss 0.0044 Regression loss 0.0043 Classification loss 0.0001 AP 0.6471 AR 0.8100
Epoch 795 batch 00004: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7200 AR 0.9500
Epoch 795 batch 00005: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7726 AR 0.9550
Epoch 795 batch 00006: Loss 0.0029 Regression loss 0.0028 Classification loss 0.0001 AP 0.7933 AR 0.9300
Epoch 795 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7170 AR 0.9750
Epoch 795 batch 00008: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0001 AP 0.5953 AR 0.9350
Epoch 795 batch 00009: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7817 AR 0.9750
Epoch 795 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8689 AR 1.0000
Epoch 796 batch 00001: Loss 0.0031 Regression loss 0.0030 Classification loss 0.0001 AP 0.6700 AR 0.9050
Epoch 796 batch 00002: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7383 AR 0.9083
Epoch 796 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7405 AR 1.0000
Epoch 796 batch 00004: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.6673 AR 0.9667
Epoch 796 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7462 AR 0.9667
Epoch 796 batch 00006: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7967 AR 0.9800
Epoch 796 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7300 AR 0.9550
Epoch 796 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7547 AR 1.0000
Epoch 796 batch 00009: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0001 AP 0.6972 AR 0.9300
Epoch 796 batch 00010: Loss 0.0015 Regression loss 0.0015 Classification loss 0.0001 AP 0.6988 AR 0.9750
Epoch 797 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6887 AR 0.9400
Epoch 797 batch 00002: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.7600 AR 0.9300
Epoch 797 batch 00003: Loss 0.0026 Regression loss 0.0026 Classification loss 0.0001 AP 0.7969 AR 0.9800
Epoch 797 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6730 AR 1.0000
Epoch 797 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7777 AR 1.0000
Epoch 797 batch 00006: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0001 AP 0.6628 AR 0.8800
Epoch 797 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7092 AR 0.9500
Epoch 797 batch 00008: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.6592 AR 0.9000
Epoch 797 batch 00009: Loss 0.0028 Regression loss 0.0027 Classification loss 0.0001 AP 0.6567 AR 0.8750
Epoch 797 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7783 AR 0.9800
Epoch 798 batch 00001: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7902 AR 0.9500
Epoch 798 batch 00002: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.6112 AR 0.9500
Epoch 798 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7610 AR 0.9100
Epoch 798 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7186 AR 0.9267
Epoch 798 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8000 AR 1.0000
Epoch 798 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6642 AR 0.9800
Epoch 798 batch 00007: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.6533 AR 0.8750
Epoch 798 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7364 AR 0.9600
Epoch 798 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8683 AR 1.0000
Epoch 798 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7014 AR 0.9800
Epoch 799 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.7605 AR 0.9417
Epoch 799 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7739 AR 0.9600
Epoch 799 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5836 AR 0.8600
Epoch 799 batch 00004: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.7292 AR 0.9667
Epoch 799 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7844 AR 0.9750
Epoch 799 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6555 AR 1.0000
Epoch 799 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5794 AR 0.8800
Epoch 799 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7083 AR 0.9550
Epoch 799 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7030 AR 0.8667
Epoch 799 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7393 AR 0.9550
Epoch 800 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6742 AR 0.8400
Epoch 800 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6467 AR 0.9800
Epoch 800 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7450 AR 0.9750
Epoch 800 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8020 AR 1.0000
Epoch 800 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7521 AR 0.9750
Epoch 800 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7144 AR 0.9300
Epoch 800 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6335 AR 0.9000
Epoch 800 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7133 AR 0.9000
Epoch 800 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7487 AR 0.9467
Epoch 800 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6467 AR 0.8750
Epoch 801 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6508 AR 0.8500
Epoch 801 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7400 AR 1.0000
Epoch 801 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7268 AR 0.9600
Epoch 801 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5989 AR 0.8750
Epoch 801 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8050 AR 0.9750
Epoch 801 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7233 AR 0.9000
Epoch 801 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7296 AR 0.9550
Epoch 801 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6983 AR 0.9667
Epoch 801 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6289 AR 0.9600
Epoch 801 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7728 AR 0.9800
Epoch 802 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7953 AR 0.9550
Epoch 802 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7200 AR 0.9750
Epoch 802 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8367 AR 1.0000
Epoch 802 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8364 AR 0.9800
Epoch 802 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6300 AR 0.9333
Epoch 802 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6895 AR 0.9800
Epoch 802 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6671 AR 0.8417
Epoch 802 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.4806 AR 0.8050
Epoch 802 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7363 AR 0.8800
Epoch 802 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6602 AR 0.9500
Epoch 803 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6171 AR 0.8800
Epoch 803 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6817 AR 1.0000
Epoch 803 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6937 AR 0.9550
Epoch 803 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7306 AR 1.0000
Epoch 803 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5633 AR 0.7817
Epoch 803 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8308 AR 0.9667
Epoch 803 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8583 AR 0.9550
Epoch 803 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7100 AR 0.9750
Epoch 803 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8371 AR 1.0000
Epoch 803 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6489 AR 0.9000
Epoch 804 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7821 AR 0.9800
Epoch 804 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7906 AR 0.9750
Epoch 804 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7942 AR 1.0000
Epoch 804 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6614 AR 1.0000
Epoch 804 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7338 AR 0.9550
Epoch 804 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8125 AR 0.9750
Epoch 804 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6526 AR 0.9333
Epoch 804 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7270 AR 0.9800
Epoch 804 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6733 AR 0.8800
Epoch 804 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6250 AR 0.9000
Epoch 805 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7330 AR 1.0000
Epoch 805 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5726 AR 0.9050
Epoch 805 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7339 AR 0.9800
Epoch 805 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6581 AR 0.8000
Epoch 805 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8783 AR 0.9800
Epoch 805 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5906 AR 0.8467
Epoch 805 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7921 AR 0.9800
Epoch 805 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6814 AR 0.9133
Epoch 805 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5858 AR 0.9500
Epoch 805 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8900 AR 0.9750
Epoch 806 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7164 AR 0.9750
Epoch 806 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6606 AR 0.9133
Epoch 806 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7711 AR 0.9800
Epoch 806 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7367 AR 1.0000
Epoch 806 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7292 AR 0.9300
Epoch 806 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7588 AR 0.9750
Epoch 806 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6811 AR 0.9750
Epoch 806 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7493 AR 0.8800
Epoch 806 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6681 AR 0.8800
Epoch 806 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6533 AR 0.8667
Epoch 807 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6439 AR 1.0000
Epoch 807 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6100 AR 0.8600
Epoch 807 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6905 AR 0.9500
Epoch 807 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.6736 AR 0.9133
Epoch 807 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7533 AR 0.9500
Epoch 807 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7975 AR 0.9750
Epoch 807 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7433 AR 0.8967
Epoch 807 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7650 AR 0.9550
Epoch 807 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7394 AR 0.9600
Epoch 807 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7981 AR 1.0000
Epoch 808 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7122 AR 0.9750
Epoch 808 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6508 AR 0.9083
Epoch 808 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7871 AR 0.9467
Epoch 808 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7741 AR 0.9800
Epoch 808 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7431 AR 1.0000
Epoch 808 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6836 AR 0.9000
Epoch 808 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6783 AR 0.9500
Epoch 808 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7056 AR 0.9550
Epoch 808 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6156 AR 0.9000
Epoch 808 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8188 AR 1.0000
Epoch 809 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7225 AR 1.0000
Epoch 809 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6086 AR 0.9083
Epoch 809 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8200 AR 0.9667
Epoch 809 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7717 AR 0.9300
Epoch 809 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6163 AR 0.8800
Epoch 809 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7132 AR 0.9500
Epoch 809 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8106 AR 1.0000
Epoch 809 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7022 AR 1.0000
Epoch 809 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8375 AR 0.9750
Epoch 809 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6083 AR 0.9300
Epoch 810 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6617 AR 0.8083
Epoch 810 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8433 AR 1.0000
Epoch 810 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6171 AR 0.8800
Epoch 810 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7925 AR 1.0000
Epoch 810 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6958 AR 0.9467
Epoch 810 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6097 AR 0.7800
Epoch 810 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5870 AR 0.7800
Epoch 810 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7900 AR 0.9350
Epoch 810 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6368 AR 0.9750
Epoch 810 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6671 AR 0.9800
Epoch 811 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7148 AR 0.9750
Epoch 811 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7014 AR 0.9667
Epoch 811 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8083 AR 0.9800
Epoch 811 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7817 AR 0.9800
Epoch 811 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5600 AR 0.7000
Epoch 811 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7767 AR 0.9800
Epoch 811 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6806 AR 0.9500
Epoch 811 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6767 AR 0.9500
Epoch 811 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6846 AR 0.9600
Epoch 811 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6592 AR 0.9500
Epoch 812 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7521 AR 0.9300
Epoch 812 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6730 AR 0.9400
Epoch 812 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7683 AR 0.9750
Epoch 812 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7067 AR 0.8550
Epoch 812 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6033 AR 0.8333
Epoch 812 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7183 AR 0.9750
Epoch 812 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7350 AR 0.9600
Epoch 812 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6767 AR 0.9550
Epoch 812 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.4837 AR 0.7500
Epoch 812 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7833 AR 0.9800
Epoch 813 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6883 AR 0.9500
Epoch 813 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7583 AR 1.0000
Epoch 813 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7800 AR 0.9500
Epoch 813 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7392 AR 0.9750
Epoch 813 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7792 AR 1.0000
Epoch 813 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7374 AR 0.9600
Epoch 813 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6750 AR 0.8550
Epoch 813 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6322 AR 0.9800
Epoch 813 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6343 AR 0.8133
Epoch 813 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6978 AR 0.9550
Epoch 814 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7016 AR 0.9350
Epoch 814 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7644 AR 1.0000
Epoch 814 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5664 AR 0.7750
Epoch 814 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7900 AR 1.0000
Epoch 814 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7467 AR 0.9800
Epoch 814 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6100 AR 1.0000
Epoch 814 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7217 AR 1.0000
Epoch 814 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8030 AR 1.0000
Epoch 814 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6583 AR 0.7883
Epoch 814 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7533 AR 0.9500
Epoch 815 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8664 AR 0.9800
Epoch 815 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6575 AR 0.9133
Epoch 815 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7517 AR 0.9500
Epoch 815 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7024 AR 0.8800
Epoch 815 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6550 AR 0.8800
Epoch 815 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7685 AR 1.0000
Epoch 815 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6683 AR 0.9800
Epoch 815 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6589 AR 0.9000
Epoch 815 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7630 AR 0.9750
Epoch 815 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7381 AR 0.9500
Epoch 816 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7264 AR 1.0000
Epoch 816 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6814 AR 0.9800
Epoch 816 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6733 AR 0.9417
Epoch 816 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7164 AR 0.9800
Epoch 816 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6683 AR 0.7550
Epoch 816 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6908 AR 0.9300
Epoch 816 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6438 AR 0.9750
Epoch 816 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7250 AR 0.8800
Epoch 816 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8167 AR 0.9750
Epoch 816 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7447 AR 1.0000
Epoch 817 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7467 AR 1.0000
Epoch 817 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7492 AR 0.9250
Epoch 817 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7486 AR 0.9800
Epoch 817 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6933 AR 0.9550
Epoch 817 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7867 AR 0.9750
Epoch 817 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5794 AR 0.6800
Epoch 817 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6863 AR 0.9800
Epoch 817 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7125 AR 0.8083
Epoch 817 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6129 AR 0.8800
Epoch 817 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6972 AR 1.0000
Epoch 818 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6773 AR 0.9500
Epoch 818 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.5767 AR 0.8300
Epoch 818 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6672 AR 0.9750
Epoch 818 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7502 AR 0.8933
Epoch 818 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7717 AR 1.0000
Epoch 818 batch 00006: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.7035 AR 1.0000
Epoch 818 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7533 AR 1.0000
Epoch 818 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6614 AR 0.8550
Epoch 818 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8583 AR 0.9750
Epoch 818 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6292 AR 0.8000
Epoch 819 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7621 AR 0.9000
Epoch 819 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.6870 AR 0.9000
Epoch 819 batch 00003: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6946 AR 1.0000
Epoch 819 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6325 AR 0.9250
Epoch 819 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6455 AR 0.8800
Epoch 819 batch 00006: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7167 AR 0.9800
Epoch 819 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.7494 AR 0.9500
Epoch 819 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7750 AR 0.9250
Epoch 819 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7367 AR 0.9750
Epoch 819 batch 00010: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6900 AR 0.9550
Epoch 820 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7400 AR 1.0000
Epoch 820 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.7864 AR 0.9800
Epoch 820 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7280 AR 1.0000
Epoch 820 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8381 AR 1.0000
Epoch 820 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7931 AR 0.9050
Epoch 820 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6533 AR 0.8750
Epoch 820 batch 00007: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6810 AR 0.8600
Epoch 820 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7055 AR 0.9300
Epoch 820 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6764 AR 1.0000
Epoch 820 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7138 AR 1.0000
Epoch 821 batch 00001: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0001 AP 0.6788 AR 0.9550
Epoch 821 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7138 AR 1.0000
Epoch 821 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.6517 AR 0.8000
Epoch 821 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6886 AR 1.0000
Epoch 821 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6671 AR 0.9400
Epoch 821 batch 00006: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.6189 AR 0.8750
Epoch 821 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8500 AR 0.9500
Epoch 821 batch 00008: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.7464 AR 1.0000
Epoch 821 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7933 AR 0.9600
Epoch 821 batch 00010: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.6870 AR 0.8550
Epoch 822 batch 00001: Loss 0.0017 Regression loss 0.0017 Classification loss 0.0001 AP 0.6133 AR 0.9750
Epoch 822 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.5296 AR 0.7600
Epoch 822 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6767 AR 1.0000
Epoch 822 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8689 AR 0.9550
Epoch 822 batch 00005: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7231 AR 1.0000
Epoch 822 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6700 AR 0.9000
Epoch 822 batch 00007: Loss 0.0017 Regression loss 0.0017 Classification loss 0.0001 AP 0.7931 AR 1.0000
Epoch 822 batch 00008: Loss 0.0024 Regression loss 0.0023 Classification loss 0.0001 AP 0.7738 AR 0.9050
Epoch 822 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7900 AR 1.0000
Epoch 822 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6898 AR 0.9600
Epoch 823 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7567 AR 0.9750
Epoch 823 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8033 AR 0.9800
Epoch 823 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7025 AR 0.9667
Epoch 823 batch 00004: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7794 AR 0.9750
Epoch 823 batch 00005: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7017 AR 0.9467
Epoch 823 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8155 AR 0.9600
Epoch 823 batch 00007: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.8056 AR 0.9750
Epoch 823 batch 00008: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.4846 AR 0.8000
Epoch 823 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7400 AR 0.9550
Epoch 823 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6306 AR 0.9550
Epoch 824 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.5675 AR 0.8267
Epoch 824 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7389 AR 1.0000
Epoch 824 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8148 AR 0.9600
Epoch 824 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7833 AR 0.9800
Epoch 824 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5874 AR 0.9417
Epoch 824 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6921 AR 0.9100
Epoch 824 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6500 AR 0.9550
Epoch 824 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7000 AR 0.9500
Epoch 824 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8333 AR 0.9800
Epoch 824 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7386 AR 0.9800
Epoch 825 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5983 AR 0.7900
Epoch 825 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6503 AR 1.0000
Epoch 825 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7005 AR 0.9550
Epoch 825 batch 00004: Loss 0.0006 Regression loss 0.0004 Classification loss 0.0001 AP 0.8733 AR 0.9800
Epoch 825 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6854 AR 0.9600
Epoch 825 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7714 AR 1.0000
Epoch 825 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8167 AR 1.0000
Epoch 825 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5033 AR 0.8750
Epoch 825 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7275 AR 0.9333
Epoch 825 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6583 AR 0.8550
Epoch 826 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6925 AR 0.9217
Epoch 826 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7100 AR 0.9250
Epoch 826 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5526 AR 0.6950
Epoch 826 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7102 AR 0.9750
Epoch 826 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8183 AR 0.9800
Epoch 826 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6678 AR 0.9550
Epoch 826 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7100 AR 0.8600
Epoch 826 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7448 AR 0.9800
Epoch 826 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6956 AR 1.0000
Epoch 826 batch 00010: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.8208 AR 1.0000
Epoch 827 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5794 AR 0.8217
Epoch 827 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6917 AR 0.9550
Epoch 827 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7738 AR 0.9800
Epoch 827 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6946 AR 1.0000
Epoch 827 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6408 AR 0.9167
Epoch 827 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6100 AR 0.8667
Epoch 827 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6903 AR 0.8300
Epoch 827 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8255 AR 0.9600
Epoch 827 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6989 AR 0.9500
Epoch 827 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7750 AR 1.0000
Epoch 828 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7164 AR 0.9800
Epoch 828 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6733 AR 0.8800
Epoch 828 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7750 AR 0.9600
Epoch 828 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7097 AR 0.9000
Epoch 828 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6892 AR 0.9750
Epoch 828 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6588 AR 0.8550
Epoch 828 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7371 AR 1.0000
Epoch 828 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5614 AR 0.8750
Epoch 828 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7072 AR 0.9333
Epoch 828 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6654 AR 0.8500
Epoch 829 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7825 AR 0.9467
Epoch 829 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7989 AR 1.0000
Epoch 829 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6940 AR 0.8750
Epoch 829 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7256 AR 0.9750
Epoch 829 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7971 AR 0.8800
Epoch 829 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7098 AR 0.9000
Epoch 829 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5638 AR 0.9017
Epoch 829 batch 00008: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6118 AR 0.9750
Epoch 829 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5900 AR 0.8600
Epoch 829 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8025 AR 1.0000
Epoch 830 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8000 AR 0.9500
Epoch 830 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6148 AR 0.9667
Epoch 830 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7547 AR 0.9250
Epoch 830 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6410 AR 0.8550
Epoch 830 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7755 AR 0.9550
Epoch 830 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7488 AR 0.9800
Epoch 830 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7233 AR 0.9800
Epoch 830 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6467 AR 0.9150
Epoch 830 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7308 AR 1.0000
Epoch 830 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7300 AR 0.9800
Epoch 831 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5811 AR 0.8133
Epoch 831 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7083 AR 0.9600
Epoch 831 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7521 AR 0.8100
Epoch 831 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7304 AR 1.0000
Epoch 831 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7021 AR 0.8800
Epoch 831 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7750 AR 1.0000
Epoch 831 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8038 AR 0.9800
Epoch 831 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6222 AR 0.9000
Epoch 831 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6467 AR 0.9000
Epoch 831 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6033 AR 0.9500
Epoch 832 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6350 AR 0.8800
Epoch 832 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8250 AR 0.9667
Epoch 832 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7376 AR 0.8900
Epoch 832 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7871 AR 0.9800
Epoch 832 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6889 AR 0.8600
Epoch 832 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5692 AR 1.0000
Epoch 832 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8133 AR 1.0000
Epoch 832 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6445 AR 0.8750
Epoch 832 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7589 AR 1.0000
Epoch 832 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7046 AR 0.9667
Epoch 833 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7350 AR 0.8000
Epoch 833 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6383 AR 0.9300
Epoch 833 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8550 AR 0.9800
Epoch 833 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6967 AR 0.9800
Epoch 833 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6660 AR 0.9800
Epoch 833 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6588 AR 0.9550
Epoch 833 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6092 AR 0.8500
Epoch 833 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7639 AR 0.9800
Epoch 833 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6083 AR 1.0000
Epoch 833 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7548 AR 0.8667
Epoch 834 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6929 AR 1.0000
Epoch 834 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7217 AR 0.9550
Epoch 834 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5821 AR 0.8350
Epoch 834 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7420 AR 0.9417
Epoch 834 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8250 AR 1.0000
Epoch 834 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7345 AR 0.8750
Epoch 834 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6511 AR 0.8883
Epoch 834 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7400 AR 0.9750
Epoch 834 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6211 AR 0.8600
Epoch 834 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7947 AR 1.0000
Epoch 835 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6893 AR 0.8750
Epoch 835 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7089 AR 0.9800
Epoch 835 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7281 AR 0.9750
Epoch 835 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6472 AR 0.9750
Epoch 835 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5387 AR 0.7750
Epoch 835 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7088 AR 0.8800
Epoch 835 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5546 AR 0.8467
Epoch 835 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6217 AR 0.8000
Epoch 835 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8150 AR 0.9600
Epoch 835 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6794 AR 0.9800
Epoch 836 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6483 AR 0.8333
Epoch 836 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7116 AR 0.9300
Epoch 836 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6933 AR 1.0000
Epoch 836 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6221 AR 1.0000
Epoch 836 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7455 AR 0.9350
Epoch 836 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8233 AR 0.9750
Epoch 836 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7725 AR 0.9800
Epoch 836 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6745 AR 1.0000
Epoch 836 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8025 AR 0.9800
Epoch 836 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7900 AR 0.9750
Epoch 837 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7217 AR 0.8500
Epoch 837 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8714 AR 1.0000
Epoch 837 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6955 AR 0.8550
Epoch 837 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6600 AR 0.9000
Epoch 837 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7249 AR 0.9800
Epoch 837 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8530 AR 0.9800
Epoch 837 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7250 AR 1.0000
Epoch 837 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5667 AR 0.9600
Epoch 837 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6900 AR 1.0000
Epoch 837 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7457 AR 0.9800
Epoch 838 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6372 AR 1.0000
Epoch 838 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8317 AR 0.9350
Epoch 838 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7438 AR 0.9550
Epoch 838 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6066 AR 0.9017
Epoch 838 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8250 AR 1.0000
Epoch 838 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7888 AR 0.9550
Epoch 838 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5720 AR 0.8750
Epoch 838 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6588 AR 0.9000
Epoch 838 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8161 AR 1.0000
Epoch 838 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6642 AR 0.9750
Epoch 839 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7367 AR 0.9500
Epoch 839 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7163 AR 0.9550
Epoch 839 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6075 AR 0.8500
Epoch 839 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6183 AR 0.9500
Epoch 839 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7017 AR 0.9800
Epoch 839 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6881 AR 0.9050
Epoch 839 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7683 AR 0.9417
Epoch 839 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7148 AR 0.9000
Epoch 839 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8042 AR 0.9800
Epoch 839 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7687 AR 1.0000
Epoch 840 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6360 AR 0.9000
Epoch 840 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.9267 AR 1.0000
Epoch 840 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5967 AR 0.8800
Epoch 840 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7350 AR 0.9750
Epoch 840 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7125 AR 0.9550
Epoch 840 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6558 AR 0.8883
Epoch 840 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7030 AR 0.9000
Epoch 840 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6517 AR 0.9550
Epoch 840 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7875 AR 1.0000
Epoch 840 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6208 AR 0.8500
Epoch 841 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7625 AR 1.0000
Epoch 841 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6592 AR 0.9500
Epoch 841 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6703 AR 0.9750
Epoch 841 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7636 AR 1.0000
Epoch 841 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7650 AR 0.9500
Epoch 841 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6730 AR 0.8333
Epoch 841 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6733 AR 0.9300
Epoch 841 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7928 AR 0.9800
Epoch 841 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7181 AR 0.9000
Epoch 841 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5803 AR 0.8350
Epoch 842 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6821 AR 0.9800
Epoch 842 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6183 AR 0.8000
Epoch 842 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6633 AR 0.7800
Epoch 842 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6463 AR 0.9417
Epoch 842 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7981 AR 1.0000
Epoch 842 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6360 AR 1.0000
Epoch 842 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6769 AR 0.9600
Epoch 842 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8383 AR 1.0000
Epoch 842 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6821 AR 0.9217
Epoch 842 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6739 AR 0.9250
Epoch 843 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7072 AR 0.9267
Epoch 843 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6683 AR 0.9800
Epoch 843 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6323 AR 0.9217
Epoch 843 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7005 AR 0.9800
Epoch 843 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6133 AR 0.7700
Epoch 843 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5780 AR 0.8800
Epoch 843 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8606 AR 1.0000
Epoch 843 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5138 AR 0.7750
Epoch 843 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8142 AR 1.0000
Epoch 843 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7162 AR 0.9250
Epoch 844 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6988 AR 0.9350
Epoch 844 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6146 AR 0.8500
Epoch 844 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7273 AR 1.0000
Epoch 844 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7406 AR 0.9550
Epoch 844 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5513 AR 0.8500
Epoch 844 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7661 AR 0.9800
Epoch 844 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7842 AR 1.0000
Epoch 844 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7800 AR 0.9550
Epoch 844 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6850 AR 0.9750
Epoch 844 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5305 AR 0.7217
Epoch 845 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7488 AR 0.9167
Epoch 845 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7696 AR 0.9600
Epoch 845 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7233 AR 1.0000
Epoch 845 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6350 AR 0.7800
Epoch 845 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6411 AR 0.9800
Epoch 845 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7300 AR 0.9500
Epoch 845 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6862 AR 0.9000
Epoch 845 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7100 AR 0.9500
Epoch 845 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6905 AR 0.9800
Epoch 845 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7267 AR 0.9800
Epoch 846 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6156 AR 0.8467
Epoch 846 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6644 AR 0.9300
Epoch 846 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7708 AR 0.9667
Epoch 846 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6433 AR 0.9750
Epoch 846 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5281 AR 0.7100
Epoch 846 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7902 AR 0.9750
Epoch 846 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7344 AR 0.9350
Epoch 846 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7993 AR 0.9800
Epoch 846 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8631 AR 1.0000
Epoch 846 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7150 AR 0.9500
Epoch 847 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6558 AR 0.8850
Epoch 847 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7383 AR 0.9500
Epoch 847 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7055 AR 1.0000
Epoch 847 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6771 AR 0.9667
Epoch 847 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6550 AR 0.8933
Epoch 847 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5516 AR 0.7600
Epoch 847 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7767 AR 0.8800
Epoch 847 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7250 AR 0.9800
Epoch 847 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7484 AR 0.9750
Epoch 847 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7695 AR 0.9750
Epoch 848 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7642 AR 0.9800
Epoch 848 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5803 AR 0.8800
Epoch 848 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7312 AR 0.9500
Epoch 848 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6114 AR 1.0000
Epoch 848 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6967 AR 0.8800
Epoch 848 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8221 AR 0.9800
Epoch 848 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8067 AR 1.0000
Epoch 848 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6988 AR 0.8550
Epoch 848 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6342 AR 0.8250
Epoch 848 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7294 AR 1.0000
Epoch 849 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6728 AR 0.9600
Epoch 849 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7467 AR 0.9500
Epoch 849 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6808 AR 0.9217
Epoch 849 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6100 AR 0.8600
Epoch 849 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6050 AR 0.8750
Epoch 849 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6526 AR 0.8300
Epoch 849 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7900 AR 1.0000
Epoch 849 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8338 AR 1.0000
Epoch 849 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8167 AR 0.9333
Epoch 849 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5509 AR 0.8550
Epoch 850 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6328 AR 0.8350
Epoch 850 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7962 AR 1.0000
Epoch 850 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7717 AR 0.9150
Epoch 850 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6133 AR 1.0000
Epoch 850 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7800 AR 0.9050
Epoch 850 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7730 AR 0.9750
Epoch 850 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7300 AR 0.8800
Epoch 850 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6633 AR 0.9667
Epoch 850 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6740 AR 0.9250
Epoch 850 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6458 AR 0.9133
Epoch 851 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7360 AR 0.9800
Epoch 851 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8217 AR 0.9333
Epoch 851 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5989 AR 0.9600
Epoch 851 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7167 AR 0.8550
Epoch 851 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7848 AR 0.9000
Epoch 851 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5864 AR 0.9000
Epoch 851 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6781 AR 0.9250
Epoch 851 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7050 AR 0.8167
Epoch 851 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5807 AR 0.8750
Epoch 851 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8000 AR 0.9550
Epoch 852 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7213 AR 0.9400
Epoch 852 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6638 AR 0.9750
Epoch 852 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6395 AR 0.9000
Epoch 852 batch 00004: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.6719 AR 0.8800
Epoch 852 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8200 AR 0.9667
Epoch 852 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6250 AR 0.8000
Epoch 852 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6880 AR 0.9250
Epoch 852 batch 00008: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6894 AR 0.9500
Epoch 852 batch 00009: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7617 AR 0.9350
Epoch 852 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6500 AR 0.9417
Epoch 853 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6538 AR 0.8300
Epoch 853 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6929 AR 0.9750
Epoch 853 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7250 AR 0.8800
Epoch 853 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7106 AR 0.9500
Epoch 853 batch 00005: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.6236 AR 1.0000
Epoch 853 batch 00006: Loss 0.0027 Regression loss 0.0026 Classification loss 0.0001 AP 0.7788 AR 0.8750
Epoch 853 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6625 AR 0.9300
Epoch 853 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7758 AR 1.0000
Epoch 853 batch 00009: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7201 AR 0.9600
Epoch 853 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7033 AR 0.9750
Epoch 854 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7150 AR 0.9600
Epoch 854 batch 00002: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.8083 AR 0.9350
Epoch 854 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6308 AR 0.9750
Epoch 854 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6613 AR 0.9500
Epoch 854 batch 00005: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.7531 AR 0.9667
Epoch 854 batch 00006: Loss 0.0025 Regression loss 0.0024 Classification loss 0.0001 AP 0.6650 AR 0.8250
Epoch 854 batch 00007: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.7820 AR 0.9750
Epoch 854 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7267 AR 0.9000
Epoch 854 batch 00009: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.7471 AR 1.0000
Epoch 854 batch 00010: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7183 AR 0.9600
Epoch 855 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7083 AR 0.9667
Epoch 855 batch 00002: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.6741 AR 0.9600
Epoch 855 batch 00003: Loss 0.0031 Regression loss 0.0030 Classification loss 0.0001 AP 0.6094 AR 0.9750
Epoch 855 batch 00004: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8700 AR 0.9750
Epoch 855 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7919 AR 0.8800
Epoch 855 batch 00006: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0001 AP 0.8371 AR 0.9800
Epoch 855 batch 00007: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.6639 AR 0.9550
Epoch 855 batch 00008: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.5389 AR 0.9000
Epoch 855 batch 00009: Loss 0.0036 Regression loss 0.0035 Classification loss 0.0001 AP 0.8014 AR 1.0000
Epoch 855 batch 00010: Loss 0.0025 Regression loss 0.0024 Classification loss 0.0001 AP 0.6817 AR 0.8750
Epoch 856 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6410 AR 0.9550
Epoch 856 batch 00002: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7638 AR 1.0000
Epoch 856 batch 00003: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7306 AR 0.8800
Epoch 856 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6464 AR 0.8750
Epoch 856 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7817 AR 0.9800
Epoch 856 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.5805 AR 0.9300
Epoch 856 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6787 AR 0.9800
Epoch 856 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7850 AR 0.9500
Epoch 856 batch 00009: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.7455 AR 0.9800
Epoch 856 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6317 AR 0.8500
Epoch 857 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6539 AR 0.9417
Epoch 857 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7180 AR 0.9467
Epoch 857 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8005 AR 1.0000
Epoch 857 batch 00004: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.7606 AR 0.9500
Epoch 857 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7833 AR 0.9750
Epoch 857 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5906 AR 0.8150
Epoch 857 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7033 AR 0.8767
Epoch 857 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6854 AR 0.9750
Epoch 857 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5700 AR 0.8050
Epoch 857 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7472 AR 1.0000
Epoch 858 batch 00001: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.5843 AR 0.8550
Epoch 858 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7483 AR 0.9550
Epoch 858 batch 00003: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7250 AR 0.8750
Epoch 858 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6511 AR 0.8400
Epoch 858 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6631 AR 0.9800
Epoch 858 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6952 AR 0.9300
Epoch 858 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5780 AR 0.9167
Epoch 858 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8683 AR 1.0000
Epoch 858 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7187 AR 0.9500
Epoch 858 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7583 AR 1.0000
Epoch 859 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8248 AR 0.9800
Epoch 859 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7694 AR 0.9800
Epoch 859 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6417 AR 0.9800
Epoch 859 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7061 AR 1.0000
Epoch 859 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7136 AR 0.9750
Epoch 859 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5877 AR 0.9100
Epoch 859 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6688 AR 0.8500
Epoch 859 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7137 AR 0.9500
Epoch 859 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7404 AR 0.9750
Epoch 859 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7283 AR 0.9000
Epoch 860 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7097 AR 1.0000
Epoch 860 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6689 AR 0.9550
Epoch 860 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7625 AR 1.0000
Epoch 860 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6255 AR 0.8300
Epoch 860 batch 00005: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.7793 AR 0.9500
Epoch 860 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6500 AR 0.9750
Epoch 860 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7700 AR 0.9550
Epoch 860 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7383 AR 0.9250
Epoch 860 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6487 AR 0.8800
Epoch 860 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7833 AR 1.0000
Epoch 861 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6555 AR 1.0000
Epoch 861 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6111 AR 0.8800
Epoch 861 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7433 AR 0.9350
Epoch 861 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8300 AR 0.9750
Epoch 861 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6876 AR 0.8267
Epoch 861 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7779 AR 0.9300
Epoch 861 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6839 AR 0.9800
Epoch 861 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7586 AR 0.9667
Epoch 861 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5727 AR 0.8000
Epoch 861 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5733 AR 0.8000
Epoch 862 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8067 AR 0.9350
Epoch 862 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8471 AR 0.9800
Epoch 862 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7822 AR 1.0000
Epoch 862 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6364 AR 0.8750
Epoch 862 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6322 AR 0.9467
Epoch 862 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5706 AR 0.7850
Epoch 862 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6017 AR 0.8000
Epoch 862 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7142 AR 0.9750
Epoch 862 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6782 AR 0.9250
Epoch 862 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7488 AR 1.0000
Epoch 863 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6567 AR 0.8800
Epoch 863 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7800 AR 1.0000
Epoch 863 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5948 AR 0.8300
Epoch 863 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5937 AR 0.8500
Epoch 863 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7467 AR 0.9550
Epoch 863 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7919 AR 1.0000
Epoch 863 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6155 AR 1.0000
Epoch 863 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6914 AR 0.9000
Epoch 863 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7583 AR 0.9333
Epoch 863 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6988 AR 0.9300
Epoch 864 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6644 AR 0.9333
Epoch 864 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7067 AR 1.0000
Epoch 864 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8298 AR 0.9300
Epoch 864 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6567 AR 0.9467
Epoch 864 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6464 AR 0.8300
Epoch 864 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6396 AR 0.8600
Epoch 864 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7078 AR 0.9800
Epoch 864 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7631 AR 0.9250
Epoch 864 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6800 AR 0.9000
Epoch 864 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7184 AR 0.9750
Epoch 865 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7714 AR 0.9800
Epoch 865 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6737 AR 0.9100
Epoch 865 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.5525 AR 0.9000
Epoch 865 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8720 AR 0.9417
Epoch 865 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.4439 AR 0.7417
Epoch 865 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8172 AR 1.0000
Epoch 865 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7450 AR 0.9350
Epoch 865 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7171 AR 0.8800
Epoch 865 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6746 AR 0.9500
Epoch 865 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7517 AR 1.0000
Epoch 866 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7439 AR 1.0000
Epoch 866 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6172 AR 0.9000
Epoch 866 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6350 AR 0.9000
Epoch 866 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7621 AR 1.0000
Epoch 866 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6667 AR 0.9667
Epoch 866 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7104 AR 0.9600
Epoch 866 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7864 AR 0.9800
Epoch 866 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6975 AR 0.8250
Epoch 866 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8417 AR 0.9750
Epoch 866 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6252 AR 0.9350
Epoch 867 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6755 AR 0.9750
Epoch 867 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7133 AR 0.9550
Epoch 867 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7303 AR 0.9667
Epoch 867 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6088 AR 0.9000
Epoch 867 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6913 AR 0.9300
Epoch 867 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6473 AR 0.8800
Epoch 867 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6796 AR 0.8883
Epoch 867 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7917 AR 0.9800
Epoch 867 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5967 AR 0.8000
Epoch 867 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7750 AR 1.0000
Epoch 868 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8016 AR 0.9800
Epoch 868 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7501 AR 0.9750
Epoch 868 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6438 AR 0.9300
Epoch 868 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6292 AR 0.9000
Epoch 868 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7171 AR 0.9350
Epoch 868 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7000 AR 0.9333
Epoch 868 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8667 AR 1.0000
Epoch 868 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8258 AR 0.9800
Epoch 868 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6639 AR 0.9500
Epoch 868 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6763 AR 0.9000
Epoch 869 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7339 AR 0.8750
Epoch 869 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7797 AR 1.0000
Epoch 869 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6621 AR 0.9000
Epoch 869 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6888 AR 0.9000
Epoch 869 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5763 AR 0.8100
Epoch 869 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6675 AR 0.8967
Epoch 869 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6644 AR 0.9100
Epoch 869 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7971 AR 1.0000
Epoch 869 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8208 AR 1.0000
Epoch 869 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6939 AR 1.0000
Epoch 870 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7256 AR 0.9750
Epoch 870 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7133 AR 0.9350
Epoch 870 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7667 AR 0.9750
Epoch 870 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7271 AR 0.9800
Epoch 870 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8542 AR 0.9750
Epoch 870 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6092 AR 0.8300
Epoch 870 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7039 AR 0.9800
Epoch 870 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7605 AR 0.9333
Epoch 870 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6446 AR 1.0000
Epoch 870 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6438 AR 0.8133
Epoch 871 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6850 AR 0.9000
Epoch 871 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6755 AR 0.8667
Epoch 871 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8038 AR 0.9400
Epoch 871 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7700 AR 0.9500
Epoch 871 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6550 AR 0.9300
Epoch 871 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.4363 AR 0.7250
Epoch 871 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7277 AR 0.9600
Epoch 871 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6783 AR 0.9000
Epoch 871 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6305 AR 0.9800
Epoch 871 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7506 AR 0.9750
Epoch 872 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6576 AR 0.9550
Epoch 872 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7749 AR 0.9800
Epoch 872 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.5950 AR 0.9000
Epoch 872 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7839 AR 0.9500
Epoch 872 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6600 AR 0.9550
Epoch 872 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6483 AR 0.9667
Epoch 872 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6471 AR 0.9217
Epoch 872 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7633 AR 0.9300
Epoch 872 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8842 AR 0.9550
Epoch 872 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7833 AR 1.0000
Epoch 873 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7083 AR 0.9550
Epoch 873 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6347 AR 0.7667
Epoch 873 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6588 AR 0.8600
Epoch 873 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6208 AR 0.8600
Epoch 873 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6875 AR 0.9500
Epoch 873 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7567 AR 1.0000
Epoch 873 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7795 AR 0.9750
Epoch 873 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7375 AR 1.0000
Epoch 873 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6717 AR 0.9600
Epoch 873 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7410 AR 0.9500
Epoch 874 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7160 AR 0.9000
Epoch 874 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6939 AR 0.9800
Epoch 874 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7017 AR 0.9500
Epoch 874 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6672 AR 0.9750
Epoch 874 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7833 AR 0.9667
Epoch 874 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8267 AR 0.9750
Epoch 874 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7407 AR 0.9217
Epoch 874 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6900 AR 1.0000
Epoch 874 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5586 AR 0.8750
Epoch 874 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7233 AR 0.8400
Epoch 875 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7733 AR 1.0000
Epoch 875 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7571 AR 0.9550
Epoch 875 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7488 AR 1.0000
Epoch 875 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7600 AR 0.9750
Epoch 875 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8248 AR 1.0000
Epoch 875 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7945 AR 1.0000
Epoch 875 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5143 AR 0.9000
Epoch 875 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7800 AR 0.9800
Epoch 875 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6683 AR 0.9067
Epoch 875 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7506 AR 1.0000
Epoch 876 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6750 AR 0.9750
Epoch 876 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6613 AR 0.9800
Epoch 876 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8106 AR 0.8800
Epoch 876 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5898 AR 0.8800
Epoch 876 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.5875 AR 0.9000
Epoch 876 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7571 AR 0.8800
Epoch 876 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6025 AR 0.8967
Epoch 876 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8072 AR 0.9750
Epoch 876 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7548 AR 0.9500
Epoch 876 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7250 AR 0.9550
Epoch 877 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6294 AR 0.8467
Epoch 877 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6525 AR 1.0000
Epoch 877 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7155 AR 0.9500
Epoch 877 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7526 AR 0.9350
Epoch 877 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6638 AR 0.9467
Epoch 877 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7892 AR 0.9800
Epoch 877 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7810 AR 0.9750
Epoch 877 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6722 AR 1.0000
Epoch 877 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8039 AR 1.0000
Epoch 877 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8375 AR 0.9800
Epoch 878 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7900 AR 0.9500
Epoch 878 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6671 AR 0.8800
Epoch 878 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6333 AR 0.9500
Epoch 878 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6061 AR 0.9000
Epoch 878 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6685 AR 0.9550
Epoch 878 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7322 AR 0.8883
Epoch 878 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7806 AR 0.9550
Epoch 878 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8042 AR 0.9500
Epoch 878 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7295 AR 0.9500
Epoch 878 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6517 AR 0.9600
Epoch 879 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7106 AR 0.9500
Epoch 879 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8375 AR 1.0000
Epoch 879 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7554 AR 0.9500
Epoch 879 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7333 AR 0.9417
Epoch 879 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7533 AR 1.0000
Epoch 879 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5889 AR 0.8800
Epoch 879 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7571 AR 0.8800
Epoch 879 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6779 AR 0.9100
Epoch 879 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6962 AR 1.0000
Epoch 879 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6338 AR 0.9800
Epoch 880 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7050 AR 1.0000
Epoch 880 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8300 AR 0.9467
Epoch 880 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5705 AR 0.7800
Epoch 880 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6364 AR 0.9750
Epoch 880 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7567 AR 0.9600
Epoch 880 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6423 AR 0.9500
Epoch 880 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7020 AR 0.9750
Epoch 880 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7405 AR 0.9550
Epoch 880 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7964 AR 1.0000
Epoch 880 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8667 AR 0.9800
Epoch 881 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7350 AR 1.0000
Epoch 881 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6581 AR 1.0000
Epoch 881 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7575 AR 0.9750
Epoch 881 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7446 AR 0.9550
Epoch 881 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7325 AR 0.8750
Epoch 881 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8167 AR 0.9600
Epoch 881 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7011 AR 0.9750
Epoch 881 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7121 AR 0.9000
Epoch 881 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7071 AR 0.9600
Epoch 881 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5061 AR 0.7133
Epoch 882 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5952 AR 0.8467
Epoch 882 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7883 AR 1.0000
Epoch 882 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8048 AR 0.9000
Epoch 882 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6472 AR 0.8967
Epoch 882 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6305 AR 0.9300
Epoch 882 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7733 AR 0.9550
Epoch 882 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6605 AR 0.8800
Epoch 882 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5790 AR 0.7800
Epoch 882 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7187 AR 0.9750
Epoch 882 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7642 AR 1.0000
Epoch 883 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7450 AR 0.9750
Epoch 883 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8031 AR 1.0000
Epoch 883 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6964 AR 0.9350
Epoch 883 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6852 AR 0.9600
Epoch 883 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6279 AR 0.8750
Epoch 883 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6821 AR 0.9500
Epoch 883 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7439 AR 0.8750
Epoch 883 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6717 AR 0.9600
Epoch 883 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5838 AR 0.8333
Epoch 883 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7386 AR 0.8750
Epoch 884 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5590 AR 0.8717
Epoch 884 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7342 AR 0.9800
Epoch 884 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7167 AR 0.9000
Epoch 884 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7449 AR 0.9550
Epoch 884 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6606 AR 0.9500
Epoch 884 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8431 AR 0.9750
Epoch 884 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6900 AR 0.7550
Epoch 884 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6583 AR 0.7750
Epoch 884 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6688 AR 1.0000
Epoch 884 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6727 AR 0.9500
Epoch 885 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7050 AR 0.9750
Epoch 885 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6483 AR 0.9750
Epoch 885 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7817 AR 1.0000
Epoch 885 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5981 AR 0.9000
Epoch 885 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7681 AR 0.9467
Epoch 885 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6955 AR 1.0000
Epoch 885 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8683 AR 0.9750
Epoch 885 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7263 AR 1.0000
Epoch 885 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6996 AR 0.9350
Epoch 885 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6877 AR 0.8800
Epoch 886 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7371 AR 0.9667
Epoch 886 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7094 AR 0.9800
Epoch 886 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7750 AR 0.9050
Epoch 886 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7217 AR 1.0000
Epoch 886 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6378 AR 0.9550
Epoch 886 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6338 AR 0.8750
Epoch 886 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6900 AR 0.9000
Epoch 886 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7333 AR 0.9600
Epoch 886 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6700 AR 0.8667
Epoch 886 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7336 AR 0.9800
Epoch 887 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8067 AR 1.0000
Epoch 887 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6280 AR 0.8067
Epoch 887 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7295 AR 0.9750
Epoch 887 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6864 AR 0.9750
Epoch 887 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6895 AR 0.8750
Epoch 887 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7850 AR 1.0000
Epoch 887 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6950 AR 1.0000
Epoch 887 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7305 AR 0.9750
Epoch 887 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7125 AR 0.8967
Epoch 887 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7061 AR 0.9100
Epoch 888 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7821 AR 0.9600
Epoch 888 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7459 AR 0.9800
Epoch 888 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8217 AR 1.0000
Epoch 888 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6860 AR 0.8500
Epoch 888 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7827 AR 0.9750
Epoch 888 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.5983 AR 0.7717
Epoch 888 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7688 AR 1.0000
Epoch 888 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7667 AR 1.0000
Epoch 888 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6381 AR 0.9800
Epoch 888 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5917 AR 0.8350
Epoch 889 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7817 AR 1.0000
Epoch 889 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6303 AR 0.8600
Epoch 889 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7633 AR 0.9800
Epoch 889 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7321 AR 0.9350
Epoch 889 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6983 AR 0.9300
Epoch 889 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7542 AR 0.9500
Epoch 889 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7121 AR 0.9800
Epoch 889 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7656 AR 0.9550
Epoch 889 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8000 AR 1.0000
Epoch 889 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6445 AR 0.9800
Epoch 890 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6952 AR 0.9000
Epoch 890 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6772 AR 0.9250
Epoch 890 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6537 AR 0.8500
Epoch 890 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7071 AR 0.9600
Epoch 890 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7655 AR 0.9333
Epoch 890 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6471 AR 0.8300
Epoch 890 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6700 AR 0.9800
Epoch 890 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7683 AR 0.9500
Epoch 890 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6625 AR 0.9400
Epoch 890 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6439 AR 0.8500
Epoch 891 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7250 AR 0.9750
Epoch 891 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7678 AR 0.9800
Epoch 891 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7772 AR 0.9800
Epoch 891 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7850 AR 0.9750
Epoch 891 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6130 AR 0.9250
Epoch 891 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7511 AR 0.9800
Epoch 891 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6806 AR 0.9667
Epoch 891 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6113 AR 0.8600
Epoch 891 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5394 AR 0.7417
Epoch 891 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7362 AR 0.9250
Epoch 892 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7767 AR 0.9800
Epoch 892 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6464 AR 0.9667
Epoch 892 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8000 AR 0.9500
Epoch 892 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7286 AR 0.9800
Epoch 892 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5630 AR 0.7550
Epoch 892 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6681 AR 0.9750
Epoch 892 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8900 AR 1.0000
Epoch 892 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8750 AR 0.9800
Epoch 892 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6596 AR 0.9800
Epoch 892 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6396 AR 0.9417
Epoch 893 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8483 AR 1.0000
Epoch 893 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7622 AR 0.9750
Epoch 893 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7817 AR 0.9750
Epoch 893 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6887 AR 0.9750
Epoch 893 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7383 AR 0.9300
Epoch 893 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7233 AR 0.8667
Epoch 893 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7183 AR 0.9800
Epoch 893 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7367 AR 0.9800
Epoch 893 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6102 AR 0.9100
Epoch 893 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7171 AR 0.9750
Epoch 894 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6767 AR 0.8750
Epoch 894 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6906 AR 1.0000
Epoch 894 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7508 AR 0.9500
Epoch 894 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7484 AR 0.9750
Epoch 894 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7645 AR 0.8750
Epoch 894 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8133 AR 1.0000
Epoch 894 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6642 AR 0.9550
Epoch 894 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6567 AR 0.8050
Epoch 894 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6386 AR 0.9150
Epoch 894 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7017 AR 0.9050
Epoch 895 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8600 AR 0.9550
Epoch 895 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7044 AR 0.9550
Epoch 895 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7121 AR 0.9500
Epoch 895 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7450 AR 0.9750
Epoch 895 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7583 AR 0.9750
Epoch 895 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6154 AR 0.9600
Epoch 895 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6236 AR 0.9467
Epoch 895 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7238 AR 0.9800
Epoch 895 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6972 AR 0.9000
Epoch 895 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7950 AR 0.9500
Epoch 896 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7239 AR 0.9417
Epoch 896 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6253 AR 0.9000
Epoch 896 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6671 AR 0.9800
Epoch 896 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7288 AR 0.8800
Epoch 896 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7150 AR 0.9750
Epoch 896 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8367 AR 1.0000
Epoch 896 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5983 AR 0.8500
Epoch 896 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8005 AR 1.0000
Epoch 896 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7877 AR 0.9800
Epoch 896 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5367 AR 0.8750
Epoch 897 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.6895 AR 0.9000
Epoch 897 batch 00002: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.6639 AR 0.9800
Epoch 897 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0000 AP 0.6860 AR 0.9467
Epoch 897 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7155 AR 0.9217
Epoch 897 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7067 AR 0.9500
Epoch 897 batch 00006: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.7500 AR 0.8800
Epoch 897 batch 00007: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.8000 AR 0.9417
Epoch 897 batch 00008: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0000 AP 0.6058 AR 0.9000
Epoch 897 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6094 AR 0.8400
Epoch 897 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7821 AR 0.9250
Epoch 898 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.7672 AR 0.9750
Epoch 898 batch 00002: Loss 0.0024 Regression loss 0.0024 Classification loss 0.0001 AP 0.7069 AR 0.9050
Epoch 898 batch 00003: Loss 0.0030 Regression loss 0.0029 Classification loss 0.0001 AP 0.7067 AR 0.9800
Epoch 898 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.7467 AR 0.9667
Epoch 898 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8183 AR 1.0000
Epoch 898 batch 00006: Loss 0.0036 Regression loss 0.0035 Classification loss 0.0001 AP 0.6400 AR 0.8500
Epoch 898 batch 00007: Loss 0.0024 Regression loss 0.0023 Classification loss 0.0001 AP 0.7614 AR 0.9250
Epoch 898 batch 00008: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.6066 AR 0.9267
Epoch 898 batch 00009: Loss 0.0058 Regression loss 0.0057 Classification loss 0.0001 AP 0.7463 AR 0.9600
Epoch 898 batch 00010: Loss 0.0066 Regression loss 0.0066 Classification loss 0.0001 AP 0.5389 AR 0.7900
Epoch 899 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7226 AR 0.9800
Epoch 899 batch 00002: Loss 0.0037 Regression loss 0.0037 Classification loss 0.0000 AP 0.7643 AR 0.9750
Epoch 899 batch 00003: Loss 0.0047 Regression loss 0.0047 Classification loss 0.0001 AP 0.5952 AR 0.9800
Epoch 899 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7150 AR 0.9000
Epoch 899 batch 00005: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.8600 AR 1.0000
Epoch 899 batch 00006: Loss 0.0021 Regression loss 0.0021 Classification loss 0.0001 AP 0.6733 AR 0.8850
Epoch 899 batch 00007: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.5720 AR 0.8300
Epoch 899 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7177 AR 0.9350
Epoch 899 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6708 AR 0.9800
Epoch 899 batch 00010: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0001 AP 0.6317 AR 0.8500
Epoch 900 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7183 AR 0.9600
Epoch 900 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7348 AR 0.9600
Epoch 900 batch 00003: Loss 0.0016 Regression loss 0.0016 Classification loss 0.0000 AP 0.7838 AR 1.0000
Epoch 900 batch 00004: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6058 AR 0.8000
Epoch 900 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8255 AR 0.9800
Epoch 900 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7485 AR 1.0000
Epoch 900 batch 00007: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0001 AP 0.6600 AR 1.0000
Epoch 900 batch 00008: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.6698 AR 0.9000
Epoch 900 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7820 AR 0.9750
Epoch 900 batch 00010: Loss 0.0023 Regression loss 0.0022 Classification loss 0.0000 AP 0.6656 AR 0.9500
Epoch 901 batch 00001: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0002 AP 0.6564 AR 0.9750
Epoch 901 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7435 AR 0.9800
Epoch 901 batch 00003: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0001 AP 0.6114 AR 0.8300
Epoch 901 batch 00004: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.6900 AR 0.9800
Epoch 901 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7200 AR 0.9600
Epoch 901 batch 00006: Loss 0.0022 Regression loss 0.0022 Classification loss 0.0001 AP 0.7838 AR 1.0000
Epoch 901 batch 00007: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.8367 AR 0.9750
Epoch 901 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6962 AR 0.8300
Epoch 901 batch 00009: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.7064 AR 0.9750
Epoch 901 batch 00010: Loss 0.0018 Regression loss 0.0018 Classification loss 0.0001 AP 0.8900 AR 0.9667
Epoch 902 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8595 AR 0.9500
Epoch 902 batch 00002: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.6333 AR 1.0000
Epoch 902 batch 00003: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.6550 AR 0.9500
Epoch 902 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5995 AR 0.8750
Epoch 902 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.8621 AR 0.9750
Epoch 902 batch 00006: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.7817 AR 0.9800
Epoch 902 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7239 AR 0.9600
Epoch 902 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6863 AR 0.9550
Epoch 902 batch 00009: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.7200 AR 0.8750
Epoch 902 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6183 AR 0.9600
Epoch 903 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6400 AR 0.8500
Epoch 903 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8150 AR 0.9500
Epoch 903 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8164 AR 0.9417
Epoch 903 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8083 AR 1.0000
Epoch 903 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6799 AR 0.9750
Epoch 903 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5107 AR 0.8200
Epoch 903 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7067 AR 1.0000
Epoch 903 batch 00008: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0000 AP 0.6675 AR 0.9300
Epoch 903 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7127 AR 0.9300
Epoch 903 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7488 AR 1.0000
Epoch 904 batch 00001: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6935 AR 0.8750
Epoch 904 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7944 AR 0.9800
Epoch 904 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7469 AR 0.9800
Epoch 904 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6392 AR 0.8300
Epoch 904 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6972 AR 1.0000
Epoch 904 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7333 AR 0.9350
Epoch 904 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6506 AR 0.8550
Epoch 904 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8711 AR 0.9800
Epoch 904 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6425 AR 1.0000
Epoch 904 batch 00010: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6321 AR 1.0000
Epoch 905 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7210 AR 1.0000
Epoch 905 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6733 AR 1.0000
Epoch 905 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6437 AR 0.9167
Epoch 905 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6755 AR 0.8600
Epoch 905 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7733 AR 1.0000
Epoch 905 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5461 AR 0.7800
Epoch 905 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7236 AR 0.9500
Epoch 905 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6328 AR 0.9600
Epoch 905 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7900 AR 0.9000
Epoch 905 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7450 AR 0.9000
Epoch 906 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6875 AR 1.0000
Epoch 906 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.6979 AR 0.8800
Epoch 906 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7480 AR 0.9217
Epoch 906 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.6533 AR 0.9000
Epoch 906 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7639 AR 1.0000
Epoch 906 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7778 AR 0.9500
Epoch 906 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7583 AR 0.9467
Epoch 906 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7083 AR 0.9800
Epoch 906 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7267 AR 0.9800
Epoch 906 batch 00010: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.7905 AR 1.0000
Epoch 907 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6717 AR 0.9000
Epoch 907 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6567 AR 0.7800
Epoch 907 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6183 AR 0.7417
Epoch 907 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6763 AR 0.9800
Epoch 907 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6714 AR 0.8967
Epoch 907 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5867 AR 0.9600
Epoch 907 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7367 AR 0.9350
Epoch 907 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7739 AR 1.0000
Epoch 907 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7667 AR 0.9800
Epoch 907 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7767 AR 0.9800
Epoch 908 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6877 AR 0.9550
Epoch 908 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8050 AR 0.9250
Epoch 908 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8211 AR 0.9800
Epoch 908 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7167 AR 1.0000
Epoch 908 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6845 AR 1.0000
Epoch 908 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7352 AR 0.9600
Epoch 908 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5300 AR 0.7750
Epoch 908 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7442 AR 0.9217
Epoch 908 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6221 AR 0.9667
Epoch 908 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7533 AR 1.0000
Epoch 909 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7083 AR 1.0000
Epoch 909 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7306 AR 0.9750
Epoch 909 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6221 AR 0.9667
Epoch 909 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8917 AR 1.0000
Epoch 909 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6233 AR 0.9000
Epoch 909 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6663 AR 0.9000
Epoch 909 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7508 AR 0.9800
Epoch 909 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6614 AR 0.9017
Epoch 909 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7917 AR 0.9800
Epoch 909 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8272 AR 0.9550
Epoch 910 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7367 AR 1.0000
Epoch 910 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7805 AR 0.9800
Epoch 910 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7017 AR 0.8667
Epoch 910 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8014 AR 0.9750
Epoch 910 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7583 AR 0.9750
Epoch 910 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5877 AR 0.8000
Epoch 910 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6675 AR 0.9300
Epoch 910 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7222 AR 0.9800
Epoch 910 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6514 AR 0.9800
Epoch 910 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6900 AR 0.9550
Epoch 911 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7675 AR 0.9750
Epoch 911 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7886 AR 1.0000
Epoch 911 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6167 AR 0.9000
Epoch 911 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7442 AR 0.9467
Epoch 911 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7212 AR 0.9250
Epoch 911 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6083 AR 0.9250
Epoch 911 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7342 AR 0.9150
Epoch 911 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6810 AR 0.8400
Epoch 911 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7393 AR 0.9750
Epoch 911 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8150 AR 0.9667
Epoch 912 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6683 AR 0.9000
Epoch 912 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8567 AR 0.9800
Epoch 912 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8564 AR 1.0000
Epoch 912 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7393 AR 0.9800
Epoch 912 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5921 AR 0.8550
Epoch 912 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6458 AR 0.9300
Epoch 912 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7425 AR 0.9667
Epoch 912 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6658 AR 0.9300
Epoch 912 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5259 AR 0.9000
Epoch 912 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7088 AR 0.8800
Epoch 913 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7500 AR 0.9217
Epoch 913 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7856 AR 0.9550
Epoch 913 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7821 AR 1.0000
Epoch 913 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7248 AR 1.0000
Epoch 913 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6558 AR 0.9750
Epoch 913 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8017 AR 0.9750
Epoch 913 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7414 AR 1.0000
Epoch 913 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6321 AR 0.8800
Epoch 913 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7600 AR 0.9750
Epoch 913 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6205 AR 0.9400
Epoch 914 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6764 AR 0.9750
Epoch 914 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8042 AR 0.9550
Epoch 914 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8098 AR 0.9550
Epoch 914 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6983 AR 0.9600
Epoch 914 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6033 AR 0.8550
Epoch 914 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8800 AR 1.0000
Epoch 914 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6800 AR 0.8000
Epoch 914 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6766 AR 0.9750
Epoch 914 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6288 AR 0.7800
Epoch 914 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6172 AR 1.0000
Epoch 915 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7400 AR 0.9600
Epoch 915 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7817 AR 0.9800
Epoch 915 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7567 AR 0.9000
Epoch 915 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7250 AR 0.8667
Epoch 915 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6572 AR 0.9250
Epoch 915 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7455 AR 0.9067
Epoch 915 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6037 AR 0.9750
Epoch 915 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8171 AR 1.0000
Epoch 915 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6240 AR 0.9750
Epoch 915 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7683 AR 0.9800
Epoch 916 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6014 AR 0.9000
Epoch 916 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7035 AR 0.9600
Epoch 916 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6661 AR 0.9600
Epoch 916 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8245 AR 0.9500
Epoch 916 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8267 AR 1.0000
Epoch 916 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8167 AR 1.0000
Epoch 916 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8467 AR 0.9800
Epoch 916 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6033 AR 0.9550
Epoch 916 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6881 AR 0.8667
Epoch 916 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6808 AR 0.8800
Epoch 917 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7805 AR 1.0000
Epoch 917 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7517 AR 1.0000
Epoch 917 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7267 AR 0.9550
Epoch 917 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7688 AR 0.9550
Epoch 917 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6553 AR 0.9600
Epoch 917 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7692 AR 1.0000
Epoch 917 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6755 AR 1.0000
Epoch 917 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6433 AR 0.8750
Epoch 917 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7556 AR 0.9300
Epoch 917 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6856 AR 0.8217
Epoch 918 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7850 AR 0.9300
Epoch 918 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7060 AR 0.9800
Epoch 918 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6617 AR 0.9400
Epoch 918 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6338 AR 0.8417
Epoch 918 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5822 AR 0.8550
Epoch 918 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7562 AR 0.9000
Epoch 918 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7622 AR 0.9750
Epoch 918 batch 00008: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7208 AR 0.9500
Epoch 918 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7705 AR 0.9800
Epoch 918 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5575 AR 0.7500
Epoch 919 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.6326 AR 0.9417
Epoch 919 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6855 AR 0.9800
Epoch 919 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6821 AR 0.9467
Epoch 919 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8350 AR 0.9600
Epoch 919 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7067 AR 0.9750
Epoch 919 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8017 AR 0.8750
Epoch 919 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8239 AR 0.9800
Epoch 919 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7892 AR 0.9750
Epoch 919 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6066 AR 0.9000
Epoch 919 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6017 AR 0.7717
Epoch 920 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7389 AR 0.9500
Epoch 920 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7288 AR 0.9800
Epoch 920 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6645 AR 0.8017
Epoch 920 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7667 AR 1.0000
Epoch 920 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7556 AR 0.9750
Epoch 920 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7058 AR 1.0000
Epoch 920 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6906 AR 0.9050
Epoch 920 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6825 AR 0.9750
Epoch 920 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7158 AR 0.9600
Epoch 920 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7533 AR 0.9800
Epoch 921 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6083 AR 0.9800
Epoch 921 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7570 AR 0.9750
Epoch 921 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6510 AR 0.9000
Epoch 921 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8098 AR 1.0000
Epoch 921 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6811 AR 0.9200
Epoch 921 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7637 AR 0.9750
Epoch 921 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8210 AR 0.9750
Epoch 921 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6588 AR 0.9217
Epoch 921 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7333 AR 0.9750
Epoch 921 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7664 AR 0.9800
Epoch 922 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7083 AR 0.8417
Epoch 922 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6921 AR 0.9400
Epoch 922 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6292 AR 0.7550
Epoch 922 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6738 AR 0.9800
Epoch 922 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6304 AR 0.9350
Epoch 922 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.7467 AR 1.0000
Epoch 922 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7498 AR 0.9750
Epoch 922 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6721 AR 0.9417
Epoch 922 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7550 AR 0.9167
Epoch 922 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7505 AR 0.9000
Epoch 923 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6008 AR 0.8667
Epoch 923 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6983 AR 0.8750
Epoch 923 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7795 AR 0.9800
Epoch 923 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6633 AR 0.9467
Epoch 923 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6183 AR 0.9400
Epoch 923 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7518 AR 0.9500
Epoch 923 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7188 AR 1.0000
Epoch 923 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7898 AR 0.9750
Epoch 923 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6889 AR 0.9600
Epoch 923 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7667 AR 0.9000
Epoch 924 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6242 AR 0.9667
Epoch 924 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7522 AR 0.8767
Epoch 924 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6443 AR 0.9600
Epoch 924 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5910 AR 0.8750
Epoch 924 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8433 AR 0.9750
Epoch 924 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6330 AR 0.8500
Epoch 924 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6089 AR 0.8750
Epoch 924 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7798 AR 0.9750
Epoch 924 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7969 AR 0.9800
Epoch 924 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7661 AR 0.9467
Epoch 925 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6339 AR 0.8583
Epoch 925 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6755 AR 0.9750
Epoch 925 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8239 AR 0.9750
Epoch 925 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6312 AR 0.9083
Epoch 925 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8617 AR 1.0000
Epoch 925 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7606 AR 0.9800
Epoch 925 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8033 AR 0.9800
Epoch 925 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7671 AR 0.8600
Epoch 925 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5881 AR 0.9000
Epoch 925 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6500 AR 0.9550
Epoch 926 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7283 AR 1.0000
Epoch 926 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7562 AR 0.9750
Epoch 926 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7872 AR 0.9217
Epoch 926 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8297 AR 0.9750
Epoch 926 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6000 AR 0.8167
Epoch 926 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7325 AR 1.0000
Epoch 926 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6783 AR 1.0000
Epoch 926 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7030 AR 0.9300
Epoch 926 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6405 AR 0.8600
Epoch 926 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6706 AR 0.9550
Epoch 927 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7500 AR 1.0000
Epoch 927 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7300 AR 0.8800
Epoch 927 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6733 AR 0.9600
Epoch 927 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7514 AR 0.9467
Epoch 927 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8417 AR 0.9750
Epoch 927 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6600 AR 0.9800
Epoch 927 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6476 AR 0.8917
Epoch 927 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6721 AR 0.8550
Epoch 927 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7442 AR 0.9750
Epoch 927 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6427 AR 0.9350
Epoch 928 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7345 AR 0.9750
Epoch 928 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8067 AR 0.9800
Epoch 928 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5645 AR 0.8500
Epoch 928 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8114 AR 1.0000
Epoch 928 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8171 AR 0.9800
Epoch 928 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6700 AR 0.8750
Epoch 928 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5958 AR 0.8000
Epoch 928 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7239 AR 0.9600
Epoch 928 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6926 AR 1.0000
Epoch 928 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6475 AR 0.8667
Epoch 929 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6183 AR 0.9800
Epoch 929 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6969 AR 0.9300
Epoch 929 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7067 AR 0.9417
Epoch 929 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7439 AR 0.9100
Epoch 929 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6398 AR 0.8750
Epoch 929 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8233 AR 0.9750
Epoch 929 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6114 AR 0.8350
Epoch 929 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7186 AR 0.9800
Epoch 929 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7511 AR 0.9550
Epoch 929 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7095 AR 0.8500
Epoch 930 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6295 AR 0.8050
Epoch 930 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6576 AR 0.8250
Epoch 930 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6996 AR 0.9550
Epoch 930 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6952 AR 0.8550
Epoch 930 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5947 AR 0.8750
Epoch 930 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6300 AR 0.9167
Epoch 930 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7271 AR 0.9800
Epoch 930 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7133 AR 0.9000
Epoch 930 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6921 AR 0.9600
Epoch 930 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8772 AR 1.0000
Epoch 931 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6892 AR 0.9667
Epoch 931 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7773 AR 0.9500
Epoch 931 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6939 AR 1.0000
Epoch 931 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5881 AR 0.8800
Epoch 931 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8667 AR 0.9550
Epoch 931 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7539 AR 0.9750
Epoch 931 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7013 AR 0.8800
Epoch 931 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6006 AR 0.9000
Epoch 931 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7167 AR 0.8550
Epoch 931 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6892 AR 0.8750
Epoch 932 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6800 AR 0.9000
Epoch 932 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7083 AR 0.9750
Epoch 932 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7583 AR 0.9350
Epoch 932 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6371 AR 0.9000
Epoch 932 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7250 AR 0.8750
Epoch 932 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6229 AR 0.8750
Epoch 932 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7617 AR 0.9750
Epoch 932 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7283 AR 0.9750
Epoch 932 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6988 AR 0.9150
Epoch 932 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7453 AR 0.9750
Epoch 933 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7594 AR 0.9800
Epoch 933 batch 00002: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.7250 AR 0.9500
Epoch 933 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7588 AR 1.0000
Epoch 933 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7395 AR 0.9800
Epoch 933 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7014 AR 1.0000
Epoch 933 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5733 AR 0.7967
Epoch 933 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5739 AR 0.7917
Epoch 933 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7388 AR 0.9400
Epoch 933 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7380 AR 1.0000
Epoch 933 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7400 AR 0.9000
Epoch 934 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6869 AR 0.9150
Epoch 934 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7783 AR 0.9750
Epoch 934 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6833 AR 0.9417
Epoch 934 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6710 AR 0.8800
Epoch 934 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7460 AR 0.9667
Epoch 934 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7148 AR 0.9217
Epoch 934 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6533 AR 0.9750
Epoch 934 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.5906 AR 0.7750
Epoch 934 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6911 AR 0.9800
Epoch 934 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6850 AR 0.8300
Epoch 935 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6250 AR 0.8750
Epoch 935 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7375 AR 0.9250
Epoch 935 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7021 AR 0.9800
Epoch 935 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8300 AR 0.9467
Epoch 935 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6922 AR 0.9800
Epoch 935 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7672 AR 0.9417
Epoch 935 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5894 AR 0.8800
Epoch 935 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7633 AR 0.9400
Epoch 935 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7080 AR 0.9750
Epoch 935 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7105 AR 0.8800
Epoch 936 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6053 AR 0.8800
Epoch 936 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.5689 AR 0.9750
Epoch 936 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7281 AR 0.9750
Epoch 936 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6967 AR 0.9000
Epoch 936 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7169 AR 0.9800
Epoch 936 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5446 AR 0.7750
Epoch 936 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8733 AR 0.9550
Epoch 936 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7917 AR 0.9750
Epoch 936 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8017 AR 0.9500
Epoch 936 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7399 AR 0.9100
Epoch 937 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7194 AR 0.9800
Epoch 937 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8448 AR 0.9800
Epoch 937 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7833 AR 0.9550
Epoch 937 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7760 AR 0.9800
Epoch 937 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6771 AR 0.9550
Epoch 937 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6296 AR 0.8750
Epoch 937 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7325 AR 1.0000
Epoch 937 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7889 AR 0.9667
Epoch 937 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5325 AR 0.8250
Epoch 937 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6580 AR 0.9217
Epoch 938 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7217 AR 0.9350
Epoch 938 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7833 AR 0.9500
Epoch 938 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6520 AR 0.9500
Epoch 938 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6906 AR 0.9667
Epoch 938 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6106 AR 0.8400
Epoch 938 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7650 AR 0.9500
Epoch 938 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7117 AR 0.9750
Epoch 938 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6731 AR 0.9750
Epoch 938 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8571 AR 0.9800
Epoch 938 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7738 AR 1.0000
Epoch 939 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8114 AR 0.9750
Epoch 939 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.7588 AR 0.9750
Epoch 939 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5494 AR 0.9800
Epoch 939 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7214 AR 0.8750
Epoch 939 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7180 AR 0.9217
Epoch 939 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7933 AR 1.0000
Epoch 939 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7330 AR 0.8800
Epoch 939 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8164 AR 0.9667
Epoch 939 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7317 AR 0.9750
Epoch 939 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5103 AR 0.7800
Epoch 940 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.5906 AR 0.9217
Epoch 940 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7064 AR 0.9000
Epoch 940 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7150 AR 0.9750
Epoch 940 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8233 AR 1.0000
Epoch 940 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6837 AR 0.8550
Epoch 940 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6867 AR 1.0000
Epoch 940 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6338 AR 0.8500
Epoch 940 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.9175 AR 0.9800
Epoch 940 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7406 AR 0.9750
Epoch 940 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6857 AR 1.0000
Epoch 941 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8156 AR 0.8750
Epoch 941 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6843 AR 0.9550
Epoch 941 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6606 AR 0.8000
Epoch 941 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6948 AR 0.9000
Epoch 941 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6304 AR 0.9550
Epoch 941 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7550 AR 0.9550
Epoch 941 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7481 AR 0.9467
Epoch 941 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8131 AR 1.0000
Epoch 941 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6820 AR 0.9750
Epoch 941 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6417 AR 0.9800
Epoch 942 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7064 AR 0.9750
Epoch 942 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.5821 AR 1.0000
Epoch 942 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8833 AR 1.0000
Epoch 942 batch 00004: Loss 0.0015 Regression loss 0.0015 Classification loss 0.0000 AP 0.8017 AR 0.9600
Epoch 942 batch 00005: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0001 AP 0.6971 AR 0.9550
Epoch 942 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7892 AR 0.9550
Epoch 942 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7048 AR 0.9750
Epoch 942 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6649 AR 0.9150
Epoch 942 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6771 AR 0.9000
Epoch 942 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6225 AR 0.9000
Epoch 943 batch 00001: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.7667 AR 1.0000
Epoch 943 batch 00002: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7505 AR 0.8550
Epoch 943 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7050 AR 0.9550
Epoch 943 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6133 AR 0.8750
Epoch 943 batch 00005: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0000 AP 0.6411 AR 0.9500
Epoch 943 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8267 AR 0.9000
Epoch 943 batch 00007: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7839 AR 0.9800
Epoch 943 batch 00008: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0001 AP 0.6614 AR 0.8550
Epoch 943 batch 00009: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.7975 AR 0.9800
Epoch 943 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6060 AR 1.0000
Epoch 944 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6983 AR 0.9667
Epoch 944 batch 00002: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.7216 AR 0.9800
Epoch 944 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.5981 AR 0.9750
Epoch 944 batch 00004: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.7750 AR 0.9500
Epoch 944 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6550 AR 0.8750
Epoch 944 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7781 AR 1.0000
Epoch 944 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6460 AR 0.8800
Epoch 944 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7792 AR 0.9800
Epoch 944 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6694 AR 0.9750
Epoch 944 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7483 AR 0.9067
Epoch 945 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6700 AR 0.9000
Epoch 945 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6883 AR 0.9500
Epoch 945 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7622 AR 0.9800
Epoch 945 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7821 AR 1.0000
Epoch 945 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6630 AR 0.9050
Epoch 945 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8125 AR 1.0000
Epoch 945 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6002 AR 0.9000
Epoch 945 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6337 AR 0.9350
Epoch 945 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.8050 AR 0.9667
Epoch 945 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6636 AR 0.8800
Epoch 946 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6981 AR 0.8800
Epoch 946 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7000 AR 0.9800
Epoch 946 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7688 AR 0.9750
Epoch 946 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7014 AR 0.9800
Epoch 946 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7417 AR 1.0000
Epoch 946 batch 00006: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7350 AR 0.8750
Epoch 946 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6776 AR 0.9467
Epoch 946 batch 00008: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.6606 AR 0.8500
Epoch 946 batch 00009: Loss 0.0014 Regression loss 0.0014 Classification loss 0.0001 AP 0.6863 AR 0.9550
Epoch 946 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6700 AR 0.7550
Epoch 947 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7798 AR 1.0000
Epoch 947 batch 00002: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7561 AR 0.9550
Epoch 947 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7150 AR 0.9100
Epoch 947 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7117 AR 0.9750
Epoch 947 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7050 AR 0.9250
Epoch 947 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6605 AR 0.9100
Epoch 947 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6508 AR 0.8750
Epoch 947 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8025 AR 0.9667
Epoch 947 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6333 AR 0.8667
Epoch 947 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7706 AR 1.0000
Epoch 948 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8257 AR 0.9600
Epoch 948 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7983 AR 0.9750
Epoch 948 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.8033 AR 1.0000
Epoch 948 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.4977 AR 0.9350
Epoch 948 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7400 AR 0.9800
Epoch 948 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6613 AR 0.8800
Epoch 948 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6842 AR 0.9750
Epoch 948 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7938 AR 0.9750
Epoch 948 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5480 AR 0.8417
Epoch 948 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8114 AR 1.0000
Epoch 949 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8388 AR 1.0000
Epoch 949 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6745 AR 0.8550
Epoch 949 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8317 AR 0.9667
Epoch 949 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7542 AR 1.0000
Epoch 949 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5792 AR 0.9550
Epoch 949 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6185 AR 0.9400
Epoch 949 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6307 AR 0.8500
Epoch 949 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7272 AR 0.9750
Epoch 949 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6514 AR 0.9000
Epoch 949 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7266 AR 0.9400
Epoch 950 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7000 AR 0.9550
Epoch 950 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7200 AR 0.9800
Epoch 950 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8133 AR 0.9400
Epoch 950 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8025 AR 0.9750
Epoch 950 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6536 AR 0.8467
Epoch 950 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6992 AR 0.9050
Epoch 950 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6814 AR 0.9750
Epoch 950 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7539 AR 1.0000
Epoch 950 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6033 AR 0.9167
Epoch 950 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7300 AR 0.8600
Epoch 951 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7356 AR 0.9417
Epoch 951 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6359 AR 0.8800
Epoch 951 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7992 AR 0.9600
Epoch 951 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7367 AR 0.9750
Epoch 951 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.6167 AR 0.9550
Epoch 951 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6578 AR 0.8550
Epoch 951 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8600 AR 0.9750
Epoch 951 batch 00008: Loss 0.0014 Regression loss 0.0014 Classification loss 0.0000 AP 0.8417 AR 1.0000
Epoch 951 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6981 AR 0.9500
Epoch 951 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5238 AR 0.8667
Epoch 952 batch 00001: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.6667 AR 0.8050
Epoch 952 batch 00002: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0001 AP 0.7850 AR 1.0000
Epoch 952 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.6669 AR 0.9800
Epoch 952 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6556 AR 0.8750
Epoch 952 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.7046 AR 1.0000
Epoch 952 batch 00006: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0000 AP 0.7437 AR 0.9500
Epoch 952 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7756 AR 0.9667
Epoch 952 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7300 AR 1.0000
Epoch 952 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6145 AR 0.8800
Epoch 952 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8717 AR 1.0000
Epoch 953 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7442 AR 0.9600
Epoch 953 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7267 AR 0.9300
Epoch 953 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6367 AR 1.0000
Epoch 953 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6637 AR 0.9417
Epoch 953 batch 00005: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0000 AP 0.8300 AR 0.9550
Epoch 953 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6847 AR 1.0000
Epoch 953 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7106 AR 1.0000
Epoch 953 batch 00008: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7119 AR 0.9600
Epoch 953 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7317 AR 0.8750
Epoch 953 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8800 AR 1.0000
Epoch 954 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.6681 AR 0.9550
Epoch 954 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5250 AR 0.8667
Epoch 954 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7452 AR 0.9600
Epoch 954 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6814 AR 0.9750
Epoch 954 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6055 AR 0.8800
Epoch 954 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6794 AR 0.9600
Epoch 954 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7617 AR 0.9750
Epoch 954 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7677 AR 1.0000
Epoch 954 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8339 AR 0.9750
Epoch 954 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8071 AR 0.9550
Epoch 955 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7203 AR 0.9800
Epoch 955 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7050 AR 0.8550
Epoch 955 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6937 AR 0.9750
Epoch 955 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6575 AR 0.9800
Epoch 955 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6000 AR 0.9167
Epoch 955 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6667 AR 0.8800
Epoch 955 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7026 AR 0.8667
Epoch 955 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8000 AR 0.9750
Epoch 955 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7708 AR 0.9250
Epoch 955 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7912 AR 1.0000
Epoch 956 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7081 AR 0.9300
Epoch 956 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8073 AR 0.9800
Epoch 956 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7533 AR 1.0000
Epoch 956 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7162 AR 0.9750
Epoch 956 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7600 AR 0.9750
Epoch 956 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6712 AR 0.9417
Epoch 956 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7171 AR 0.8217
Epoch 956 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7164 AR 0.9600
Epoch 956 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5493 AR 0.9000
Epoch 956 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6683 AR 0.9000
Epoch 957 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8117 AR 0.9800
Epoch 957 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7546 AR 0.9400
Epoch 957 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7617 AR 0.9500
Epoch 957 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.5434 AR 0.8750
Epoch 957 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7220 AR 1.0000
Epoch 957 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6905 AR 1.0000
Epoch 957 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6067 AR 0.9350
Epoch 957 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7271 AR 0.9000
Epoch 957 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7295 AR 0.9750
Epoch 957 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7712 AR 0.9417
Epoch 958 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6429 AR 0.9000
Epoch 958 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8131 AR 1.0000
Epoch 958 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7650 AR 0.9750
Epoch 958 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6396 AR 0.9600
Epoch 958 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7850 AR 0.9550
Epoch 958 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5242 AR 0.7800
Epoch 958 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7305 AR 0.8800
Epoch 958 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7080 AR 1.0000
Epoch 958 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7433 AR 0.9750
Epoch 958 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6517 AR 0.9000
Epoch 959 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6058 AR 0.9000
Epoch 959 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6461 AR 0.8667
Epoch 959 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8250 AR 0.9750
Epoch 959 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6979 AR 1.0000
Epoch 959 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7617 AR 0.9600
Epoch 959 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7628 AR 0.9750
Epoch 959 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7183 AR 0.8750
Epoch 959 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7238 AR 0.9800
Epoch 959 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7164 AR 0.8500
Epoch 959 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6390 AR 0.9467
Epoch 960 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8871 AR 0.9800
Epoch 960 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.9400 AR 1.0000
Epoch 960 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7433 AR 1.0000
Epoch 960 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.4378 AR 0.6133
Epoch 960 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7147 AR 1.0000
Epoch 960 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7305 AR 1.0000
Epoch 960 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6650 AR 0.9750
Epoch 960 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7327 AR 0.9800
Epoch 960 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6155 AR 0.8800
Epoch 960 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6100 AR 0.7967
Epoch 961 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6380 AR 0.9000
Epoch 961 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6300 AR 0.9017
Epoch 961 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6567 AR 0.9500
Epoch 961 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.9083 AR 0.9750
Epoch 961 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7167 AR 1.0000
Epoch 961 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6230 AR 0.9750
Epoch 961 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5706 AR 0.8467
Epoch 961 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8625 AR 1.0000
Epoch 961 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7584 AR 0.9750
Epoch 961 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6817 AR 0.9600
Epoch 962 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7648 AR 0.9750
Epoch 962 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7792 AR 1.0000
Epoch 962 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6440 AR 0.9800
Epoch 962 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6722 AR 0.9800
Epoch 962 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6935 AR 0.8750
Epoch 962 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6188 AR 0.8750
Epoch 962 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7250 AR 0.9417
Epoch 962 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7517 AR 0.9550
Epoch 962 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7823 AR 0.9217
Epoch 962 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7053 AR 1.0000
Epoch 963 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5880 AR 0.9750
Epoch 963 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7700 AR 1.0000
Epoch 963 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7260 AR 0.9000
Epoch 963 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6737 AR 0.9667
Epoch 963 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7567 AR 0.9750
Epoch 963 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6608 AR 0.9800
Epoch 963 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5708 AR 0.8000
Epoch 963 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8100 AR 0.9600
Epoch 963 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7217 AR 0.9133
Epoch 963 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7243 AR 0.9050
Epoch 964 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8217 AR 0.9550
Epoch 964 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7133 AR 0.9600
Epoch 964 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6964 AR 1.0000
Epoch 964 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7796 AR 1.0000
Epoch 964 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6519 AR 1.0000
Epoch 964 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7298 AR 1.0000
Epoch 964 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6788 AR 0.9000
Epoch 964 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6900 AR 0.8800
Epoch 964 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7295 AR 0.9750
Epoch 964 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7700 AR 1.0000
Epoch 965 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.8067 AR 0.9600
Epoch 965 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6976 AR 0.9800
Epoch 965 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6893 AR 0.9050
Epoch 965 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6031 AR 0.9467
Epoch 965 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6727 AR 0.9000
Epoch 965 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7450 AR 0.9800
Epoch 965 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7367 AR 1.0000
Epoch 965 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.9167 AR 0.9750
Epoch 965 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6314 AR 0.9667
Epoch 965 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6856 AR 0.9800
Epoch 966 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6597 AR 0.9000
Epoch 966 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6790 AR 0.9600
Epoch 966 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6606 AR 0.9750
Epoch 966 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7821 AR 1.0000
Epoch 966 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7733 AR 0.9800
Epoch 966 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8217 AR 0.9750
Epoch 966 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7089 AR 0.9417
Epoch 966 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6125 AR 0.8550
Epoch 966 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6977 AR 0.9000
Epoch 966 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7217 AR 0.9300
Epoch 967 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7981 AR 1.0000
Epoch 967 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5445 AR 0.7250
Epoch 967 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8246 AR 1.0000
Epoch 967 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6071 AR 0.7550
Epoch 967 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8200 AR 1.0000
Epoch 967 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7163 AR 0.9300
Epoch 967 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7806 AR 0.9800
Epoch 967 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5669 AR 0.8350
Epoch 967 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7008 AR 0.9500
Epoch 967 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6125 AR 0.9800
Epoch 968 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8758 AR 1.0000
Epoch 968 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7240 AR 0.9350
Epoch 968 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7471 AR 1.0000
Epoch 968 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7775 AR 0.9600
Epoch 968 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6733 AR 0.9250
Epoch 968 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7470 AR 0.9800
Epoch 968 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6213 AR 0.8750
Epoch 968 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7000 AR 0.9750
Epoch 968 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7367 AR 1.0000
Epoch 968 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7110 AR 1.0000
Epoch 969 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7217 AR 0.9300
Epoch 969 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7539 AR 1.0000
Epoch 969 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.7517 AR 0.9750
Epoch 969 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7723 AR 0.9417
Epoch 969 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7100 AR 0.9600
Epoch 969 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7872 AR 0.9750
Epoch 969 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6051 AR 0.9350
Epoch 969 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6641 AR 0.9750
Epoch 969 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6000 AR 0.7800
Epoch 969 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7714 AR 0.9800
Epoch 970 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7498 AR 0.9500
Epoch 970 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6729 AR 0.9750
Epoch 970 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7171 AR 0.9350
Epoch 970 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8686 AR 1.0000
Epoch 970 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7500 AR 1.0000
Epoch 970 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8094 AR 0.9600
Epoch 970 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7017 AR 0.8800
Epoch 970 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6255 AR 0.9267
Epoch 970 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7672 AR 1.0000
Epoch 970 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5458 AR 0.9750
Epoch 971 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.5964 AR 0.7917
Epoch 971 batch 00002: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7955 AR 0.9550
Epoch 971 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6306 AR 0.9550
Epoch 971 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7863 AR 0.9800
Epoch 971 batch 00005: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.7233 AR 0.9750
Epoch 971 batch 00006: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0000 AP 0.7089 AR 0.9750
Epoch 971 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7012 AR 0.9500
Epoch 971 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7731 AR 0.9750
Epoch 971 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6838 AR 0.9667
Epoch 971 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7161 AR 0.9600
Epoch 972 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6655 AR 0.9167
Epoch 972 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7405 AR 1.0000
Epoch 972 batch 00003: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7967 AR 0.9550
Epoch 972 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7664 AR 0.9550
Epoch 972 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8300 AR 0.9750
Epoch 972 batch 00006: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.5053 AR 0.8500
Epoch 972 batch 00007: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0000 AP 0.7862 AR 1.0000
Epoch 972 batch 00008: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0000 AP 0.7042 AR 0.9600
Epoch 972 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6537 AR 0.9067
Epoch 972 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8317 AR 1.0000
Epoch 973 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8714 AR 1.0000
Epoch 973 batch 00002: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.6933 AR 0.9750
Epoch 973 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6472 AR 0.9467
Epoch 973 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7355 AR 0.9667
Epoch 973 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6357 AR 0.9600
Epoch 973 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7129 AR 0.9750
Epoch 973 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8621 AR 1.0000
Epoch 973 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5875 AR 0.9400
Epoch 973 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6788 AR 0.9800
Epoch 973 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7383 AR 0.8750
Epoch 974 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7194 AR 0.8600
Epoch 974 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7539 AR 1.0000
Epoch 974 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7888 AR 0.9550
Epoch 974 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7148 AR 0.9000
Epoch 974 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6571 AR 0.8750
Epoch 974 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7275 AR 0.9800
Epoch 974 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7358 AR 0.9333
Epoch 974 batch 00008: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.6334 AR 0.8500
Epoch 974 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6028 AR 0.9000
Epoch 974 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7938 AR 0.9750
Epoch 975 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8817 AR 0.9750
Epoch 975 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7588 AR 0.9750
Epoch 975 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6122 AR 0.9800
Epoch 975 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6095 AR 0.9500
Epoch 975 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6873 AR 0.9333
Epoch 975 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7610 AR 1.0000
Epoch 975 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7089 AR 0.9500
Epoch 975 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.8645 AR 0.9550
Epoch 975 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6405 AR 0.9600
Epoch 975 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8292 AR 0.9800
Epoch 976 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6755 AR 0.9800
Epoch 976 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6394 AR 0.9750
Epoch 976 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8026 AR 0.9400
Epoch 976 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7967 AR 1.0000
Epoch 976 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.8600 AR 1.0000
Epoch 976 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7358 AR 0.9250
Epoch 976 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6453 AR 0.9083
Epoch 976 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7651 AR 0.9750
Epoch 976 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7748 AR 1.0000
Epoch 976 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6242 AR 0.9750
Epoch 977 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8039 AR 0.9800
Epoch 977 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6593 AR 0.9000
Epoch 977 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8431 AR 0.9800
Epoch 977 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6367 AR 0.8800
Epoch 977 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6050 AR 0.9267
Epoch 977 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7381 AR 0.9000
Epoch 977 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7010 AR 0.9600
Epoch 977 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6922 AR 0.9167
Epoch 977 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6059 AR 0.8800
Epoch 977 batch 00010: Loss 0.0015 Regression loss 0.0015 Classification loss 0.0000 AP 0.6567 AR 0.8800
Epoch 978 batch 00001: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0000 AP 0.7508 AR 0.8750
Epoch 978 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7389 AR 1.0000
Epoch 978 batch 00003: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.6967 AR 0.9800
Epoch 978 batch 00004: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7185 AR 0.9800
Epoch 978 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7700 AR 0.9667
Epoch 978 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7214 AR 0.9667
Epoch 978 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6114 AR 0.7050
Epoch 978 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.6842 AR 0.9000
Epoch 978 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6775 AR 0.9500
Epoch 978 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7019 AR 0.9750
Epoch 979 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7238 AR 0.9750
Epoch 979 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6776 AR 0.9100
Epoch 979 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7848 AR 0.9500
Epoch 979 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7300 AR 0.9500
Epoch 979 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7722 AR 1.0000
Epoch 979 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7583 AR 0.9000
Epoch 979 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7917 AR 1.0000
Epoch 979 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6048 AR 1.0000
Epoch 979 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7185 AR 0.9217
Epoch 979 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5756 AR 0.8300
Epoch 980 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6854 AR 1.0000
Epoch 980 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7130 AR 1.0000
Epoch 980 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8171 AR 1.0000
Epoch 980 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7236 AR 0.9550
Epoch 980 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6227 AR 0.8800
Epoch 980 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7075 AR 0.9000
Epoch 980 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.8905 AR 0.9750
Epoch 980 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7592 AR 0.9750
Epoch 980 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7233 AR 1.0000
Epoch 980 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6380 AR 0.9800
Epoch 981 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7081 AR 0.9667
Epoch 981 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7131 AR 0.9017
Epoch 981 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7055 AR 0.9300
Epoch 981 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7658 AR 1.0000
Epoch 981 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7514 AR 0.9750
Epoch 981 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6308 AR 0.9550
Epoch 981 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7560 AR 0.9550
Epoch 981 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7423 AR 0.9250
Epoch 981 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7050 AR 0.8750
Epoch 981 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5983 AR 0.8550
Epoch 982 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7989 AR 0.9800
Epoch 982 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7627 AR 0.9500
Epoch 982 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6567 AR 0.8500
Epoch 982 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7353 AR 0.9750
Epoch 982 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7407 AR 0.9800
Epoch 982 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6849 AR 1.0000
Epoch 982 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6498 AR 0.9800
Epoch 982 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8433 AR 1.0000
Epoch 982 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6605 AR 0.8550
Epoch 982 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6405 AR 0.8750
Epoch 983 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6429 AR 0.9417
Epoch 983 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7714 AR 0.9350
Epoch 983 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7080 AR 0.9750
Epoch 983 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7110 AR 0.8850
Epoch 983 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.9121 AR 0.9750
Epoch 983 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8217 AR 0.9750
Epoch 983 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7000 AR 0.9750
Epoch 983 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7120 AR 0.9800
Epoch 983 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6945 AR 0.9750
Epoch 983 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6725 AR 0.9800
Epoch 984 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6233 AR 0.8750
Epoch 984 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0000 AP 0.8273 AR 1.0000
Epoch 984 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7333 AR 0.9400
Epoch 984 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7016 AR 0.9350
Epoch 984 batch 00005: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.6622 AR 0.9500
Epoch 984 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7080 AR 0.9000
Epoch 984 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6097 AR 0.7800
Epoch 984 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8431 AR 1.0000
Epoch 984 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7143 AR 0.9750
Epoch 984 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6331 AR 0.8500
Epoch 985 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6787 AR 0.9000
Epoch 985 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7088 AR 0.9600
Epoch 985 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6516 AR 0.9467
Epoch 985 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6767 AR 0.9000
Epoch 985 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6892 AR 0.9000
Epoch 985 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7798 AR 1.0000
Epoch 985 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6919 AR 0.8600
Epoch 985 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5347 AR 0.8750
Epoch 985 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8169 AR 0.9750
Epoch 985 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7308 AR 0.9750
Epoch 986 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6617 AR 0.8600
Epoch 986 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7792 AR 0.9800
Epoch 986 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8161 AR 0.9800
Epoch 986 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7088 AR 0.9550
Epoch 986 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7000 AR 0.9800
Epoch 986 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6594 AR 0.9500
Epoch 986 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6898 AR 0.9250
Epoch 986 batch 00008: Loss 0.0017 Regression loss 0.0017 Classification loss 0.0000 AP 0.5978 AR 0.8800
Epoch 986 batch 00009: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.8369 AR 0.9550
Epoch 986 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6771 AR 1.0000
Epoch 987 batch 00001: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0000 AP 0.7100 AR 0.9000
Epoch 987 batch 00002: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7348 AR 0.9417
Epoch 987 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.5687 AR 0.9600
Epoch 987 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7628 AR 0.9400
Epoch 987 batch 00005: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0000 AP 0.9064 AR 1.0000
Epoch 987 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6039 AR 0.9750
Epoch 987 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7136 AR 0.9600
Epoch 987 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6267 AR 0.9800
Epoch 987 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6947 AR 0.9750
Epoch 987 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8650 AR 1.0000
Epoch 988 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7177 AR 0.9750
Epoch 988 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6998 AR 0.9400
Epoch 988 batch 00003: Loss 0.0015 Regression loss 0.0015 Classification loss 0.0001 AP 0.6114 AR 0.8000
Epoch 988 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.6608 AR 0.9417
Epoch 988 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7183 AR 0.9750
Epoch 988 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6831 AR 0.9750
Epoch 988 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7488 AR 0.9400
Epoch 988 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7148 AR 0.9750
Epoch 988 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.7650 AR 0.9000
Epoch 988 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8156 AR 0.9600
Epoch 989 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7000 AR 0.9500
Epoch 989 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.6727 AR 0.9500
Epoch 989 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6531 AR 0.9467
Epoch 989 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7305 AR 0.9667
Epoch 989 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.8312 AR 1.0000
Epoch 989 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6650 AR 0.9300
Epoch 989 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6083 AR 0.8600
Epoch 989 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7575 AR 0.9500
Epoch 989 batch 00009: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7014 AR 1.0000
Epoch 989 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7893 AR 0.9550
Epoch 990 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7295 AR 0.9550
Epoch 990 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7288 AR 1.0000
Epoch 990 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7648 AR 0.9667
Epoch 990 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7958 AR 1.0000
Epoch 990 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0000 AP 0.7971 AR 0.9550
Epoch 990 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6105 AR 0.8500
Epoch 990 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7631 AR 1.0000
Epoch 990 batch 00008: Loss 0.0016 Regression loss 0.0016 Classification loss 0.0000 AP 0.7005 AR 0.9133
Epoch 990 batch 00009: Loss 0.0016 Regression loss 0.0016 Classification loss 0.0001 AP 0.6322 AR 0.9750
Epoch 990 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7328 AR 0.9200
Epoch 991 batch 00001: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8017 AR 0.8750
Epoch 991 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7521 AR 1.0000
Epoch 991 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8346 AR 1.0000
Epoch 991 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.8022 AR 1.0000
Epoch 991 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6267 AR 0.9550
Epoch 991 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7533 AR 1.0000
Epoch 991 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8714 AR 1.0000
Epoch 991 batch 00008: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.6198 AR 0.8150
Epoch 991 batch 00009: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0000 AP 0.6398 AR 0.9500
Epoch 991 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5853 AR 0.8800
Epoch 992 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7067 AR 0.9417
Epoch 992 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7378 AR 1.0000
Epoch 992 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6245 AR 0.9750
Epoch 992 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7829 AR 1.0000
Epoch 992 batch 00005: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0000 AP 0.7430 AR 0.9550
Epoch 992 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6789 AR 0.9800
Epoch 992 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7900 AR 0.9750
Epoch 992 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7411 AR 0.9550
Epoch 992 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7505 AR 1.0000
Epoch 992 batch 00010: Loss 0.0014 Regression loss 0.0014 Classification loss 0.0001 AP 0.7606 AR 0.9267
Epoch 993 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6800 AR 0.8100
Epoch 993 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8363 AR 1.0000
Epoch 993 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6796 AR 0.9500
Epoch 993 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7736 AR 0.9800
Epoch 993 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6731 AR 1.0000
Epoch 993 batch 00006: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0001 AP 0.7621 AR 0.9800
Epoch 993 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7322 AR 0.9667
Epoch 993 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6908 AR 0.9500
Epoch 993 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7458 AR 1.0000
Epoch 993 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5998 AR 0.8800
Epoch 994 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7375 AR 0.9667
Epoch 994 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8058 AR 1.0000
Epoch 994 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6088 AR 0.9000
Epoch 994 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.9017 AR 0.9500
Epoch 994 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7750 AR 0.9750
Epoch 994 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6906 AR 0.9800
Epoch 994 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7748 AR 1.0000
Epoch 994 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.6154 AR 0.9000
Epoch 994 batch 00009: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.6116 AR 0.9550
Epoch 994 batch 00010: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6838 AR 0.9800
Epoch 995 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6667 AR 0.9167
Epoch 995 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7267 AR 0.9800
Epoch 995 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7914 AR 1.0000
Epoch 995 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6092 AR 0.9800
Epoch 995 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7735 AR 0.9800
Epoch 995 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7133 AR 0.9500
Epoch 995 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8336 AR 1.0000
Epoch 995 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6671 AR 0.8467
Epoch 995 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7367 AR 0.9750
Epoch 995 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7377 AR 1.0000
Epoch 996 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7727 AR 0.9667
Epoch 996 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6917 AR 0.9500
Epoch 996 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.7022 AR 0.9000
Epoch 996 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6614 AR 0.8300
Epoch 996 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7472 AR 1.0000
Epoch 996 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7988 AR 0.9400
Epoch 996 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6731 AR 0.9800
Epoch 996 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6738 AR 0.8600
Epoch 996 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.6998 AR 0.9500
Epoch 996 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6205 AR 0.9750
Epoch 997 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6071 AR 0.9400
Epoch 997 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6338 AR 0.9300
Epoch 997 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6123 AR 0.9500
Epoch 997 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7167 AR 0.8550
Epoch 997 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6737 AR 0.9750
Epoch 997 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6131 AR 0.8800
Epoch 997 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.7467 AR 0.9750
Epoch 997 batch 00008: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7648 AR 1.0000
Epoch 997 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8458 AR 0.9800
Epoch 997 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8300 AR 0.9750
Epoch 998 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.7226 AR 0.9800
Epoch 998 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6867 AR 1.0000
Epoch 998 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7914 AR 0.9750
Epoch 998 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7485 AR 1.0000
Epoch 998 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7456 AR 0.9600
Epoch 998 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7225 AR 0.9400
Epoch 998 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7371 AR 0.9750
Epoch 998 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6180 AR 0.9000
Epoch 998 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6733 AR 0.9500
Epoch 998 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7153 AR 0.9800
Epoch 999 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6938 AR 0.9800
Epoch 999 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7964 AR 0.9000
Epoch 999 batch 00003: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0000 AP 0.8014 AR 1.0000
Epoch 999 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7917 AR 0.9800
Epoch 999 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7263 AR 1.0000
Epoch 999 batch 00006: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7471 AR 0.9300
Epoch 999 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6431 AR 0.9750
Epoch 999 batch 00008: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7852 AR 0.9500
Epoch 999 batch 00009: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.7800 AR 0.9000
Epoch 999 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6086 AR 0.8750
Epoch 1000 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7244 AR 1.0000
Epoch 1000 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6917 AR 0.8600
Epoch 1000 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.9050 AR 0.9750
Epoch 1000 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7814 AR 0.9800
Epoch 1000 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6138 AR 0.9250
Epoch 1000 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7139 AR 1.0000
Epoch 1000 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7983 AR 1.0000
Epoch 1000 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7083 AR 0.9800
Epoch 1000 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6474 AR 0.9550
Epoch 1000 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6783 AR 0.8967
Epoch 1001 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6771 AR 0.8800
Epoch 1001 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7531 AR 0.9550
Epoch 1001 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7183 AR 0.9550
Epoch 1001 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7971 AR 0.9750
Epoch 1001 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7167 AR 0.9000
Epoch 1001 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7687 AR 1.0000
Epoch 1001 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.5350 AR 0.8267
Epoch 1001 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6888 AR 1.0000
Epoch 1001 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6069 AR 0.8350
Epoch 1001 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7200 AR 0.9550
Epoch 1002 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8072 AR 1.0000
Epoch 1002 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6583 AR 0.9500
Epoch 1002 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7122 AR 0.9600
Epoch 1002 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7717 AR 0.9800
Epoch 1002 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8196 AR 0.9800
Epoch 1002 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7121 AR 0.9500
Epoch 1002 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7086 AR 1.0000
Epoch 1002 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5092 AR 0.9667
Epoch 1002 batch 00009: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.7800 AR 0.9800
Epoch 1002 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7500 AR 1.0000
Epoch 1003 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8473 AR 1.0000
Epoch 1003 batch 00002: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0000 AP 0.7544 AR 1.0000
Epoch 1003 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.5622 AR 0.8467
Epoch 1003 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6883 AR 0.9750
Epoch 1003 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.8717 AR 1.0000
Epoch 1003 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6583 AR 0.9400
Epoch 1003 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8171 AR 0.9800
Epoch 1003 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6948 AR 0.9750
Epoch 1003 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7231 AR 1.0000
Epoch 1003 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5853 AR 0.9100
Epoch 1004 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7814 AR 1.0000
Epoch 1004 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6250 AR 0.7417
Epoch 1004 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7117 AR 0.9300
Epoch 1004 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7012 AR 0.8750
Epoch 1004 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6111 AR 0.9800
Epoch 1004 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8237 AR 0.9550
Epoch 1004 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6394 AR 0.9350
Epoch 1004 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5655 AR 0.8500
Epoch 1004 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7214 AR 0.9267
Epoch 1004 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8183 AR 1.0000
Epoch 1005 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6414 AR 0.9000
Epoch 1005 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8180 AR 1.0000
Epoch 1005 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6433 AR 0.9050
Epoch 1005 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7189 AR 1.0000
Epoch 1005 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7352 AR 0.9800
Epoch 1005 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7138 AR 0.8900
Epoch 1005 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8117 AR 0.9750
Epoch 1005 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7106 AR 0.8800
Epoch 1005 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7400 AR 1.0000
Epoch 1005 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7016 AR 0.9600
Epoch 1006 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6638 AR 0.9050
Epoch 1006 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8067 AR 1.0000
Epoch 1006 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7198 AR 0.9500
Epoch 1006 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8050 AR 0.9550
Epoch 1006 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5992 AR 0.9600
Epoch 1006 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.5609 AR 0.8550
Epoch 1006 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7371 AR 0.9550
Epoch 1006 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8167 AR 0.9667
Epoch 1006 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7870 AR 1.0000
Epoch 1006 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6708 AR 0.9750
Epoch 1007 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6781 AR 0.9000
Epoch 1007 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6355 AR 0.9600
Epoch 1007 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7282 AR 1.0000
Epoch 1007 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7817 AR 0.9100
Epoch 1007 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7292 AR 1.0000
Epoch 1007 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7325 AR 1.0000
Epoch 1007 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6451 AR 0.8550
Epoch 1007 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.7983 AR 0.9500
Epoch 1007 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7233 AR 0.9800
Epoch 1007 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6783 AR 0.8800
Epoch 1008 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7833 AR 0.9750
Epoch 1008 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8200 AR 1.0000
Epoch 1008 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6298 AR 0.9750
Epoch 1008 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7303 AR 0.9400
Epoch 1008 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7467 AR 0.9600
Epoch 1008 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7267 AR 1.0000
Epoch 1008 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6708 AR 0.8500
Epoch 1008 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7389 AR 0.9750
Epoch 1008 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6805 AR 0.9550
Epoch 1008 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6653 AR 0.9800
Epoch 1009 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6903 AR 0.9750
Epoch 1009 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6412 AR 0.9050
Epoch 1009 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.9048 AR 0.9800
Epoch 1009 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7681 AR 1.0000
Epoch 1009 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6652 AR 0.9467
Epoch 1009 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8375 AR 1.0000
Epoch 1009 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8350 AR 1.0000
Epoch 1009 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6806 AR 0.8800
Epoch 1009 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7417 AR 0.9667
Epoch 1009 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.4706 AR 0.7750
Epoch 1010 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7867 AR 1.0000
Epoch 1010 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8548 AR 1.0000
Epoch 1010 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6350 AR 0.9000
Epoch 1010 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7905 AR 0.9550
Epoch 1010 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6625 AR 1.0000
Epoch 1010 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7344 AR 0.9750
Epoch 1010 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6682 AR 0.9800
Epoch 1010 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6689 AR 0.9000
Epoch 1010 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8700 AR 1.0000
Epoch 1010 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6560 AR 0.9350
Epoch 1011 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7148 AR 1.0000
Epoch 1011 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6600 AR 0.8750
Epoch 1011 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6964 AR 1.0000
Epoch 1011 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7132 AR 1.0000
Epoch 1011 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6983 AR 1.0000
Epoch 1011 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7000 AR 0.9333
Epoch 1011 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8100 AR 0.8350
Epoch 1011 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6784 AR 0.9800
Epoch 1011 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7700 AR 0.9500
Epoch 1011 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7019 AR 0.9750
Epoch 1012 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6912 AR 0.8850
Epoch 1012 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6950 AR 0.8600
Epoch 1012 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7514 AR 0.9800
Epoch 1012 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6905 AR 0.9500
Epoch 1012 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7622 AR 1.0000
Epoch 1012 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6925 AR 0.8500
Epoch 1012 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7617 AR 1.0000
Epoch 1012 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7276 AR 0.9600
Epoch 1012 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6922 AR 0.9000
Epoch 1012 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.5958 AR 0.9800
Epoch 1013 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7786 AR 0.9800
Epoch 1013 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5807 AR 0.8250
Epoch 1013 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7961 AR 1.0000
Epoch 1013 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7755 AR 0.9800
Epoch 1013 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.5422 AR 0.7667
Epoch 1013 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7805 AR 0.9600
Epoch 1013 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7150 AR 0.9350
Epoch 1013 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7825 AR 1.0000
Epoch 1013 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6838 AR 0.9550
Epoch 1013 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6770 AR 0.9500
Epoch 1014 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6752 AR 1.0000
Epoch 1014 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6133 AR 1.0000
Epoch 1014 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6833 AR 0.8750
Epoch 1014 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.7705 AR 0.9600
Epoch 1014 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8633 AR 1.0000
Epoch 1014 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6767 AR 0.9000
Epoch 1014 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7067 AR 0.9550
Epoch 1014 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7206 AR 0.9550
Epoch 1014 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8517 AR 0.9800
Epoch 1014 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6321 AR 0.9300
Epoch 1015 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.8131 AR 0.9667
Epoch 1015 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5498 AR 0.7750
Epoch 1015 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6317 AR 1.0000
Epoch 1015 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7500 AR 1.0000
Epoch 1015 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7339 AR 1.0000
Epoch 1015 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6681 AR 0.9550
Epoch 1015 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6694 AR 0.8600
Epoch 1015 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7168 AR 0.9800
Epoch 1015 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7933 AR 0.9667
Epoch 1015 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7992 AR 0.9800
Epoch 1016 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7798 AR 1.0000
Epoch 1016 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8098 AR 1.0000
Epoch 1016 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6085 AR 0.9800
Epoch 1016 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7092 AR 1.0000
Epoch 1016 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6316 AR 0.8467
Epoch 1016 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8231 AR 1.0000
Epoch 1016 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8183 AR 0.9500
Epoch 1016 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7392 AR 0.9750
Epoch 1016 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7700 AR 1.0000
Epoch 1016 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6755 AR 0.8950
Epoch 1017 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7144 AR 0.8800
Epoch 1017 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7353 AR 0.9750
Epoch 1017 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6483 AR 0.9017
Epoch 1017 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7401 AR 1.0000
Epoch 1017 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6501 AR 0.9217
Epoch 1017 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6264 AR 0.8750
Epoch 1017 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7717 AR 0.9800
Epoch 1017 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7338 AR 0.9000
Epoch 1017 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8196 AR 0.9800
Epoch 1017 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7767 AR 0.9800
Epoch 1018 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8403 AR 0.9600
Epoch 1018 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7429 AR 1.0000
Epoch 1018 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7071 AR 0.9667
Epoch 1018 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6800 AR 1.0000
Epoch 1018 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7499 AR 0.9800
Epoch 1018 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7556 AR 0.9800
Epoch 1018 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6238 AR 0.8967
Epoch 1018 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6850 AR 0.8500
Epoch 1018 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7550 AR 1.0000
Epoch 1018 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7442 AR 0.9750
Epoch 1019 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8300 AR 0.9750
Epoch 1019 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7633 AR 0.9750
Epoch 1019 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7339 AR 1.0000
Epoch 1019 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6983 AR 0.9800
Epoch 1019 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6350 AR 0.9000
Epoch 1019 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6817 AR 0.9800
Epoch 1019 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6917 AR 1.0000
Epoch 1019 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6800 AR 0.9550
Epoch 1019 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7972 AR 1.0000
Epoch 1019 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6725 AR 0.9267
Epoch 1020 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7342 AR 1.0000
Epoch 1020 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7393 AR 0.9800
Epoch 1020 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7420 AR 0.9750
Epoch 1020 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7411 AR 0.9800
Epoch 1020 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6550 AR 0.8750
Epoch 1020 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6981 AR 0.8750
Epoch 1020 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6267 AR 0.9600
Epoch 1020 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7756 AR 0.9750
Epoch 1020 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7083 AR 0.9167
Epoch 1020 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7617 AR 0.9800
Epoch 1021 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8225 AR 0.9800
Epoch 1021 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7764 AR 1.0000
Epoch 1021 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8705 AR 1.0000
Epoch 1021 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8148 AR 1.0000
Epoch 1021 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7617 AR 0.9800
Epoch 1021 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7135 AR 1.0000
Epoch 1021 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5250 AR 0.8350
Epoch 1021 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7314 AR 0.9750
Epoch 1021 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6814 AR 0.9750
Epoch 1021 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6702 AR 0.9800
Epoch 1022 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6308 AR 0.9300
Epoch 1022 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7233 AR 0.8350
Epoch 1022 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7810 AR 1.0000
Epoch 1022 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7248 AR 0.9667
Epoch 1022 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8746 AR 0.9600
Epoch 1022 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7067 AR 0.9083
Epoch 1022 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.8100 AR 1.0000
Epoch 1022 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6685 AR 1.0000
Epoch 1022 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7550 AR 0.9800
Epoch 1022 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7352 AR 1.0000
Epoch 1023 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6906 AR 0.7750
Epoch 1023 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7246 AR 0.9150
Epoch 1023 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6433 AR 0.9750
Epoch 1023 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6848 AR 1.0000
Epoch 1023 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6081 AR 0.9417
Epoch 1023 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8000 AR 0.9600
Epoch 1023 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8683 AR 1.0000
Epoch 1023 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5895 AR 0.9350
Epoch 1023 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8298 AR 1.0000
Epoch 1023 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6741 AR 1.0000
Epoch 1024 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6998 AR 0.9750
Epoch 1024 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7752 AR 0.9750
Epoch 1024 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7081 AR 0.9600
Epoch 1024 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.9100 AR 1.0000
Epoch 1024 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7433 AR 0.9800
Epoch 1024 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7077 AR 1.0000
Epoch 1024 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6317 AR 0.9600
Epoch 1024 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7571 AR 1.0000
Epoch 1024 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7722 AR 0.9550
Epoch 1024 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6062 AR 0.9250
Epoch 1025 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7100 AR 0.9750
Epoch 1025 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8189 AR 0.9800
Epoch 1025 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7950 AR 0.9500
Epoch 1025 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7175 AR 1.0000
Epoch 1025 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7217 AR 0.9800
Epoch 1025 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7800 AR 0.9750
Epoch 1025 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7797 AR 0.9800
Epoch 1025 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6911 AR 0.9417
Epoch 1025 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6910 AR 0.9800
Epoch 1025 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6930 AR 1.0000
Epoch 1026 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7128 AR 1.0000
Epoch 1026 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6770 AR 0.9667
Epoch 1026 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7152 AR 0.9750
Epoch 1026 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7781 AR 1.0000
Epoch 1026 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6171 AR 0.9350
Epoch 1026 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7072 AR 1.0000
Epoch 1026 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7667 AR 0.9500
Epoch 1026 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8083 AR 0.8500
Epoch 1026 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7633 AR 0.9100
Epoch 1026 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6719 AR 0.9467
Epoch 1027 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7620 AR 1.0000
Epoch 1027 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6662 AR 0.8750
Epoch 1027 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.5881 AR 0.8600
Epoch 1027 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6782 AR 0.8750
Epoch 1027 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.8898 AR 0.9800
Epoch 1027 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6550 AR 0.9550
Epoch 1027 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8450 AR 0.9600
Epoch 1027 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.5771 AR 0.8750
Epoch 1027 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6869 AR 0.9550
Epoch 1027 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6261 AR 0.9300
Epoch 1028 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6894 AR 0.8800
Epoch 1028 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7073 AR 0.9800
Epoch 1028 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6452 AR 1.0000
Epoch 1028 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.7550 AR 1.0000
Epoch 1028 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.6863 AR 0.8550
Epoch 1028 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8417 AR 0.9750
Epoch 1028 batch 00007: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0000 AP 0.6183 AR 0.9550
Epoch 1028 batch 00008: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.5981 AR 0.8417
Epoch 1028 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7714 AR 0.9800
Epoch 1028 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7656 AR 0.8800
Epoch 1029 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7567 AR 0.9800
Epoch 1029 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7592 AR 0.9467
Epoch 1029 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7638 AR 0.9800
Epoch 1029 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.7437 AR 0.9750
Epoch 1029 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6639 AR 0.9000
Epoch 1029 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7483 AR 1.0000
Epoch 1029 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6472 AR 0.9300
Epoch 1029 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7736 AR 0.8800
Epoch 1029 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6400 AR 0.8750
Epoch 1029 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6590 AR 1.0000
Epoch 1030 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8333 AR 0.9500
Epoch 1030 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6338 AR 0.8667
Epoch 1030 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7538 AR 0.9750
Epoch 1030 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6705 AR 0.9400
Epoch 1030 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0000 AP 0.6947 AR 0.9750
Epoch 1030 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6960 AR 0.9550
Epoch 1030 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6825 AR 1.0000
Epoch 1030 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7888 AR 0.9800
Epoch 1030 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7550 AR 0.9800
Epoch 1030 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6711 AR 0.9667
Epoch 1031 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8767 AR 1.0000
Epoch 1031 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7514 AR 0.9800
Epoch 1031 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7033 AR 1.0000
Epoch 1031 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6877 AR 0.9550
Epoch 1031 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7475 AR 0.9600
Epoch 1031 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6190 AR 0.9250
Epoch 1031 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7322 AR 0.9500
Epoch 1031 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6864 AR 0.9300
Epoch 1031 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7188 AR 0.9800
Epoch 1031 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6233 AR 0.8750
Epoch 1032 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7581 AR 1.0000
Epoch 1032 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6575 AR 1.0000
Epoch 1032 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7567 AR 1.0000
Epoch 1032 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6888 AR 0.9800
Epoch 1032 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.5645 AR 0.8167
Epoch 1032 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7652 AR 0.9350
Epoch 1032 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8522 AR 1.0000
Epoch 1032 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8471 AR 1.0000
Epoch 1032 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6567 AR 0.8750
Epoch 1032 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7267 AR 0.8800
Epoch 1033 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7350 AR 0.9300
Epoch 1033 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8008 AR 1.0000
Epoch 1033 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7650 AR 0.9000
Epoch 1033 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7192 AR 0.9750
Epoch 1033 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6943 AR 0.9000
Epoch 1033 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7467 AR 1.0000
Epoch 1033 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6278 AR 0.8550
Epoch 1033 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7292 AR 0.9350
Epoch 1033 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7552 AR 1.0000
Epoch 1033 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6067 AR 0.8800
Epoch 1034 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7231 AR 0.9000
Epoch 1034 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6186 AR 0.8500
Epoch 1034 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6050 AR 0.9000
Epoch 1034 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5900 AR 0.8800
Epoch 1034 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7767 AR 0.9550
Epoch 1034 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7591 AR 0.9350
Epoch 1034 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8171 AR 1.0000
Epoch 1034 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.7438 AR 0.9750
Epoch 1034 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7708 AR 0.9750
Epoch 1034 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7042 AR 1.0000
Epoch 1035 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5838 AR 0.9000
Epoch 1035 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6437 AR 0.9600
Epoch 1035 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8145 AR 1.0000
Epoch 1035 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7722 AR 0.9667
Epoch 1035 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7155 AR 0.9750
Epoch 1035 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7183 AR 0.9000
Epoch 1035 batch 00007: Loss 0.0018 Regression loss 0.0018 Classification loss 0.0000 AP 0.6722 AR 0.7750
Epoch 1035 batch 00008: Loss 0.0029 Regression loss 0.0029 Classification loss 0.0001 AP 0.8446 AR 1.0000
Epoch 1035 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6703 AR 0.9550
Epoch 1035 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7540 AR 0.9500
Epoch 1036 batch 00001: Loss 0.0030 Regression loss 0.0029 Classification loss 0.0001 AP 0.6717 AR 0.9600
Epoch 1036 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7696 AR 1.0000
Epoch 1036 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7348 AR 0.9550
Epoch 1036 batch 00004: Loss 0.0020 Regression loss 0.0020 Classification loss 0.0001 AP 0.7505 AR 1.0000
Epoch 1036 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.7710 AR 0.9300
Epoch 1036 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6208 AR 0.9000
Epoch 1036 batch 00007: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7386 AR 0.9600
Epoch 1036 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6581 AR 0.8750
Epoch 1036 batch 00009: Loss 0.0016 Regression loss 0.0016 Classification loss 0.0000 AP 0.7030 AR 0.9250
Epoch 1036 batch 00010: Loss 0.0025 Regression loss 0.0025 Classification loss 0.0000 AP 0.7744 AR 1.0000
Epoch 1037 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8067 AR 1.0000
Epoch 1037 batch 00002: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.8203 AR 0.9750
Epoch 1037 batch 00003: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.7244 AR 0.9467
Epoch 1037 batch 00004: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0000 AP 0.6017 AR 0.8667
Epoch 1037 batch 00005: Loss 0.0006 Regression loss 0.0004 Classification loss 0.0001 AP 0.6827 AR 0.9550
Epoch 1037 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7267 AR 1.0000
Epoch 1037 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7764 AR 0.8800
Epoch 1037 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6000 AR 0.9000
Epoch 1037 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6443 AR 0.9467
Epoch 1037 batch 00010: Loss 0.0006 Regression loss 0.0004 Classification loss 0.0001 AP 0.6817 AR 0.9667
Epoch 1038 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7369 AR 0.9750
Epoch 1038 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8195 AR 1.0000
Epoch 1038 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6788 AR 0.8800
Epoch 1038 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7299 AR 1.0000
Epoch 1038 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6505 AR 0.8800
Epoch 1038 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7417 AR 0.9750
Epoch 1038 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7125 AR 1.0000
Epoch 1038 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.8333 AR 1.0000
Epoch 1038 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7142 AR 0.9217
Epoch 1038 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6498 AR 1.0000
Epoch 1039 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6598 AR 0.9600
Epoch 1039 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6483 AR 0.9400
Epoch 1039 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7042 AR 0.9000
Epoch 1039 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7695 AR 0.9750
Epoch 1039 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6600 AR 0.8550
Epoch 1039 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6556 AR 0.8083
Epoch 1039 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6767 AR 0.9250
Epoch 1039 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5539 AR 0.8750
Epoch 1039 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7983 AR 0.9300
Epoch 1039 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7864 AR 1.0000
Epoch 1040 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5964 AR 0.8800
Epoch 1040 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7518 AR 0.9250
Epoch 1040 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7250 AR 1.0000
Epoch 1040 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7667 AR 1.0000
Epoch 1040 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5567 AR 0.8000
Epoch 1040 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7350 AR 0.9550
Epoch 1040 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7767 AR 0.9550
Epoch 1040 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8014 AR 0.9467
Epoch 1040 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6471 AR 0.9750
Epoch 1040 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7314 AR 0.9350
Epoch 1041 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7637 AR 1.0000
Epoch 1041 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.8038 AR 0.9467
Epoch 1041 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7705 AR 0.9800
Epoch 1041 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7225 AR 1.0000
Epoch 1041 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6555 AR 0.9000
Epoch 1041 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6360 AR 0.8800
Epoch 1041 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6578 AR 0.9800
Epoch 1041 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7800 AR 1.0000
Epoch 1041 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7206 AR 0.8550
Epoch 1041 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6469 AR 0.9750
Epoch 1042 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6345 AR 0.9750
Epoch 1042 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7189 AR 1.0000
Epoch 1042 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8267 AR 0.9750
Epoch 1042 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7523 AR 1.0000
Epoch 1042 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7696 AR 0.9500
Epoch 1042 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6321 AR 0.9000
Epoch 1042 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8153 AR 0.9750
Epoch 1042 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6419 AR 0.9750
Epoch 1042 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7533 AR 1.0000
Epoch 1042 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5706 AR 0.8150
Epoch 1043 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6867 AR 0.8750
Epoch 1043 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8071 AR 1.0000
Epoch 1043 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7988 AR 0.9600
Epoch 1043 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7198 AR 0.9467
Epoch 1043 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7594 AR 0.9800
Epoch 1043 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7072 AR 0.9500
Epoch 1043 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6700 AR 0.9050
Epoch 1043 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6754 AR 0.9500
Epoch 1043 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6629 AR 0.9000
Epoch 1043 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7152 AR 0.9800
Epoch 1044 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6083 AR 1.0000
Epoch 1044 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7364 AR 0.9250
Epoch 1044 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7117 AR 0.8800
Epoch 1044 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7789 AR 0.9600
Epoch 1044 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8028 AR 1.0000
Epoch 1044 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6525 AR 0.9217
Epoch 1044 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7931 AR 1.0000
Epoch 1044 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7017 AR 0.8550
Epoch 1044 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6488 AR 0.9667
Epoch 1044 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7284 AR 0.9500
Epoch 1045 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7318 AR 0.9750
Epoch 1045 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6717 AR 0.9000
Epoch 1045 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7911 AR 0.9400
Epoch 1045 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6263 AR 0.8800
Epoch 1045 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7267 AR 0.9550
Epoch 1045 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8714 AR 0.9800
Epoch 1045 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6836 AR 0.9750
Epoch 1045 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7900 AR 1.0000
Epoch 1045 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5955 AR 1.0000
Epoch 1045 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6917 AR 0.8800
Epoch 1046 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7171 AR 0.9550
Epoch 1046 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8606 AR 1.0000
Epoch 1046 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.8005 AR 0.9750
Epoch 1046 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.6708 AR 0.9800
Epoch 1046 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6333 AR 0.8217
Epoch 1046 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7406 AR 1.0000
Epoch 1046 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7090 AR 0.9050
Epoch 1046 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6850 AR 0.9000
Epoch 1046 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6084 AR 0.9000
Epoch 1046 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7042 AR 0.9667
Epoch 1047 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7038 AR 0.9550
Epoch 1047 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7103 AR 1.0000
Epoch 1047 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6517 AR 0.9800
Epoch 1047 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6903 AR 0.9800
Epoch 1047 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.7483 AR 0.9750
Epoch 1047 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8498 AR 1.0000
Epoch 1047 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7667 AR 0.9600
Epoch 1047 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.7310 AR 0.8800
Epoch 1047 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7077 AR 0.9800
Epoch 1047 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.5445 AR 0.7500
Epoch 1048 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7164 AR 0.9000
Epoch 1048 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7583 AR 0.9750
Epoch 1048 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7988 AR 0.9750
Epoch 1048 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6369 AR 0.9417
Epoch 1048 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7754 AR 0.9550
Epoch 1048 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6750 AR 0.9800
Epoch 1048 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6962 AR 0.9500
Epoch 1048 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5878 AR 0.8800
Epoch 1048 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8267 AR 0.9467
Epoch 1048 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7021 AR 0.9800
Epoch 1049 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7967 AR 0.8800
Epoch 1049 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7114 AR 1.0000
Epoch 1049 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8417 AR 0.8750
Epoch 1049 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7681 AR 1.0000
Epoch 1049 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6037 AR 0.8750
Epoch 1049 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7017 AR 1.0000
Epoch 1049 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8883 AR 1.0000
Epoch 1049 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7464 AR 0.9000
Epoch 1049 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5705 AR 0.8700
Epoch 1049 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6567 AR 1.0000
Epoch 1050 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6700 AR 0.9667
Epoch 1050 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6989 AR 1.0000
Epoch 1050 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8083 AR 1.0000
Epoch 1050 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6556 AR 0.9550
Epoch 1050 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6962 AR 0.9550
Epoch 1050 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.7456 AR 0.9600
Epoch 1050 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7650 AR 0.9750
Epoch 1050 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7017 AR 0.9000
Epoch 1050 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7836 AR 0.9800
Epoch 1050 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7210 AR 0.9350
Epoch 1051 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7617 AR 1.0000
Epoch 1051 batch 00002: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.8237 AR 0.9800
Epoch 1051 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7039 AR 1.0000
Epoch 1051 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8398 AR 1.0000
Epoch 1051 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6671 AR 0.8800
Epoch 1051 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7077 AR 0.9500
Epoch 1051 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6168 AR 0.9550
Epoch 1051 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6061 AR 0.8750
Epoch 1051 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6567 AR 0.9550
Epoch 1051 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7833 AR 0.9000
Epoch 1052 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8017 AR 1.0000
Epoch 1052 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7144 AR 0.9667
Epoch 1052 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7908 AR 1.0000
Epoch 1052 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7567 AR 0.9800
Epoch 1052 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7160 AR 1.0000
Epoch 1052 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6833 AR 0.9250
Epoch 1052 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6056 AR 0.9550
Epoch 1052 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7450 AR 0.8550
Epoch 1052 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7620 AR 0.9333
Epoch 1052 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6508 AR 0.9750
Epoch 1053 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8464 AR 1.0000
Epoch 1053 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6651 AR 0.9050
Epoch 1053 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5000 AR 0.6800
Epoch 1053 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7298 AR 0.9000
Epoch 1053 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7583 AR 0.9800
Epoch 1053 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7564 AR 0.9667
Epoch 1053 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6033 AR 0.9300
Epoch 1053 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6576 AR 0.9500
Epoch 1053 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6583 AR 0.9300
Epoch 1053 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7950 AR 0.9000
Epoch 1054 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7150 AR 1.0000
Epoch 1054 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5995 AR 0.9000
Epoch 1054 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8002 AR 1.0000
Epoch 1054 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8363 AR 0.9800
Epoch 1054 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7255 AR 0.8550
Epoch 1054 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8205 AR 1.0000
Epoch 1054 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7200 AR 0.9600
Epoch 1054 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8517 AR 0.9800
Epoch 1054 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6506 AR 1.0000
Epoch 1054 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6439 AR 0.9350
Epoch 1055 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6737 AR 0.9750
Epoch 1055 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6489 AR 0.9800
Epoch 1055 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7238 AR 1.0000
Epoch 1055 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.7255 AR 0.9800
Epoch 1055 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.7047 AR 0.9750
Epoch 1055 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7531 AR 1.0000
Epoch 1055 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8100 AR 0.9050
Epoch 1055 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7487 AR 0.9500
Epoch 1055 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7758 AR 0.9500
Epoch 1055 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7439 AR 0.9550
Epoch 1056 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.6917 AR 0.9750
Epoch 1056 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6408 AR 0.9000
Epoch 1056 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6333 AR 0.9217
Epoch 1056 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6759 AR 0.9000
Epoch 1056 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7017 AR 0.8550
Epoch 1056 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7850 AR 1.0000
Epoch 1056 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7513 AR 0.9800
Epoch 1056 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7031 AR 0.9000
Epoch 1056 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6752 AR 0.9000
Epoch 1056 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7638 AR 0.9550
Epoch 1057 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6205 AR 0.8600
Epoch 1057 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7677 AR 0.9600
Epoch 1057 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6400 AR 0.9750
Epoch 1057 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7105 AR 1.0000
Epoch 1057 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6410 AR 0.8750
Epoch 1057 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6955 AR 0.9500
Epoch 1057 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6692 AR 0.9100
Epoch 1057 batch 00008: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7550 AR 1.0000
Epoch 1057 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8226 AR 1.0000
Epoch 1057 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7800 AR 0.9667
Epoch 1058 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5691 AR 0.8600
Epoch 1058 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7667 AR 0.9667
Epoch 1058 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.6789 AR 1.0000
Epoch 1058 batch 00004: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.7144 AR 0.9750
Epoch 1058 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6200 AR 1.0000
Epoch 1058 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8000 AR 0.9000
Epoch 1058 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.7528 AR 1.0000
Epoch 1058 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7903 AR 0.9600
Epoch 1058 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8562 AR 0.9750
Epoch 1058 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7583 AR 0.9800
Epoch 1059 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6317 AR 0.9467
Epoch 1059 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6455 AR 1.0000
Epoch 1059 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7317 AR 0.9800
Epoch 1059 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5967 AR 0.8250
Epoch 1059 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6881 AR 0.8750
Epoch 1059 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6967 AR 0.9400
Epoch 1059 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7348 AR 0.8417
Epoch 1059 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7456 AR 0.9800
Epoch 1059 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7563 AR 0.9800
Epoch 1059 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7052 AR 0.8800
Epoch 1060 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6533 AR 0.9000
Epoch 1060 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7425 AR 0.9350
Epoch 1060 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7283 AR 1.0000
Epoch 1060 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6248 AR 0.7650
Epoch 1060 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6086 AR 0.9250
Epoch 1060 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7011 AR 0.9800
Epoch 1060 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6814 AR 0.9000
Epoch 1060 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6727 AR 1.0000
Epoch 1060 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7767 AR 1.0000
Epoch 1060 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8508 AR 0.9750
Epoch 1061 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6071 AR 0.8600
Epoch 1061 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7181 AR 0.9167
Epoch 1061 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6433 AR 0.9000
Epoch 1061 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7170 AR 0.9000
Epoch 1061 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8622 AR 1.0000
Epoch 1061 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6880 AR 1.0000
Epoch 1061 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7552 AR 0.9500
Epoch 1061 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5940 AR 0.9600
Epoch 1061 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6442 AR 0.8400
Epoch 1061 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7100 AR 1.0000
Epoch 1062 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8250 AR 1.0000
Epoch 1062 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7350 AR 0.9550
Epoch 1062 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6713 AR 0.9550
Epoch 1062 batch 00004: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0000 AP 0.6819 AR 0.9467
Epoch 1062 batch 00005: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0000 AP 0.8348 AR 1.0000
Epoch 1062 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7822 AR 0.9600
Epoch 1062 batch 00007: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0000 AP 0.8164 AR 0.9750
Epoch 1062 batch 00008: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.7155 AR 1.0000
Epoch 1062 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6771 AR 0.9550
Epoch 1062 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0000 AP 0.6950 AR 1.0000
Epoch 1063 batch 00001: Loss 0.0025 Regression loss 0.0024 Classification loss 0.0000 AP 0.8005 AR 0.9550
Epoch 1063 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6497 AR 0.9600
Epoch 1063 batch 00003: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.6200 AR 0.8500
Epoch 1063 batch 00004: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.8046 AR 0.9550
Epoch 1063 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7137 AR 0.9800
Epoch 1063 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7131 AR 1.0000
Epoch 1063 batch 00007: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7479 AR 0.9250
Epoch 1063 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8300 AR 0.9800
Epoch 1063 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7367 AR 1.0000
Epoch 1063 batch 00010: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0001 AP 0.7333 AR 0.9333
Epoch 1064 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6802 AR 0.9000
Epoch 1064 batch 00002: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.6900 AR 0.9550
Epoch 1064 batch 00003: Loss 0.0022 Regression loss 0.0022 Classification loss 0.0000 AP 0.7088 AR 0.9750
Epoch 1064 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7348 AR 0.9300
Epoch 1064 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7850 AR 0.9600
Epoch 1064 batch 00006: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.6206 AR 0.8667
Epoch 1064 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8069 AR 0.9800
Epoch 1064 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7108 AR 0.9300
Epoch 1064 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5127 AR 0.8000
Epoch 1064 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6906 AR 0.9500
Epoch 1065 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6412 AR 0.8750
Epoch 1065 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7292 AR 0.9500
Epoch 1065 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.6111 AR 0.8133
Epoch 1065 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7331 AR 1.0000
Epoch 1065 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6892 AR 0.9350
Epoch 1065 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8233 AR 1.0000
Epoch 1065 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7425 AR 1.0000
Epoch 1065 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.8575 AR 0.9500
Epoch 1065 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7136 AR 0.9500
Epoch 1065 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7342 AR 0.9467
Epoch 1066 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6472 AR 0.9467
Epoch 1066 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7550 AR 0.9800
Epoch 1066 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6036 AR 0.9750
Epoch 1066 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7470 AR 0.9750
Epoch 1066 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7189 AR 0.9800
Epoch 1066 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8317 AR 1.0000
Epoch 1066 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8360 AR 0.9800
Epoch 1066 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6591 AR 0.8300
Epoch 1066 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6683 AR 0.8800
Epoch 1066 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6983 AR 0.8800
Epoch 1067 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7381 AR 0.8917
Epoch 1067 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8317 AR 1.0000
Epoch 1067 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8158 AR 0.9600
Epoch 1067 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6267 AR 0.9000
Epoch 1067 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7722 AR 0.9800
Epoch 1067 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7202 AR 1.0000
Epoch 1067 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6442 AR 0.9350
Epoch 1067 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7331 AR 0.9750
Epoch 1067 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7608 AR 0.9750
Epoch 1067 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6560 AR 0.9800
Epoch 1068 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6400 AR 0.9467
Epoch 1068 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7150 AR 1.0000
Epoch 1068 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7377 AR 0.9550
Epoch 1068 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.8500 AR 1.0000
Epoch 1068 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7898 AR 0.9750
Epoch 1068 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.8431 AR 0.9750
Epoch 1068 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7325 AR 0.9800
Epoch 1068 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5960 AR 0.8800
Epoch 1068 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.6544 AR 0.9550
Epoch 1068 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7346 AR 1.0000
Epoch 1069 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7305 AR 1.0000
Epoch 1069 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8383 AR 1.0000
Epoch 1069 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5866 AR 0.9150
Epoch 1069 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7806 AR 1.0000
Epoch 1069 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7569 AR 1.0000
Epoch 1069 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6814 AR 0.8550
Epoch 1069 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7067 AR 0.9467
Epoch 1069 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6419 AR 0.9667
Epoch 1069 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7800 AR 0.9800
Epoch 1069 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7516 AR 0.9550
Epoch 1070 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7314 AR 0.9750
Epoch 1070 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6729 AR 1.0000
Epoch 1070 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8538 AR 0.9800
Epoch 1070 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7267 AR 0.9550
Epoch 1070 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8100 AR 0.9000
Epoch 1070 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5958 AR 0.9300
Epoch 1070 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7583 AR 1.0000
Epoch 1070 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7233 AR 0.9667
Epoch 1070 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7114 AR 0.9350
Epoch 1070 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6629 AR 0.9500
Epoch 1071 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7099 AR 1.0000
Epoch 1071 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7395 AR 0.9550
Epoch 1071 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7600 AR 1.0000
Epoch 1071 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5821 AR 0.9000
Epoch 1071 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7181 AR 0.9800
Epoch 1071 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8783 AR 0.9550
Epoch 1071 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7600 AR 1.0000
Epoch 1071 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7733 AR 1.0000
Epoch 1071 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7780 AR 1.0000
Epoch 1071 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6088 AR 0.9800
Epoch 1072 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.7133 AR 0.8800
Epoch 1072 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7421 AR 0.9000
Epoch 1072 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7239 AR 0.9550
Epoch 1072 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7191 AR 0.9550
Epoch 1072 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6864 AR 0.9333
Epoch 1072 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7767 AR 0.9500
Epoch 1072 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6994 AR 0.9417
Epoch 1072 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7000 AR 0.9800
Epoch 1072 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6827 AR 0.8800
Epoch 1072 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7117 AR 1.0000
Epoch 1073 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7692 AR 1.0000
Epoch 1073 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8355 AR 0.9750
Epoch 1073 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6167 AR 0.8550
Epoch 1073 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7808 AR 0.9800
Epoch 1073 batch 00005: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6338 AR 0.9550
Epoch 1073 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8288 AR 1.0000
Epoch 1073 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6448 AR 0.9300
Epoch 1073 batch 00008: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7148 AR 1.0000
Epoch 1073 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6197 AR 0.9000
Epoch 1073 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8167 AR 1.0000
Epoch 1074 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6503 AR 0.9750
Epoch 1074 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7105 AR 0.9467
Epoch 1074 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8017 AR 1.0000
Epoch 1074 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7317 AR 0.9800
Epoch 1074 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7133 AR 0.8750
Epoch 1074 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7714 AR 1.0000
Epoch 1074 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7122 AR 1.0000
Epoch 1074 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6092 AR 0.9350
Epoch 1074 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7828 AR 0.9000
Epoch 1074 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7016 AR 0.9800
Epoch 1075 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7567 AR 1.0000
Epoch 1075 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6500 AR 0.8750
Epoch 1075 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8164 AR 0.9800
Epoch 1075 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7169 AR 0.9800
Epoch 1075 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7409 AR 0.9300
Epoch 1075 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5520 AR 0.8000
Epoch 1075 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7660 AR 0.9750
Epoch 1075 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7238 AR 0.9750
Epoch 1075 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8471 AR 0.9100
Epoch 1075 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7705 AR 0.9750
Epoch 1076 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.8233 AR 1.0000
Epoch 1076 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7717 AR 0.9750
Epoch 1076 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8025 AR 0.9750
Epoch 1076 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6555 AR 0.9667
Epoch 1076 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7589 AR 0.9750
Epoch 1076 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6478 AR 0.9800
Epoch 1076 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6431 AR 0.9000
Epoch 1076 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6405 AR 0.9000
Epoch 1076 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7875 AR 0.9550
Epoch 1076 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6627 AR 0.8900
Epoch 1077 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8217 AR 1.0000
Epoch 1077 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6919 AR 0.9300
Epoch 1077 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7371 AR 0.9750
Epoch 1077 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6267 AR 0.9750
Epoch 1077 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5813 AR 0.8550
Epoch 1077 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7353 AR 0.9800
Epoch 1077 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7498 AR 1.0000
Epoch 1077 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7389 AR 0.9800
Epoch 1077 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7967 AR 0.8800
Epoch 1077 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7521 AR 0.9800
Epoch 1078 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7721 AR 1.0000
Epoch 1078 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6755 AR 0.9800
Epoch 1078 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7756 AR 1.0000
Epoch 1078 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7656 AR 0.8750
Epoch 1078 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6088 AR 0.8750
Epoch 1078 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6652 AR 0.9300
Epoch 1078 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8117 AR 0.9467
Epoch 1078 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.5450 AR 0.9200
Epoch 1078 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7687 AR 0.9500
Epoch 1078 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6964 AR 0.9667
Epoch 1079 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.7358 AR 0.9750
Epoch 1079 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7300 AR 0.9800
Epoch 1079 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7520 AR 1.0000
Epoch 1079 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6433 AR 0.9350
Epoch 1079 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8089 AR 1.0000
Epoch 1079 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7617 AR 1.0000
Epoch 1079 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7967 AR 0.9600
Epoch 1079 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7130 AR 1.0000
Epoch 1079 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7089 AR 0.9750
Epoch 1079 batch 00010: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7883 AR 0.9750
Epoch 1080 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7181 AR 0.9750
Epoch 1080 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7250 AR 0.9350
Epoch 1080 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7912 AR 1.0000
Epoch 1080 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7005 AR 0.9600
Epoch 1080 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7812 AR 0.9667
Epoch 1080 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7833 AR 1.0000
Epoch 1080 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8393 AR 0.9550
Epoch 1080 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6443 AR 0.9467
Epoch 1080 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6864 AR 0.8750
Epoch 1080 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5789 AR 0.9550
Epoch 1081 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6287 AR 0.9050
Epoch 1081 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7014 AR 0.9000
Epoch 1081 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6917 AR 0.9750
Epoch 1081 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7627 AR 0.9800
Epoch 1081 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7983 AR 1.0000
Epoch 1081 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7126 AR 1.0000
Epoch 1081 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8073 AR 1.0000
Epoch 1081 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7730 AR 0.9750
Epoch 1081 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7075 AR 0.9550
Epoch 1081 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7127 AR 0.9800
Epoch 1082 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6917 AR 0.9500
Epoch 1082 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8614 AR 1.0000
Epoch 1082 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7656 AR 0.9550
Epoch 1082 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7479 AR 0.9500
Epoch 1082 batch 00005: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.8198 AR 1.0000
Epoch 1082 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6542 AR 0.9600
Epoch 1082 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6239 AR 0.8800
Epoch 1082 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6750 AR 1.0000
Epoch 1082 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7106 AR 0.9000
Epoch 1082 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6805 AR 1.0000
Epoch 1083 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6877 AR 0.9800
Epoch 1083 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.5628 AR 0.7850
Epoch 1083 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7572 AR 1.0000
Epoch 1083 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7253 AR 0.9000
Epoch 1083 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6833 AR 0.9000
Epoch 1083 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7564 AR 0.8750
Epoch 1083 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.5367 AR 0.8500
Epoch 1083 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8517 AR 0.9800
Epoch 1083 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6707 AR 0.9550
Epoch 1083 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7526 AR 0.9350
Epoch 1084 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7493 AR 0.9800
Epoch 1084 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7548 AR 0.9550
Epoch 1084 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8217 AR 0.9550
Epoch 1084 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6947 AR 0.9750
Epoch 1084 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6355 AR 1.0000
Epoch 1084 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7031 AR 0.9600
Epoch 1084 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.5183 AR 0.9000
Epoch 1084 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7517 AR 0.9500
Epoch 1084 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7381 AR 1.0000
Epoch 1084 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8562 AR 0.9550
Epoch 1085 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7233 AR 0.9500
Epoch 1085 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7094 AR 0.9300
Epoch 1085 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8117 AR 0.9800
Epoch 1085 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6977 AR 0.9800
Epoch 1085 batch 00005: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.7272 AR 0.9750
Epoch 1085 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7483 AR 0.9067
Epoch 1085 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7563 AR 0.9750
Epoch 1085 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.8220 AR 1.0000
Epoch 1085 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.6438 AR 1.0000
Epoch 1085 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6555 AR 1.0000
Epoch 1086 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7267 AR 1.0000
Epoch 1086 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7589 AR 1.0000
Epoch 1086 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7571 AR 0.9550
Epoch 1086 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6881 AR 1.0000
Epoch 1086 batch 00005: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.8233 AR 0.9550
Epoch 1086 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6667 AR 0.9800
Epoch 1086 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5000 AR 0.8667
Epoch 1086 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.7469 AR 0.9550
Epoch 1086 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7088 AR 0.8800
Epoch 1086 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8817 AR 0.9750
Epoch 1087 batch 00001: Loss 0.0015 Regression loss 0.0015 Classification loss 0.0000 AP 0.6714 AR 0.9750
Epoch 1087 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5628 AR 0.8467
Epoch 1087 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6177 AR 0.9800
Epoch 1087 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7686 AR 1.0000
Epoch 1087 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8360 AR 0.9800
Epoch 1087 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.7114 AR 0.8550
Epoch 1087 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0000 AP 0.7617 AR 1.0000
Epoch 1087 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.5592 AR 0.9050
Epoch 1087 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6833 AR 0.9467
Epoch 1087 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8767 AR 0.9750
Epoch 1088 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7067 AR 0.9667
Epoch 1088 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6719 AR 0.9150
Epoch 1088 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7600 AR 0.9750
Epoch 1088 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7920 AR 0.9750
Epoch 1088 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7909 AR 0.9800
Epoch 1088 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7630 AR 0.9800
Epoch 1088 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7306 AR 0.9600
Epoch 1088 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.6512 AR 0.9750
Epoch 1088 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6636 AR 0.9800
Epoch 1088 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7000 AR 0.9000
Epoch 1089 batch 00001: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7667 AR 0.9800
Epoch 1089 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0000 AP 0.7571 AR 1.0000
Epoch 1089 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7538 AR 0.9750
Epoch 1089 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.5933 AR 0.9150
Epoch 1089 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6758 AR 0.8917
Epoch 1089 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8286 AR 0.9750
Epoch 1089 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7181 AR 0.9000
Epoch 1089 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7611 AR 0.9800
Epoch 1089 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7180 AR 1.0000
Epoch 1089 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6258 AR 0.9300
Epoch 1090 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6293 AR 0.8750
Epoch 1090 batch 00002: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7583 AR 1.0000
Epoch 1090 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7650 AR 0.9467
Epoch 1090 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7003 AR 0.9550
Epoch 1090 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.7711 AR 1.0000
Epoch 1090 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7633 AR 0.9800
Epoch 1090 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7642 AR 1.0000
Epoch 1090 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8253 AR 1.0000
Epoch 1090 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7992 AR 1.0000
Epoch 1090 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6763 AR 1.0000
Epoch 1091 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0000 AP 0.7719 AR 1.0000
Epoch 1091 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7616 AR 1.0000
Epoch 1091 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6600 AR 0.9417
Epoch 1091 batch 00004: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.7850 AR 1.0000
Epoch 1091 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7125 AR 0.8400
Epoch 1091 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6544 AR 1.0000
Epoch 1091 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6470 AR 0.9750
Epoch 1091 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7358 AR 1.0000
Epoch 1091 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8055 AR 0.9550
Epoch 1091 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6644 AR 0.9250
Epoch 1092 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7488 AR 1.0000
Epoch 1092 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7450 AR 0.8417
Epoch 1092 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7864 AR 0.9550
Epoch 1092 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7250 AR 0.9800
Epoch 1092 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7414 AR 0.9800
Epoch 1092 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6898 AR 1.0000
Epoch 1092 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7421 AR 1.0000
Epoch 1092 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7352 AR 0.9800
Epoch 1092 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6386 AR 0.9550
Epoch 1092 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7389 AR 1.0000
Epoch 1093 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6648 AR 0.8550
Epoch 1093 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7533 AR 1.0000
Epoch 1093 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7639 AR 0.9550
Epoch 1093 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7371 AR 1.0000
Epoch 1093 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7656 AR 0.9550
Epoch 1093 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6958 AR 0.9750
Epoch 1093 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7350 AR 0.9667
Epoch 1093 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7364 AR 1.0000
Epoch 1093 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7168 AR 1.0000
Epoch 1093 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6102 AR 0.8400
Epoch 1094 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7856 AR 0.9800
Epoch 1094 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7171 AR 0.9750
Epoch 1094 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7881 AR 1.0000
Epoch 1094 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7309 AR 1.0000
Epoch 1094 batch 00005: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7196 AR 0.9800
Epoch 1094 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7133 AR 0.9000
Epoch 1094 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7117 AR 0.9350
Epoch 1094 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8181 AR 0.9800
Epoch 1094 batch 00009: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6771 AR 0.9217
Epoch 1094 batch 00010: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7377 AR 1.0000
Epoch 1095 batch 00001: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7610 AR 0.9800
Epoch 1095 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6183 AR 0.7600
Epoch 1095 batch 00003: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.8589 AR 0.9600
Epoch 1095 batch 00004: Loss 0.0001 Regression loss 0.0001 Classification loss 0.0000 AP 0.7581 AR 0.9400
Epoch 1095 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6806 AR 0.9800
Epoch 1095 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6881 AR 0.9500
Epoch 1095 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6971 AR 0.9550
Epoch 1095 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5555 AR 0.9000
Epoch 1095 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6838 AR 0.9167
Epoch 1095 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7750 AR 0.9500
Epoch 1096 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6437 AR 0.9600
Epoch 1096 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.8214 AR 0.9600
Epoch 1096 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8017 AR 1.0000
Epoch 1096 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7872 AR 1.0000
Epoch 1096 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6505 AR 0.9667
Epoch 1096 batch 00006: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7875 AR 0.9750
Epoch 1096 batch 00007: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7461 AR 0.9300
Epoch 1096 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7233 AR 0.9800
Epoch 1096 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7283 AR 0.8750
Epoch 1096 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6310 AR 0.9800
Epoch 1097 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8133 AR 0.9800
Epoch 1097 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.5521 AR 0.7550
Epoch 1097 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8205 AR 0.9417
Epoch 1097 batch 00004: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6886 AR 0.9800
Epoch 1097 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7314 AR 1.0000
Epoch 1097 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7177 AR 1.0000
Epoch 1097 batch 00007: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6972 AR 0.8800
Epoch 1097 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7328 AR 0.9550
Epoch 1097 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7006 AR 0.9750
Epoch 1097 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7433 AR 1.0000
Epoch 1098 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6853 AR 0.9000
Epoch 1098 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8494 AR 1.0000
Epoch 1098 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6953 AR 0.9600
Epoch 1098 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6846 AR 1.0000
Epoch 1098 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7433 AR 0.9550
Epoch 1098 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7933 AR 0.9550
Epoch 1098 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7167 AR 0.9750
Epoch 1098 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6235 AR 0.8600
Epoch 1098 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7625 AR 1.0000
Epoch 1098 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6605 AR 1.0000
Epoch 1099 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7680 AR 0.9800
Epoch 1099 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8083 AR 0.9350
Epoch 1099 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7225 AR 0.9600
Epoch 1099 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6167 AR 1.0000
Epoch 1099 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7364 AR 0.9550
Epoch 1099 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7883 AR 1.0000
Epoch 1099 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6539 AR 0.8750
Epoch 1099 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7401 AR 0.9600
Epoch 1099 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6788 AR 0.9750
Epoch 1099 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7181 AR 0.9800
Epoch 1100 batch 00001: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6722 AR 1.0000
Epoch 1100 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7567 AR 0.8850
Epoch 1100 batch 00003: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.8654 AR 1.0000
Epoch 1100 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6241 AR 0.9800
Epoch 1100 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6919 AR 0.9800
Epoch 1100 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6155 AR 0.9000
Epoch 1100 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7162 AR 0.9800
Epoch 1100 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7650 AR 0.9800
Epoch 1100 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7208 AR 1.0000
Epoch 1100 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7667 AR 0.9750
Epoch 1101 batch 00001: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.9133 AR 1.0000
Epoch 1101 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6656 AR 1.0000
Epoch 1101 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6906 AR 1.0000
Epoch 1101 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6002 AR 0.8800
Epoch 1101 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8838 AR 1.0000
Epoch 1101 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7367 AR 0.9500
Epoch 1101 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6358 AR 0.9400
Epoch 1101 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6222 AR 0.9250
Epoch 1101 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7849 AR 0.9600
Epoch 1101 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7062 AR 0.9800
Epoch 1102 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.4900 AR 0.7550
Epoch 1102 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7821 AR 0.9800
Epoch 1102 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6989 AR 0.9800
Epoch 1102 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7833 AR 0.9800
Epoch 1102 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7472 AR 0.9500
Epoch 1102 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6476 AR 1.0000
Epoch 1102 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7414 AR 1.0000
Epoch 1102 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7733 AR 0.9600
Epoch 1102 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7972 AR 0.9417
Epoch 1102 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7506 AR 1.0000
Epoch 1103 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7122 AR 0.9750
Epoch 1103 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7706 AR 0.8750
Epoch 1103 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7098 AR 0.9667
Epoch 1103 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7047 AR 0.9600
Epoch 1103 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6589 AR 0.8600
Epoch 1103 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6050 AR 0.8500
Epoch 1103 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6905 AR 1.0000
Epoch 1103 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6826 AR 0.9800
Epoch 1103 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8312 AR 1.0000
Epoch 1103 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7889 AR 0.9800
Epoch 1104 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6938 AR 0.9550
Epoch 1104 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7892 AR 1.0000
Epoch 1104 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7989 AR 0.9800
Epoch 1104 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6531 AR 0.8800
Epoch 1104 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7076 AR 0.9667
Epoch 1104 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7536 AR 0.9000
Epoch 1104 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7217 AR 0.9550
Epoch 1104 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6367 AR 0.9550
Epoch 1104 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6356 AR 0.9667
Epoch 1104 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7556 AR 0.9750
Epoch 1105 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7555 AR 0.9750
Epoch 1105 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7092 AR 0.9350
Epoch 1105 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7536 AR 0.8667
Epoch 1105 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7639 AR 0.9750
Epoch 1105 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5456 AR 0.9000
Epoch 1105 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7548 AR 0.9550
Epoch 1105 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7150 AR 0.9800
Epoch 1105 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7706 AR 0.9750
Epoch 1105 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.5680 AR 0.9267
Epoch 1105 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7889 AR 1.0000
Epoch 1106 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6743 AR 0.8750
Epoch 1106 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6673 AR 1.0000
Epoch 1106 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6666 AR 0.9350
Epoch 1106 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6883 AR 1.0000
Epoch 1106 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7814 AR 0.9600
Epoch 1106 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6913 AR 1.0000
Epoch 1106 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7356 AR 0.9500
Epoch 1106 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7083 AR 0.9800
Epoch 1106 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8392 AR 1.0000
Epoch 1106 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7821 AR 0.9217
Epoch 1107 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7005 AR 0.8600
Epoch 1107 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8550 AR 0.9800
Epoch 1107 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6738 AR 0.9350
Epoch 1107 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7400 AR 1.0000
Epoch 1107 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8050 AR 0.9417
Epoch 1107 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7597 AR 0.9800
Epoch 1107 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5505 AR 0.7800
Epoch 1107 batch 00008: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.6844 AR 0.9750
Epoch 1107 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6350 AR 1.0000
Epoch 1107 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6383 AR 0.9083
Epoch 1108 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6202 AR 0.9667
Epoch 1108 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7317 AR 0.9750
Epoch 1108 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7588 AR 0.9750
Epoch 1108 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7000 AR 0.9350
Epoch 1108 batch 00005: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.7317 AR 0.8667
Epoch 1108 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7725 AR 0.9800
Epoch 1108 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7431 AR 1.0000
Epoch 1108 batch 00008: Loss 0.0017 Regression loss 0.0017 Classification loss 0.0001 AP 0.6287 AR 0.9550
Epoch 1108 batch 00009: Loss 0.0015 Regression loss 0.0015 Classification loss 0.0000 AP 0.8150 AR 0.9000
Epoch 1108 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6864 AR 0.9300
Epoch 1109 batch 00001: Loss 0.0021 Regression loss 0.0021 Classification loss 0.0000 AP 0.6611 AR 0.9550
Epoch 1109 batch 00002: Loss 0.0023 Regression loss 0.0023 Classification loss 0.0000 AP 0.8300 AR 0.9800
Epoch 1109 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6386 AR 0.8750
Epoch 1109 batch 00004: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7242 AR 1.0000
Epoch 1109 batch 00005: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.6206 AR 0.8550
Epoch 1109 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6493 AR 0.8800
Epoch 1109 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0000 AP 0.7056 AR 0.9800
Epoch 1109 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7175 AR 0.9050
Epoch 1109 batch 00009: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.8300 AR 0.9333
Epoch 1109 batch 00010: Loss 0.0025 Regression loss 0.0024 Classification loss 0.0000 AP 0.6237 AR 0.9267
Epoch 1110 batch 00001: Loss 0.0018 Regression loss 0.0018 Classification loss 0.0001 AP 0.8283 AR 0.9750
Epoch 1110 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7883 AR 0.9800
Epoch 1110 batch 00003: Loss 0.0025 Regression loss 0.0025 Classification loss 0.0000 AP 0.5967 AR 1.0000
Epoch 1110 batch 00004: Loss 0.0025 Regression loss 0.0024 Classification loss 0.0001 AP 0.6714 AR 0.9050
Epoch 1110 batch 00005: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7179 AR 0.9750
Epoch 1110 batch 00006: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7917 AR 0.9500
Epoch 1110 batch 00007: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0001 AP 0.8800 AR 0.9800
Epoch 1110 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7946 AR 1.0000
Epoch 1110 batch 00009: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6270 AR 0.9750
Epoch 1110 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6296 AR 0.8667
Epoch 1111 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0000 AP 0.6917 AR 1.0000
Epoch 1111 batch 00002: Loss 0.0040 Regression loss 0.0039 Classification loss 0.0001 AP 0.6917 AR 0.9500
Epoch 1111 batch 00003: Loss 0.0024 Regression loss 0.0024 Classification loss 0.0000 AP 0.6600 AR 0.9000
Epoch 1111 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7217 AR 0.9000
Epoch 1111 batch 00005: Loss 0.0027 Regression loss 0.0027 Classification loss 0.0000 AP 0.7105 AR 0.9467
Epoch 1111 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7204 AR 0.9800
Epoch 1111 batch 00007: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.8505 AR 1.0000
Epoch 1111 batch 00008: Loss 0.0027 Regression loss 0.0026 Classification loss 0.0001 AP 0.6755 AR 0.9400
Epoch 1111 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6933 AR 0.8167
Epoch 1111 batch 00010: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7617 AR 0.9350
Epoch 1112 batch 00001: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7467 AR 0.8800
Epoch 1112 batch 00002: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.5363 AR 0.8800
Epoch 1112 batch 00003: Loss 0.0013 Regression loss 0.0013 Classification loss 0.0000 AP 0.8650 AR 1.0000
Epoch 1112 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7075 AR 0.9667
Epoch 1112 batch 00005: Loss 0.0016 Regression loss 0.0016 Classification loss 0.0001 AP 0.7030 AR 0.9300
Epoch 1112 batch 00006: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6417 AR 0.9750
Epoch 1112 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6743 AR 0.9750
Epoch 1112 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6710 AR 0.9017
Epoch 1112 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.8317 AR 1.0000
Epoch 1112 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7062 AR 0.9500
Epoch 1113 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7967 AR 0.9667
Epoch 1113 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7338 AR 1.0000
Epoch 1113 batch 00003: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.6755 AR 0.8750
Epoch 1113 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.7275 AR 1.0000
Epoch 1113 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7337 AR 0.9600
Epoch 1113 batch 00006: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6936 AR 0.9750
Epoch 1113 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7492 AR 0.9400
Epoch 1113 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7288 AR 0.8900
Epoch 1113 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7481 AR 0.9750
Epoch 1113 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6167 AR 0.8667
Epoch 1114 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7183 AR 0.9800
Epoch 1114 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5498 AR 0.8750
Epoch 1114 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7389 AR 1.0000
Epoch 1114 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6433 AR 0.7800
Epoch 1114 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7189 AR 0.9550
Epoch 1114 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7443 AR 0.9417
Epoch 1114 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7095 AR 0.9750
Epoch 1114 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8300 AR 0.9800
Epoch 1114 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8200 AR 0.9800
Epoch 1114 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7821 AR 0.9800
Epoch 1115 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7088 AR 0.9750
Epoch 1115 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7500 AR 0.9800
Epoch 1115 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7338 AR 0.9000
Epoch 1115 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7848 AR 0.9800
Epoch 1115 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7745 AR 0.9750
Epoch 1115 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5600 AR 0.9017
Epoch 1115 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7955 AR 1.0000
Epoch 1115 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7817 AR 0.9800
Epoch 1115 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6766 AR 0.9800
Epoch 1115 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8183 AR 0.9400
Epoch 1116 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6686 AR 0.9750
Epoch 1116 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6561 AR 0.9467
Epoch 1116 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7818 AR 0.9600
Epoch 1116 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7633 AR 1.0000
Epoch 1116 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8100 AR 1.0000
Epoch 1116 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7756 AR 0.9800
Epoch 1116 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6788 AR 0.9300
Epoch 1116 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.5645 AR 0.8750
Epoch 1116 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7017 AR 0.8800
Epoch 1116 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7949 AR 0.9800
Epoch 1117 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.7900 AR 0.9050
Epoch 1117 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8288 AR 0.9750
Epoch 1117 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7092 AR 1.0000
Epoch 1117 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8205 AR 1.0000
Epoch 1117 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6356 AR 0.9417
Epoch 1117 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7256 AR 0.9800
Epoch 1117 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.7267 AR 0.9800
Epoch 1117 batch 00008: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7015 AR 0.9800
Epoch 1117 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.7467 AR 0.9600
Epoch 1117 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6780 AR 1.0000
Epoch 1118 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6250 AR 0.8750
Epoch 1118 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8342 AR 0.9750
Epoch 1118 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6867 AR 0.9800
Epoch 1118 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6600 AR 0.8600
Epoch 1118 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7088 AR 0.8550
Epoch 1118 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7156 AR 0.9800
Epoch 1118 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8054 AR 1.0000
Epoch 1118 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6971 AR 0.9667
Epoch 1118 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7460 AR 1.0000
Epoch 1118 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7214 AR 1.0000
Epoch 1119 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7850 AR 0.9750
Epoch 1119 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7078 AR 0.9750
Epoch 1119 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7229 AR 0.9000
Epoch 1119 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6298 AR 0.8750
Epoch 1119 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7233 AR 1.0000
Epoch 1119 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6850 AR 0.9467
Epoch 1119 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7548 AR 0.9750
Epoch 1119 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7600 AR 0.9600
Epoch 1119 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7967 AR 0.9800
Epoch 1119 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6956 AR 1.0000
Epoch 1120 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6895 AR 0.8750
Epoch 1120 batch 00002: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7848 AR 0.9667
Epoch 1120 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7764 AR 1.0000
Epoch 1120 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7167 AR 0.9750
Epoch 1120 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7908 AR 0.9400
Epoch 1120 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8250 AR 1.0000
Epoch 1120 batch 00007: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6527 AR 0.9600
Epoch 1120 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6797 AR 0.9750
Epoch 1120 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6950 AR 0.9550
Epoch 1120 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7406 AR 1.0000
Epoch 1121 batch 00001: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7650 AR 1.0000
Epoch 1121 batch 00002: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.8267 AR 1.0000
Epoch 1121 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6617 AR 0.9750
Epoch 1121 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7833 AR 1.0000
Epoch 1121 batch 00005: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0001 AP 0.7929 AR 0.9550
Epoch 1121 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.5950 AR 0.8750
Epoch 1121 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7149 AR 0.9600
Epoch 1121 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6048 AR 0.9000
Epoch 1121 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6898 AR 0.9200
Epoch 1121 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8221 AR 0.9250
Epoch 1122 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6406 AR 0.9000
Epoch 1122 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7767 AR 0.9667
Epoch 1122 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7900 AR 1.0000
Epoch 1122 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7895 AR 1.0000
Epoch 1122 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6015 AR 0.9550
Epoch 1122 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6933 AR 0.9000
Epoch 1122 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6933 AR 1.0000
Epoch 1122 batch 00008: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.8038 AR 1.0000
Epoch 1122 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7513 AR 0.9350
Epoch 1122 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7855 AR 0.9550
Epoch 1123 batch 00001: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7800 AR 0.9800
Epoch 1123 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6656 AR 1.0000
Epoch 1123 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7383 AR 1.0000
Epoch 1123 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7469 AR 0.9217
Epoch 1123 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7139 AR 0.9500
Epoch 1123 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6351 AR 0.9500
Epoch 1123 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7600 AR 0.9750
Epoch 1123 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7071 AR 0.9400
Epoch 1123 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7698 AR 0.9800
Epoch 1123 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7421 AR 1.0000
Epoch 1124 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7414 AR 0.9500
Epoch 1124 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7322 AR 0.9750
Epoch 1124 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.7170 AR 0.9467
Epoch 1124 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.7171 AR 0.9417
Epoch 1124 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7448 AR 0.9800
Epoch 1124 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7039 AR 0.9750
Epoch 1124 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7017 AR 0.9000
Epoch 1124 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7727 AR 0.9600
Epoch 1124 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7131 AR 1.0000
Epoch 1124 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7238 AR 1.0000
Epoch 1125 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7723 AR 1.0000
Epoch 1125 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7900 AR 0.9300
Epoch 1125 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5886 AR 0.9000
Epoch 1125 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7023 AR 0.9667
Epoch 1125 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7364 AR 1.0000
Epoch 1125 batch 00006: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7255 AR 0.9600
Epoch 1125 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7694 AR 1.0000
Epoch 1125 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7166 AR 1.0000
Epoch 1125 batch 00009: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7900 AR 1.0000
Epoch 1125 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6928 AR 0.9550
Epoch 1126 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6619 AR 0.9550
Epoch 1126 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6195 AR 0.8850
Epoch 1126 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8338 AR 0.9800
Epoch 1126 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6708 AR 0.9800
Epoch 1126 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6684 AR 0.9550
Epoch 1126 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6683 AR 0.9000
Epoch 1126 batch 00007: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7221 AR 0.9500
Epoch 1126 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8503 AR 1.0000
Epoch 1126 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6633 AR 0.9750
Epoch 1126 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8869 AR 1.0000
Epoch 1127 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7305 AR 0.9600
Epoch 1127 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8150 AR 1.0000
Epoch 1127 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7244 AR 0.9800
Epoch 1127 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7706 AR 0.9500
Epoch 1127 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8008 AR 0.9500
Epoch 1127 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6458 AR 0.9600
Epoch 1127 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6321 AR 0.9550
Epoch 1127 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7200 AR 0.9750
Epoch 1127 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7467 AR 1.0000
Epoch 1127 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8231 AR 0.9750
Epoch 1128 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6967 AR 0.9750
Epoch 1128 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7292 AR 0.9350
Epoch 1128 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6923 AR 0.9000
Epoch 1128 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6542 AR 0.9750
Epoch 1128 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8267 AR 1.0000
Epoch 1128 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.5806 AR 0.8333
Epoch 1128 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8238 AR 1.0000
Epoch 1128 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8300 AR 1.0000
Epoch 1128 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6505 AR 0.9350
Epoch 1128 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7128 AR 0.9800
Epoch 1129 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7202 AR 0.9500
Epoch 1129 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7239 AR 0.9667
Epoch 1129 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7571 AR 0.9800
Epoch 1129 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7275 AR 0.8800
Epoch 1129 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7150 AR 0.9550
Epoch 1129 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7453 AR 1.0000
Epoch 1129 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6692 AR 0.9300
Epoch 1129 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7369 AR 0.9750
Epoch 1129 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8567 AR 0.9750
Epoch 1129 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6100 AR 0.9000
Epoch 1130 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7006 AR 0.9800
Epoch 1130 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7357 AR 0.9800
Epoch 1130 batch 00003: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.5638 AR 0.8667
Epoch 1130 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5927 AR 0.9050
Epoch 1130 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5808 AR 0.8300
Epoch 1130 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6695 AR 0.8550
Epoch 1130 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7506 AR 0.9417
Epoch 1130 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8133 AR 1.0000
Epoch 1130 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8058 AR 0.9750
Epoch 1130 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7083 AR 0.9750
Epoch 1131 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7139 AR 1.0000
Epoch 1131 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7508 AR 0.9750
Epoch 1131 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8305 AR 0.9600
Epoch 1131 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7717 AR 0.9550
Epoch 1131 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7605 AR 0.9800
Epoch 1131 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7864 AR 1.0000
Epoch 1131 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8231 AR 0.9417
Epoch 1131 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6962 AR 0.9750
Epoch 1131 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7020 AR 1.0000
Epoch 1131 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6592 AR 0.9750
Epoch 1132 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6928 AR 0.9750
Epoch 1132 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6086 AR 0.9800
Epoch 1132 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7467 AR 0.9400
Epoch 1132 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7317 AR 1.0000
Epoch 1132 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8514 AR 0.9500
Epoch 1132 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7371 AR 1.0000
Epoch 1132 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6200 AR 0.8750
Epoch 1132 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7542 AR 0.9550
Epoch 1132 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6872 AR 1.0000
Epoch 1132 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8139 AR 0.9800
Epoch 1133 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6478 AR 0.9800
Epoch 1133 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7375 AR 0.9800
Epoch 1133 batch 00003: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7250 AR 0.9250
Epoch 1133 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7421 AR 0.9550
Epoch 1133 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5564 AR 0.8750
Epoch 1133 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7067 AR 0.9667
Epoch 1133 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8814 AR 1.0000
Epoch 1133 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8067 AR 1.0000
Epoch 1133 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7155 AR 1.0000
Epoch 1133 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7510 AR 0.9550
Epoch 1134 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6650 AR 0.9417
Epoch 1134 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6917 AR 0.9417
Epoch 1134 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8656 AR 1.0000
Epoch 1134 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7723 AR 0.9417
Epoch 1134 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7530 AR 0.9800
Epoch 1134 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6571 AR 0.8800
Epoch 1134 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6800 AR 0.9000
Epoch 1134 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7600 AR 1.0000
Epoch 1134 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6550 AR 0.9750
Epoch 1134 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6955 AR 0.9600
Epoch 1135 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6948 AR 0.9750
Epoch 1135 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8275 AR 1.0000
Epoch 1135 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5560 AR 0.8150
Epoch 1135 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6342 AR 1.0000
Epoch 1135 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7008 AR 0.9500
Epoch 1135 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7672 AR 0.9800
Epoch 1135 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8067 AR 0.9333
Epoch 1135 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6876 AR 0.9500
Epoch 1135 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7960 AR 1.0000
Epoch 1135 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.8083 AR 0.9600
Epoch 1136 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6756 AR 0.9500
Epoch 1136 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7900 AR 0.9000
Epoch 1136 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6455 AR 0.9200
Epoch 1136 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7733 AR 0.9800
Epoch 1136 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6656 AR 0.9550
Epoch 1136 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6964 AR 1.0000
Epoch 1136 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7281 AR 1.0000
Epoch 1136 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7018 AR 0.9250
Epoch 1136 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7467 AR 0.9750
Epoch 1136 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7575 AR 0.9500
Epoch 1137 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8456 AR 0.9750
Epoch 1137 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6831 AR 0.9800
Epoch 1137 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7322 AR 0.9350
Epoch 1137 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7148 AR 0.8800
Epoch 1137 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7698 AR 1.0000
Epoch 1137 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7650 AR 1.0000
Epoch 1137 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6433 AR 0.8500
Epoch 1137 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6671 AR 0.9600
Epoch 1137 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7098 AR 0.9000
Epoch 1137 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7214 AR 0.9000
Epoch 1138 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5478 AR 0.9800
Epoch 1138 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6800 AR 0.8600
Epoch 1138 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6529 AR 0.9000
Epoch 1138 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7575 AR 1.0000
Epoch 1138 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6636 AR 0.9467
Epoch 1138 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8367 AR 1.0000
Epoch 1138 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7467 AR 0.9000
Epoch 1138 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6950 AR 0.9167
Epoch 1138 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6417 AR 0.8800
Epoch 1138 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8406 AR 0.9550
Epoch 1139 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8031 AR 1.0000
Epoch 1139 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8567 AR 0.9800
Epoch 1139 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6633 AR 0.9000
Epoch 1139 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6217 AR 0.8500
Epoch 1139 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7147 AR 0.9133
Epoch 1139 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6852 AR 0.9800
Epoch 1139 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6592 AR 0.9550
Epoch 1139 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6913 AR 0.9800
Epoch 1139 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7571 AR 0.9800
Epoch 1139 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7067 AR 0.9000
Epoch 1140 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8021 AR 0.9800
Epoch 1140 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8048 AR 1.0000
Epoch 1140 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5052 AR 0.8800
Epoch 1140 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6947 AR 0.9300
Epoch 1140 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8156 AR 1.0000
Epoch 1140 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.6994 AR 0.8350
Epoch 1140 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6738 AR 0.9750
Epoch 1140 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6817 AR 0.9350
Epoch 1140 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7800 AR 0.9550
Epoch 1140 batch 00010: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6900 AR 0.9800
Epoch 1141 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7105 AR 0.9350
Epoch 1141 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6214 AR 0.8750
Epoch 1141 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7572 AR 1.0000
Epoch 1141 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7300 AR 0.9350
Epoch 1141 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7553 AR 0.9600
Epoch 1141 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6364 AR 0.9000
Epoch 1141 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7706 AR 1.0000
Epoch 1141 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7533 AR 1.0000
Epoch 1141 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6876 AR 0.9750
Epoch 1141 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7255 AR 0.9800
Epoch 1142 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6788 AR 0.9800
Epoch 1142 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6459 AR 0.8350
Epoch 1142 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7464 AR 1.0000
Epoch 1142 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8000 AR 1.0000
Epoch 1142 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7735 AR 0.9800
Epoch 1142 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6560 AR 0.9800
Epoch 1142 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8267 AR 0.9750
Epoch 1142 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7250 AR 0.9500
Epoch 1142 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6772 AR 0.9800
Epoch 1142 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6756 AR 0.9000
Epoch 1143 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6639 AR 0.9000
Epoch 1143 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6673 AR 0.9800
Epoch 1143 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7133 AR 0.9600
Epoch 1143 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8038 AR 0.9800
Epoch 1143 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6461 AR 0.9167
Epoch 1143 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7788 AR 1.0000
Epoch 1143 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6505 AR 0.9550
Epoch 1143 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7433 AR 0.9800
Epoch 1143 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7213 AR 0.9600
Epoch 1143 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7094 AR 0.9000
Epoch 1144 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6125 AR 0.9217
Epoch 1144 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7600 AR 0.9750
Epoch 1144 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7627 AR 0.9600
Epoch 1144 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7706 AR 0.9550
Epoch 1144 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8517 AR 1.0000
Epoch 1144 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6703 AR 0.9800
Epoch 1144 batch 00007: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6583 AR 0.8800
Epoch 1144 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8758 AR 1.0000
Epoch 1144 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6067 AR 1.0000
Epoch 1144 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6983 AR 0.9500
Epoch 1145 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6976 AR 0.9600
Epoch 1145 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5945 AR 0.8300
Epoch 1145 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6433 AR 0.9800
Epoch 1145 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7881 AR 0.9750
Epoch 1145 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6345 AR 0.9500
Epoch 1145 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7622 AR 0.9750
Epoch 1145 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6471 AR 0.9000
Epoch 1145 batch 00008: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.5805 AR 0.8600
Epoch 1145 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.8439 AR 0.9667
Epoch 1145 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8371 AR 0.9600
Epoch 1146 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7871 AR 0.9800
Epoch 1146 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6850 AR 0.9417
Epoch 1146 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6813 AR 0.9400
Epoch 1146 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7548 AR 0.9800
Epoch 1146 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7767 AR 0.9750
Epoch 1146 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7350 AR 0.9500
Epoch 1146 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7802 AR 0.9500
Epoch 1146 batch 00008: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.6017 AR 1.0000
Epoch 1146 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7653 AR 1.0000
Epoch 1146 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7000 AR 1.0000
Epoch 1147 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7350 AR 0.9800
Epoch 1147 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7197 AR 0.9750
Epoch 1147 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6656 AR 0.9000
Epoch 1147 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7483 AR 0.8800
Epoch 1147 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7050 AR 0.9500
Epoch 1147 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6817 AR 0.8750
Epoch 1147 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7195 AR 0.9600
Epoch 1147 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7273 AR 0.9800
Epoch 1147 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6738 AR 0.9750
Epoch 1147 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7392 AR 0.9300
Epoch 1148 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8100 AR 0.9800
Epoch 1148 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6643 AR 0.9217
Epoch 1148 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6608 AR 0.9350
Epoch 1148 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7373 AR 1.0000
Epoch 1148 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6714 AR 0.8750
Epoch 1148 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6600 AR 0.8350
Epoch 1148 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7056 AR 1.0000
Epoch 1148 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7314 AR 0.9000
Epoch 1148 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7396 AR 1.0000
Epoch 1148 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6983 AR 0.9500
Epoch 1149 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7064 AR 0.9000
Epoch 1149 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.7036 AR 0.8300
Epoch 1149 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6179 AR 1.0000
Epoch 1149 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7767 AR 0.9500
Epoch 1149 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7448 AR 0.9000
Epoch 1149 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7742 AR 0.9800
Epoch 1149 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7706 AR 0.9667
Epoch 1149 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7767 AR 0.9800
Epoch 1149 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6517 AR 0.9800
Epoch 1149 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7081 AR 0.9667
Epoch 1150 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7536 AR 0.9750
Epoch 1150 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7548 AR 0.9667
Epoch 1150 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5319 AR 0.8800
Epoch 1150 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8342 AR 0.9667
Epoch 1150 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7188 AR 0.9750
Epoch 1150 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8605 AR 0.9550
Epoch 1150 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7370 AR 1.0000
Epoch 1150 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7033 AR 0.9800
Epoch 1150 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7120 AR 1.0000
Epoch 1150 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.7017 AR 0.9100
Epoch 1151 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7592 AR 1.0000
Epoch 1151 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7900 AR 0.9750
Epoch 1151 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6586 AR 0.8800
Epoch 1151 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8233 AR 0.9750
Epoch 1151 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8148 AR 1.0000
Epoch 1151 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6342 AR 0.8750
Epoch 1151 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5976 AR 0.9017
Epoch 1151 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6111 AR 0.8550
Epoch 1151 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.8417 AR 1.0000
Epoch 1151 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6371 AR 0.8800
Epoch 1152 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6302 AR 0.8600
Epoch 1152 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7457 AR 0.9550
Epoch 1152 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6683 AR 0.9750
Epoch 1152 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7429 AR 0.9500
Epoch 1152 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7250 AR 0.9267
Epoch 1152 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6692 AR 0.9417
Epoch 1152 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6814 AR 1.0000
Epoch 1152 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7739 AR 0.9000
Epoch 1152 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7205 AR 1.0000
Epoch 1152 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7021 AR 0.9600
Epoch 1153 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7220 AR 0.9750
Epoch 1153 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7131 AR 0.9600
Epoch 1153 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7275 AR 0.9800
Epoch 1153 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7667 AR 0.9550
Epoch 1153 batch 00005: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7881 AR 1.0000
Epoch 1153 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6917 AR 0.9800
Epoch 1153 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5527 AR 0.8500
Epoch 1153 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7300 AR 1.0000
Epoch 1153 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7228 AR 0.9350
Epoch 1153 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7833 AR 1.0000
Epoch 1154 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7352 AR 0.9300
Epoch 1154 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6756 AR 0.9750
Epoch 1154 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7356 AR 0.9550
Epoch 1154 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6258 AR 1.0000
Epoch 1154 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7171 AR 0.9800
Epoch 1154 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7633 AR 0.9750
Epoch 1154 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7886 AR 0.9550
Epoch 1154 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7617 AR 0.9000
Epoch 1154 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6789 AR 0.9667
Epoch 1154 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7450 AR 0.9550
Epoch 1155 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6398 AR 0.9550
Epoch 1155 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7356 AR 0.9750
Epoch 1155 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7338 AR 1.0000
Epoch 1155 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6758 AR 0.9800
Epoch 1155 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7062 AR 1.0000
Epoch 1155 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7121 AR 0.9300
Epoch 1155 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7600 AR 1.0000
Epoch 1155 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7333 AR 0.9000
Epoch 1155 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7169 AR 0.9550
Epoch 1155 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0001 AP 0.7064 AR 0.8850
Epoch 1156 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7283 AR 1.0000
Epoch 1156 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7688 AR 0.9800
Epoch 1156 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6233 AR 0.9800
Epoch 1156 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7667 AR 0.9750
Epoch 1156 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7350 AR 0.9750
Epoch 1156 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6924 AR 0.9800
Epoch 1156 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7142 AR 0.9800
Epoch 1156 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6488 AR 0.9000
Epoch 1156 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7550 AR 0.9500
Epoch 1156 batch 00010: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7977 AR 0.9800
Epoch 1157 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6865 AR 0.9400
Epoch 1157 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7717 AR 0.9750
Epoch 1157 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6314 AR 0.8083
Epoch 1157 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6850 AR 0.9800
Epoch 1157 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8202 AR 1.0000
Epoch 1157 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6738 AR 0.9800
Epoch 1157 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7146 AR 0.9550
Epoch 1157 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7267 AR 0.9750
Epoch 1157 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7561 AR 0.9800
Epoch 1157 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7856 AR 0.9800
Epoch 1158 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7288 AR 0.9550
Epoch 1158 batch 00002: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7739 AR 1.0000
Epoch 1158 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7721 AR 0.9750
Epoch 1158 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7489 AR 0.9750
Epoch 1158 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7794 AR 0.9500
Epoch 1158 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7731 AR 0.9800
Epoch 1158 batch 00007: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.6627 AR 0.9267
Epoch 1158 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5780 AR 0.9600
Epoch 1158 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6305 AR 0.8800
Epoch 1158 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7667 AR 1.0000
Epoch 1159 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7305 AR 0.9600
Epoch 1159 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7548 AR 0.8750
Epoch 1159 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6767 AR 1.0000
Epoch 1159 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6517 AR 0.9550
Epoch 1159 batch 00005: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7106 AR 0.9417
Epoch 1159 batch 00006: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7026 AR 1.0000
Epoch 1159 batch 00007: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6619 AR 0.9800
Epoch 1159 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8227 AR 0.9750
Epoch 1159 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7481 AR 0.9800
Epoch 1159 batch 00010: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7933 AR 0.9667
Epoch 1160 batch 00001: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7981 AR 0.9800
Epoch 1160 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7071 AR 0.9600
Epoch 1160 batch 00003: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7650 AR 1.0000
Epoch 1160 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7205 AR 0.9600
Epoch 1160 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5950 AR 0.9000
Epoch 1160 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7833 AR 0.9550
Epoch 1160 batch 00007: Loss 0.0001 Regression loss 0.0001 Classification loss 0.0000 AP 0.7219 AR 1.0000
Epoch 1160 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6583 AR 0.9500
Epoch 1160 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7730 AR 1.0000
Epoch 1160 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8038 AR 1.0000
Epoch 1161 batch 00001: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6969 AR 0.9217
Epoch 1161 batch 00002: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6933 AR 0.9350
Epoch 1161 batch 00003: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7477 AR 1.0000
Epoch 1161 batch 00004: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6280 AR 1.0000
Epoch 1161 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7431 AR 0.9500
Epoch 1161 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7614 AR 0.9750
Epoch 1161 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7350 AR 0.9600
Epoch 1161 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7452 AR 0.9750
Epoch 1161 batch 00009: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.8217 AR 1.0000
Epoch 1161 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7572 AR 1.0000
Epoch 1162 batch 00001: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.7489 AR 1.0000
Epoch 1162 batch 00002: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6120 AR 0.8000
Epoch 1162 batch 00003: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6323 AR 0.8667
Epoch 1162 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5871 AR 0.8500
Epoch 1162 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7933 AR 0.9550
Epoch 1162 batch 00006: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7283 AR 1.0000
Epoch 1162 batch 00007: Loss 0.0001 Regression loss 0.0001 Classification loss 0.0000 AP 0.6958 AR 0.9800
Epoch 1162 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7496 AR 1.0000
Epoch 1162 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8136 AR 0.9350
Epoch 1162 batch 00010: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6033 AR 0.8500
Epoch 1163 batch 00001: Loss 0.0001 Regression loss 0.0001 Classification loss 0.0000 AP 0.8398 AR 1.0000
Epoch 1163 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7095 AR 0.9350
Epoch 1163 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7467 AR 1.0000
Epoch 1163 batch 00004: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.5466 AR 0.8950
Epoch 1163 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7955 AR 1.0000
Epoch 1163 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7921 AR 0.9750
Epoch 1163 batch 00007: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6470 AR 0.9500
Epoch 1163 batch 00008: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.6571 AR 0.9400
Epoch 1163 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7067 AR 1.0000
Epoch 1163 batch 00010: Loss 0.0002 Regression loss 0.0001 Classification loss 0.0000 AP 0.8133 AR 1.0000
Epoch 1164 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8150 AR 1.0000
Epoch 1164 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7977 AR 1.0000
Epoch 1164 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7371 AR 0.9800
Epoch 1164 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6675 AR 0.9350
Epoch 1164 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7962 AR 0.9550
Epoch 1164 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5699 AR 0.9550
Epoch 1164 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6933 AR 0.9667
Epoch 1164 batch 00008: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.5788 AR 0.8417
Epoch 1164 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6838 AR 0.9800
Epoch 1164 batch 00010: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.8900 AR 0.9800
Epoch 1165 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7633 AR 0.9000
Epoch 1165 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7738 AR 0.9800
Epoch 1165 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7003 AR 0.9550
Epoch 1165 batch 00004: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7822 AR 0.9750
Epoch 1165 batch 00005: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6488 AR 0.9667
Epoch 1165 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8425 AR 0.9550
Epoch 1165 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7272 AR 0.9550
Epoch 1165 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.5448 AR 0.9000
Epoch 1165 batch 00009: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6448 AR 0.9300
Epoch 1165 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8107 AR 1.0000
Epoch 1166 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7533 AR 0.9550
Epoch 1166 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7177 AR 0.9000
Epoch 1166 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7250 AR 0.9550
Epoch 1166 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7046 AR 0.9750
Epoch 1166 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7598 AR 0.9500
Epoch 1166 batch 00006: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6867 AR 1.0000
Epoch 1166 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7476 AR 0.9800
Epoch 1166 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.7084 AR 0.9350
Epoch 1166 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6944 AR 1.0000
Epoch 1166 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7867 AR 1.0000
Epoch 1167 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6744 AR 0.9000
Epoch 1167 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7425 AR 0.9750
Epoch 1167 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7360 AR 0.9300
Epoch 1167 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6145 AR 0.9750
Epoch 1167 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7983 AR 0.9550
Epoch 1167 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6417 AR 0.9600
Epoch 1167 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7064 AR 0.9467
Epoch 1167 batch 00008: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.6592 AR 0.8800
Epoch 1167 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.6613 AR 0.9750
Epoch 1167 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0000 AP 0.8933 AR 0.9550
Epoch 1168 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7433 AR 0.9750
Epoch 1168 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7073 AR 1.0000
Epoch 1168 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6647 AR 1.0000
Epoch 1168 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7706 AR 0.9550
Epoch 1168 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6856 AR 0.9000
Epoch 1168 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8071 AR 0.9667
Epoch 1168 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7481 AR 0.9300
Epoch 1168 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7070 AR 0.9800
Epoch 1168 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6930 AR 0.9467
Epoch 1168 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6817 AR 0.9500
Epoch 1169 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7633 AR 0.9550
Epoch 1169 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8314 AR 0.9800
Epoch 1169 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.6756 AR 1.0000
Epoch 1169 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.7870 AR 0.9750
Epoch 1169 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.6205 AR 0.9800
Epoch 1169 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6314 AR 0.9500
Epoch 1169 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7138 AR 0.9800
Epoch 1169 batch 00008: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.7083 AR 0.9550
Epoch 1169 batch 00009: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0000 AP 0.6781 AR 0.8667
Epoch 1169 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.8142 AR 0.9750
Epoch 1170 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6877 AR 1.0000
Epoch 1170 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7317 AR 0.9667
Epoch 1170 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7261 AR 0.9800
Epoch 1170 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6802 AR 0.9750
Epoch 1170 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7696 AR 0.9800
Epoch 1170 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7583 AR 0.9000
Epoch 1170 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8050 AR 0.9750
Epoch 1170 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6341 AR 0.9550
Epoch 1170 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6498 AR 0.9000
Epoch 1170 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7967 AR 0.9800
Epoch 1171 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7383 AR 0.9250
Epoch 1171 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7748 AR 0.9800
Epoch 1171 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6505 AR 0.8050
Epoch 1171 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6888 AR 0.9000
Epoch 1171 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.5733 AR 0.8667
Epoch 1171 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6467 AR 1.0000
Epoch 1171 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8117 AR 0.9750
Epoch 1171 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7283 AR 0.9333
Epoch 1171 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.7828 AR 0.8950
Epoch 1171 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6456 AR 0.8550
Epoch 1172 batch 00001: Loss 0.0002 Regression loss 0.0002 Classification loss 0.0000 AP 0.7431 AR 0.8800
Epoch 1172 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7850 AR 0.9750
Epoch 1172 batch 00003: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.6792 AR 0.9000
Epoch 1172 batch 00004: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7125 AR 0.8800
Epoch 1172 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6152 AR 0.9800
Epoch 1172 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7344 AR 0.9300
Epoch 1172 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.7705 AR 0.9600
Epoch 1172 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6839 AR 0.9750
Epoch 1172 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6771 AR 0.9750
Epoch 1172 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8198 AR 1.0000
Epoch 1173 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6929 AR 0.9500
Epoch 1173 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7381 AR 0.9800
Epoch 1173 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7433 AR 1.0000
Epoch 1173 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7500 AR 0.9550
Epoch 1173 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.7456 AR 0.9167
Epoch 1173 batch 00006: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.6546 AR 0.9250
Epoch 1173 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6419 AR 0.9467
Epoch 1173 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7121 AR 1.0000
Epoch 1173 batch 00009: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0000 AP 0.6833 AR 0.7800
Epoch 1173 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7697 AR 1.0000
Epoch 1174 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7822 AR 1.0000
Epoch 1174 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7017 AR 1.0000
Epoch 1174 batch 00003: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0000 AP 0.5895 AR 0.9250
Epoch 1174 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6929 AR 0.9550
Epoch 1174 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7289 AR 0.9550
Epoch 1174 batch 00006: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0000 AP 0.8147 AR 0.9800
Epoch 1174 batch 00007: Loss 0.0022 Regression loss 0.0022 Classification loss 0.0001 AP 0.8161 AR 1.0000
Epoch 1174 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7139 AR 1.0000
Epoch 1174 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6133 AR 0.8500
Epoch 1174 batch 00010: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0000 AP 0.7738 AR 0.9667
Epoch 1175 batch 00001: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0000 AP 0.5833 AR 0.8417
Epoch 1175 batch 00002: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.9350 AR 1.0000
Epoch 1175 batch 00003: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.8505 AR 1.0000
Epoch 1175 batch 00004: Loss 0.0022 Regression loss 0.0021 Classification loss 0.0001 AP 0.6415 AR 0.8600
Epoch 1175 batch 00005: Loss 0.0014 Regression loss 0.0014 Classification loss 0.0001 AP 0.7622 AR 0.9550
Epoch 1175 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6272 AR 1.0000
Epoch 1175 batch 00007: Loss 0.0032 Regression loss 0.0032 Classification loss 0.0000 AP 0.6350 AR 0.8417
Epoch 1175 batch 00008: Loss 0.0027 Regression loss 0.0026 Classification loss 0.0001 AP 0.6648 AR 0.9750
Epoch 1175 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6514 AR 0.9250
Epoch 1175 batch 00010: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.6455 AR 0.9800
Epoch 1176 batch 00001: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.6798 AR 0.9800
Epoch 1176 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8508 AR 1.0000
Epoch 1176 batch 00003: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7744 AR 0.9750
Epoch 1176 batch 00004: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0000 AP 0.6677 AR 1.0000
Epoch 1176 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7975 AR 0.9500
Epoch 1176 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7281 AR 0.8600
Epoch 1176 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6158 AR 0.9000
Epoch 1176 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7580 AR 1.0000
Epoch 1176 batch 00009: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7750 AR 0.9167
Epoch 1176 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7105 AR 0.9350
Epoch 1177 batch 00001: Loss 0.0014 Regression loss 0.0009 Classification loss 0.0004 AP 0.6544 AR 0.9333
Epoch 1177 batch 00002: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.6523 AR 0.8900
Epoch 1177 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8068 AR 1.0000
Epoch 1177 batch 00004: Loss 0.0016 Regression loss 0.0011 Classification loss 0.0005 AP 0.6983 AR 0.9750
Epoch 1177 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7233 AR 0.9800
Epoch 1177 batch 00006: Loss 0.0022 Regression loss 0.0011 Classification loss 0.0011 AP 0.6613 AR 0.8800
Epoch 1177 batch 00007: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0005 AP 0.8017 AR 1.0000
Epoch 1177 batch 00008: Loss 0.0121 Regression loss 0.0034 Classification loss 0.0087 AP 0.8850 AR 0.9250
Epoch 1177 batch 00009: Loss 0.4776 Regression loss 0.0097 Classification loss 0.4679 AP 0.2006 AR 0.3233
Epoch 1177 batch 00010: Loss 0.5213 Regression loss 0.0235 Classification loss 0.4978 AP 0.0000 AR 0.0000
Epoch 1178 batch 00001: Loss 1.3411 Regression loss 0.0481 Classification loss 1.2930 AP 0.0333 AR 0.0500
Epoch 1178 batch 00002: Loss 0.2087 Regression loss 0.0387 Classification loss 0.1700 AP 0.1542 AR 0.2200
Epoch 1178 batch 00003: Loss 0.2692 Regression loss 0.0411 Classification loss 0.2281 AP 0.1000 AR 0.0000
Epoch 1178 batch 00004: Loss 0.6337 Regression loss 0.0235 Classification loss 0.6102 AP 0.1169 AR 0.2833
Epoch 1178 batch 00005: Loss 1.1195 Regression loss 0.0249 Classification loss 1.0946 AP 0.0700 AR 0.1667
Epoch 1178 batch 00006: Loss 0.6302 Regression loss 0.0377 Classification loss 0.5925 AP 0.0467 AR 0.0933
Epoch 1178 batch 00007: Loss 0.2627 Regression loss 0.0315 Classification loss 0.2312 AP 0.1819 AR 0.1783
Epoch 1178 batch 00008: Loss 0.2389 Regression loss 0.0252 Classification loss 0.2137 AP 0.1322 AR 0.2267
Epoch 1178 batch 00009: Loss 0.2898 Regression loss 0.0513 Classification loss 0.2385 AP 0.0919 AR 0.2233
Epoch 1178 batch 00010: Loss 0.4979 Regression loss 0.0297 Classification loss 0.4682 AP 0.1286 AR 0.3250
Epoch 1179 batch 00001: Loss 0.5172 Regression loss 0.0356 Classification loss 0.4816 AP 0.0476 AR 0.0700
Epoch 1179 batch 00002: Loss 0.5954 Regression loss 0.0233 Classification loss 0.5721 AP 0.1076 AR 0.2583
Epoch 1179 batch 00003: Loss 0.2825 Regression loss 0.0529 Classification loss 0.2296 AP 0.0792 AR 0.1200
Epoch 1179 batch 00004: Loss 0.2515 Regression loss 0.0404 Classification loss 0.2111 AP 0.1194 AR 0.2683
Epoch 1179 batch 00005: Loss 0.2255 Regression loss 0.0355 Classification loss 0.1900 AP 0.0601 AR 0.1317
Epoch 1179 batch 00006: Loss 0.2052 Regression loss 0.0365 Classification loss 0.1687 AP 0.1202 AR 0.3683
Epoch 1179 batch 00007: Loss 0.2037 Regression loss 0.0379 Classification loss 0.1658 AP 0.0820 AR 0.2400
Epoch 1179 batch 00008: Loss 0.3154 Regression loss 0.0363 Classification loss 0.2791 AP 0.0778 AR 0.2833
Epoch 1179 batch 00009: Loss 0.1429 Regression loss 0.0251 Classification loss 0.1178 AP 0.1339 AR 0.2833
Epoch 1179 batch 00010: Loss 0.1529 Regression loss 0.0263 Classification loss 0.1266 AP 0.3153 AR 0.3333
Epoch 1180 batch 00001: Loss 0.1784 Regression loss 0.0441 Classification loss 0.1343 AP 0.1333 AR 0.3200
Epoch 1180 batch 00002: Loss 0.1332 Regression loss 0.0289 Classification loss 0.1043 AP 0.1367 AR 0.2933
Epoch 1180 batch 00003: Loss 0.1175 Regression loss 0.0225 Classification loss 0.0949 AP 0.2102 AR 0.5167
Epoch 1180 batch 00004: Loss 0.1356 Regression loss 0.0264 Classification loss 0.1092 AP 0.0860 AR 0.2617
Epoch 1180 batch 00005: Loss 0.0603 Regression loss 0.0313 Classification loss 0.0289 AP 0.1513 AR 0.3500
Epoch 1180 batch 00006: Loss 0.0973 Regression loss 0.0301 Classification loss 0.0673 AP 0.0754 AR 0.1650
Epoch 1180 batch 00007: Loss 0.0822 Regression loss 0.0247 Classification loss 0.0575 AP 0.1761 AR 0.4117
Epoch 1180 batch 00008: Loss 0.1010 Regression loss 0.0286 Classification loss 0.0724 AP 0.2176 AR 0.3250
Epoch 1180 batch 00009: Loss 0.0555 Regression loss 0.0278 Classification loss 0.0277 AP 0.2579 AR 0.2583
Epoch 1180 batch 00010: Loss 0.0501 Regression loss 0.0258 Classification loss 0.0243 AP 0.2601 AR 0.4517
Epoch 1181 batch 00001: Loss 0.0565 Regression loss 0.0290 Classification loss 0.0275 AP 0.2031 AR 0.4267
Epoch 1181 batch 00002: Loss 0.0715 Regression loss 0.0249 Classification loss 0.0466 AP 0.1832 AR 0.4583
Epoch 1181 batch 00003: Loss 0.0332 Regression loss 0.0160 Classification loss 0.0172 AP 0.3351 AR 0.5850
Epoch 1181 batch 00004: Loss 0.0487 Regression loss 0.0232 Classification loss 0.0254 AP 0.3048 AR 0.6533
Epoch 1181 batch 00005: Loss 0.0670 Regression loss 0.0178 Classification loss 0.0492 AP 0.2611 AR 0.4083
Epoch 1181 batch 00006: Loss 0.0352 Regression loss 0.0181 Classification loss 0.0172 AP 0.3235 AR 0.5933
Epoch 1181 batch 00007: Loss 0.0298 Regression loss 0.0135 Classification loss 0.0163 AP 0.3869 AR 0.5867
Epoch 1181 batch 00008: Loss 0.0606 Regression loss 0.0128 Classification loss 0.0479 AP 0.3780 AR 0.5800
Epoch 1181 batch 00009: Loss 0.0531 Regression loss 0.0147 Classification loss 0.0383 AP 0.4967 AR 0.6917
Epoch 1181 batch 00010: Loss 0.1014 Regression loss 0.0172 Classification loss 0.0843 AP 0.4552 AR 0.7333
Epoch 1182 batch 00001: Loss 0.0373 Regression loss 0.0132 Classification loss 0.0241 AP 0.5334 AR 0.6917
Epoch 1182 batch 00002: Loss 0.0658 Regression loss 0.0126 Classification loss 0.0532 AP 0.3583 AR 0.5417
Epoch 1182 batch 00003: Loss 0.0288 Regression loss 0.0157 Classification loss 0.0131 AP 0.2508 AR 0.5517
Epoch 1182 batch 00004: Loss 0.0335 Regression loss 0.0173 Classification loss 0.0162 AP 0.2680 AR 0.4717
Epoch 1182 batch 00005: Loss 0.0259 Regression loss 0.0122 Classification loss 0.0136 AP 0.5295 AR 0.7417
Epoch 1182 batch 00006: Loss 0.0338 Regression loss 0.0166 Classification loss 0.0172 AP 0.3183 AR 0.5900
Epoch 1182 batch 00007: Loss 0.0355 Regression loss 0.0128 Classification loss 0.0227 AP 0.2931 AR 0.4767
Epoch 1182 batch 00008: Loss 0.0247 Regression loss 0.0103 Classification loss 0.0143 AP 0.4833 AR 0.6833
Epoch 1182 batch 00009: Loss 0.0442 Regression loss 0.0118 Classification loss 0.0324 AP 0.4172 AR 0.6733
Epoch 1182 batch 00010: Loss 0.0211 Regression loss 0.0106 Classification loss 0.0105 AP 0.4417 AR 0.7550
Epoch 1183 batch 00001: Loss 0.0345 Regression loss 0.0120 Classification loss 0.0225 AP 0.4979 AR 0.6600
Epoch 1183 batch 00002: Loss 0.0275 Regression loss 0.0118 Classification loss 0.0157 AP 0.4430 AR 0.6700
Epoch 1183 batch 00003: Loss 0.0221 Regression loss 0.0110 Classification loss 0.0111 AP 0.4489 AR 0.7483
Epoch 1183 batch 00004: Loss 0.0282 Regression loss 0.0102 Classification loss 0.0180 AP 0.5291 AR 0.7900
Epoch 1183 batch 00005: Loss 0.0197 Regression loss 0.0098 Classification loss 0.0099 AP 0.5171 AR 0.7050
Epoch 1183 batch 00006: Loss 0.0321 Regression loss 0.0140 Classification loss 0.0181 AP 0.4077 AR 0.8100
Epoch 1183 batch 00007: Loss 0.0141 Regression loss 0.0114 Classification loss 0.0028 AP 0.2733 AR 0.5167
Epoch 1183 batch 00008: Loss 0.0319 Regression loss 0.0130 Classification loss 0.0189 AP 0.3817 AR 0.5983
Epoch 1183 batch 00009: Loss 0.0227 Regression loss 0.0103 Classification loss 0.0124 AP 0.4045 AR 0.6017
Epoch 1183 batch 00010: Loss 0.0245 Regression loss 0.0146 Classification loss 0.0099 AP 0.5179 AR 0.6350
Epoch 1184 batch 00001: Loss 0.0172 Regression loss 0.0091 Classification loss 0.0081 AP 0.4295 AR 0.6900
Epoch 1184 batch 00002: Loss 0.0197 Regression loss 0.0098 Classification loss 0.0099 AP 0.4475 AR 0.7200
Epoch 1184 batch 00003: Loss 0.0236 Regression loss 0.0105 Classification loss 0.0132 AP 0.4136 AR 0.6983
Epoch 1184 batch 00004: Loss 0.0177 Regression loss 0.0133 Classification loss 0.0044 AP 0.4067 AR 0.5950
Epoch 1184 batch 00005: Loss 0.0164 Regression loss 0.0077 Classification loss 0.0087 AP 0.5112 AR 0.7500
Epoch 1184 batch 00006: Loss 0.0212 Regression loss 0.0099 Classification loss 0.0113 AP 0.4319 AR 0.6017
Epoch 1184 batch 00007: Loss 0.0181 Regression loss 0.0108 Classification loss 0.0073 AP 0.4884 AR 0.6650
Epoch 1184 batch 00008: Loss 0.0254 Regression loss 0.0097 Classification loss 0.0157 AP 0.4583 AR 0.6300
Epoch 1184 batch 00009: Loss 0.0210 Regression loss 0.0095 Classification loss 0.0116 AP 0.4575 AR 0.6833
Epoch 1184 batch 00010: Loss 0.0173 Regression loss 0.0100 Classification loss 0.0074 AP 0.4162 AR 0.6450
Epoch 1185 batch 00001: Loss 0.0190 Regression loss 0.0109 Classification loss 0.0080 AP 0.4337 AR 0.6900
Epoch 1185 batch 00002: Loss 0.0121 Regression loss 0.0089 Classification loss 0.0032 AP 0.6076 AR 0.8967
Epoch 1185 batch 00003: Loss 0.0188 Regression loss 0.0090 Classification loss 0.0098 AP 0.6264 AR 0.7617
Epoch 1185 batch 00004: Loss 0.0122 Regression loss 0.0096 Classification loss 0.0026 AP 0.4571 AR 0.6133
Epoch 1185 batch 00005: Loss 0.0117 Regression loss 0.0081 Classification loss 0.0036 AP 0.4429 AR 0.6467
Epoch 1185 batch 00006: Loss 0.0132 Regression loss 0.0083 Classification loss 0.0050 AP 0.4533 AR 0.6067
Epoch 1185 batch 00007: Loss 0.0232 Regression loss 0.0089 Classification loss 0.0143 AP 0.4583 AR 0.7250
Epoch 1185 batch 00008: Loss 0.0153 Regression loss 0.0108 Classification loss 0.0046 AP 0.3481 AR 0.4767
Epoch 1185 batch 00009: Loss 0.0191 Regression loss 0.0089 Classification loss 0.0102 AP 0.5002 AR 0.6733
Epoch 1185 batch 00010: Loss 0.0162 Regression loss 0.0103 Classification loss 0.0059 AP 0.3544 AR 0.5717
Epoch 1186 batch 00001: Loss 0.0163 Regression loss 0.0089 Classification loss 0.0074 AP 0.7879 AR 0.9050
Epoch 1186 batch 00002: Loss 0.0117 Regression loss 0.0080 Classification loss 0.0038 AP 0.5189 AR 0.8400
Epoch 1186 batch 00003: Loss 0.0136 Regression loss 0.0091 Classification loss 0.0046 AP 0.3928 AR 0.6967
Epoch 1186 batch 00004: Loss 0.0115 Regression loss 0.0085 Classification loss 0.0030 AP 0.3374 AR 0.6133
Epoch 1186 batch 00005: Loss 0.0120 Regression loss 0.0077 Classification loss 0.0043 AP 0.6529 AR 0.8050
Epoch 1186 batch 00006: Loss 0.0214 Regression loss 0.0116 Classification loss 0.0098 AP 0.3983 AR 0.6083
Epoch 1186 batch 00007: Loss 0.0136 Regression loss 0.0094 Classification loss 0.0043 AP 0.5310 AR 0.6833
Epoch 1186 batch 00008: Loss 0.0159 Regression loss 0.0075 Classification loss 0.0084 AP 0.5220 AR 0.7100
Epoch 1186 batch 00009: Loss 0.0118 Regression loss 0.0071 Classification loss 0.0047 AP 0.5972 AR 0.7917
Epoch 1186 batch 00010: Loss 0.0130 Regression loss 0.0094 Classification loss 0.0035 AP 0.5264 AR 0.7733
Epoch 1187 batch 00001: Loss 0.0117 Regression loss 0.0073 Classification loss 0.0044 AP 0.5158 AR 0.7867
Epoch 1187 batch 00002: Loss 0.0116 Regression loss 0.0082 Classification loss 0.0034 AP 0.4175 AR 0.7000
Epoch 1187 batch 00003: Loss 0.0122 Regression loss 0.0080 Classification loss 0.0042 AP 0.4998 AR 0.7167
Epoch 1187 batch 00004: Loss 0.0153 Regression loss 0.0090 Classification loss 0.0063 AP 0.4529 AR 0.6400
Epoch 1187 batch 00005: Loss 0.0123 Regression loss 0.0073 Classification loss 0.0051 AP 0.3679 AR 0.6350
Epoch 1187 batch 00006: Loss 0.0112 Regression loss 0.0077 Classification loss 0.0035 AP 0.5122 AR 0.8900
Epoch 1187 batch 00007: Loss 0.0117 Regression loss 0.0077 Classification loss 0.0040 AP 0.6100 AR 0.7667
Epoch 1187 batch 00008: Loss 0.0119 Regression loss 0.0078 Classification loss 0.0041 AP 0.4194 AR 0.5450
Epoch 1187 batch 00009: Loss 0.0115 Regression loss 0.0085 Classification loss 0.0030 AP 0.5329 AR 0.8767
Epoch 1187 batch 00010: Loss 0.0097 Regression loss 0.0072 Classification loss 0.0025 AP 0.4950 AR 0.7750
Epoch 1188 batch 00001: Loss 0.0099 Regression loss 0.0078 Classification loss 0.0021 AP 0.5833 AR 0.6567
Epoch 1188 batch 00002: Loss 0.0116 Regression loss 0.0072 Classification loss 0.0044 AP 0.4015 AR 0.5933
Epoch 1188 batch 00003: Loss 0.0107 Regression loss 0.0080 Classification loss 0.0027 AP 0.5129 AR 0.7750
Epoch 1188 batch 00004: Loss 0.0108 Regression loss 0.0066 Classification loss 0.0042 AP 0.5925 AR 0.8250
Epoch 1188 batch 00005: Loss 0.0102 Regression loss 0.0076 Classification loss 0.0026 AP 0.5030 AR 0.6350
Epoch 1188 batch 00006: Loss 0.0095 Regression loss 0.0067 Classification loss 0.0028 AP 0.5950 AR 0.7950
Epoch 1188 batch 00007: Loss 0.0128 Regression loss 0.0084 Classification loss 0.0044 AP 0.6619 AR 0.8667
Epoch 1188 batch 00008: Loss 0.0107 Regression loss 0.0081 Classification loss 0.0025 AP 0.6048 AR 0.8667
Epoch 1188 batch 00009: Loss 0.0117 Regression loss 0.0077 Classification loss 0.0041 AP 0.6214 AR 0.8250
Epoch 1188 batch 00010: Loss 0.0096 Regression loss 0.0066 Classification loss 0.0029 AP 0.5700 AR 0.7683
Epoch 1189 batch 00001: Loss 0.0105 Regression loss 0.0074 Classification loss 0.0031 AP 0.6071 AR 0.7400
Epoch 1189 batch 00002: Loss 0.0103 Regression loss 0.0076 Classification loss 0.0027 AP 0.5929 AR 0.8700
Epoch 1189 batch 00003: Loss 0.0108 Regression loss 0.0080 Classification loss 0.0028 AP 0.5040 AR 0.8000
Epoch 1189 batch 00004: Loss 0.0113 Regression loss 0.0059 Classification loss 0.0054 AP 0.5648 AR 0.6933
Epoch 1189 batch 00005: Loss 0.0087 Regression loss 0.0067 Classification loss 0.0020 AP 0.5894 AR 0.7867
Epoch 1189 batch 00006: Loss 0.0080 Regression loss 0.0058 Classification loss 0.0021 AP 0.6302 AR 0.8333
Epoch 1189 batch 00007: Loss 0.0099 Regression loss 0.0077 Classification loss 0.0021 AP 0.5186 AR 0.8550
Epoch 1189 batch 00008: Loss 0.0126 Regression loss 0.0087 Classification loss 0.0039 AP 0.6567 AR 0.7750
Epoch 1189 batch 00009: Loss 0.0085 Regression loss 0.0063 Classification loss 0.0022 AP 0.6165 AR 0.8433
Epoch 1189 batch 00010: Loss 0.0103 Regression loss 0.0073 Classification loss 0.0030 AP 0.5583 AR 0.7050
Epoch 1190 batch 00001: Loss 0.0093 Regression loss 0.0064 Classification loss 0.0029 AP 0.5417 AR 0.7400
Epoch 1190 batch 00002: Loss 0.0092 Regression loss 0.0072 Classification loss 0.0020 AP 0.5840 AR 0.7900
Epoch 1190 batch 00003: Loss 0.0082 Regression loss 0.0068 Classification loss 0.0014 AP 0.5862 AR 0.7750
Epoch 1190 batch 00004: Loss 0.0084 Regression loss 0.0073 Classification loss 0.0011 AP 0.6258 AR 0.8850
Epoch 1190 batch 00005: Loss 0.0101 Regression loss 0.0069 Classification loss 0.0032 AP 0.5158 AR 0.7750
Epoch 1190 batch 00006: Loss 0.0098 Regression loss 0.0068 Classification loss 0.0030 AP 0.6870 AR 0.8000
Epoch 1190 batch 00007: Loss 0.0077 Regression loss 0.0049 Classification loss 0.0028 AP 0.5341 AR 0.6900
Epoch 1190 batch 00008: Loss 0.0089 Regression loss 0.0062 Classification loss 0.0027 AP 0.6054 AR 0.8000
Epoch 1190 batch 00009: Loss 0.0120 Regression loss 0.0092 Classification loss 0.0027 AP 0.4947 AR 0.7300
Epoch 1190 batch 00010: Loss 0.0081 Regression loss 0.0060 Classification loss 0.0021 AP 0.6450 AR 0.8333
Epoch 1191 batch 00001: Loss 0.0093 Regression loss 0.0065 Classification loss 0.0029 AP 0.5445 AR 0.7350
Epoch 1191 batch 00002: Loss 0.0079 Regression loss 0.0060 Classification loss 0.0018 AP 0.5079 AR 0.7017
Epoch 1191 batch 00003: Loss 0.0084 Regression loss 0.0070 Classification loss 0.0014 AP 0.6775 AR 0.9000
Epoch 1191 batch 00004: Loss 0.0073 Regression loss 0.0053 Classification loss 0.0020 AP 0.5230 AR 0.7367
Epoch 1191 batch 00005: Loss 0.0085 Regression loss 0.0065 Classification loss 0.0021 AP 0.5133 AR 0.7667
Epoch 1191 batch 00006: Loss 0.0084 Regression loss 0.0063 Classification loss 0.0021 AP 0.5554 AR 0.8317
Epoch 1191 batch 00007: Loss 0.0093 Regression loss 0.0060 Classification loss 0.0034 AP 0.6257 AR 0.8417
Epoch 1191 batch 00008: Loss 0.0082 Regression loss 0.0069 Classification loss 0.0013 AP 0.5883 AR 0.7600
Epoch 1191 batch 00009: Loss 0.0074 Regression loss 0.0065 Classification loss 0.0009 AP 0.5850 AR 0.7783
Epoch 1191 batch 00010: Loss 0.0087 Regression loss 0.0068 Classification loss 0.0019 AP 0.8239 AR 0.9583
Epoch 1192 batch 00001: Loss 0.0083 Regression loss 0.0062 Classification loss 0.0021 AP 0.5563 AR 0.8333
Epoch 1192 batch 00002: Loss 0.0088 Regression loss 0.0075 Classification loss 0.0013 AP 0.6333 AR 0.7250
Epoch 1192 batch 00003: Loss 0.0073 Regression loss 0.0054 Classification loss 0.0018 AP 0.6217 AR 0.8333
Epoch 1192 batch 00004: Loss 0.0076 Regression loss 0.0057 Classification loss 0.0019 AP 0.5845 AR 0.7917
Epoch 1192 batch 00005: Loss 0.0082 Regression loss 0.0068 Classification loss 0.0014 AP 0.6517 AR 0.9000
Epoch 1192 batch 00006: Loss 0.0091 Regression loss 0.0070 Classification loss 0.0020 AP 0.5440 AR 0.8000
Epoch 1192 batch 00007: Loss 0.0070 Regression loss 0.0056 Classification loss 0.0014 AP 0.7300 AR 0.9300
Epoch 1192 batch 00008: Loss 0.0083 Regression loss 0.0048 Classification loss 0.0034 AP 0.6305 AR 0.9100
Epoch 1192 batch 00009: Loss 0.0070 Regression loss 0.0056 Classification loss 0.0013 AP 0.5963 AR 0.7833
Epoch 1192 batch 00010: Loss 0.0080 Regression loss 0.0064 Classification loss 0.0015 AP 0.5986 AR 0.8533
Epoch 1193 batch 00001: Loss 0.0070 Regression loss 0.0054 Classification loss 0.0017 AP 0.6543 AR 0.8000
Epoch 1193 batch 00002: Loss 0.0082 Regression loss 0.0061 Classification loss 0.0022 AP 0.6221 AR 0.8267
Epoch 1193 batch 00003: Loss 0.0072 Regression loss 0.0057 Classification loss 0.0015 AP 0.5329 AR 0.7917
Epoch 1193 batch 00004: Loss 0.0073 Regression loss 0.0047 Classification loss 0.0026 AP 0.6000 AR 0.7183
Epoch 1193 batch 00005: Loss 0.0065 Regression loss 0.0051 Classification loss 0.0014 AP 0.5546 AR 0.7650
Epoch 1193 batch 00006: Loss 0.0060 Regression loss 0.0050 Classification loss 0.0010 AP 0.4449 AR 0.7500
Epoch 1193 batch 00007: Loss 0.0073 Regression loss 0.0063 Classification loss 0.0010 AP 0.5525 AR 0.7833
Epoch 1193 batch 00008: Loss 0.0097 Regression loss 0.0080 Classification loss 0.0018 AP 0.6572 AR 0.9250
Epoch 1193 batch 00009: Loss 0.0084 Regression loss 0.0068 Classification loss 0.0017 AP 0.6542 AR 0.7967
Epoch 1193 batch 00010: Loss 0.0068 Regression loss 0.0054 Classification loss 0.0014 AP 0.7643 AR 0.9400
Epoch 1194 batch 00001: Loss 0.0059 Regression loss 0.0047 Classification loss 0.0012 AP 0.6433 AR 0.8333
Epoch 1194 batch 00002: Loss 0.0068 Regression loss 0.0053 Classification loss 0.0015 AP 0.5931 AR 0.7667
Epoch 1194 batch 00003: Loss 0.0074 Regression loss 0.0065 Classification loss 0.0010 AP 0.5595 AR 0.7267
Epoch 1194 batch 00004: Loss 0.0059 Regression loss 0.0046 Classification loss 0.0013 AP 0.6787 AR 0.8700
Epoch 1194 batch 00005: Loss 0.0062 Regression loss 0.0050 Classification loss 0.0012 AP 0.5096 AR 0.9500
Epoch 1194 batch 00006: Loss 0.0077 Regression loss 0.0055 Classification loss 0.0022 AP 0.4640 AR 0.6617
Epoch 1194 batch 00007: Loss 0.0075 Regression loss 0.0062 Classification loss 0.0013 AP 0.7725 AR 0.9467
Epoch 1194 batch 00008: Loss 0.0073 Regression loss 0.0053 Classification loss 0.0019 AP 0.7045 AR 0.7850
Epoch 1194 batch 00009: Loss 0.0076 Regression loss 0.0062 Classification loss 0.0014 AP 0.6889 AR 0.9667
Epoch 1194 batch 00010: Loss 0.0088 Regression loss 0.0064 Classification loss 0.0025 AP 0.5561 AR 0.6850
Epoch 1195 batch 00001: Loss 0.0069 Regression loss 0.0060 Classification loss 0.0009 AP 0.6190 AR 0.7600
Epoch 1195 batch 00002: Loss 0.0056 Regression loss 0.0039 Classification loss 0.0017 AP 0.5757 AR 0.9000
Epoch 1195 batch 00003: Loss 0.0066 Regression loss 0.0054 Classification loss 0.0013 AP 0.7417 AR 0.9000
Epoch 1195 batch 00004: Loss 0.0084 Regression loss 0.0070 Classification loss 0.0014 AP 0.6183 AR 0.8217
Epoch 1195 batch 00005: Loss 0.0065 Regression loss 0.0053 Classification loss 0.0011 AP 0.6586 AR 0.8167
Epoch 1195 batch 00006: Loss 0.0070 Regression loss 0.0057 Classification loss 0.0013 AP 0.7555 AR 0.8883
Epoch 1195 batch 00007: Loss 0.0080 Regression loss 0.0059 Classification loss 0.0020 AP 0.6221 AR 0.7100
Epoch 1195 batch 00008: Loss 0.0075 Regression loss 0.0065 Classification loss 0.0011 AP 0.5129 AR 0.6650
Epoch 1195 batch 00009: Loss 0.0066 Regression loss 0.0048 Classification loss 0.0018 AP 0.5714 AR 0.8250
Epoch 1195 batch 00010: Loss 0.0074 Regression loss 0.0054 Classification loss 0.0020 AP 0.5200 AR 0.7967
Epoch 1196 batch 00001: Loss 0.0061 Regression loss 0.0049 Classification loss 0.0012 AP 0.8217 AR 0.9800
Epoch 1196 batch 00002: Loss 0.0071 Regression loss 0.0054 Classification loss 0.0017 AP 0.6767 AR 0.7917
Epoch 1196 batch 00003: Loss 0.0060 Regression loss 0.0051 Classification loss 0.0009 AP 0.5292 AR 0.7467
Epoch 1196 batch 00004: Loss 0.0075 Regression loss 0.0062 Classification loss 0.0013 AP 0.5075 AR 0.6983
Epoch 1196 batch 00005: Loss 0.0067 Regression loss 0.0053 Classification loss 0.0014 AP 0.6055 AR 0.8433
Epoch 1196 batch 00006: Loss 0.0070 Regression loss 0.0051 Classification loss 0.0018 AP 0.7308 AR 0.8917
Epoch 1196 batch 00007: Loss 0.0076 Regression loss 0.0059 Classification loss 0.0016 AP 0.6683 AR 0.9000
Epoch 1196 batch 00008: Loss 0.0079 Regression loss 0.0066 Classification loss 0.0013 AP 0.5570 AR 0.8400
Epoch 1196 batch 00009: Loss 0.0070 Regression loss 0.0052 Classification loss 0.0018 AP 0.6624 AR 0.8950
Epoch 1196 batch 00010: Loss 0.0075 Regression loss 0.0067 Classification loss 0.0007 AP 0.5967 AR 0.8300
Epoch 1197 batch 00001: Loss 0.0058 Regression loss 0.0048 Classification loss 0.0009 AP 0.7050 AR 0.9600
Epoch 1197 batch 00002: Loss 0.0059 Regression loss 0.0049 Classification loss 0.0010 AP 0.4995 AR 0.7767
Epoch 1197 batch 00003: Loss 0.0053 Regression loss 0.0045 Classification loss 0.0008 AP 0.4969 AR 0.8200
Epoch 1197 batch 00004: Loss 0.0068 Regression loss 0.0056 Classification loss 0.0012 AP 0.6131 AR 0.8717
Epoch 1197 batch 00005: Loss 0.0056 Regression loss 0.0049 Classification loss 0.0007 AP 0.7333 AR 0.9000
Epoch 1197 batch 00006: Loss 0.0067 Regression loss 0.0049 Classification loss 0.0018 AP 0.6262 AR 0.8267
Epoch 1197 batch 00007: Loss 0.0077 Regression loss 0.0061 Classification loss 0.0015 AP 0.5981 AR 0.8050
Epoch 1197 batch 00008: Loss 0.0073 Regression loss 0.0060 Classification loss 0.0013 AP 0.6160 AR 0.8017
Epoch 1197 batch 00009: Loss 0.0062 Regression loss 0.0048 Classification loss 0.0014 AP 0.5925 AR 0.8050
Epoch 1197 batch 00010: Loss 0.0080 Regression loss 0.0063 Classification loss 0.0018 AP 0.6136 AR 0.7667
Epoch 1198 batch 00001: Loss 0.0058 Regression loss 0.0042 Classification loss 0.0017 AP 0.6202 AR 0.7817
Epoch 1198 batch 00002: Loss 0.0058 Regression loss 0.0050 Classification loss 0.0008 AP 0.5101 AR 0.7617
Epoch 1198 batch 00003: Loss 0.0058 Regression loss 0.0046 Classification loss 0.0012 AP 0.5750 AR 0.7833
Epoch 1198 batch 00004: Loss 0.0063 Regression loss 0.0052 Classification loss 0.0011 AP 0.6951 AR 0.8417
Epoch 1198 batch 00005: Loss 0.0055 Regression loss 0.0045 Classification loss 0.0010 AP 0.7012 AR 0.9750
Epoch 1198 batch 00006: Loss 0.0062 Regression loss 0.0051 Classification loss 0.0011 AP 0.7221 AR 0.8650
Epoch 1198 batch 00007: Loss 0.0060 Regression loss 0.0051 Classification loss 0.0009 AP 0.8548 AR 0.9467
Epoch 1198 batch 00008: Loss 0.0060 Regression loss 0.0047 Classification loss 0.0013 AP 0.6713 AR 1.0000
Epoch 1198 batch 00009: Loss 0.0077 Regression loss 0.0056 Classification loss 0.0021 AP 0.5388 AR 0.8650
Epoch 1198 batch 00010: Loss 0.0052 Regression loss 0.0045 Classification loss 0.0008 AP 0.7329 AR 0.8917
Epoch 1199 batch 00001: Loss 0.0069 Regression loss 0.0058 Classification loss 0.0010 AP 0.5612 AR 0.8500
Epoch 1199 batch 00002: Loss 0.0054 Regression loss 0.0045 Classification loss 0.0009 AP 0.6012 AR 0.7650
Epoch 1199 batch 00003: Loss 0.0057 Regression loss 0.0050 Classification loss 0.0007 AP 0.6883 AR 0.8850
Epoch 1199 batch 00004: Loss 0.0068 Regression loss 0.0049 Classification loss 0.0019 AP 0.6683 AR 0.7550
Epoch 1199 batch 00005: Loss 0.0050 Regression loss 0.0042 Classification loss 0.0007 AP 0.6926 AR 0.9417
Epoch 1199 batch 00006: Loss 0.0058 Regression loss 0.0048 Classification loss 0.0010 AP 0.7701 AR 0.9600
Epoch 1199 batch 00007: Loss 0.0072 Regression loss 0.0058 Classification loss 0.0014 AP 0.4952 AR 0.6833
Epoch 1199 batch 00008: Loss 0.0063 Regression loss 0.0046 Classification loss 0.0017 AP 0.5375 AR 0.7717
Epoch 1199 batch 00009: Loss 0.0062 Regression loss 0.0048 Classification loss 0.0015 AP 0.6917 AR 0.8550
Epoch 1199 batch 00010: Loss 0.0052 Regression loss 0.0044 Classification loss 0.0008 AP 0.6262 AR 0.8050
Epoch 1200 batch 00001: Loss 0.0067 Regression loss 0.0055 Classification loss 0.0011 AP 0.6517 AR 0.9167
Epoch 1200 batch 00002: Loss 0.0056 Regression loss 0.0046 Classification loss 0.0010 AP 0.5708 AR 0.8167
Epoch 1200 batch 00003: Loss 0.0058 Regression loss 0.0046 Classification loss 0.0011 AP 0.7567 AR 0.8917
Epoch 1200 batch 00004: Loss 0.0063 Regression loss 0.0052 Classification loss 0.0011 AP 0.5810 AR 0.7467
Epoch 1200 batch 00005: Loss 0.0062 Regression loss 0.0051 Classification loss 0.0011 AP 0.7406 AR 0.9800
Epoch 1200 batch 00006: Loss 0.0051 Regression loss 0.0046 Classification loss 0.0005 AP 0.6150 AR 0.8067
Epoch 1200 batch 00007: Loss 0.0061 Regression loss 0.0050 Classification loss 0.0011 AP 0.6211 AR 0.8750
Epoch 1200 batch 00008: Loss 0.0066 Regression loss 0.0048 Classification loss 0.0018 AP 0.5824 AR 0.7700
Epoch 1200 batch 00009: Loss 0.0050 Regression loss 0.0042 Classification loss 0.0007 AP 0.7220 AR 1.0000
Epoch 1200 batch 00010: Loss 0.0049 Regression loss 0.0036 Classification loss 0.0013 AP 0.6812 AR 0.8467
Epoch 1201 batch 00001: Loss 0.0055 Regression loss 0.0048 Classification loss 0.0008 AP 0.6648 AR 0.9750
Epoch 1201 batch 00002: Loss 0.0061 Regression loss 0.0044 Classification loss 0.0016 AP 0.6356 AR 0.8617
Epoch 1201 batch 00003: Loss 0.0054 Regression loss 0.0042 Classification loss 0.0012 AP 0.5911 AR 0.7400
Epoch 1201 batch 00004: Loss 0.0057 Regression loss 0.0047 Classification loss 0.0010 AP 0.6229 AR 0.8267
Epoch 1201 batch 00005: Loss 0.0047 Regression loss 0.0041 Classification loss 0.0006 AP 0.7090 AR 0.9350
Epoch 1201 batch 00006: Loss 0.0054 Regression loss 0.0046 Classification loss 0.0008 AP 0.6524 AR 0.8650
Epoch 1201 batch 00007: Loss 0.0044 Regression loss 0.0036 Classification loss 0.0008 AP 0.7672 AR 0.9667
Epoch 1201 batch 00008: Loss 0.0068 Regression loss 0.0056 Classification loss 0.0012 AP 0.5845 AR 0.6583
Epoch 1201 batch 00009: Loss 0.0057 Regression loss 0.0047 Classification loss 0.0010 AP 0.5983 AR 0.8267
Epoch 1201 batch 00010: Loss 0.0058 Regression loss 0.0049 Classification loss 0.0009 AP 0.7692 AR 0.9500
Epoch 1202 batch 00001: Loss 0.0061 Regression loss 0.0050 Classification loss 0.0011 AP 0.6450 AR 0.9217
Epoch 1202 batch 00002: Loss 0.0046 Regression loss 0.0035 Classification loss 0.0011 AP 0.7383 AR 0.8467
Epoch 1202 batch 00003: Loss 0.0058 Regression loss 0.0046 Classification loss 0.0012 AP 0.6142 AR 0.9050
Epoch 1202 batch 00004: Loss 0.0056 Regression loss 0.0043 Classification loss 0.0012 AP 0.7405 AR 0.9600
Epoch 1202 batch 00005: Loss 0.0042 Regression loss 0.0035 Classification loss 0.0007 AP 0.7812 AR 0.9600
Epoch 1202 batch 00006: Loss 0.0051 Regression loss 0.0043 Classification loss 0.0007 AP 0.5767 AR 0.7217
Epoch 1202 batch 00007: Loss 0.0056 Regression loss 0.0049 Classification loss 0.0008 AP 0.6463 AR 0.9167
Epoch 1202 batch 00008: Loss 0.0065 Regression loss 0.0057 Classification loss 0.0009 AP 0.5223 AR 0.7600
Epoch 1202 batch 00009: Loss 0.0051 Regression loss 0.0042 Classification loss 0.0009 AP 0.5973 AR 0.8667
Epoch 1202 batch 00010: Loss 0.0049 Regression loss 0.0041 Classification loss 0.0008 AP 0.7592 AR 0.9500
Epoch 1203 batch 00001: Loss 0.0048 Regression loss 0.0042 Classification loss 0.0006 AP 0.6679 AR 0.9750
Epoch 1203 batch 00002: Loss 0.0045 Regression loss 0.0037 Classification loss 0.0008 AP 0.6637 AR 0.8000
Epoch 1203 batch 00003: Loss 0.0053 Regression loss 0.0044 Classification loss 0.0009 AP 0.6174 AR 0.7650
Epoch 1203 batch 00004: Loss 0.0059 Regression loss 0.0046 Classification loss 0.0013 AP 0.6433 AR 0.9167
Epoch 1203 batch 00005: Loss 0.0056 Regression loss 0.0041 Classification loss 0.0015 AP 0.6389 AR 0.8500
Epoch 1203 batch 00006: Loss 0.0057 Regression loss 0.0049 Classification loss 0.0008 AP 0.5987 AR 0.8100
Epoch 1203 batch 00007: Loss 0.0047 Regression loss 0.0041 Classification loss 0.0007 AP 0.8567 AR 0.9300
Epoch 1203 batch 00008: Loss 0.0059 Regression loss 0.0051 Classification loss 0.0007 AP 0.6986 AR 0.8650
Epoch 1203 batch 00009: Loss 0.0054 Regression loss 0.0047 Classification loss 0.0007 AP 0.5900 AR 0.8467
Epoch 1203 batch 00010: Loss 0.0043 Regression loss 0.0034 Classification loss 0.0009 AP 0.6852 AR 0.9133
Epoch 1204 batch 00001: Loss 0.0057 Regression loss 0.0046 Classification loss 0.0011 AP 0.6726 AR 0.9417
Epoch 1204 batch 00002: Loss 0.0049 Regression loss 0.0042 Classification loss 0.0007 AP 0.6233 AR 0.8750
Epoch 1204 batch 00003: Loss 0.0044 Regression loss 0.0037 Classification loss 0.0007 AP 0.6600 AR 0.8017
Epoch 1204 batch 00004: Loss 0.0048 Regression loss 0.0041 Classification loss 0.0007 AP 0.5771 AR 0.8400
Epoch 1204 batch 00005: Loss 0.0046 Regression loss 0.0040 Classification loss 0.0006 AP 0.6675 AR 0.7917
Epoch 1204 batch 00006: Loss 0.0045 Regression loss 0.0039 Classification loss 0.0006 AP 0.7079 AR 0.8933
Epoch 1204 batch 00007: Loss 0.0060 Regression loss 0.0042 Classification loss 0.0018 AP 0.6345 AR 0.7000
Epoch 1204 batch 00008: Loss 0.0049 Regression loss 0.0041 Classification loss 0.0008 AP 0.6212 AR 0.8250
Epoch 1204 batch 00009: Loss 0.0051 Regression loss 0.0042 Classification loss 0.0009 AP 0.7400 AR 0.9500
Epoch 1204 batch 00010: Loss 0.0058 Regression loss 0.0050 Classification loss 0.0008 AP 0.7100 AR 0.8750
Epoch 1205 batch 00001: Loss 0.0047 Regression loss 0.0039 Classification loss 0.0007 AP 0.6100 AR 0.8167
Epoch 1205 batch 00002: Loss 0.0048 Regression loss 0.0042 Classification loss 0.0006 AP 0.6070 AR 0.9167
Epoch 1205 batch 00003: Loss 0.0051 Regression loss 0.0043 Classification loss 0.0008 AP 0.5381 AR 0.7050
Epoch 1205 batch 00004: Loss 0.0050 Regression loss 0.0043 Classification loss 0.0007 AP 0.6987 AR 0.9400
Epoch 1205 batch 00005: Loss 0.0041 Regression loss 0.0035 Classification loss 0.0007 AP 0.6504 AR 0.9250
Epoch 1205 batch 00006: Loss 0.0055 Regression loss 0.0042 Classification loss 0.0013 AP 0.7433 AR 0.7817
Epoch 1205 batch 00007: Loss 0.0052 Regression loss 0.0043 Classification loss 0.0009 AP 0.7067 AR 0.8767
Epoch 1205 batch 00008: Loss 0.0049 Regression loss 0.0043 Classification loss 0.0006 AP 0.6512 AR 0.9667
Epoch 1205 batch 00009: Loss 0.0057 Regression loss 0.0042 Classification loss 0.0015 AP 0.5779 AR 0.7350
Epoch 1205 batch 00010: Loss 0.0045 Regression loss 0.0039 Classification loss 0.0006 AP 0.6983 AR 0.8750
Epoch 1206 batch 00001: Loss 0.0049 Regression loss 0.0042 Classification loss 0.0007 AP 0.8246 AR 0.9417
Epoch 1206 batch 00002: Loss 0.0045 Regression loss 0.0034 Classification loss 0.0011 AP 0.7167 AR 0.8800
Epoch 1206 batch 00003: Loss 0.0046 Regression loss 0.0038 Classification loss 0.0008 AP 0.6725 AR 0.8167
Epoch 1206 batch 00004: Loss 0.0060 Regression loss 0.0051 Classification loss 0.0009 AP 0.6461 AR 0.9800
Epoch 1206 batch 00005: Loss 0.0048 Regression loss 0.0038 Classification loss 0.0011 AP 0.5929 AR 0.8100
Epoch 1206 batch 00006: Loss 0.0054 Regression loss 0.0043 Classification loss 0.0011 AP 0.6236 AR 0.8600
Epoch 1206 batch 00007: Loss 0.0046 Regression loss 0.0039 Classification loss 0.0006 AP 0.6442 AR 0.9667
Epoch 1206 batch 00008: Loss 0.0046 Regression loss 0.0040 Classification loss 0.0006 AP 0.7171 AR 0.8800
Epoch 1206 batch 00009: Loss 0.0043 Regression loss 0.0037 Classification loss 0.0006 AP 0.6438 AR 0.7933
Epoch 1206 batch 00010: Loss 0.0048 Regression loss 0.0042 Classification loss 0.0005 AP 0.5881 AR 0.9500
Epoch 1207 batch 00001: Loss 0.0045 Regression loss 0.0036 Classification loss 0.0009 AP 0.6379 AR 0.8967
Epoch 1207 batch 00002: Loss 0.0045 Regression loss 0.0037 Classification loss 0.0008 AP 0.6419 AR 0.9300
Epoch 1207 batch 00003: Loss 0.0043 Regression loss 0.0037 Classification loss 0.0005 AP 0.7867 AR 0.9100
Epoch 1207 batch 00004: Loss 0.0050 Regression loss 0.0041 Classification loss 0.0009 AP 0.6839 AR 0.9000
Epoch 1207 batch 00005: Loss 0.0041 Regression loss 0.0035 Classification loss 0.0006 AP 0.6286 AR 0.7850
Epoch 1207 batch 00006: Loss 0.0051 Regression loss 0.0046 Classification loss 0.0005 AP 0.5067 AR 0.8467
Epoch 1207 batch 00007: Loss 0.0048 Regression loss 0.0036 Classification loss 0.0011 AP 0.6633 AR 0.8500
Epoch 1207 batch 00008: Loss 0.0055 Regression loss 0.0048 Classification loss 0.0007 AP 0.5833 AR 0.7000
Epoch 1207 batch 00009: Loss 0.0045 Regression loss 0.0037 Classification loss 0.0008 AP 0.6383 AR 0.9050
Epoch 1207 batch 00010: Loss 0.0046 Regression loss 0.0039 Classification loss 0.0007 AP 0.7452 AR 0.9100
Epoch 1208 batch 00001: Loss 0.0049 Regression loss 0.0041 Classification loss 0.0008 AP 0.7600 AR 0.9217
Epoch 1208 batch 00002: Loss 0.0035 Regression loss 0.0031 Classification loss 0.0004 AP 0.7398 AR 1.0000
Epoch 1208 batch 00003: Loss 0.0048 Regression loss 0.0039 Classification loss 0.0010 AP 0.7167 AR 0.9150
Epoch 1208 batch 00004: Loss 0.0048 Regression loss 0.0040 Classification loss 0.0008 AP 0.5376 AR 0.8600
Epoch 1208 batch 00005: Loss 0.0045 Regression loss 0.0035 Classification loss 0.0009 AP 0.7589 AR 0.8850
Epoch 1208 batch 00006: Loss 0.0049 Regression loss 0.0043 Classification loss 0.0006 AP 0.6800 AR 0.8167
Epoch 1208 batch 00007: Loss 0.0043 Regression loss 0.0033 Classification loss 0.0010 AP 0.6753 AR 0.8517
Epoch 1208 batch 00008: Loss 0.0050 Regression loss 0.0044 Classification loss 0.0006 AP 0.6492 AR 0.8667
Epoch 1208 batch 00009: Loss 0.0052 Regression loss 0.0046 Classification loss 0.0006 AP 0.6095 AR 0.9100
Epoch 1208 batch 00010: Loss 0.0046 Regression loss 0.0040 Classification loss 0.0006 AP 0.6083 AR 0.7250
Epoch 1209 batch 00001: Loss 0.0045 Regression loss 0.0038 Classification loss 0.0007 AP 0.6179 AR 0.8167
Epoch 1209 batch 00002: Loss 0.0033 Regression loss 0.0029 Classification loss 0.0004 AP 0.6800 AR 0.8967
Epoch 1209 batch 00003: Loss 0.0055 Regression loss 0.0047 Classification loss 0.0008 AP 0.6764 AR 0.8750
Epoch 1209 batch 00004: Loss 0.0038 Regression loss 0.0033 Classification loss 0.0005 AP 0.6083 AR 0.8267
Epoch 1209 batch 00005: Loss 0.0046 Regression loss 0.0039 Classification loss 0.0008 AP 0.6403 AR 0.7800
Epoch 1209 batch 00006: Loss 0.0045 Regression loss 0.0038 Classification loss 0.0006 AP 0.6192 AR 0.9267
Epoch 1209 batch 00007: Loss 0.0056 Regression loss 0.0047 Classification loss 0.0009 AP 0.7867 AR 1.0000
Epoch 1209 batch 00008: Loss 0.0054 Regression loss 0.0042 Classification loss 0.0012 AP 0.6817 AR 0.8717
Epoch 1209 batch 00009: Loss 0.0040 Regression loss 0.0035 Classification loss 0.0005 AP 0.7506 AR 0.9550
Epoch 1209 batch 00010: Loss 0.0043 Regression loss 0.0034 Classification loss 0.0010 AP 0.7517 AR 0.8800
Epoch 1210 batch 00001: Loss 0.0050 Regression loss 0.0039 Classification loss 0.0012 AP 0.6617 AR 0.8550
Epoch 1210 batch 00002: Loss 0.0047 Regression loss 0.0042 Classification loss 0.0006 AP 0.7992 AR 0.9550
Epoch 1210 batch 00003: Loss 0.0040 Regression loss 0.0033 Classification loss 0.0006 AP 0.6600 AR 0.9750
Epoch 1210 batch 00004: Loss 0.0047 Regression loss 0.0037 Classification loss 0.0010 AP 0.4875 AR 0.7667
Epoch 1210 batch 00005: Loss 0.0041 Regression loss 0.0036 Classification loss 0.0005 AP 0.8405 AR 0.9217
Epoch 1210 batch 00006: Loss 0.0035 Regression loss 0.0030 Classification loss 0.0004 AP 0.7850 AR 0.9500
Epoch 1210 batch 00007: Loss 0.0048 Regression loss 0.0043 Classification loss 0.0005 AP 0.6625 AR 0.8350
Epoch 1210 batch 00008: Loss 0.0041 Regression loss 0.0035 Classification loss 0.0007 AP 0.6975 AR 0.8500
Epoch 1210 batch 00009: Loss 0.0042 Regression loss 0.0037 Classification loss 0.0005 AP 0.5237 AR 0.7833
Epoch 1210 batch 00010: Loss 0.0047 Regression loss 0.0038 Classification loss 0.0008 AP 0.7333 AR 0.8667
Epoch 1211 batch 00001: Loss 0.0042 Regression loss 0.0032 Classification loss 0.0010 AP 0.7129 AR 0.8900
Epoch 1211 batch 00002: Loss 0.0046 Regression loss 0.0041 Classification loss 0.0005 AP 0.7400 AR 0.9667
Epoch 1211 batch 00003: Loss 0.0042 Regression loss 0.0036 Classification loss 0.0006 AP 0.6058 AR 0.8267
Epoch 1211 batch 00004: Loss 0.0051 Regression loss 0.0042 Classification loss 0.0008 AP 0.6388 AR 0.8567
Epoch 1211 batch 00005: Loss 0.0043 Regression loss 0.0036 Classification loss 0.0007 AP 0.8267 AR 0.8800
Epoch 1211 batch 00006: Loss 0.0043 Regression loss 0.0036 Classification loss 0.0006 AP 0.8133 AR 0.9550
Epoch 1211 batch 00007: Loss 0.0048 Regression loss 0.0043 Classification loss 0.0006 AP 0.6000 AR 0.8000
Epoch 1211 batch 00008: Loss 0.0045 Regression loss 0.0039 Classification loss 0.0006 AP 0.5862 AR 0.8300
Epoch 1211 batch 00009: Loss 0.0039 Regression loss 0.0034 Classification loss 0.0005 AP 0.6892 AR 0.9350
Epoch 1211 batch 00010: Loss 0.0035 Regression loss 0.0032 Classification loss 0.0004 AP 0.6492 AR 0.9750
Epoch 1212 batch 00001: Loss 0.0044 Regression loss 0.0040 Classification loss 0.0004 AP 0.7975 AR 0.8950
Epoch 1212 batch 00002: Loss 0.0041 Regression loss 0.0034 Classification loss 0.0007 AP 0.5867 AR 0.8550
Epoch 1212 batch 00003: Loss 0.0043 Regression loss 0.0036 Classification loss 0.0007 AP 0.7050 AR 0.7967
Epoch 1212 batch 00004: Loss 0.0051 Regression loss 0.0044 Classification loss 0.0008 AP 0.6201 AR 0.8500
Epoch 1212 batch 00005: Loss 0.0040 Regression loss 0.0034 Classification loss 0.0007 AP 0.6005 AR 0.7967
Epoch 1212 batch 00006: Loss 0.0049 Regression loss 0.0043 Classification loss 0.0006 AP 0.6583 AR 0.8300
Epoch 1212 batch 00007: Loss 0.0037 Regression loss 0.0032 Classification loss 0.0005 AP 0.6053 AR 0.9050
Epoch 1212 batch 00008: Loss 0.0036 Regression loss 0.0029 Classification loss 0.0006 AP 0.7683 AR 0.9750
Epoch 1212 batch 00009: Loss 0.0040 Regression loss 0.0032 Classification loss 0.0008 AP 0.6567 AR 0.9300
Epoch 1212 batch 00010: Loss 0.0045 Regression loss 0.0039 Classification loss 0.0006 AP 0.7388 AR 0.8417
Epoch 1213 batch 00001: Loss 0.0037 Regression loss 0.0032 Classification loss 0.0005 AP 0.8067 AR 1.0000
Epoch 1213 batch 00002: Loss 0.0050 Regression loss 0.0047 Classification loss 0.0004 AP 0.7333 AR 0.9050
Epoch 1213 batch 00003: Loss 0.0033 Regression loss 0.0030 Classification loss 0.0003 AP 0.6483 AR 0.8550
Epoch 1213 batch 00004: Loss 0.0038 Regression loss 0.0033 Classification loss 0.0004 AP 0.4767 AR 0.6850
Epoch 1213 batch 00005: Loss 0.0045 Regression loss 0.0040 Classification loss 0.0005 AP 0.6762 AR 0.8500
Epoch 1213 batch 00006: Loss 0.0042 Regression loss 0.0035 Classification loss 0.0007 AP 0.6512 AR 0.9167
Epoch 1213 batch 00007: Loss 0.0048 Regression loss 0.0037 Classification loss 0.0011 AP 0.6883 AR 0.8100
Epoch 1213 batch 00008: Loss 0.0058 Regression loss 0.0050 Classification loss 0.0008 AP 0.6567 AR 0.8567
Epoch 1213 batch 00009: Loss 0.0039 Regression loss 0.0033 Classification loss 0.0006 AP 0.6975 AR 0.9500
Epoch 1213 batch 00010: Loss 0.0052 Regression loss 0.0047 Classification loss 0.0005 AP 0.5988 AR 0.7900
Epoch 1214 batch 00001: Loss 0.0051 Regression loss 0.0042 Classification loss 0.0008 AP 0.6442 AR 0.7483
Epoch 1214 batch 00002: Loss 0.0038 Regression loss 0.0033 Classification loss 0.0004 AP 0.7452 AR 0.9150
Epoch 1214 batch 00003: Loss 0.0042 Regression loss 0.0033 Classification loss 0.0009 AP 0.7286 AR 0.9417
Epoch 1214 batch 00004: Loss 0.0046 Regression loss 0.0041 Classification loss 0.0005 AP 0.6821 AR 0.8967
Epoch 1214 batch 00005: Loss 0.0038 Regression loss 0.0033 Classification loss 0.0005 AP 0.7120 AR 0.9500
Epoch 1214 batch 00006: Loss 0.0034 Regression loss 0.0031 Classification loss 0.0004 AP 0.8008 AR 0.9350
Epoch 1214 batch 00007: Loss 0.0037 Regression loss 0.0033 Classification loss 0.0005 AP 0.7750 AR 0.9750
Epoch 1214 batch 00008: Loss 0.0033 Regression loss 0.0030 Classification loss 0.0003 AP 0.6398 AR 0.9000
Epoch 1214 batch 00009: Loss 0.0036 Regression loss 0.0031 Classification loss 0.0005 AP 0.8367 AR 0.9750
Epoch 1214 batch 00010: Loss 0.0041 Regression loss 0.0033 Classification loss 0.0008 AP 0.6820 AR 0.9550
Epoch 1215 batch 00001: Loss 0.0043 Regression loss 0.0037 Classification loss 0.0006 AP 0.7892 AR 1.0000
Epoch 1215 batch 00002: Loss 0.0045 Regression loss 0.0038 Classification loss 0.0007 AP 0.6017 AR 0.8917
Epoch 1215 batch 00003: Loss 0.0039 Regression loss 0.0031 Classification loss 0.0008 AP 0.6631 AR 0.8250
Epoch 1215 batch 00004: Loss 0.0042 Regression loss 0.0035 Classification loss 0.0006 AP 0.8071 AR 0.9467
Epoch 1215 batch 00005: Loss 0.0038 Regression loss 0.0034 Classification loss 0.0004 AP 0.7050 AR 0.9500
Epoch 1215 batch 00006: Loss 0.0038 Regression loss 0.0034 Classification loss 0.0004 AP 0.7436 AR 0.9750
Epoch 1215 batch 00007: Loss 0.0036 Regression loss 0.0030 Classification loss 0.0005 AP 0.7233 AR 0.8800
Epoch 1215 batch 00008: Loss 0.0035 Regression loss 0.0030 Classification loss 0.0005 AP 0.6725 AR 0.9550
Epoch 1215 batch 00009: Loss 0.0039 Regression loss 0.0035 Classification loss 0.0004 AP 0.6771 AR 0.8967
Epoch 1215 batch 00010: Loss 0.0043 Regression loss 0.0037 Classification loss 0.0006 AP 0.7525 AR 0.8350
Epoch 1216 batch 00001: Loss 0.0043 Regression loss 0.0038 Classification loss 0.0005 AP 0.7625 AR 0.9750
Epoch 1216 batch 00002: Loss 0.0040 Regression loss 0.0036 Classification loss 0.0004 AP 0.7464 AR 0.9800
Epoch 1216 batch 00003: Loss 0.0038 Regression loss 0.0034 Classification loss 0.0004 AP 0.6850 AR 0.8800
Epoch 1216 batch 00004: Loss 0.0039 Regression loss 0.0035 Classification loss 0.0005 AP 0.6817 AR 0.9417
Epoch 1216 batch 00005: Loss 0.0036 Regression loss 0.0032 Classification loss 0.0005 AP 0.7404 AR 0.9100
Epoch 1216 batch 00006: Loss 0.0037 Regression loss 0.0032 Classification loss 0.0005 AP 0.7950 AR 0.9750
Epoch 1216 batch 00007: Loss 0.0043 Regression loss 0.0035 Classification loss 0.0009 AP 0.6800 AR 0.7767
Epoch 1216 batch 00008: Loss 0.0043 Regression loss 0.0038 Classification loss 0.0005 AP 0.7525 AR 0.9217
Epoch 1216 batch 00009: Loss 0.0037 Regression loss 0.0029 Classification loss 0.0008 AP 0.6788 AR 0.8900
Epoch 1216 batch 00010: Loss 0.0034 Regression loss 0.0028 Classification loss 0.0005 AP 0.5350 AR 0.7000
Epoch 1217 batch 00001: Loss 0.0040 Regression loss 0.0035 Classification loss 0.0005 AP 0.5905 AR 0.8717
Epoch 1217 batch 00002: Loss 0.0043 Regression loss 0.0039 Classification loss 0.0004 AP 0.6522 AR 0.8400
Epoch 1217 batch 00003: Loss 0.0034 Regression loss 0.0031 Classification loss 0.0002 AP 0.8464 AR 0.9500
Epoch 1217 batch 00004: Loss 0.0042 Regression loss 0.0036 Classification loss 0.0006 AP 0.8479 AR 0.9800
Epoch 1217 batch 00005: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6531 AR 0.9500
Epoch 1217 batch 00006: Loss 0.0046 Regression loss 0.0038 Classification loss 0.0009 AP 0.7193 AR 0.9200
Epoch 1217 batch 00007: Loss 0.0045 Regression loss 0.0040 Classification loss 0.0005 AP 0.5900 AR 0.8417
Epoch 1217 batch 00008: Loss 0.0041 Regression loss 0.0035 Classification loss 0.0007 AP 0.6617 AR 0.9133
Epoch 1217 batch 00009: Loss 0.0031 Regression loss 0.0026 Classification loss 0.0005 AP 0.7900 AR 0.9750
Epoch 1217 batch 00010: Loss 0.0043 Regression loss 0.0037 Classification loss 0.0006 AP 0.7106 AR 0.9150
Epoch 1218 batch 00001: Loss 0.0039 Regression loss 0.0035 Classification loss 0.0004 AP 0.5871 AR 0.9167
Epoch 1218 batch 00002: Loss 0.0037 Regression loss 0.0034 Classification loss 0.0004 AP 0.7600 AR 0.9467
Epoch 1218 batch 00003: Loss 0.0038 Regression loss 0.0027 Classification loss 0.0010 AP 0.6119 AR 0.8067
Epoch 1218 batch 00004: Loss 0.0036 Regression loss 0.0031 Classification loss 0.0005 AP 0.7452 AR 0.9000
Epoch 1218 batch 00005: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.6770 AR 0.9000
Epoch 1218 batch 00006: Loss 0.0033 Regression loss 0.0028 Classification loss 0.0005 AP 0.7288 AR 0.8800
Epoch 1218 batch 00007: Loss 0.0033 Regression loss 0.0028 Classification loss 0.0004 AP 0.7898 AR 0.9250
Epoch 1218 batch 00008: Loss 0.0034 Regression loss 0.0028 Classification loss 0.0005 AP 0.7133 AR 0.9550
Epoch 1218 batch 00009: Loss 0.0040 Regression loss 0.0033 Classification loss 0.0007 AP 0.7100 AR 0.8667
Epoch 1218 batch 00010: Loss 0.0036 Regression loss 0.0032 Classification loss 0.0004 AP 0.5643 AR 0.8400
Epoch 1219 batch 00001: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.7533 AR 0.9500
Epoch 1219 batch 00002: Loss 0.0038 Regression loss 0.0034 Classification loss 0.0004 AP 0.5757 AR 0.8467
Epoch 1219 batch 00003: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.6062 AR 0.9350
Epoch 1219 batch 00004: Loss 0.0040 Regression loss 0.0033 Classification loss 0.0008 AP 0.7064 AR 0.9600
Epoch 1219 batch 00005: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0004 AP 0.8423 AR 0.9333
Epoch 1219 batch 00006: Loss 0.0035 Regression loss 0.0030 Classification loss 0.0005 AP 0.6755 AR 0.9750
Epoch 1219 batch 00007: Loss 0.0031 Regression loss 0.0026 Classification loss 0.0004 AP 0.7450 AR 0.9000
Epoch 1219 batch 00008: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0002 AP 0.7475 AR 0.8917
Epoch 1219 batch 00009: Loss 0.0040 Regression loss 0.0033 Classification loss 0.0007 AP 0.8012 AR 0.9600
Epoch 1219 batch 00010: Loss 0.0038 Regression loss 0.0033 Classification loss 0.0005 AP 0.5262 AR 0.8167
Epoch 1220 batch 00001: Loss 0.0032 Regression loss 0.0027 Classification loss 0.0005 AP 0.7917 AR 0.9500
Epoch 1220 batch 00002: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.6858 AR 0.9267
Epoch 1220 batch 00003: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0004 AP 0.7583 AR 1.0000
Epoch 1220 batch 00004: Loss 0.0044 Regression loss 0.0037 Classification loss 0.0007 AP 0.6471 AR 0.9300
Epoch 1220 batch 00005: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.7090 AR 0.9350
Epoch 1220 batch 00006: Loss 0.0033 Regression loss 0.0029 Classification loss 0.0004 AP 0.7808 AR 0.9500
Epoch 1220 batch 00007: Loss 0.0035 Regression loss 0.0025 Classification loss 0.0009 AP 0.7400 AR 0.9300
Epoch 1220 batch 00008: Loss 0.0031 Regression loss 0.0026 Classification loss 0.0005 AP 0.7527 AR 0.9750
Epoch 1220 batch 00009: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0003 AP 0.7764 AR 0.9667
Epoch 1220 batch 00010: Loss 0.0041 Regression loss 0.0038 Classification loss 0.0003 AP 0.5363 AR 0.8300
Epoch 1221 batch 00001: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0003 AP 0.7345 AR 1.0000
Epoch 1221 batch 00002: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0005 AP 0.6425 AR 0.8100
Epoch 1221 batch 00003: Loss 0.0033 Regression loss 0.0028 Classification loss 0.0004 AP 0.7038 AR 0.9083
Epoch 1221 batch 00004: Loss 0.0037 Regression loss 0.0033 Classification loss 0.0004 AP 0.7280 AR 0.9800
Epoch 1221 batch 00005: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.7425 AR 0.9750
Epoch 1221 batch 00006: Loss 0.0032 Regression loss 0.0027 Classification loss 0.0004 AP 0.7500 AR 1.0000
Epoch 1221 batch 00007: Loss 0.0034 Regression loss 0.0029 Classification loss 0.0005 AP 0.5933 AR 0.7250
Epoch 1221 batch 00008: Loss 0.0034 Regression loss 0.0029 Classification loss 0.0006 AP 0.8417 AR 0.9800
Epoch 1221 batch 00009: Loss 0.0035 Regression loss 0.0028 Classification loss 0.0006 AP 0.6807 AR 0.8900
Epoch 1221 batch 00010: Loss 0.0036 Regression loss 0.0033 Classification loss 0.0003 AP 0.7755 AR 0.9350
Epoch 1222 batch 00001: Loss 0.0039 Regression loss 0.0034 Classification loss 0.0005 AP 0.7590 AR 0.9300
Epoch 1222 batch 00002: Loss 0.0035 Regression loss 0.0031 Classification loss 0.0003 AP 0.6781 AR 0.9800
Epoch 1222 batch 00003: Loss 0.0033 Regression loss 0.0030 Classification loss 0.0003 AP 0.6592 AR 0.8417
Epoch 1222 batch 00004: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6921 AR 0.9800
Epoch 1222 batch 00005: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.8067 AR 1.0000
Epoch 1222 batch 00006: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.8481 AR 0.9550
Epoch 1222 batch 00007: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0005 AP 0.7350 AR 1.0000
Epoch 1222 batch 00008: Loss 0.0037 Regression loss 0.0028 Classification loss 0.0009 AP 0.7631 AR 0.9217
Epoch 1222 batch 00009: Loss 0.0032 Regression loss 0.0027 Classification loss 0.0005 AP 0.6275 AR 0.8600
Epoch 1222 batch 00010: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.7078 AR 0.9750
Epoch 1223 batch 00001: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0002 AP 0.6750 AR 0.9750
Epoch 1223 batch 00002: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.7258 AR 0.8667
Epoch 1223 batch 00003: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0003 AP 0.6867 AR 0.9417
Epoch 1223 batch 00004: Loss 0.0029 Regression loss 0.0021 Classification loss 0.0007 AP 0.8767 AR 0.9300
Epoch 1223 batch 00005: Loss 0.0034 Regression loss 0.0029 Classification loss 0.0005 AP 0.6567 AR 0.9250
Epoch 1223 batch 00006: Loss 0.0033 Regression loss 0.0029 Classification loss 0.0004 AP 0.9086 AR 0.9800
Epoch 1223 batch 00007: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0005 AP 0.6500 AR 0.8600
Epoch 1223 batch 00008: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6306 AR 0.9500
Epoch 1223 batch 00009: Loss 0.0041 Regression loss 0.0035 Classification loss 0.0006 AP 0.7492 AR 0.9800
Epoch 1223 batch 00010: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.6610 AR 0.8950
Epoch 1224 batch 00001: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.7000 AR 1.0000
Epoch 1224 batch 00002: Loss 0.0035 Regression loss 0.0031 Classification loss 0.0004 AP 0.7481 AR 0.9100
Epoch 1224 batch 00003: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.6817 AR 0.9000
Epoch 1224 batch 00004: Loss 0.0034 Regression loss 0.0030 Classification loss 0.0004 AP 0.8767 AR 1.0000
Epoch 1224 batch 00005: Loss 0.0033 Regression loss 0.0031 Classification loss 0.0003 AP 0.6281 AR 0.8750
Epoch 1224 batch 00006: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.7671 AR 0.9750
Epoch 1224 batch 00007: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.6175 AR 0.9133
Epoch 1224 batch 00008: Loss 0.0035 Regression loss 0.0028 Classification loss 0.0007 AP 0.7193 AR 0.8900
Epoch 1224 batch 00009: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0002 AP 0.7483 AR 1.0000
Epoch 1224 batch 00010: Loss 0.0031 Regression loss 0.0024 Classification loss 0.0007 AP 0.7217 AR 0.9750
Epoch 1225 batch 00001: Loss 0.0030 Regression loss 0.0028 Classification loss 0.0003 AP 0.7463 AR 0.9800
Epoch 1225 batch 00002: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0004 AP 0.7667 AR 1.0000
Epoch 1225 batch 00003: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.6933 AR 0.9250
Epoch 1225 batch 00004: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.7008 AR 0.9750
Epoch 1225 batch 00005: Loss 0.0036 Regression loss 0.0033 Classification loss 0.0003 AP 0.6375 AR 0.9800
Epoch 1225 batch 00006: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0003 AP 0.5921 AR 0.7867
Epoch 1225 batch 00007: Loss 0.0029 Regression loss 0.0023 Classification loss 0.0006 AP 0.6471 AR 0.9267
Epoch 1225 batch 00008: Loss 0.0035 Regression loss 0.0028 Classification loss 0.0006 AP 0.5702 AR 0.7600
Epoch 1225 batch 00009: Loss 0.0032 Regression loss 0.0028 Classification loss 0.0005 AP 0.7369 AR 0.9250
Epoch 1225 batch 00010: Loss 0.0035 Regression loss 0.0030 Classification loss 0.0005 AP 0.8667 AR 1.0000
Epoch 1226 batch 00001: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.7533 AR 0.9217
Epoch 1226 batch 00002: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.7458 AR 0.9750
Epoch 1226 batch 00003: Loss 0.0039 Regression loss 0.0035 Classification loss 0.0004 AP 0.6275 AR 0.9000
Epoch 1226 batch 00004: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.7219 AR 0.8300
Epoch 1226 batch 00005: Loss 0.0029 Regression loss 0.0024 Classification loss 0.0006 AP 0.7414 AR 1.0000
Epoch 1226 batch 00006: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.7500 AR 0.9500
Epoch 1226 batch 00007: Loss 0.0031 Regression loss 0.0024 Classification loss 0.0007 AP 0.7183 AR 0.9400
Epoch 1226 batch 00008: Loss 0.0031 Regression loss 0.0029 Classification loss 0.0003 AP 0.6892 AR 0.9050
Epoch 1226 batch 00009: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.7371 AR 1.0000
Epoch 1226 batch 00010: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7111 AR 0.9217
Epoch 1227 batch 00001: Loss 0.0036 Regression loss 0.0028 Classification loss 0.0007 AP 0.7171 AR 0.9350
Epoch 1227 batch 00002: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.6708 AR 0.9350
Epoch 1227 batch 00003: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.7200 AR 0.9600
Epoch 1227 batch 00004: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.7233 AR 0.9000
Epoch 1227 batch 00005: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.7086 AR 0.9467
Epoch 1227 batch 00006: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0002 AP 0.6400 AR 0.9000
Epoch 1227 batch 00007: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0002 AP 0.7639 AR 0.9000
Epoch 1227 batch 00008: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.8017 AR 0.9750
Epoch 1227 batch 00009: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.7401 AR 0.9300
Epoch 1227 batch 00010: Loss 0.0034 Regression loss 0.0031 Classification loss 0.0003 AP 0.7198 AR 0.9167
Epoch 1228 batch 00001: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.6548 AR 0.9400
Epoch 1228 batch 00002: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0002 AP 0.6288 AR 0.9550
Epoch 1228 batch 00003: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0003 AP 0.7026 AR 0.9000
Epoch 1228 batch 00004: Loss 0.0031 Regression loss 0.0024 Classification loss 0.0006 AP 0.7882 AR 0.9200
Epoch 1228 batch 00005: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7058 AR 1.0000
Epoch 1228 batch 00006: Loss 0.0028 Regression loss 0.0023 Classification loss 0.0005 AP 0.6550 AR 0.8500
Epoch 1228 batch 00007: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.7836 AR 0.9800
Epoch 1228 batch 00008: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.6783 AR 0.8750
Epoch 1228 batch 00009: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7950 AR 0.8750
Epoch 1228 batch 00010: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.7272 AR 1.0000
Epoch 1229 batch 00001: Loss 0.0030 Regression loss 0.0025 Classification loss 0.0005 AP 0.5538 AR 0.8550
Epoch 1229 batch 00002: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.6711 AR 0.8800
Epoch 1229 batch 00003: Loss 0.0029 Regression loss 0.0026 Classification loss 0.0003 AP 0.6036 AR 0.9000
Epoch 1229 batch 00004: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7100 AR 0.9150
Epoch 1229 batch 00005: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.8371 AR 1.0000
Epoch 1229 batch 00006: Loss 0.0028 Regression loss 0.0024 Classification loss 0.0004 AP 0.8400 AR 1.0000
Epoch 1229 batch 00007: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.8206 AR 1.0000
Epoch 1229 batch 00008: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0002 AP 0.7017 AR 1.0000
Epoch 1229 batch 00009: Loss 0.0030 Regression loss 0.0024 Classification loss 0.0007 AP 0.6189 AR 0.9050
Epoch 1229 batch 00010: Loss 0.0031 Regression loss 0.0028 Classification loss 0.0003 AP 0.6752 AR 0.8100
Epoch 1230 batch 00001: Loss 0.0026 Regression loss 0.0020 Classification loss 0.0005 AP 0.7113 AR 0.8900
Epoch 1230 batch 00002: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0002 AP 0.6733 AR 0.8800
Epoch 1230 batch 00003: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.6948 AR 1.0000
Epoch 1230 batch 00004: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.8233 AR 0.9417
Epoch 1230 batch 00005: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0004 AP 0.7058 AR 0.9400
Epoch 1230 batch 00006: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.8271 AR 0.9500
Epoch 1230 batch 00007: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.6655 AR 0.9600
Epoch 1230 batch 00008: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0003 AP 0.9083 AR 1.0000
Epoch 1230 batch 00009: Loss 0.0031 Regression loss 0.0027 Classification loss 0.0004 AP 0.7338 AR 1.0000
Epoch 1230 batch 00010: Loss 0.0033 Regression loss 0.0029 Classification loss 0.0004 AP 0.7342 AR 1.0000
Epoch 1231 batch 00001: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7075 AR 0.9800
Epoch 1231 batch 00002: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7671 AR 0.9800
Epoch 1231 batch 00003: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0004 AP 0.7695 AR 0.9267
Epoch 1231 batch 00004: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.5888 AR 0.9000
Epoch 1231 batch 00005: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0003 AP 0.7792 AR 0.9500
Epoch 1231 batch 00006: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0002 AP 0.7552 AR 0.9550
Epoch 1231 batch 00007: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.8205 AR 1.0000
Epoch 1231 batch 00008: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0004 AP 0.7871 AR 0.9350
Epoch 1231 batch 00009: Loss 0.0028 Regression loss 0.0021 Classification loss 0.0006 AP 0.7133 AR 0.9800
Epoch 1231 batch 00010: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.6533 AR 0.9800
Epoch 1232 batch 00001: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7904 AR 0.9750
Epoch 1232 batch 00002: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6633 AR 0.8600
Epoch 1232 batch 00003: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.6950 AR 0.9350
Epoch 1232 batch 00004: Loss 0.0030 Regression loss 0.0028 Classification loss 0.0003 AP 0.5867 AR 0.8500
Epoch 1232 batch 00005: Loss 0.0027 Regression loss 0.0023 Classification loss 0.0003 AP 0.6150 AR 0.9000
Epoch 1232 batch 00006: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.8775 AR 0.9750
Epoch 1232 batch 00007: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.7838 AR 0.9550
Epoch 1232 batch 00008: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7475 AR 0.9800
Epoch 1232 batch 00009: Loss 0.0032 Regression loss 0.0025 Classification loss 0.0007 AP 0.6636 AR 0.8383
Epoch 1232 batch 00010: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.6917 AR 0.9167
Epoch 1233 batch 00001: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6045 AR 0.8267
Epoch 1233 batch 00002: Loss 0.0029 Regression loss 0.0025 Classification loss 0.0004 AP 0.7783 AR 0.9000
Epoch 1233 batch 00003: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7410 AR 0.9600
Epoch 1233 batch 00004: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.7592 AR 0.9750
Epoch 1233 batch 00005: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0003 AP 0.6943 AR 0.9600
Epoch 1233 batch 00006: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.7354 AR 0.9250
Epoch 1233 batch 00007: Loss 0.0029 Regression loss 0.0023 Classification loss 0.0007 AP 0.6700 AR 0.8600
Epoch 1233 batch 00008: Loss 0.0030 Regression loss 0.0027 Classification loss 0.0003 AP 0.8792 AR 1.0000
Epoch 1233 batch 00009: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.5998 AR 0.8600
Epoch 1233 batch 00010: Loss 0.0021 Regression loss 0.0020 Classification loss 0.0001 AP 0.7733 AR 0.9750
Epoch 1234 batch 00001: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0004 AP 0.6100 AR 0.9300
Epoch 1234 batch 00002: Loss 0.0030 Regression loss 0.0025 Classification loss 0.0004 AP 0.7128 AR 0.9800
Epoch 1234 batch 00003: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0003 AP 0.7100 AR 0.9750
Epoch 1234 batch 00004: Loss 0.0028 Regression loss 0.0025 Classification loss 0.0002 AP 0.6113 AR 0.8500
Epoch 1234 batch 00005: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.8388 AR 0.9750
Epoch 1234 batch 00006: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.5964 AR 0.8000
Epoch 1234 batch 00007: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.6171 AR 0.8050
Epoch 1234 batch 00008: Loss 0.0027 Regression loss 0.0022 Classification loss 0.0006 AP 0.8355 AR 0.9800
Epoch 1234 batch 00009: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.8867 AR 1.0000
Epoch 1234 batch 00010: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7286 AR 0.9150
Epoch 1235 batch 00001: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.8500 AR 0.9500
Epoch 1235 batch 00002: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.5423 AR 0.7800
Epoch 1235 batch 00003: Loss 0.0032 Regression loss 0.0029 Classification loss 0.0003 AP 0.7054 AR 0.9600
Epoch 1235 batch 00004: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7530 AR 0.9800
Epoch 1235 batch 00005: Loss 0.0027 Regression loss 0.0021 Classification loss 0.0006 AP 0.6700 AR 0.9267
Epoch 1235 batch 00006: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.7571 AR 0.9600
Epoch 1235 batch 00007: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7371 AR 0.9550
Epoch 1235 batch 00008: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.6471 AR 1.0000
Epoch 1235 batch 00009: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7773 AR 1.0000
Epoch 1235 batch 00010: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.8933 AR 1.0000
Epoch 1236 batch 00001: Loss 0.0027 Regression loss 0.0025 Classification loss 0.0003 AP 0.8256 AR 0.9800
Epoch 1236 batch 00002: Loss 0.0028 Regression loss 0.0021 Classification loss 0.0007 AP 0.6317 AR 0.9800
Epoch 1236 batch 00003: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0003 AP 0.6939 AR 1.0000
Epoch 1236 batch 00004: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0003 AP 0.7838 AR 0.9133
Epoch 1236 batch 00005: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.8800 AR 0.9750
Epoch 1236 batch 00006: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.8183 AR 1.0000
Epoch 1236 batch 00007: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6817 AR 0.9800
Epoch 1236 batch 00008: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.5931 AR 0.8800
Epoch 1236 batch 00009: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7317 AR 0.8500
Epoch 1236 batch 00010: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.7800 AR 1.0000
Epoch 1237 batch 00001: Loss 0.0030 Regression loss 0.0026 Classification loss 0.0004 AP 0.7038 AR 1.0000
Epoch 1237 batch 00002: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.8417 AR 1.0000
Epoch 1237 batch 00003: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0002 AP 0.7717 AR 1.0000
Epoch 1237 batch 00004: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0005 AP 0.7583 AR 0.9150
Epoch 1237 batch 00005: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6150 AR 0.9100
Epoch 1237 batch 00006: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0003 AP 0.6992 AR 1.0000
Epoch 1237 batch 00007: Loss 0.0024 Regression loss 0.0023 Classification loss 0.0002 AP 0.7922 AR 1.0000
Epoch 1237 batch 00008: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.8283 AR 1.0000
Epoch 1237 batch 00009: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7219 AR 0.9750
Epoch 1237 batch 00010: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0002 AP 0.7138 AR 0.9400
Epoch 1238 batch 00001: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.8050 AR 0.9800
Epoch 1238 batch 00002: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0002 AP 0.6831 AR 0.9050
Epoch 1238 batch 00003: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0004 AP 0.7900 AR 0.9600
Epoch 1238 batch 00004: Loss 0.0024 Regression loss 0.0023 Classification loss 0.0002 AP 0.5796 AR 0.9600
Epoch 1238 batch 00005: Loss 0.0025 Regression loss 0.0023 Classification loss 0.0003 AP 0.7605 AR 0.9800
Epoch 1238 batch 00006: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0003 AP 0.6333 AR 0.8750
Epoch 1238 batch 00007: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7106 AR 0.9667
Epoch 1238 batch 00008: Loss 0.0027 Regression loss 0.0021 Classification loss 0.0006 AP 0.7200 AR 0.9600
Epoch 1238 batch 00009: Loss 0.0025 Regression loss 0.0021 Classification loss 0.0003 AP 0.7894 AR 1.0000
Epoch 1238 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.8400 AR 1.0000
Epoch 1239 batch 00001: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.7350 AR 0.8833
Epoch 1239 batch 00002: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7325 AR 1.0000
Epoch 1239 batch 00003: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7350 AR 0.8417
Epoch 1239 batch 00004: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.5662 AR 0.9217
Epoch 1239 batch 00005: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0002 AP 0.7395 AR 0.9750
Epoch 1239 batch 00006: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.8086 AR 0.9800
Epoch 1239 batch 00007: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7356 AR 0.9250
Epoch 1239 batch 00008: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7867 AR 0.9417
Epoch 1239 batch 00009: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.6992 AR 0.9600
Epoch 1239 batch 00010: Loss 0.0028 Regression loss 0.0021 Classification loss 0.0007 AP 0.7667 AR 0.9800
Epoch 1240 batch 00001: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6548 AR 0.9000
Epoch 1240 batch 00002: Loss 0.0029 Regression loss 0.0027 Classification loss 0.0002 AP 0.7233 AR 0.9750
Epoch 1240 batch 00003: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7817 AR 0.9350
Epoch 1240 batch 00004: Loss 0.0027 Regression loss 0.0021 Classification loss 0.0006 AP 0.6220 AR 0.9217
Epoch 1240 batch 00005: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7175 AR 0.9750
Epoch 1240 batch 00006: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.8117 AR 0.9800
Epoch 1240 batch 00007: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0003 AP 0.8350 AR 0.9750
Epoch 1240 batch 00008: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.6821 AR 0.9300
Epoch 1240 batch 00009: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.7871 AR 0.9500
Epoch 1240 batch 00010: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7462 AR 0.9750
Epoch 1241 batch 00001: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0001 AP 0.6238 AR 0.9800
Epoch 1241 batch 00002: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7805 AR 0.9300
Epoch 1241 batch 00003: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7517 AR 0.9750
Epoch 1241 batch 00004: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6671 AR 0.9300
Epoch 1241 batch 00005: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0005 AP 0.8294 AR 0.9400
Epoch 1241 batch 00006: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.8186 AR 0.9300
Epoch 1241 batch 00007: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.7525 AR 0.9500
Epoch 1241 batch 00008: Loss 0.0026 Regression loss 0.0022 Classification loss 0.0003 AP 0.5871 AR 0.8350
Epoch 1241 batch 00009: Loss 0.0024 Regression loss 0.0022 Classification loss 0.0002 AP 0.7456 AR 1.0000
Epoch 1241 batch 00010: Loss 0.0026 Regression loss 0.0023 Classification loss 0.0003 AP 0.7983 AR 0.9800
Epoch 1242 batch 00001: Loss 0.0024 Regression loss 0.0020 Classification loss 0.0003 AP 0.7617 AR 0.9417
Epoch 1242 batch 00002: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6950 AR 0.9750
Epoch 1242 batch 00003: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6914 AR 0.9250
Epoch 1242 batch 00004: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.8133 AR 0.9800
Epoch 1242 batch 00005: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7350 AR 1.0000
Epoch 1242 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.5959 AR 0.8267
Epoch 1242 batch 00007: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7736 AR 1.0000
Epoch 1242 batch 00008: Loss 0.0027 Regression loss 0.0024 Classification loss 0.0003 AP 0.8800 AR 0.9750
Epoch 1242 batch 00009: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7305 AR 0.9750
Epoch 1242 batch 00010: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0005 AP 0.7606 AR 0.9400
Epoch 1243 batch 00001: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.8800 AR 1.0000
Epoch 1243 batch 00002: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6075 AR 0.8500
Epoch 1243 batch 00003: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.8500 AR 0.9600
Epoch 1243 batch 00004: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.6792 AR 0.9250
Epoch 1243 batch 00005: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7481 AR 0.9467
Epoch 1243 batch 00006: Loss 0.0025 Regression loss 0.0022 Classification loss 0.0003 AP 0.7079 AR 0.9500
Epoch 1243 batch 00007: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7000 AR 0.9750
Epoch 1243 batch 00008: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7050 AR 0.9500
Epoch 1243 batch 00009: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.7221 AR 0.9550
Epoch 1243 batch 00010: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0002 AP 0.7544 AR 0.9600
Epoch 1244 batch 00001: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7767 AR 0.9350
Epoch 1244 batch 00002: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6933 AR 0.9250
Epoch 1244 batch 00003: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7497 AR 0.9400
Epoch 1244 batch 00004: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.6906 AR 1.0000
Epoch 1244 batch 00005: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.8067 AR 0.9500
Epoch 1244 batch 00006: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6510 AR 0.9800
Epoch 1244 batch 00007: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0002 AP 0.7250 AR 0.9750
Epoch 1244 batch 00008: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.7667 AR 1.0000
Epoch 1244 batch 00009: Loss 0.0025 Regression loss 0.0020 Classification loss 0.0005 AP 0.7777 AR 0.9550
Epoch 1244 batch 00010: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0002 AP 0.7745 AR 0.9550
Epoch 1245 batch 00001: Loss 0.0026 Regression loss 0.0021 Classification loss 0.0005 AP 0.7254 AR 0.8983
Epoch 1245 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8305 AR 1.0000
Epoch 1245 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0001 AP 0.7239 AR 0.9800
Epoch 1245 batch 00004: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0001 AP 0.7483 AR 0.9500
Epoch 1245 batch 00005: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0003 AP 0.7250 AR 0.9000
Epoch 1245 batch 00006: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.6367 AR 0.9750
Epoch 1245 batch 00007: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.5847 AR 0.9300
Epoch 1245 batch 00008: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7981 AR 0.9500
Epoch 1245 batch 00009: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.8392 AR 0.9150
Epoch 1245 batch 00010: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7838 AR 1.0000
Epoch 1246 batch 00001: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7871 AR 0.9250
Epoch 1246 batch 00002: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7206 AR 0.9600
Epoch 1246 batch 00003: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7743 AR 1.0000
Epoch 1246 batch 00004: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7988 AR 0.9550
Epoch 1246 batch 00005: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.8167 AR 0.9250
Epoch 1246 batch 00006: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.6367 AR 0.9000
Epoch 1246 batch 00007: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0002 AP 0.8047 AR 0.9550
Epoch 1246 batch 00008: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.6952 AR 0.9800
Epoch 1246 batch 00009: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0005 AP 0.6938 AR 0.9800
Epoch 1246 batch 00010: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.6500 AR 0.9800
Epoch 1247 batch 00001: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0002 AP 0.7515 AR 1.0000
Epoch 1247 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7817 AR 1.0000
Epoch 1247 batch 00003: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7850 AR 0.9400
Epoch 1247 batch 00004: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0003 AP 0.8050 AR 0.9667
Epoch 1247 batch 00005: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7505 AR 1.0000
Epoch 1247 batch 00006: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0001 AP 0.7398 AR 1.0000
Epoch 1247 batch 00007: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7369 AR 0.8850
Epoch 1247 batch 00008: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0003 AP 0.6776 AR 0.9550
Epoch 1247 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6892 AR 0.9050
Epoch 1247 batch 00010: Loss 0.0024 Regression loss 0.0021 Classification loss 0.0002 AP 0.7550 AR 1.0000
Epoch 1248 batch 00001: Loss 0.0023 Regression loss 0.0021 Classification loss 0.0002 AP 0.7514 AR 0.9633
Epoch 1248 batch 00002: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7417 AR 1.0000
Epoch 1248 batch 00003: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.6988 AR 0.9750
Epoch 1248 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7279 AR 0.9750
Epoch 1248 batch 00005: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0002 AP 0.7405 AR 0.9600
Epoch 1248 batch 00006: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7676 AR 0.9600
Epoch 1248 batch 00007: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6573 AR 0.9000
Epoch 1248 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7333 AR 0.9750
Epoch 1248 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7563 AR 0.9250
Epoch 1248 batch 00010: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.8317 AR 1.0000
Epoch 1249 batch 00001: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7246 AR 0.9800
Epoch 1249 batch 00002: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.7483 AR 0.9600
Epoch 1249 batch 00003: Loss 0.0024 Regression loss 0.0019 Classification loss 0.0005 AP 0.7460 AR 0.9200
Epoch 1249 batch 00004: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.7895 AR 0.9500
Epoch 1249 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7167 AR 0.9550
Epoch 1249 batch 00006: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7121 AR 0.9800
Epoch 1249 batch 00007: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7000 AR 0.9500
Epoch 1249 batch 00008: Loss 0.0023 Regression loss 0.0019 Classification loss 0.0004 AP 0.7883 AR 0.9750
Epoch 1249 batch 00009: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.7817 AR 0.9750
Epoch 1249 batch 00010: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7414 AR 0.9667
Epoch 1250 batch 00001: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.6314 AR 0.9350
Epoch 1250 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7325 AR 0.9300
Epoch 1250 batch 00003: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7417 AR 0.9800
Epoch 1250 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7000 AR 0.9000
Epoch 1250 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7288 AR 1.0000
Epoch 1250 batch 00006: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.8600 AR 0.9750
Epoch 1250 batch 00007: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7939 AR 0.9583
Epoch 1250 batch 00008: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7567 AR 0.9550
Epoch 1250 batch 00009: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6894 AR 0.9600
Epoch 1250 batch 00010: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7458 AR 0.9250
Epoch 1251 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6276 AR 0.9500
Epoch 1251 batch 00002: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7188 AR 1.0000
Epoch 1251 batch 00003: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.8250 AR 0.9750
Epoch 1251 batch 00004: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7217 AR 0.9800
Epoch 1251 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7150 AR 0.9750
Epoch 1251 batch 00006: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7783 AR 0.8900
Epoch 1251 batch 00007: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0003 AP 0.7830 AR 0.9800
Epoch 1251 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7564 AR 0.9550
Epoch 1251 batch 00009: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7414 AR 0.9550
Epoch 1251 batch 00010: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0002 AP 0.8023 AR 1.0000
Epoch 1252 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7483 AR 0.9750
Epoch 1252 batch 00002: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7400 AR 1.0000
Epoch 1252 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.8567 AR 0.9750
Epoch 1252 batch 00004: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.8163 AR 0.9600
Epoch 1252 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7688 AR 0.9750
Epoch 1252 batch 00006: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7400 AR 0.8867
Epoch 1252 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6855 AR 1.0000
Epoch 1252 batch 00008: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.7036 AR 0.8950
Epoch 1252 batch 00009: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7806 AR 1.0000
Epoch 1252 batch 00010: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.6133 AR 0.8800
Epoch 1253 batch 00001: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0002 AP 0.7311 AR 0.9800
Epoch 1253 batch 00002: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7417 AR 0.9100
Epoch 1253 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6692 AR 0.9600
Epoch 1253 batch 00004: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0003 AP 0.7298 AR 0.9800
Epoch 1253 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.8349 AR 0.9300
Epoch 1253 batch 00006: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8883 AR 1.0000
Epoch 1253 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6583 AR 0.9267
Epoch 1253 batch 00008: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7645 AR 0.9750
Epoch 1253 batch 00009: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7898 AR 0.9600
Epoch 1253 batch 00010: Loss 0.0022 Regression loss 0.0020 Classification loss 0.0002 AP 0.7421 AR 1.0000
Epoch 1254 batch 00001: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0002 AP 0.7086 AR 0.9800
Epoch 1254 batch 00002: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6967 AR 1.0000
Epoch 1254 batch 00003: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6860 AR 0.9800
Epoch 1254 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7800 AR 0.9200
Epoch 1254 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7317 AR 0.9250
Epoch 1254 batch 00006: Loss 0.0023 Regression loss 0.0020 Classification loss 0.0002 AP 0.7700 AR 0.9750
Epoch 1254 batch 00007: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7892 AR 0.9800
Epoch 1254 batch 00008: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.8481 AR 0.9800
Epoch 1254 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6900 AR 1.0000
Epoch 1254 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7667 AR 0.9000
Epoch 1255 batch 00001: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7072 AR 1.0000
Epoch 1255 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.8650 AR 1.0000
Epoch 1255 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0001 AP 0.7393 AR 0.9800
Epoch 1255 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7519 AR 1.0000
Epoch 1255 batch 00005: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.7092 AR 0.9000
Epoch 1255 batch 00006: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0003 AP 0.7417 AR 0.9000
Epoch 1255 batch 00007: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.8258 AR 1.0000
Epoch 1255 batch 00008: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6835 AR 0.9550
Epoch 1255 batch 00009: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.8106 AR 0.9600
Epoch 1255 batch 00010: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.5967 AR 0.9800
Epoch 1256 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7913 AR 1.0000
Epoch 1256 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7148 AR 1.0000
Epoch 1256 batch 00003: Loss 0.0021 Regression loss 0.0018 Classification loss 0.0003 AP 0.6452 AR 0.8100
Epoch 1256 batch 00004: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7433 AR 0.8650
Epoch 1256 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.8250 AR 0.9750
Epoch 1256 batch 00006: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.6671 AR 0.9800
Epoch 1256 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7208 AR 1.0000
Epoch 1256 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7564 AR 0.9800
Epoch 1256 batch 00009: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0002 AP 0.7988 AR 1.0000
Epoch 1256 batch 00010: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7221 AR 1.0000
Epoch 1257 batch 00001: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7393 AR 0.9350
Epoch 1257 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7088 AR 1.0000
Epoch 1257 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.8800 AR 1.0000
Epoch 1257 batch 00004: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.7250 AR 0.9600
Epoch 1257 batch 00005: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.8300 AR 1.0000
Epoch 1257 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.9033 AR 0.9750
Epoch 1257 batch 00007: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6472 AR 1.0000
Epoch 1257 batch 00008: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.7767 AR 0.9800
Epoch 1257 batch 00009: Loss 0.0021 Regression loss 0.0017 Classification loss 0.0003 AP 0.6852 AR 0.9550
Epoch 1257 batch 00010: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.7800 AR 1.0000
Epoch 1258 batch 00001: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7168 AR 0.9600
Epoch 1258 batch 00002: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6942 AR 0.9100
Epoch 1258 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7824 AR 1.0000
Epoch 1258 batch 00004: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.6650 AR 0.9017
Epoch 1258 batch 00005: Loss 0.0020 Regression loss 0.0017 Classification loss 0.0003 AP 0.8317 AR 1.0000
Epoch 1258 batch 00006: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8104 AR 1.0000
Epoch 1258 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8117 AR 1.0000
Epoch 1258 batch 00008: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.7514 AR 0.8600
Epoch 1258 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6344 AR 1.0000
Epoch 1258 batch 00010: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7983 AR 0.9800
Epoch 1259 batch 00001: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7294 AR 0.9300
Epoch 1259 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7242 AR 1.0000
Epoch 1259 batch 00003: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7702 AR 0.9800
Epoch 1259 batch 00004: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7905 AR 1.0000
Epoch 1259 batch 00005: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0001 AP 0.8298 AR 0.9800
Epoch 1259 batch 00006: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0004 AP 0.5771 AR 0.9550
Epoch 1259 batch 00007: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.6758 AR 0.9050
Epoch 1259 batch 00008: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.7838 AR 0.9550
Epoch 1259 batch 00009: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.7198 AR 0.9750
Epoch 1259 batch 00010: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7883 AR 0.9550
Epoch 1260 batch 00001: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7231 AR 1.0000
Epoch 1260 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6688 AR 1.0000
Epoch 1260 batch 00003: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.8750 AR 1.0000
Epoch 1260 batch 00004: Loss 0.0022 Regression loss 0.0019 Classification loss 0.0004 AP 0.8581 AR 0.9350
Epoch 1260 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7850 AR 0.9600
Epoch 1260 batch 00006: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6098 AR 0.8750
Epoch 1260 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8050 AR 1.0000
Epoch 1260 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6721 AR 0.9067
Epoch 1260 batch 00009: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.8200 AR 1.0000
Epoch 1260 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7422 AR 0.9500
Epoch 1261 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.7531 AR 0.9750
Epoch 1261 batch 00002: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7100 AR 0.9750
Epoch 1261 batch 00003: Loss 0.0021 Regression loss 0.0019 Classification loss 0.0002 AP 0.8077 AR 0.9583
Epoch 1261 batch 00004: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7767 AR 0.9800
Epoch 1261 batch 00005: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0004 AP 0.7975 AR 0.9600
Epoch 1261 batch 00006: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.8100 AR 0.9667
Epoch 1261 batch 00007: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.6939 AR 1.0000
Epoch 1261 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7750 AR 0.9100
Epoch 1261 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6694 AR 1.0000
Epoch 1261 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7686 AR 0.9667
Epoch 1262 batch 00001: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7342 AR 1.0000
Epoch 1262 batch 00002: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.7284 AR 0.9800
Epoch 1262 batch 00003: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.7821 AR 0.9750
Epoch 1262 batch 00004: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.8514 AR 1.0000
Epoch 1262 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7167 AR 0.9017
Epoch 1262 batch 00006: Loss 0.0026 Regression loss 0.0024 Classification loss 0.0003 AP 0.6755 AR 1.0000
Epoch 1262 batch 00007: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.8498 AR 0.9800
Epoch 1262 batch 00008: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6833 AR 1.0000
Epoch 1262 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7655 AR 0.9550
Epoch 1262 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7700 AR 1.0000
Epoch 1263 batch 00001: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.8500 AR 1.0000
Epoch 1263 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6292 AR 0.8750
Epoch 1263 batch 00003: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6548 AR 0.8400
Epoch 1263 batch 00004: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0002 AP 0.8631 AR 0.9750
Epoch 1263 batch 00005: Loss 0.0020 Regression loss 0.0018 Classification loss 0.0002 AP 0.6850 AR 0.9050
Epoch 1263 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7639 AR 0.9300
Epoch 1263 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7046 AR 0.9350
Epoch 1263 batch 00008: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7655 AR 0.9600
Epoch 1263 batch 00009: Loss 0.0020 Regression loss 0.0019 Classification loss 0.0001 AP 0.6698 AR 0.9750
Epoch 1263 batch 00010: Loss 0.0018 Regression loss 0.0014 Classification loss 0.0004 AP 0.6236 AR 0.8800
Epoch 1264 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7950 AR 0.9600
Epoch 1264 batch 00002: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7583 AR 0.9417
Epoch 1264 batch 00003: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7005 AR 0.9750
Epoch 1264 batch 00004: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.6725 AR 0.9600
Epoch 1264 batch 00005: Loss 0.0020 Regression loss 0.0016 Classification loss 0.0005 AP 0.7425 AR 0.8800
Epoch 1264 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7583 AR 0.9500
Epoch 1264 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7217 AR 0.9800
Epoch 1264 batch 00008: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7488 AR 0.9600
Epoch 1264 batch 00009: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7070 AR 1.0000
Epoch 1264 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7988 AR 1.0000
Epoch 1265 batch 00001: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7783 AR 0.9600
Epoch 1265 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5889 AR 0.9000
Epoch 1265 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7947 AR 0.9667
Epoch 1265 batch 00004: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7550 AR 0.9300
Epoch 1265 batch 00005: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7283 AR 1.0000
Epoch 1265 batch 00006: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.6990 AR 1.0000
Epoch 1265 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7617 AR 0.9050
Epoch 1265 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7183 AR 0.9100
Epoch 1265 batch 00009: Loss 0.0022 Regression loss 0.0018 Classification loss 0.0004 AP 0.7925 AR 0.9600
Epoch 1265 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0001 AP 0.7271 AR 0.9500
Epoch 1266 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0003 AP 0.7089 AR 0.9750
Epoch 1266 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.8143 AR 0.9800
Epoch 1266 batch 00003: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.6900 AR 0.9100
Epoch 1266 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7967 AR 0.9800
Epoch 1266 batch 00005: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.8213 AR 1.0000
Epoch 1266 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7833 AR 0.9800
Epoch 1266 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6864 AR 0.9550
Epoch 1266 batch 00008: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.6558 AR 0.8600
Epoch 1266 batch 00009: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.8300 AR 0.9500
Epoch 1266 batch 00010: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.6879 AR 0.9600
Epoch 1267 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8764 AR 0.9550
Epoch 1267 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7826 AR 0.9750
Epoch 1267 batch 00003: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.7588 AR 0.9600
Epoch 1267 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.6348 AR 1.0000
Epoch 1267 batch 00005: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.7288 AR 0.9600
Epoch 1267 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7242 AR 0.9750
Epoch 1267 batch 00007: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.7205 AR 0.9600
Epoch 1267 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.6975 AR 1.0000
Epoch 1267 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7717 AR 0.9800
Epoch 1267 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7942 AR 0.9800
Epoch 1268 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7413 AR 0.9800
Epoch 1268 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.8283 AR 1.0000
Epoch 1268 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6850 AR 0.9500
Epoch 1268 batch 00004: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.7186 AR 0.8600
Epoch 1268 batch 00005: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.9050 AR 1.0000
Epoch 1268 batch 00006: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0002 AP 0.6069 AR 0.8500
Epoch 1268 batch 00007: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.6988 AR 0.9800
Epoch 1268 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8333 AR 0.9750
Epoch 1268 batch 00009: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7500 AR 0.9800
Epoch 1268 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7050 AR 1.0000
Epoch 1269 batch 00001: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7367 AR 0.9750
Epoch 1269 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7933 AR 1.0000
Epoch 1269 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.7650 AR 1.0000
Epoch 1269 batch 00004: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6138 AR 0.9550
Epoch 1269 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7344 AR 1.0000
Epoch 1269 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.7972 AR 0.9050
Epoch 1269 batch 00007: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0001 AP 0.8681 AR 0.9800
Epoch 1269 batch 00008: Loss 0.0019 Regression loss 0.0017 Classification loss 0.0002 AP 0.7525 AR 0.9000
Epoch 1269 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6950 AR 0.9350
Epoch 1269 batch 00010: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7550 AR 1.0000
Epoch 1270 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6496 AR 1.0000
Epoch 1270 batch 00002: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.8089 AR 1.0000
Epoch 1270 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.8883 AR 0.9750
Epoch 1270 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7350 AR 0.9800
Epoch 1270 batch 00005: Loss 0.0019 Regression loss 0.0016 Classification loss 0.0003 AP 0.7075 AR 1.0000
Epoch 1270 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8225 AR 0.9550
Epoch 1270 batch 00007: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.5536 AR 0.8800
Epoch 1270 batch 00008: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7871 AR 0.9050
Epoch 1270 batch 00009: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7172 AR 0.8550
Epoch 1270 batch 00010: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.7721 AR 0.9750
Epoch 1271 batch 00001: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0001 AP 0.6955 AR 1.0000
Epoch 1271 batch 00002: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0001 AP 0.8967 AR 0.9800
Epoch 1271 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7219 AR 0.9800
Epoch 1271 batch 00004: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0002 AP 0.6367 AR 0.8500
Epoch 1271 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7486 AR 0.9750
Epoch 1271 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7803 AR 0.9750
Epoch 1271 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.7589 AR 0.8500
Epoch 1271 batch 00008: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.7767 AR 0.8800
Epoch 1271 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5381 AR 0.9600
Epoch 1271 batch 00010: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7892 AR 0.8800
Epoch 1272 batch 00001: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0002 AP 0.7448 AR 0.9417
Epoch 1272 batch 00002: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8167 AR 1.0000
Epoch 1272 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.8267 AR 0.9550
Epoch 1272 batch 00004: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0001 AP 0.7764 AR 1.0000
Epoch 1272 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7193 AR 1.0000
Epoch 1272 batch 00006: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.6705 AR 0.9750
Epoch 1272 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7633 AR 1.0000
Epoch 1272 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.7567 AR 0.9600
Epoch 1272 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7558 AR 0.9550
Epoch 1272 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0001 AP 0.7750 AR 0.9800
Epoch 1273 batch 00001: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.6944 AR 0.9267
Epoch 1273 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7486 AR 1.0000
Epoch 1273 batch 00003: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.7411 AR 0.9600
Epoch 1273 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.8395 AR 0.9800
Epoch 1273 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7221 AR 0.9500
Epoch 1273 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7800 AR 0.9750
Epoch 1273 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.7570 AR 0.9333
Epoch 1273 batch 00008: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.5821 AR 0.9000
Epoch 1273 batch 00009: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0002 AP 0.8306 AR 1.0000
Epoch 1273 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7192 AR 1.0000
Epoch 1274 batch 00001: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.8050 AR 1.0000
Epoch 1274 batch 00002: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0001 AP 0.7725 AR 0.9750
Epoch 1274 batch 00003: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6667 AR 0.9300
Epoch 1274 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6829 AR 0.9750
Epoch 1274 batch 00005: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7450 AR 0.9250
Epoch 1274 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6814 AR 1.0000
Epoch 1274 batch 00007: Loss 0.0018 Regression loss 0.0015 Classification loss 0.0003 AP 0.8671 AR 0.9600
Epoch 1274 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6238 AR 0.7417
Epoch 1274 batch 00009: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7675 AR 0.9800
Epoch 1274 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0001 AP 0.7271 AR 0.9750
Epoch 1275 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6764 AR 0.8667
Epoch 1275 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7800 AR 0.9550
Epoch 1275 batch 00003: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7543 AR 1.0000
Epoch 1275 batch 00004: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.9150 AR 0.9350
Epoch 1275 batch 00005: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.5886 AR 0.9750
Epoch 1275 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.6179 AR 0.9250
Epoch 1275 batch 00007: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.7439 AR 0.9000
Epoch 1275 batch 00008: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7740 AR 1.0000
Epoch 1275 batch 00009: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6683 AR 0.9800
Epoch 1275 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.8164 AR 1.0000
Epoch 1276 batch 00001: Loss 0.0018 Regression loss 0.0017 Classification loss 0.0001 AP 0.7196 AR 0.9000
Epoch 1276 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.7583 AR 0.9500
Epoch 1276 batch 00003: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.8008 AR 1.0000
Epoch 1276 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6378 AR 0.8800
Epoch 1276 batch 00005: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.5516 AR 0.9050
Epoch 1276 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7538 AR 1.0000
Epoch 1276 batch 00007: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.6722 AR 0.8500
Epoch 1276 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.8476 AR 1.0000
Epoch 1276 batch 00009: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.5967 AR 0.9150
Epoch 1276 batch 00010: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.8286 AR 0.9800
Epoch 1277 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.8300 AR 0.9750
Epoch 1277 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.7000 AR 1.0000
Epoch 1277 batch 00003: Loss 0.0018 Regression loss 0.0016 Classification loss 0.0002 AP 0.7666 AR 0.9800
Epoch 1277 batch 00004: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6895 AR 0.9350
Epoch 1277 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8189 AR 0.9800
Epoch 1277 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7167 AR 0.9600
Epoch 1277 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6571 AR 0.8750
Epoch 1277 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7794 AR 0.9750
Epoch 1277 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6748 AR 0.9750
Epoch 1277 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7846 AR 0.9667
Epoch 1278 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0001 AP 0.8392 AR 1.0000
Epoch 1278 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.7521 AR 0.9550
Epoch 1278 batch 00003: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6687 AR 0.9000
Epoch 1278 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7767 AR 0.9250
Epoch 1278 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6585 AR 0.9500
Epoch 1278 batch 00006: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6838 AR 0.9300
Epoch 1278 batch 00007: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.7714 AR 0.9583
Epoch 1278 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7086 AR 0.9300
Epoch 1278 batch 00009: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7500 AR 0.9000
Epoch 1278 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6808 AR 0.9750
Epoch 1279 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7505 AR 0.9300
Epoch 1279 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8263 AR 1.0000
Epoch 1279 batch 00003: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6461 AR 0.9100
Epoch 1279 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.8198 AR 0.9600
Epoch 1279 batch 00005: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.7150 AR 0.8750
Epoch 1279 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.8308 AR 1.0000
Epoch 1279 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6552 AR 0.9300
Epoch 1279 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6117 AR 0.9167
Epoch 1279 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6981 AR 0.9000
Epoch 1279 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.6278 AR 0.9600
Epoch 1280 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6939 AR 0.9750
Epoch 1280 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7425 AR 0.9150
Epoch 1280 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.5848 AR 0.9800
Epoch 1280 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6625 AR 0.8750
Epoch 1280 batch 00005: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.7455 AR 1.0000
Epoch 1280 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.8221 AR 0.9750
Epoch 1280 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.7714 AR 0.9500
Epoch 1280 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6931 AR 0.9300
Epoch 1280 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7264 AR 1.0000
Epoch 1280 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.9550 AR 1.0000
Epoch 1281 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7300 AR 0.9750
Epoch 1281 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8467 AR 1.0000
Epoch 1281 batch 00003: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.6794 AR 0.9300
Epoch 1281 batch 00004: Loss 0.0017 Regression loss 0.0014 Classification loss 0.0003 AP 0.8508 AR 0.9350
Epoch 1281 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7138 AR 1.0000
Epoch 1281 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7180 AR 0.9550
Epoch 1281 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6543 AR 0.8500
Epoch 1281 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8779 AR 0.9750
Epoch 1281 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6068 AR 0.9800
Epoch 1281 batch 00010: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.7400 AR 0.9550
Epoch 1282 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8300 AR 1.0000
Epoch 1282 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7661 AR 0.9800
Epoch 1282 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6833 AR 0.8600
Epoch 1282 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7488 AR 0.9667
Epoch 1282 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7275 AR 1.0000
Epoch 1282 batch 00006: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6600 AR 0.9000
Epoch 1282 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7531 AR 1.0000
Epoch 1282 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7631 AR 0.9500
Epoch 1282 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8600 AR 0.9800
Epoch 1282 batch 00010: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7708 AR 0.9500
Epoch 1283 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.9229 AR 0.9750
Epoch 1283 batch 00002: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.6430 AR 0.8667
Epoch 1283 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6817 AR 0.9350
Epoch 1283 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7981 AR 0.9800
Epoch 1283 batch 00005: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7525 AR 0.9400
Epoch 1283 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7317 AR 0.9550
Epoch 1283 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8000 AR 1.0000
Epoch 1283 batch 00008: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.6418 AR 0.8500
Epoch 1283 batch 00009: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7560 AR 1.0000
Epoch 1283 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7805 AR 1.0000
Epoch 1284 batch 00001: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6814 AR 0.9667
Epoch 1284 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.8088 AR 0.9550
Epoch 1284 batch 00003: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0002 AP 0.7300 AR 1.0000
Epoch 1284 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8383 AR 0.9800
Epoch 1284 batch 00005: Loss 0.0019 Regression loss 0.0018 Classification loss 0.0001 AP 0.8417 AR 0.9667
Epoch 1284 batch 00006: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7243 AR 0.9500
Epoch 1284 batch 00007: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7458 AR 0.9550
Epoch 1284 batch 00008: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.7977 AR 0.9800
Epoch 1284 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7643 AR 0.9800
Epoch 1284 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.5652 AR 0.9000
Epoch 1285 batch 00001: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7324 AR 0.9667
Epoch 1285 batch 00002: Loss 0.0016 Regression loss 0.0013 Classification loss 0.0003 AP 0.6679 AR 0.7900
Epoch 1285 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.8098 AR 1.0000
Epoch 1285 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7305 AR 0.9800
Epoch 1285 batch 00005: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7256 AR 0.9800
Epoch 1285 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6531 AR 1.0000
Epoch 1285 batch 00007: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8850 AR 1.0000
Epoch 1285 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6921 AR 1.0000
Epoch 1285 batch 00009: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7858 AR 0.9550
Epoch 1285 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7925 AR 1.0000
Epoch 1286 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7371 AR 1.0000
Epoch 1286 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6717 AR 0.9417
Epoch 1286 batch 00003: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.7513 AR 0.9800
Epoch 1286 batch 00004: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7571 AR 0.9833
Epoch 1286 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7606 AR 0.9800
Epoch 1286 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8679 AR 0.9750
Epoch 1286 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7329 AR 0.9750
Epoch 1286 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7714 AR 0.9500
Epoch 1286 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7094 AR 0.9800
Epoch 1286 batch 00010: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.7852 AR 0.9500
Epoch 1287 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7933 AR 1.0000
Epoch 1287 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.9167 AR 1.0000
Epoch 1287 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7752 AR 0.9800
Epoch 1287 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6964 AR 0.9167
Epoch 1287 batch 00005: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.6798 AR 0.8417
Epoch 1287 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7567 AR 0.9750
Epoch 1287 batch 00007: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7482 AR 0.9750
Epoch 1287 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.8092 AR 0.9750
Epoch 1287 batch 00009: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0002 AP 0.7542 AR 0.9583
Epoch 1287 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.5767 AR 0.8550
Epoch 1288 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7483 AR 0.9300
Epoch 1288 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.4833 AR 0.8300
Epoch 1288 batch 00003: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.8133 AR 0.9800
Epoch 1288 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.7330 AR 1.0000
Epoch 1288 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8283 AR 1.0000
Epoch 1288 batch 00006: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6786 AR 1.0000
Epoch 1288 batch 00007: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8011 AR 0.9750
Epoch 1288 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.7829 AR 1.0000
Epoch 1288 batch 00009: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8296 AR 0.9750
Epoch 1288 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7858 AR 0.9800
Epoch 1289 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6117 AR 0.9750
Epoch 1289 batch 00002: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7738 AR 1.0000
Epoch 1289 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.6808 AR 0.9000
Epoch 1289 batch 00004: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.8395 AR 0.9050
Epoch 1289 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6900 AR 0.9750
Epoch 1289 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6862 AR 1.0000
Epoch 1289 batch 00007: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.8725 AR 0.9800
Epoch 1289 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8030 AR 1.0000
Epoch 1289 batch 00009: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7542 AR 0.9500
Epoch 1289 batch 00010: Loss 0.0017 Regression loss 0.0015 Classification loss 0.0002 AP 0.8100 AR 0.9600
Epoch 1290 batch 00001: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7305 AR 0.9750
Epoch 1290 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7131 AR 1.0000
Epoch 1290 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7202 AR 0.9500
Epoch 1290 batch 00004: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0002 AP 0.7542 AR 0.9400
Epoch 1290 batch 00005: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6586 AR 0.8800
Epoch 1290 batch 00006: Loss 0.0016 Regression loss 0.0014 Classification loss 0.0002 AP 0.8917 AR 0.9800
Epoch 1290 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7714 AR 0.9500
Epoch 1290 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7025 AR 1.0000
Epoch 1290 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7302 AR 0.9750
Epoch 1290 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7925 AR 0.9750
Epoch 1291 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8292 AR 1.0000
Epoch 1291 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6517 AR 0.9250
Epoch 1291 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7867 AR 0.8600
Epoch 1291 batch 00004: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.6442 AR 0.9350
Epoch 1291 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7383 AR 0.9467
Epoch 1291 batch 00006: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.7933 AR 0.9750
Epoch 1291 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6800 AR 1.0000
Epoch 1291 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7819 AR 1.0000
Epoch 1291 batch 00009: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7045 AR 0.8400
Epoch 1291 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.8121 AR 1.0000
Epoch 1292 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6358 AR 0.9000
Epoch 1292 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8764 AR 1.0000
Epoch 1292 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7550 AR 0.9800
Epoch 1292 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7667 AR 0.9467
Epoch 1292 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6530 AR 0.9500
Epoch 1292 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8236 AR 1.0000
Epoch 1292 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0002 AP 0.6544 AR 0.9750
Epoch 1292 batch 00008: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7817 AR 0.9750
Epoch 1292 batch 00009: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7062 AR 0.9100
Epoch 1292 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7842 AR 0.9350
Epoch 1293 batch 00001: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0001 AP 0.7488 AR 1.0000
Epoch 1293 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8127 AR 1.0000
Epoch 1293 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.6948 AR 0.9550
Epoch 1293 batch 00004: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.7928 AR 0.8850
Epoch 1293 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7600 AR 1.0000
Epoch 1293 batch 00006: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6375 AR 0.8800
Epoch 1293 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7317 AR 0.9800
Epoch 1293 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5750 AR 0.8750
Epoch 1293 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8548 AR 1.0000
Epoch 1293 batch 00010: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.8281 AR 0.9800
Epoch 1294 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7662 AR 0.9800
Epoch 1294 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8050 AR 0.9750
Epoch 1294 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8631 AR 1.0000
Epoch 1294 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8200 AR 0.9350
Epoch 1294 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7648 AR 1.0000
Epoch 1294 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7572 AR 0.9800
Epoch 1294 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8098 AR 0.9600
Epoch 1294 batch 00008: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5643 AR 0.8250
Epoch 1294 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7592 AR 1.0000
Epoch 1294 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5583 AR 0.9000
Epoch 1295 batch 00001: Loss 0.0015 Regression loss 0.0012 Classification loss 0.0003 AP 0.6900 AR 0.9400
Epoch 1295 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8550 AR 1.0000
Epoch 1295 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7350 AR 0.8750
Epoch 1295 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6683 AR 0.9000
Epoch 1295 batch 00005: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.7630 AR 1.0000
Epoch 1295 batch 00006: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.6409 AR 0.9750
Epoch 1295 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7625 AR 0.9417
Epoch 1295 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7850 AR 0.9750
Epoch 1295 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6395 AR 0.9550
Epoch 1295 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.8221 AR 0.9750
Epoch 1296 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7302 AR 1.0000
Epoch 1296 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7342 AR 0.9800
Epoch 1296 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7675 AR 1.0000
Epoch 1296 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6600 AR 0.8217
Epoch 1296 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8000 AR 0.9750
Epoch 1296 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.7929 AR 0.9800
Epoch 1296 batch 00007: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.8817 AR 0.9800
Epoch 1296 batch 00008: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7514 AR 1.0000
Epoch 1296 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7183 AR 0.9500
Epoch 1296 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.5923 AR 0.9000
Epoch 1297 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8517 AR 0.9750
Epoch 1297 batch 00002: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.7392 AR 0.9100
Epoch 1297 batch 00003: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7849 AR 0.9800
Epoch 1297 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7133 AR 0.8800
Epoch 1297 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7543 AR 1.0000
Epoch 1297 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7831 AR 0.9750
Epoch 1297 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.6400 AR 0.8550
Epoch 1297 batch 00008: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.6700 AR 0.9300
Epoch 1297 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7400 AR 0.9467
Epoch 1297 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6925 AR 0.9800
Epoch 1298 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7156 AR 0.9750
Epoch 1298 batch 00002: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8638 AR 1.0000
Epoch 1298 batch 00003: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6792 AR 0.9750
Epoch 1298 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6967 AR 0.9100
Epoch 1298 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8238 AR 0.9000
Epoch 1298 batch 00006: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0002 AP 0.7121 AR 0.9100
Epoch 1298 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6723 AR 0.9800
Epoch 1298 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7583 AR 0.9800
Epoch 1298 batch 00009: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.7361 AR 0.9750
Epoch 1298 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7039 AR 0.9667
Epoch 1299 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7398 AR 0.9750
Epoch 1299 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7148 AR 0.9417
Epoch 1299 batch 00003: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.6745 AR 1.0000
Epoch 1299 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7655 AR 0.9550
Epoch 1299 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7026 AR 0.9800
Epoch 1299 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8083 AR 1.0000
Epoch 1299 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8133 AR 1.0000
Epoch 1299 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7360 AR 0.9800
Epoch 1299 batch 00009: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7564 AR 0.9750
Epoch 1299 batch 00010: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7192 AR 0.9017
Epoch 1300 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5988 AR 0.9000
Epoch 1300 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8505 AR 0.9800
Epoch 1300 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7598 AR 0.9800
Epoch 1300 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.7617 AR 0.9750
Epoch 1300 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.8531 AR 0.9550
Epoch 1300 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7456 AR 1.0000
Epoch 1300 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7350 AR 0.9600
Epoch 1300 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.6733 AR 0.9667
Epoch 1300 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6943 AR 0.9000
Epoch 1300 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7139 AR 0.9500
Epoch 1301 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6827 AR 0.9600
Epoch 1301 batch 00002: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0003 AP 0.6800 AR 0.9600
Epoch 1301 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6524 AR 0.9500
Epoch 1301 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6255 AR 0.8667
Epoch 1301 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8250 AR 1.0000
Epoch 1301 batch 00006: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7996 AR 1.0000
Epoch 1301 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7050 AR 0.8750
Epoch 1301 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7850 AR 1.0000
Epoch 1301 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7367 AR 0.9050
Epoch 1301 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.8681 AR 0.9800
Epoch 1302 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6667 AR 0.8667
Epoch 1302 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7189 AR 0.9550
Epoch 1302 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7267 AR 0.9750
Epoch 1302 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6530 AR 0.8600
Epoch 1302 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6736 AR 0.9050
Epoch 1302 batch 00006: Loss 0.0014 Regression loss 0.0011 Classification loss 0.0004 AP 0.8467 AR 0.9800
Epoch 1302 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7461 AR 1.0000
Epoch 1302 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.8092 AR 0.9750
Epoch 1302 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7767 AR 1.0000
Epoch 1302 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6869 AR 1.0000
Epoch 1303 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7655 AR 1.0000
Epoch 1303 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8371 AR 1.0000
Epoch 1303 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8208 AR 0.9550
Epoch 1303 batch 00004: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6517 AR 0.8550
Epoch 1303 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7467 AR 0.9550
Epoch 1303 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6614 AR 0.9500
Epoch 1303 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7524 AR 0.9800
Epoch 1303 batch 00008: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7046 AR 0.8600
Epoch 1303 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6355 AR 0.9417
Epoch 1303 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8067 AR 1.0000
Epoch 1304 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7571 AR 0.9083
Epoch 1304 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6642 AR 0.9600
Epoch 1304 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7314 AR 0.9000
Epoch 1304 batch 00004: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7117 AR 0.9800
Epoch 1304 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8817 AR 1.0000
Epoch 1304 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7677 AR 1.0000
Epoch 1304 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7652 AR 0.9750
Epoch 1304 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7495 AR 0.9667
Epoch 1304 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7617 AR 0.9750
Epoch 1304 batch 00010: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.5921 AR 0.7900
Epoch 1305 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7437 AR 0.9750
Epoch 1305 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7133 AR 0.9800
Epoch 1305 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6717 AR 0.9750
Epoch 1305 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7108 AR 0.9750
Epoch 1305 batch 00005: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8200 AR 0.9250
Epoch 1305 batch 00006: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7731 AR 0.9800
Epoch 1305 batch 00007: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0002 AP 0.7877 AR 0.9250
Epoch 1305 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7338 AR 0.9750
Epoch 1305 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7600 AR 0.9800
Epoch 1305 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7131 AR 0.8800
Epoch 1306 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6350 AR 0.8750
Epoch 1306 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7798 AR 0.9750
Epoch 1306 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7433 AR 0.9000
Epoch 1306 batch 00004: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.8600 AR 1.0000
Epoch 1306 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.8117 AR 0.9800
Epoch 1306 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6667 AR 0.9550
Epoch 1306 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8442 AR 0.9750
Epoch 1306 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.5621 AR 0.9800
Epoch 1306 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7848 AR 0.9500
Epoch 1306 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7517 AR 0.9550
Epoch 1307 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6909 AR 0.9300
Epoch 1307 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7671 AR 1.0000
Epoch 1307 batch 00003: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8097 AR 0.9750
Epoch 1307 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.8175 AR 0.9750
Epoch 1307 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7214 AR 0.9000
Epoch 1307 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.8100 AR 0.9600
Epoch 1307 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6196 AR 1.0000
Epoch 1307 batch 00008: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.8614 AR 1.0000
Epoch 1307 batch 00009: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0002 AP 0.7814 AR 0.9800
Epoch 1307 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6642 AR 0.9750
Epoch 1308 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7047 AR 0.9600
Epoch 1308 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7139 AR 0.9750
Epoch 1308 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7767 AR 1.0000
Epoch 1308 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.5833 AR 0.9467
Epoch 1308 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7693 AR 0.9550
Epoch 1308 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0002 AP 0.6400 AR 0.8500
Epoch 1308 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8317 AR 1.0000
Epoch 1308 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.8536 AR 1.0000
Epoch 1308 batch 00009: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7000 AR 0.7850
Epoch 1308 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7038 AR 0.8800
Epoch 1309 batch 00001: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.8167 AR 0.9800
Epoch 1309 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7717 AR 0.9000
Epoch 1309 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7014 AR 0.8800
Epoch 1309 batch 00004: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.7083 AR 0.9800
Epoch 1309 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8058 AR 0.9467
Epoch 1309 batch 00006: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7156 AR 0.8100
Epoch 1309 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7921 AR 0.9800
Epoch 1309 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7017 AR 0.9500
Epoch 1309 batch 00009: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6100 AR 0.9667
Epoch 1309 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7408 AR 0.9800
Epoch 1310 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6961 AR 0.9667
Epoch 1310 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6692 AR 0.8917
Epoch 1310 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7222 AR 0.9550
Epoch 1310 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0002 AP 0.7800 AR 0.9600
Epoch 1310 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.8145 AR 0.9750
Epoch 1310 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5955 AR 0.8800
Epoch 1310 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6583 AR 0.9500
Epoch 1310 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8621 AR 0.9800
Epoch 1310 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6820 AR 1.0000
Epoch 1310 batch 00010: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.9208 AR 1.0000
Epoch 1311 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6102 AR 0.9800
Epoch 1311 batch 00002: Loss 0.0015 Regression loss 0.0013 Classification loss 0.0003 AP 0.7067 AR 0.9550
Epoch 1311 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7683 AR 0.9550
Epoch 1311 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7825 AR 1.0000
Epoch 1311 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.6830 AR 0.8550
Epoch 1311 batch 00006: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7881 AR 0.9750
Epoch 1311 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8476 AR 1.0000
Epoch 1311 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6569 AR 0.9467
Epoch 1311 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7721 AR 0.9000
Epoch 1311 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7850 AR 1.0000
Epoch 1312 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7130 AR 1.0000
Epoch 1312 batch 00002: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0001 AP 0.8488 AR 1.0000
Epoch 1312 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7808 AR 0.9550
Epoch 1312 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7298 AR 0.9800
Epoch 1312 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7067 AR 0.9000
Epoch 1312 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7611 AR 0.9350
Epoch 1312 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7330 AR 0.9300
Epoch 1312 batch 00008: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6762 AR 0.9417
Epoch 1312 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7256 AR 0.9500
Epoch 1312 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7714 AR 0.9800
Epoch 1313 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7645 AR 0.9667
Epoch 1313 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6288 AR 0.7750
Epoch 1313 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8833 AR 1.0000
Epoch 1313 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7136 AR 0.9800
Epoch 1313 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6975 AR 0.9150
Epoch 1313 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7955 AR 0.9667
Epoch 1313 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6728 AR 0.9800
Epoch 1313 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.8250 AR 0.9750
Epoch 1313 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7183 AR 0.8800
Epoch 1313 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6805 AR 0.9000
Epoch 1314 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7217 AR 0.8800
Epoch 1314 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7817 AR 0.9750
Epoch 1314 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5926 AR 0.9417
Epoch 1314 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8289 AR 1.0000
Epoch 1314 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6917 AR 0.9467
Epoch 1314 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7383 AR 0.9050
Epoch 1314 batch 00007: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.6321 AR 0.8500
Epoch 1314 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7881 AR 0.9800
Epoch 1314 batch 00009: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.8983 AR 0.9800
Epoch 1314 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6919 AR 0.9550
Epoch 1315 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7317 AR 0.8800
Epoch 1315 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7371 AR 0.9000
Epoch 1315 batch 00003: Loss 0.0014 Regression loss 0.0012 Classification loss 0.0002 AP 0.6857 AR 0.8800
Epoch 1315 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7973 AR 1.0000
Epoch 1315 batch 00005: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.8781 AR 0.9600
Epoch 1315 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6381 AR 0.8500
Epoch 1315 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7705 AR 0.9667
Epoch 1315 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6250 AR 0.9250
Epoch 1315 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7885 AR 1.0000
Epoch 1315 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6878 AR 0.9600
Epoch 1316 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7456 AR 0.9800
Epoch 1316 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6969 AR 0.9800
Epoch 1316 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6877 AR 0.8800
Epoch 1316 batch 00004: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7350 AR 0.9500
Epoch 1316 batch 00005: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7750 AR 0.8500
Epoch 1316 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8217 AR 1.0000
Epoch 1316 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6748 AR 0.9800
Epoch 1316 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.8155 AR 0.9500
Epoch 1316 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6333 AR 0.9300
Epoch 1316 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7333 AR 0.9417
Epoch 1317 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8223 AR 1.0000
Epoch 1317 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8333 AR 1.0000
Epoch 1317 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6721 AR 0.9600
Epoch 1317 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7652 AR 0.9500
Epoch 1317 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8800 AR 1.0000
Epoch 1317 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6461 AR 0.8800
Epoch 1317 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7223 AR 0.9500
Epoch 1317 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5869 AR 0.9000
Epoch 1317 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.6883 AR 1.0000
Epoch 1317 batch 00010: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0002 AP 0.7814 AR 0.9217
Epoch 1318 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7097 AR 0.9800
Epoch 1318 batch 00002: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.8083 AR 0.9750
Epoch 1318 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5858 AR 0.8500
Epoch 1318 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7223 AR 1.0000
Epoch 1318 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7374 AR 1.0000
Epoch 1318 batch 00006: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6975 AR 1.0000
Epoch 1318 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7594 AR 0.8500
Epoch 1318 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7450 AR 0.9167
Epoch 1318 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8348 AR 1.0000
Epoch 1318 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.8140 AR 0.9150
Epoch 1319 batch 00001: Loss 0.0013 Regression loss 0.0011 Classification loss 0.0002 AP 0.7296 AR 0.9750
Epoch 1319 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7217 AR 0.9600
Epoch 1319 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7445 AR 0.9000
Epoch 1319 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7708 AR 1.0000
Epoch 1319 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6917 AR 0.9500
Epoch 1319 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8438 AR 1.0000
Epoch 1319 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7850 AR 1.0000
Epoch 1319 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8173 AR 0.9600
Epoch 1319 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6128 AR 0.8883
Epoch 1319 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7588 AR 0.9000
Epoch 1320 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7388 AR 0.9350
Epoch 1320 batch 00002: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7798 AR 0.9417
Epoch 1320 batch 00003: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6433 AR 0.8800
Epoch 1320 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7052 AR 0.9300
Epoch 1320 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7684 AR 0.9750
Epoch 1320 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7814 AR 1.0000
Epoch 1320 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7164 AR 0.9500
Epoch 1320 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7798 AR 0.9800
Epoch 1320 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.7005 AR 0.8667
Epoch 1320 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7377 AR 1.0000
Epoch 1321 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7188 AR 0.9800
Epoch 1321 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6639 AR 0.9250
Epoch 1321 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7651 AR 1.0000
Epoch 1321 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7921 AR 1.0000
Epoch 1321 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6878 AR 0.8800
Epoch 1321 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7055 AR 0.9250
Epoch 1321 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8692 AR 1.0000
Epoch 1321 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7175 AR 0.9667
Epoch 1321 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.8033 AR 0.9350
Epoch 1321 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7317 AR 1.0000
Epoch 1322 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7861 AR 0.9800
Epoch 1322 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7683 AR 0.8800
Epoch 1322 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8448 AR 0.9667
Epoch 1322 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6921 AR 0.9000
Epoch 1322 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6323 AR 0.9550
Epoch 1322 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7129 AR 1.0000
Epoch 1322 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8088 AR 1.0000
Epoch 1322 batch 00008: Loss 0.0012 Regression loss 0.0009 Classification loss 0.0002 AP 0.7164 AR 0.8767
Epoch 1322 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6881 AR 0.8750
Epoch 1322 batch 00010: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7500 AR 0.9300
Epoch 1323 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7198 AR 0.9000
Epoch 1323 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6333 AR 0.9050
Epoch 1323 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7108 AR 1.0000
Epoch 1323 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8238 AR 0.9750
Epoch 1323 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6196 AR 0.8800
Epoch 1323 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7689 AR 0.9750
Epoch 1323 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8214 AR 0.9600
Epoch 1323 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7050 AR 0.8467
Epoch 1323 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7817 AR 0.9750
Epoch 1323 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7917 AR 1.0000
Epoch 1324 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7143 AR 0.8500
Epoch 1324 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7300 AR 0.8550
Epoch 1324 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7461 AR 0.9600
Epoch 1324 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8120 AR 0.9550
Epoch 1324 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7864 AR 0.9300
Epoch 1324 batch 00006: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7908 AR 0.9750
Epoch 1324 batch 00007: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.6427 AR 0.8500
Epoch 1324 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6726 AR 0.9750
Epoch 1324 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7350 AR 0.9750
Epoch 1324 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7094 AR 0.9467
Epoch 1325 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6842 AR 0.8967
Epoch 1325 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7550 AR 0.8750
Epoch 1325 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.6606 AR 0.8800
Epoch 1325 batch 00004: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7921 AR 0.9550
Epoch 1325 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7356 AR 0.9800
Epoch 1325 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.9238 AR 0.9800
Epoch 1325 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6221 AR 0.9500
Epoch 1325 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7292 AR 1.0000
Epoch 1325 batch 00009: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7900 AR 1.0000
Epoch 1325 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7577 AR 1.0000
Epoch 1326 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8150 AR 0.9750
Epoch 1326 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7931 AR 0.9000
Epoch 1326 batch 00003: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.9022 AR 1.0000
Epoch 1326 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7750 AR 0.9800
Epoch 1326 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7267 AR 1.0000
Epoch 1326 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6053 AR 0.9467
Epoch 1326 batch 00007: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7350 AR 0.8800
Epoch 1326 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.6044 AR 0.8100
Epoch 1326 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.5976 AR 0.9250
Epoch 1326 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8631 AR 0.9800
Epoch 1327 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.4300 AR 0.7750
Epoch 1327 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.9181 AR 1.0000
Epoch 1327 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6379 AR 0.8500
Epoch 1327 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7262 AR 0.9800
Epoch 1327 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7431 AR 0.9467
Epoch 1327 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8444 AR 0.9600
Epoch 1327 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7508 AR 0.9350
Epoch 1327 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6963 AR 0.9550
Epoch 1327 batch 00009: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7500 AR 0.8550
Epoch 1327 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7469 AR 0.9750
Epoch 1328 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6980 AR 0.9100
Epoch 1328 batch 00002: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7750 AR 0.9250
Epoch 1328 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6798 AR 0.9750
Epoch 1328 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6487 AR 1.0000
Epoch 1328 batch 00005: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7471 AR 0.9750
Epoch 1328 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6300 AR 0.8467
Epoch 1328 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8167 AR 1.0000
Epoch 1328 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8663 AR 1.0000
Epoch 1328 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7525 AR 0.9600
Epoch 1328 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6967 AR 0.8800
Epoch 1329 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6814 AR 1.0000
Epoch 1329 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.6683 AR 0.8467
Epoch 1329 batch 00003: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7973 AR 1.0000
Epoch 1329 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7460 AR 0.9550
Epoch 1329 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7955 AR 0.9217
Epoch 1329 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7767 AR 0.9100
Epoch 1329 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.7050 AR 0.8667
Epoch 1329 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6439 AR 0.9750
Epoch 1329 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7550 AR 0.9350
Epoch 1329 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8098 AR 1.0000
Epoch 1330 batch 00001: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7817 AR 0.9800
Epoch 1330 batch 00002: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7993 AR 1.0000
Epoch 1330 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6655 AR 0.9167
Epoch 1330 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6548 AR 0.8750
Epoch 1330 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7992 AR 0.9800
Epoch 1330 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7828 AR 0.9600
Epoch 1330 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6710 AR 0.8600
Epoch 1330 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7335 AR 0.9550
Epoch 1330 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8283 AR 1.0000
Epoch 1330 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7142 AR 0.9750
Epoch 1331 batch 00001: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6030 AR 0.9600
Epoch 1331 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7814 AR 0.9550
Epoch 1331 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6583 AR 0.9000
Epoch 1331 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7936 AR 1.0000
Epoch 1331 batch 00005: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7892 AR 0.9500
Epoch 1331 batch 00006: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7642 AR 0.9400
Epoch 1331 batch 00007: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7264 AR 0.8500
Epoch 1331 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7905 AR 1.0000
Epoch 1331 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6828 AR 0.9750
Epoch 1331 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7055 AR 0.9417
Epoch 1332 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7321 AR 0.9800
Epoch 1332 batch 00002: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6467 AR 0.9667
Epoch 1332 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7398 AR 1.0000
Epoch 1332 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.8000 AR 0.9100
Epoch 1332 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8758 AR 1.0000
Epoch 1332 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6880 AR 0.9250
Epoch 1332 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7067 AR 1.0000
Epoch 1332 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6812 AR 0.8800
Epoch 1332 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6964 AR 0.8167
Epoch 1332 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7544 AR 0.9550
Epoch 1333 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7814 AR 0.9800
Epoch 1333 batch 00002: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7767 AR 0.9750
Epoch 1333 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8089 AR 1.0000
Epoch 1333 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.6761 AR 0.8600
Epoch 1333 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6800 AR 0.8750
Epoch 1333 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6266 AR 0.8800
Epoch 1333 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7150 AR 0.9800
Epoch 1333 batch 00008: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8398 AR 0.9550
Epoch 1333 batch 00009: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7100 AR 0.8550
Epoch 1333 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.5714 AR 0.9667
Epoch 1334 batch 00001: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7733 AR 0.9500
Epoch 1334 batch 00002: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7917 AR 0.8550
Epoch 1334 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8483 AR 0.9600
Epoch 1334 batch 00004: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7650 AR 0.9417
Epoch 1334 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7755 AR 0.9800
Epoch 1334 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.7553 AR 0.9800
Epoch 1334 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7008 AR 0.9550
Epoch 1334 batch 00008: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6529 AR 0.8750
Epoch 1334 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6623 AR 0.9667
Epoch 1334 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7214 AR 0.9550
Epoch 1335 batch 00001: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.7955 AR 0.9600
Epoch 1335 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8483 AR 0.9750
Epoch 1335 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6905 AR 1.0000
Epoch 1335 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6558 AR 0.8750
Epoch 1335 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8186 AR 0.9750
Epoch 1335 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7529 AR 0.9250
Epoch 1335 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8075 AR 1.0000
Epoch 1335 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7267 AR 0.8300
Epoch 1335 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7433 AR 0.9600
Epoch 1335 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6014 AR 0.9550
Epoch 1336 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6623 AR 0.8800
Epoch 1336 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.8871 AR 0.9550
Epoch 1336 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6950 AR 0.9750
Epoch 1336 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6433 AR 0.9350
Epoch 1336 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7738 AR 0.8550
Epoch 1336 batch 00006: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8948 AR 1.0000
Epoch 1336 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7467 AR 0.9800
Epoch 1336 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.8017 AR 0.9750
Epoch 1336 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6862 AR 0.9750
Epoch 1336 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6708 AR 0.9417
Epoch 1337 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8100 AR 1.0000
Epoch 1337 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7405 AR 0.9750
Epoch 1337 batch 00003: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.6662 AR 0.9800
Epoch 1337 batch 00004: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7700 AR 0.9800
Epoch 1337 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7423 AR 1.0000
Epoch 1337 batch 00006: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8247 AR 0.9550
Epoch 1337 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7400 AR 0.9500
Epoch 1337 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7173 AR 0.9417
Epoch 1337 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7650 AR 0.9750
Epoch 1337 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6805 AR 0.9800
Epoch 1338 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7917 AR 0.9500
Epoch 1338 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7167 AR 0.9800
Epoch 1338 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7864 AR 1.0000
Epoch 1338 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6612 AR 0.9000
Epoch 1338 batch 00005: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0002 AP 0.8081 AR 0.9017
Epoch 1338 batch 00006: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6976 AR 1.0000
Epoch 1338 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7421 AR 0.9800
Epoch 1338 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7714 AR 1.0000
Epoch 1338 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7960 AR 0.9500
Epoch 1338 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7417 AR 1.0000
Epoch 1339 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6751 AR 0.9750
Epoch 1339 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6038 AR 0.8267
Epoch 1339 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7933 AR 0.9050
Epoch 1339 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0002 AP 0.7931 AR 0.9800
Epoch 1339 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7167 AR 0.9000
Epoch 1339 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7130 AR 0.9750
Epoch 1339 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6464 AR 1.0000
Epoch 1339 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8000 AR 0.9750
Epoch 1339 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8367 AR 0.9550
Epoch 1339 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8439 AR 1.0000
Epoch 1340 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7389 AR 1.0000
Epoch 1340 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5816 AR 0.9300
Epoch 1340 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7322 AR 1.0000
Epoch 1340 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8698 AR 0.9750
Epoch 1340 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.8267 AR 0.9800
Epoch 1340 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7264 AR 0.9750
Epoch 1340 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7093 AR 0.9750
Epoch 1340 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8433 AR 0.9800
Epoch 1340 batch 00009: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7444 AR 0.9400
Epoch 1340 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7750 AR 0.9750
Epoch 1341 batch 00001: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.6280 AR 0.8800
Epoch 1341 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6214 AR 0.9350
Epoch 1341 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7383 AR 0.9350
Epoch 1341 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7867 AR 0.8750
Epoch 1341 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.8233 AR 0.9800
Epoch 1341 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.9464 AR 1.0000
Epoch 1341 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6750 AR 0.8750
Epoch 1341 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7933 AR 0.9750
Epoch 1341 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7263 AR 1.0000
Epoch 1341 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.5500 AR 0.8000
Epoch 1342 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7183 AR 0.9000
Epoch 1342 batch 00002: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8933 AR 0.9800
Epoch 1342 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7410 AR 1.0000
Epoch 1342 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7234 AR 1.0000
Epoch 1342 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7750 AR 0.9800
Epoch 1342 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7600 AR 0.9750
Epoch 1342 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7167 AR 0.8750
Epoch 1342 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7206 AR 0.9250
Epoch 1342 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.6838 AR 0.9550
Epoch 1342 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7817 AR 0.9350
Epoch 1343 batch 00001: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7783 AR 0.9750
Epoch 1343 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7600 AR 0.9750
Epoch 1343 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7520 AR 1.0000
Epoch 1343 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6238 AR 0.8750
Epoch 1343 batch 00005: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6838 AR 0.9500
Epoch 1343 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8438 AR 0.9550
Epoch 1343 batch 00007: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7117 AR 0.9467
Epoch 1343 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8083 AR 0.9600
Epoch 1343 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6851 AR 0.9750
Epoch 1343 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7364 AR 0.9000
Epoch 1344 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7005 AR 0.9800
Epoch 1344 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7947 AR 1.0000
Epoch 1344 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7362 AR 0.8750
Epoch 1344 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7305 AR 0.9667
Epoch 1344 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8598 AR 0.9800
Epoch 1344 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8142 AR 0.9550
Epoch 1344 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7400 AR 0.9600
Epoch 1344 batch 00008: Loss 0.0011 Regression loss 0.0009 Classification loss 0.0001 AP 0.7156 AR 1.0000
Epoch 1344 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5833 AR 0.8667
Epoch 1344 batch 00010: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8000 AR 0.9500
Epoch 1345 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7638 AR 0.9017
Epoch 1345 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7098 AR 1.0000
Epoch 1345 batch 00003: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7756 AR 1.0000
Epoch 1345 batch 00004: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7842 AR 0.9550
Epoch 1345 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7200 AR 0.8750
Epoch 1345 batch 00006: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7142 AR 0.9217
Epoch 1345 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6942 AR 1.0000
Epoch 1345 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8321 AR 1.0000
Epoch 1345 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8312 AR 0.9500
Epoch 1345 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7718 AR 1.0000
Epoch 1346 batch 00001: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7100 AR 1.0000
Epoch 1346 batch 00002: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.8181 AR 0.9217
Epoch 1346 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7663 AR 0.9500
Epoch 1346 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7488 AR 0.9800
Epoch 1346 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8314 AR 1.0000
Epoch 1346 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7381 AR 0.9550
Epoch 1346 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7419 AR 0.9800
Epoch 1346 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6221 AR 0.8750
Epoch 1346 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8167 AR 0.9750
Epoch 1346 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7211 AR 0.9800
Epoch 1347 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7164 AR 0.9500
Epoch 1347 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6633 AR 0.8550
Epoch 1347 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7155 AR 1.0000
Epoch 1347 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8186 AR 1.0000
Epoch 1347 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7203 AR 0.9600
Epoch 1347 batch 00006: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7500 AR 1.0000
Epoch 1347 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8406 AR 1.0000
Epoch 1347 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8030 AR 1.0000
Epoch 1347 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6274 AR 0.8833
Epoch 1347 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8036 AR 0.9750
Epoch 1348 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7973 AR 1.0000
Epoch 1348 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7305 AR 0.9800
Epoch 1348 batch 00003: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.6169 AR 1.0000
Epoch 1348 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6933 AR 0.9667
Epoch 1348 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6817 AR 0.9217
Epoch 1348 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7405 AR 0.9750
Epoch 1348 batch 00007: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.7833 AR 0.9500
Epoch 1348 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8381 AR 0.9800
Epoch 1348 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7500 AR 0.7800
Epoch 1348 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8331 AR 1.0000
Epoch 1349 batch 00001: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6633 AR 0.9800
Epoch 1349 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8383 AR 0.9250
Epoch 1349 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8723 AR 1.0000
Epoch 1349 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7914 AR 1.0000
Epoch 1349 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7267 AR 1.0000
Epoch 1349 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8089 AR 1.0000
Epoch 1349 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8588 AR 1.0000
Epoch 1349 batch 00008: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.6881 AR 0.9800
Epoch 1349 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6313 AR 0.9800
Epoch 1349 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7588 AR 1.0000
Epoch 1350 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6485 AR 0.9800
Epoch 1350 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6878 AR 0.9800
Epoch 1350 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8114 AR 0.9500
Epoch 1350 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6867 AR 0.8667
Epoch 1350 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6219 AR 1.0000
Epoch 1350 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6300 AR 0.8850
Epoch 1350 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7755 AR 0.9550
Epoch 1350 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.8562 AR 0.9800
Epoch 1350 batch 00009: Loss 0.0012 Regression loss 0.0010 Classification loss 0.0001 AP 0.8231 AR 0.9550
Epoch 1350 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8058 AR 1.0000
Epoch 1351 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7326 AR 0.9750
Epoch 1351 batch 00002: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0000 AP 0.6550 AR 1.0000
Epoch 1351 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7254 AR 0.9800
Epoch 1351 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7983 AR 0.9300
Epoch 1351 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.8117 AR 1.0000
Epoch 1351 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6514 AR 0.8800
Epoch 1351 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7851 AR 0.9750
Epoch 1351 batch 00008: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.8564 AR 0.9550
Epoch 1351 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7839 AR 0.8750
Epoch 1351 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7183 AR 1.0000
Epoch 1352 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8042 AR 0.9300
Epoch 1352 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7746 AR 0.9550
Epoch 1352 batch 00003: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7508 AR 1.0000
Epoch 1352 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7717 AR 1.0000
Epoch 1352 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6356 AR 0.9417
Epoch 1352 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7631 AR 1.0000
Epoch 1352 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6780 AR 0.9000
Epoch 1352 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7270 AR 0.9550
Epoch 1352 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.8621 AR 1.0000
Epoch 1352 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7533 AR 0.9550
Epoch 1353 batch 00001: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7798 AR 0.9000
Epoch 1353 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6225 AR 0.8550
Epoch 1353 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7217 AR 1.0000
Epoch 1353 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7521 AR 1.0000
Epoch 1353 batch 00005: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7850 AR 1.0000
Epoch 1353 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7571 AR 0.9500
Epoch 1353 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7650 AR 0.9750
Epoch 1353 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7423 AR 0.9750
Epoch 1353 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7325 AR 0.9350
Epoch 1353 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7375 AR 0.9100
Epoch 1354 batch 00001: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.6467 AR 1.0000
Epoch 1354 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7342 AR 0.8550
Epoch 1354 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7292 AR 0.9550
Epoch 1354 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8017 AR 0.9800
Epoch 1354 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6250 AR 0.9000
Epoch 1354 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7867 AR 1.0000
Epoch 1354 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7978 AR 0.9750
Epoch 1354 batch 00008: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7221 AR 0.9300
Epoch 1354 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8250 AR 0.9750
Epoch 1354 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6752 AR 0.9000
Epoch 1355 batch 00001: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7631 AR 0.9800
Epoch 1355 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0002 AP 0.7967 AR 0.9800
Epoch 1355 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7733 AR 0.9750
Epoch 1355 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6367 AR 0.8667
Epoch 1355 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8471 AR 0.9750
Epoch 1355 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7117 AR 0.8667
Epoch 1355 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7905 AR 1.0000
Epoch 1355 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6701 AR 0.9300
Epoch 1355 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7311 AR 1.0000
Epoch 1355 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6325 AR 0.8667
Epoch 1356 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8151 AR 0.9750
Epoch 1356 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7236 AR 1.0000
Epoch 1356 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8533 AR 0.9500
Epoch 1356 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.6975 AR 0.9550
Epoch 1356 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6836 AR 1.0000
Epoch 1356 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8775 AR 0.9750
Epoch 1356 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5985 AR 0.8800
Epoch 1356 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7928 AR 0.9050
Epoch 1356 batch 00009: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0001 AP 0.6767 AR 0.7800
Epoch 1356 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7006 AR 1.0000
Epoch 1357 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7467 AR 0.9750
Epoch 1357 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7580 AR 1.0000
Epoch 1357 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7933 AR 0.9750
Epoch 1357 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6386 AR 0.9250
Epoch 1357 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6151 AR 0.8800
Epoch 1357 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7633 AR 1.0000
Epoch 1357 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8588 AR 1.0000
Epoch 1357 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7964 AR 0.9500
Epoch 1357 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6866 AR 0.8800
Epoch 1357 batch 00010: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7979 AR 0.9600
Epoch 1358 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6681 AR 0.8750
Epoch 1358 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7469 AR 0.9800
Epoch 1358 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6283 AR 0.9400
Epoch 1358 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7548 AR 0.9500
Epoch 1358 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6800 AR 0.8000
Epoch 1358 batch 00006: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.8833 AR 1.0000
Epoch 1358 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8439 AR 0.9800
Epoch 1358 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7006 AR 1.0000
Epoch 1358 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8417 AR 0.9800
Epoch 1358 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6605 AR 0.9750
Epoch 1359 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7805 AR 0.9750
Epoch 1359 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5905 AR 0.8000
Epoch 1359 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7886 AR 0.9750
Epoch 1359 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6733 AR 0.9300
Epoch 1359 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.9458 AR 0.9750
Epoch 1359 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7336 AR 0.9800
Epoch 1359 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.9371 AR 1.0000
Epoch 1359 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6981 AR 0.9800
Epoch 1359 batch 00009: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7467 AR 0.9600
Epoch 1359 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6358 AR 1.0000
Epoch 1360 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6800 AR 0.9667
Epoch 1360 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7788 AR 0.9750
Epoch 1360 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7538 AR 1.0000
Epoch 1360 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5883 AR 0.7800
Epoch 1360 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8400 AR 1.0000
Epoch 1360 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7639 AR 0.9500
Epoch 1360 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7044 AR 0.9200
Epoch 1360 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7214 AR 0.9000
Epoch 1360 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7783 AR 0.9750
Epoch 1360 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8363 AR 0.9750
Epoch 1361 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7761 AR 0.9800
Epoch 1361 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6730 AR 1.0000
Epoch 1361 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7567 AR 0.9800
Epoch 1361 batch 00004: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7092 AR 0.8750
Epoch 1361 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7781 AR 0.9250
Epoch 1361 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8886 AR 1.0000
Epoch 1361 batch 00007: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.7683 AR 0.9350
Epoch 1361 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7421 AR 1.0000
Epoch 1361 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7358 AR 0.9467
Epoch 1361 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5600 AR 0.8750
Epoch 1362 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6921 AR 0.8750
Epoch 1362 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8472 AR 1.0000
Epoch 1362 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7614 AR 0.9000
Epoch 1362 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7998 AR 0.9750
Epoch 1362 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7905 AR 0.9750
Epoch 1362 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7985 AR 0.9800
Epoch 1362 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7362 AR 1.0000
Epoch 1362 batch 00008: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.5783 AR 0.9300
Epoch 1362 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6775 AR 0.8800
Epoch 1362 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7169 AR 0.9350
Epoch 1363 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8398 AR 1.0000
Epoch 1363 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6390 AR 0.8800
Epoch 1363 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7821 AR 0.8750
Epoch 1363 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6600 AR 0.9600
Epoch 1363 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7488 AR 0.9750
Epoch 1363 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7614 AR 0.9800
Epoch 1363 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7150 AR 0.9550
Epoch 1363 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8071 AR 0.9000
Epoch 1363 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8264 AR 1.0000
Epoch 1363 batch 00010: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7150 AR 1.0000
Epoch 1364 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6555 AR 0.9167
Epoch 1364 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7152 AR 0.9500
Epoch 1364 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7083 AR 1.0000
Epoch 1364 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8514 AR 0.9800
Epoch 1364 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6731 AR 0.8800
Epoch 1364 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7946 AR 0.9500
Epoch 1364 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7571 AR 0.9000
Epoch 1364 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8020 AR 0.9600
Epoch 1364 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6421 AR 0.8800
Epoch 1364 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6550 AR 0.9550
Epoch 1365 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7492 AR 0.9750
Epoch 1365 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7388 AR 0.9500
Epoch 1365 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6659 AR 0.8600
Epoch 1365 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7767 AR 1.0000
Epoch 1365 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7348 AR 0.9100
Epoch 1365 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.9133 AR 1.0000
Epoch 1365 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7219 AR 1.0000
Epoch 1365 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6772 AR 0.9000
Epoch 1365 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8181 AR 1.0000
Epoch 1365 batch 00010: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.5983 AR 0.9000
Epoch 1366 batch 00001: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0002 AP 0.6317 AR 0.8217
Epoch 1366 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7983 AR 0.9750
Epoch 1366 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8417 AR 1.0000
Epoch 1366 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6638 AR 0.9000
Epoch 1366 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7280 AR 0.9800
Epoch 1366 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8042 AR 1.0000
Epoch 1366 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7131 AR 0.9600
Epoch 1366 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7773 AR 0.9750
Epoch 1366 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6706 AR 0.9000
Epoch 1366 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8338 AR 0.9750
Epoch 1367 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6503 AR 0.9550
Epoch 1367 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7008 AR 0.9500
Epoch 1367 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7496 AR 0.8800
Epoch 1367 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7417 AR 0.9000
Epoch 1367 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6356 AR 0.9000
Epoch 1367 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7183 AR 0.9500
Epoch 1367 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8417 AR 0.9800
Epoch 1367 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7917 AR 0.9800
Epoch 1367 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7981 AR 0.9600
Epoch 1367 batch 00010: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6398 AR 0.8750
Epoch 1368 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7400 AR 0.8800
Epoch 1368 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6842 AR 0.9550
Epoch 1368 batch 00003: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6642 AR 0.9500
Epoch 1368 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8633 AR 1.0000
Epoch 1368 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6980 AR 1.0000
Epoch 1368 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7238 AR 0.8767
Epoch 1368 batch 00007: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0000 AP 0.8331 AR 1.0000
Epoch 1368 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6083 AR 0.9000
Epoch 1368 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8767 AR 0.9800
Epoch 1368 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7386 AR 1.0000
Epoch 1369 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8183 AR 1.0000
Epoch 1369 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6800 AR 0.8000
Epoch 1369 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7338 AR 0.9800
Epoch 1369 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6244 AR 0.8217
Epoch 1369 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8121 AR 1.0000
Epoch 1369 batch 00006: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6445 AR 1.0000
Epoch 1369 batch 00007: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6410 AR 0.9500
Epoch 1369 batch 00008: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7759 AR 0.9750
Epoch 1369 batch 00009: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8383 AR 1.0000
Epoch 1369 batch 00010: Loss 0.0010 Regression loss 0.0008 Classification loss 0.0002 AP 0.7867 AR 0.9300
Epoch 1370 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7702 AR 1.0000
Epoch 1370 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8267 AR 0.9800
Epoch 1370 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7998 AR 0.9750
Epoch 1370 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5871 AR 0.8550
Epoch 1370 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8522 AR 1.0000
Epoch 1370 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6903 AR 0.9000
Epoch 1370 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7550 AR 0.9800
Epoch 1370 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7050 AR 0.9500
Epoch 1370 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7536 AR 0.9000
Epoch 1370 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6992 AR 0.8800
Epoch 1371 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7100 AR 0.9550
Epoch 1371 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6456 AR 0.9000
Epoch 1371 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7189 AR 0.9000
Epoch 1371 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7544 AR 1.0000
Epoch 1371 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0002 AP 0.8142 AR 0.9600
Epoch 1371 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7850 AR 0.9667
Epoch 1371 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8087 AR 0.9800
Epoch 1371 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6556 AR 0.8500
Epoch 1371 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7225 AR 0.9000
Epoch 1371 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6583 AR 0.9000
Epoch 1372 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6621 AR 0.9750
Epoch 1372 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6681 AR 1.0000
Epoch 1372 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7761 AR 0.9550
Epoch 1372 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5314 AR 0.7550
Epoch 1372 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8695 AR 1.0000
Epoch 1372 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8508 AR 0.9500
Epoch 1372 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5972 AR 0.8750
Epoch 1372 batch 00008: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.8588 AR 0.9800
Epoch 1372 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6197 AR 0.8600
Epoch 1372 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7233 AR 1.0000
Epoch 1373 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8131 AR 1.0000
Epoch 1373 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6233 AR 0.9250
Epoch 1373 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6969 AR 1.0000
Epoch 1373 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7780 AR 0.9800
Epoch 1373 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6233 AR 0.7217
Epoch 1373 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7288 AR 0.9267
Epoch 1373 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7183 AR 0.9750
Epoch 1373 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7800 AR 0.9467
Epoch 1373 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6190 AR 0.9000
Epoch 1373 batch 00010: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.9029 AR 1.0000
Epoch 1374 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8488 AR 0.9750
Epoch 1374 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7600 AR 0.9600
Epoch 1374 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7714 AR 0.8800
Epoch 1374 batch 00004: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.6233 AR 0.8800
Epoch 1374 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.5981 AR 0.9000
Epoch 1374 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6598 AR 1.0000
Epoch 1374 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8952 AR 1.0000
Epoch 1374 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7421 AR 0.9600
Epoch 1374 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6921 AR 0.8500
Epoch 1374 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7783 AR 0.9800
Epoch 1375 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8064 AR 0.9750
Epoch 1375 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8710 AR 1.0000
Epoch 1375 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7892 AR 1.0000
Epoch 1375 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8758 AR 0.9750
Epoch 1375 batch 00005: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7150 AR 0.9400
Epoch 1375 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6947 AR 0.8467
Epoch 1375 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6576 AR 1.0000
Epoch 1375 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7443 AR 0.9550
Epoch 1375 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7233 AR 1.0000
Epoch 1375 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.5262 AR 0.7000
Epoch 1376 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8883 AR 0.9800
Epoch 1376 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7494 AR 0.9300
Epoch 1376 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8133 AR 1.0000
Epoch 1376 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8003 AR 0.9500
Epoch 1376 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6933 AR 0.8467
Epoch 1376 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6283 AR 0.8750
Epoch 1376 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7621 AR 0.9417
Epoch 1376 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7702 AR 0.9800
Epoch 1376 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7471 AR 0.9467
Epoch 1376 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5431 AR 0.8750
Epoch 1377 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7450 AR 1.0000
Epoch 1377 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7605 AR 0.9750
Epoch 1377 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7879 AR 0.9750
Epoch 1377 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7606 AR 0.9800
Epoch 1377 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7813 AR 0.9550
Epoch 1377 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6766 AR 0.8800
Epoch 1377 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7064 AR 0.8750
Epoch 1377 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7178 AR 0.8800
Epoch 1377 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7406 AR 0.9800
Epoch 1377 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7821 AR 1.0000
Epoch 1378 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6548 AR 1.0000
Epoch 1378 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6993 AR 0.9600
Epoch 1378 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5850 AR 0.8583
Epoch 1378 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8378 AR 0.9800
Epoch 1378 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7398 AR 1.0000
Epoch 1378 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7867 AR 0.9000
Epoch 1378 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6874 AR 1.0000
Epoch 1378 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7881 AR 0.9000
Epoch 1378 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8400 AR 0.9750
Epoch 1378 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8058 AR 0.9600
Epoch 1379 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6806 AR 0.9500
Epoch 1379 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7631 AR 1.0000
Epoch 1379 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7867 AR 0.9750
Epoch 1379 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6730 AR 0.9800
Epoch 1379 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8600 AR 0.9750
Epoch 1379 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8467 AR 0.9800
Epoch 1379 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7088 AR 0.8800
Epoch 1379 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7350 AR 0.9300
Epoch 1379 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8000 AR 1.0000
Epoch 1379 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6481 AR 0.8800
Epoch 1380 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8148 AR 0.9800
Epoch 1380 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7496 AR 0.9000
Epoch 1380 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6176 AR 0.9750
Epoch 1380 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7675 AR 0.9800
Epoch 1380 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7161 AR 0.8667
Epoch 1380 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7383 AR 0.9600
Epoch 1380 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6981 AR 0.9000
Epoch 1380 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8250 AR 0.9750
Epoch 1380 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6183 AR 0.8550
Epoch 1380 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8467 AR 1.0000
Epoch 1381 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6255 AR 0.8667
Epoch 1381 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7350 AR 0.9800
Epoch 1381 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8833 AR 0.9800
Epoch 1381 batch 00004: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8125 AR 1.0000
Epoch 1381 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8055 AR 0.9750
Epoch 1381 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6133 AR 0.8600
Epoch 1381 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6905 AR 0.9000
Epoch 1381 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6925 AR 0.9800
Epoch 1381 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8114 AR 0.9550
Epoch 1381 batch 00010: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8176 AR 1.0000
Epoch 1382 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8105 AR 0.9500
Epoch 1382 batch 00002: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.6408 AR 0.8500
Epoch 1382 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.9067 AR 0.9800
Epoch 1382 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7845 AR 0.9750
Epoch 1382 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.8294 AR 0.9800
Epoch 1382 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5971 AR 0.9267
Epoch 1382 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5824 AR 0.9000
Epoch 1382 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7467 AR 1.0000
Epoch 1382 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6667 AR 0.9000
Epoch 1382 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7725 AR 0.9300
Epoch 1383 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7736 AR 1.0000
Epoch 1383 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6925 AR 0.9667
Epoch 1383 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6500 AR 0.8600
Epoch 1383 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7450 AR 0.9467
Epoch 1383 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6064 AR 0.9300
Epoch 1383 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7183 AR 0.8750
Epoch 1383 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8171 AR 0.9000
Epoch 1383 batch 00008: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8764 AR 1.0000
Epoch 1383 batch 00009: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.6919 AR 0.9600
Epoch 1383 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.8417 AR 0.9750
Epoch 1384 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5400 AR 0.7467
Epoch 1384 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6893 AR 0.9550
Epoch 1384 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8164 AR 1.0000
Epoch 1384 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8267 AR 0.9750
Epoch 1384 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7228 AR 0.9800
Epoch 1384 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7083 AR 1.0000
Epoch 1384 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7548 AR 0.9800
Epoch 1384 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8617 AR 0.9750
Epoch 1384 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7488 AR 0.9000
Epoch 1384 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7689 AR 0.9800
Epoch 1385 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7633 AR 1.0000
Epoch 1385 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7502 AR 0.9000
Epoch 1385 batch 00003: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7183 AR 0.9800
Epoch 1385 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6869 AR 0.9550
Epoch 1385 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7350 AR 0.9467
Epoch 1385 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8133 AR 0.9800
Epoch 1385 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6969 AR 0.9417
Epoch 1385 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7025 AR 0.9550
Epoch 1385 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7452 AR 0.8800
Epoch 1385 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7722 AR 0.9000
Epoch 1386 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6728 AR 0.9600
Epoch 1386 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7483 AR 1.0000
Epoch 1386 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7336 AR 0.9000
Epoch 1386 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8871 AR 1.0000
Epoch 1386 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6244 AR 1.0000
Epoch 1386 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7506 AR 0.9800
Epoch 1386 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7398 AR 0.9800
Epoch 1386 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7717 AR 0.8600
Epoch 1386 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7599 AR 0.9600
Epoch 1386 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7214 AR 0.8417
Epoch 1387 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7281 AR 0.8350
Epoch 1387 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6150 AR 0.8600
Epoch 1387 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8188 AR 1.0000
Epoch 1387 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7197 AR 0.9800
Epoch 1387 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6932 AR 0.9417
Epoch 1387 batch 00006: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7038 AR 0.9500
Epoch 1387 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6550 AR 0.9467
Epoch 1387 batch 00008: Loss 0.0008 Regression loss 0.0006 Classification loss 0.0001 AP 0.7564 AR 0.9000
Epoch 1387 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7517 AR 0.8750
Epoch 1387 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8233 AR 0.9600
Epoch 1388 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7750 AR 1.0000
Epoch 1388 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8475 AR 1.0000
Epoch 1388 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6888 AR 0.8350
Epoch 1388 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7564 AR 1.0000
Epoch 1388 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7661 AR 1.0000
Epoch 1388 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7683 AR 0.9800
Epoch 1388 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6898 AR 0.9333
Epoch 1388 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7800 AR 0.9500
Epoch 1388 batch 00009: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7117 AR 0.8550
Epoch 1388 batch 00010: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7132 AR 1.0000
Epoch 1389 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7419 AR 0.9800
Epoch 1389 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7717 AR 0.8883
Epoch 1389 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.5831 AR 0.9000
Epoch 1389 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7929 AR 0.9750
Epoch 1389 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7619 AR 0.9667
Epoch 1389 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.9071 AR 1.0000
Epoch 1389 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7286 AR 0.9000
Epoch 1389 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7805 AR 1.0000
Epoch 1389 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.5583 AR 0.8150
Epoch 1389 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7880 AR 0.9500
Epoch 1390 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6994 AR 0.8800
Epoch 1390 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6758 AR 0.8133
Epoch 1390 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7625 AR 1.0000
Epoch 1390 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8543 AR 1.0000
Epoch 1390 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7783 AR 0.9800
Epoch 1390 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7589 AR 1.0000
Epoch 1390 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8083 AR 0.9050
Epoch 1390 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6505 AR 0.9000
Epoch 1390 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7886 AR 0.9550
Epoch 1390 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7814 AR 1.0000
Epoch 1391 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7400 AR 0.9550
Epoch 1391 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8014 AR 0.9467
Epoch 1391 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6547 AR 0.8750
Epoch 1391 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5830 AR 0.9217
Epoch 1391 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7600 AR 1.0000
Epoch 1391 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7506 AR 0.9750
Epoch 1391 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7705 AR 0.9800
Epoch 1391 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8214 AR 0.9600
Epoch 1391 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6950 AR 0.9000
Epoch 1391 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8417 AR 0.9000
Epoch 1392 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7000 AR 0.9000
Epoch 1392 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7700 AR 0.9800
Epoch 1392 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7831 AR 0.9800
Epoch 1392 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6735 AR 0.9217
Epoch 1392 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7348 AR 0.9000
Epoch 1392 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8119 AR 1.0000
Epoch 1392 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8731 AR 1.0000
Epoch 1392 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7189 AR 0.9667
Epoch 1392 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6393 AR 0.9600
Epoch 1392 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6892 AR 0.8300
Epoch 1393 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8033 AR 0.9417
Epoch 1393 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7258 AR 0.8800
Epoch 1393 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5582 AR 0.9000
Epoch 1393 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7583 AR 0.8750
Epoch 1393 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6283 AR 0.8850
Epoch 1393 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8229 AR 0.9800
Epoch 1393 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8050 AR 1.0000
Epoch 1393 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6500 AR 0.8467
Epoch 1393 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7338 AR 1.0000
Epoch 1393 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8171 AR 1.0000
Epoch 1394 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7302 AR 0.9500
Epoch 1394 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8364 AR 0.9300
Epoch 1394 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.5750 AR 0.9000
Epoch 1394 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7433 AR 0.9350
Epoch 1394 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7167 AR 0.8550
Epoch 1394 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8124 AR 1.0000
Epoch 1394 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8067 AR 0.9750
Epoch 1394 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7817 AR 0.9600
Epoch 1394 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6744 AR 0.9667
Epoch 1394 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7217 AR 0.9217
Epoch 1395 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6742 AR 0.9600
Epoch 1395 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6848 AR 0.9250
Epoch 1395 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7263 AR 0.9000
Epoch 1395 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8452 AR 0.9600
Epoch 1395 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7500 AR 1.0000
Epoch 1395 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7905 AR 0.9800
Epoch 1395 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7131 AR 0.9667
Epoch 1395 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8950 AR 0.9800
Epoch 1395 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6178 AR 0.8800
Epoch 1395 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6905 AR 0.8750
Epoch 1396 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6933 AR 0.8800
Epoch 1396 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7881 AR 0.9500
Epoch 1396 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7868 AR 0.9800
Epoch 1396 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8200 AR 0.9800
Epoch 1396 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7828 AR 0.9550
Epoch 1396 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7546 AR 0.9800
Epoch 1396 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6903 AR 0.9417
Epoch 1396 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5544 AR 0.8667
Epoch 1396 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7588 AR 0.9750
Epoch 1396 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8306 AR 1.0000
Epoch 1397 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8173 AR 1.0000
Epoch 1397 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6988 AR 0.9000
Epoch 1397 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6680 AR 0.9167
Epoch 1397 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8586 AR 1.0000
Epoch 1397 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7914 AR 0.9550
Epoch 1397 batch 00006: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7369 AR 0.9417
Epoch 1397 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7264 AR 1.0000
Epoch 1397 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7005 AR 0.9600
Epoch 1397 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7833 AR 1.0000
Epoch 1397 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6983 AR 0.8600
Epoch 1398 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6839 AR 0.9300
Epoch 1398 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7781 AR 0.8800
Epoch 1398 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8193 AR 0.9750
Epoch 1398 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7517 AR 0.9467
Epoch 1398 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7152 AR 0.9000
Epoch 1398 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7433 AR 0.9750
Epoch 1398 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7217 AR 0.8800
Epoch 1398 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7433 AR 0.8800
Epoch 1398 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7946 AR 1.0000
Epoch 1398 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6145 AR 1.0000
Epoch 1399 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7819 AR 1.0000
Epoch 1399 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7139 AR 0.9417
Epoch 1399 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6586 AR 0.9667
Epoch 1399 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7238 AR 0.8800
Epoch 1399 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6017 AR 0.9550
Epoch 1399 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8448 AR 1.0000
Epoch 1399 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8117 AR 0.9467
Epoch 1399 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6583 AR 0.9300
Epoch 1399 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6800 AR 0.9000
Epoch 1399 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8881 AR 0.9750
Epoch 1400 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7263 AR 0.9800
Epoch 1400 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7850 AR 1.0000
Epoch 1400 batch 00003: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8414 AR 0.9750
Epoch 1400 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8054 AR 1.0000
Epoch 1400 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7910 AR 0.9800
Epoch 1400 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7576 AR 0.9800
Epoch 1400 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7731 AR 0.8750
Epoch 1400 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6864 AR 0.9000
Epoch 1400 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7260 AR 0.9000
Epoch 1400 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5912 AR 0.8750
Epoch 1401 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6614 AR 0.9600
Epoch 1401 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7917 AR 0.9000
Epoch 1401 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8764 AR 1.0000
Epoch 1401 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8448 AR 1.0000
Epoch 1401 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6487 AR 0.8500
Epoch 1401 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6613 AR 0.9100
Epoch 1401 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7417 AR 0.8750
Epoch 1401 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8633 AR 1.0000
Epoch 1401 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6700 AR 0.9500
Epoch 1401 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6699 AR 0.9800
Epoch 1402 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6183 AR 0.8000
Epoch 1402 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7650 AR 0.9300
Epoch 1402 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6921 AR 1.0000
Epoch 1402 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6927 AR 0.9300
Epoch 1402 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8536 AR 1.0000
Epoch 1402 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8717 AR 0.9800
Epoch 1402 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7583 AR 0.9800
Epoch 1402 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.8248 AR 0.9667
Epoch 1402 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7833 AR 0.9000
Epoch 1402 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6271 AR 0.9750
Epoch 1403 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6655 AR 0.7600
Epoch 1403 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7521 AR 0.9750
Epoch 1403 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8055 AR 1.0000
Epoch 1403 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7733 AR 0.9550
Epoch 1403 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6767 AR 0.9000
Epoch 1403 batch 00006: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7433 AR 0.9400
Epoch 1403 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7744 AR 0.9667
Epoch 1403 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7683 AR 1.0000
Epoch 1403 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7452 AR 0.9300
Epoch 1403 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7398 AR 0.9750
Epoch 1404 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8417 AR 0.8800
Epoch 1404 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6814 AR 0.9667
Epoch 1404 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7727 AR 1.0000
Epoch 1404 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6863 AR 0.9667
Epoch 1404 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6543 AR 0.9000
Epoch 1404 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7287 AR 0.9100
Epoch 1404 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8814 AR 1.0000
Epoch 1404 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7771 AR 0.9750
Epoch 1404 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7400 AR 1.0000
Epoch 1404 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7008 AR 0.9100
Epoch 1405 batch 00001: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7014 AR 0.9500
Epoch 1405 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7062 AR 1.0000
Epoch 1405 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6548 AR 0.9800
Epoch 1405 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7288 AR 0.9000
Epoch 1405 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7483 AR 0.9467
Epoch 1405 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7836 AR 0.9667
Epoch 1405 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7467 AR 0.8800
Epoch 1405 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7967 AR 0.9750
Epoch 1405 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8612 AR 0.9800
Epoch 1405 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7050 AR 0.9050
Epoch 1406 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7500 AR 0.8667
Epoch 1406 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7148 AR 0.9750
Epoch 1406 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7405 AR 0.8750
Epoch 1406 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7743 AR 0.9550
Epoch 1406 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6298 AR 0.8350
Epoch 1406 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8667 AR 1.0000
Epoch 1406 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7964 AR 0.9800
Epoch 1406 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7500 AR 0.8800
Epoch 1406 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5667 AR 0.8500
Epoch 1406 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7269 AR 0.9467
Epoch 1407 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7217 AR 1.0000
Epoch 1407 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8317 AR 0.9600
Epoch 1407 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6288 AR 0.8550
Epoch 1407 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8164 AR 0.9750
Epoch 1407 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7338 AR 0.9800
Epoch 1407 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7333 AR 0.9800
Epoch 1407 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6083 AR 0.8550
Epoch 1407 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7831 AR 0.9800
Epoch 1407 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7607 AR 0.9500
Epoch 1407 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7850 AR 1.0000
Epoch 1408 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7363 AR 0.9550
Epoch 1408 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8155 AR 0.9750
Epoch 1408 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7086 AR 1.0000
Epoch 1408 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7548 AR 0.8750
Epoch 1408 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7850 AR 1.0000
Epoch 1408 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7133 AR 0.9000
Epoch 1408 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6856 AR 0.9667
Epoch 1408 batch 00008: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7348 AR 0.9300
Epoch 1408 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7052 AR 0.9667
Epoch 1408 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7406 AR 1.0000
Epoch 1409 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7083 AR 0.8800
Epoch 1409 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6131 AR 0.9000
Epoch 1409 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7209 AR 0.9550
Epoch 1409 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8098 AR 1.0000
Epoch 1409 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7250 AR 0.9167
Epoch 1409 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7996 AR 0.9600
Epoch 1409 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7750 AR 0.9000
Epoch 1409 batch 00008: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.8017 AR 0.9667
Epoch 1409 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7248 AR 0.9750
Epoch 1409 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7202 AR 0.9667
Epoch 1410 batch 00001: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8417 AR 0.9500
Epoch 1410 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7750 AR 0.8800
Epoch 1410 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6735 AR 1.0000
Epoch 1410 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7778 AR 1.0000
Epoch 1410 batch 00005: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6048 AR 0.9800
Epoch 1410 batch 00006: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.6964 AR 1.0000
Epoch 1410 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0000 AP 0.7883 AR 0.9800
Epoch 1410 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7805 AR 0.9500
Epoch 1410 batch 00009: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.7489 AR 1.0000
Epoch 1410 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7060 AR 0.8500
Epoch 1411 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7636 AR 1.0000
Epoch 1411 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7750 AR 0.8750
Epoch 1411 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8061 AR 0.9550
Epoch 1411 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8579 AR 1.0000
Epoch 1411 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6724 AR 0.9267
Epoch 1411 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6183 AR 0.9250
Epoch 1411 batch 00007: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0000 AP 0.7950 AR 0.9667
Epoch 1411 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7333 AR 0.9550
Epoch 1411 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6360 AR 1.0000
Epoch 1411 batch 00010: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0001 AP 0.6534 AR 0.8750
Epoch 1412 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6483 AR 0.9550
Epoch 1412 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6792 AR 0.8800
Epoch 1412 batch 00003: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.5953 AR 0.8000
Epoch 1412 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7088 AR 0.9800
Epoch 1412 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7458 AR 0.9600
Epoch 1412 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6519 AR 0.9250
Epoch 1412 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7955 AR 1.0000
Epoch 1412 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7986 AR 0.9417
Epoch 1412 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8250 AR 0.9750
Epoch 1412 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8100 AR 0.9467
Epoch 1413 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7596 AR 0.9667
Epoch 1413 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7679 AR 0.9500
Epoch 1413 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8121 AR 1.0000
Epoch 1413 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8839 AR 0.9750
Epoch 1413 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6661 AR 0.8800
Epoch 1413 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6720 AR 0.9750
Epoch 1413 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7100 AR 1.0000
Epoch 1413 batch 00008: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.6800 AR 0.8550
Epoch 1413 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7431 AR 0.9100
Epoch 1413 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6350 AR 0.9000
Epoch 1414 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7624 AR 0.9800
Epoch 1414 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8700 AR 0.9500
Epoch 1414 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8131 AR 1.0000
Epoch 1414 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5554 AR 0.8750
Epoch 1414 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6021 AR 0.9000
Epoch 1414 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7856 AR 0.9300
Epoch 1414 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7064 AR 0.9000
Epoch 1414 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8250 AR 1.0000
Epoch 1414 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8192 AR 1.0000
Epoch 1414 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6967 AR 0.9600
Epoch 1415 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7693 AR 0.9750
Epoch 1415 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8479 AR 1.0000
Epoch 1415 batch 00003: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.8083 AR 0.9000
Epoch 1415 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6625 AR 0.7800
Epoch 1415 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7814 AR 0.9800
Epoch 1415 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6894 AR 0.9800
Epoch 1415 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6476 AR 0.8967
Epoch 1415 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7452 AR 1.0000
Epoch 1415 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6800 AR 0.9500
Epoch 1415 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8150 AR 0.9750
Epoch 1416 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6433 AR 0.9000
Epoch 1416 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7264 AR 0.9500
Epoch 1416 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7223 AR 0.8300
Epoch 1416 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7264 AR 1.0000
Epoch 1416 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6975 AR 0.9333
Epoch 1416 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7958 AR 0.9300
Epoch 1416 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8550 AR 1.0000
Epoch 1416 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5764 AR 0.8500
Epoch 1416 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7236 AR 1.0000
Epoch 1416 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7538 AR 0.8800
Epoch 1417 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7817 AR 1.0000
Epoch 1417 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6524 AR 0.8800
Epoch 1417 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6850 AR 0.9667
Epoch 1417 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7889 AR 1.0000
Epoch 1417 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6919 AR 0.8600
Epoch 1417 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5746 AR 0.8467
Epoch 1417 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8167 AR 0.9000
Epoch 1417 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7467 AR 0.9300
Epoch 1417 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8417 AR 1.0000
Epoch 1417 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6898 AR 0.9750
Epoch 1418 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6831 AR 0.9500
Epoch 1418 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8169 AR 1.0000
Epoch 1418 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7689 AR 0.9800
Epoch 1418 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7614 AR 0.9750
Epoch 1418 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7783 AR 0.9467
Epoch 1418 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7683 AR 0.9750
Epoch 1418 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5358 AR 0.9000
Epoch 1418 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8317 AR 1.0000
Epoch 1418 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6610 AR 0.8500
Epoch 1418 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7050 AR 0.8217
Epoch 1419 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7483 AR 0.8967
Epoch 1419 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7642 AR 0.9467
Epoch 1419 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7921 AR 0.9500
Epoch 1419 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6006 AR 0.9000
Epoch 1419 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7249 AR 0.9800
Epoch 1419 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7226 AR 0.9800
Epoch 1419 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8550 AR 0.9000
Epoch 1419 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6643 AR 0.9800
Epoch 1419 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7281 AR 0.9750
Epoch 1419 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7617 AR 0.9750
Epoch 1420 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6679 AR 0.9750
Epoch 1420 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7405 AR 0.9800
Epoch 1420 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7327 AR 0.9000
Epoch 1420 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8833 AR 0.9750
Epoch 1420 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7881 AR 1.0000
Epoch 1420 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8289 AR 1.0000
Epoch 1420 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7167 AR 0.8750
Epoch 1420 batch 00008: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.7746 AR 0.9800
Epoch 1420 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.4786 AR 0.8300
Epoch 1420 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7600 AR 0.9000
Epoch 1421 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6656 AR 0.9000
Epoch 1421 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7067 AR 0.8250
Epoch 1421 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6683 AR 0.8800
Epoch 1421 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7473 AR 1.0000
Epoch 1421 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8114 AR 1.0000
Epoch 1421 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6148 AR 0.8550
Epoch 1421 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8000 AR 0.9167
Epoch 1421 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5990 AR 0.9167
Epoch 1421 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8312 AR 0.9800
Epoch 1421 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8038 AR 1.0000
Epoch 1422 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7119 AR 0.9800
Epoch 1422 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5628 AR 0.8667
Epoch 1422 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6443 AR 0.9000
Epoch 1422 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7964 AR 0.9800
Epoch 1422 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8614 AR 1.0000
Epoch 1422 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7500 AR 1.0000
Epoch 1422 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7200 AR 0.8467
Epoch 1422 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6683 AR 0.9250
Epoch 1422 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8625 AR 0.9750
Epoch 1422 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7164 AR 0.9250
Epoch 1423 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7800 AR 0.9000
Epoch 1423 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6527 AR 0.9800
Epoch 1423 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7083 AR 1.0000
Epoch 1423 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7464 AR 0.9550
Epoch 1423 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6667 AR 0.8800
Epoch 1423 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8136 AR 0.9550
Epoch 1423 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7436 AR 1.0000
Epoch 1423 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7400 AR 0.8750
Epoch 1423 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8075 AR 1.0000
Epoch 1423 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7879 AR 0.9750
Epoch 1424 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6725 AR 0.9417
Epoch 1424 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6602 AR 1.0000
Epoch 1424 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6458 AR 0.8217
Epoch 1424 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8071 AR 0.9800
Epoch 1424 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7026 AR 1.0000
Epoch 1424 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7429 AR 0.9550
Epoch 1424 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8571 AR 1.0000
Epoch 1424 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7900 AR 0.9750
Epoch 1424 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6667 AR 0.8000
Epoch 1424 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8600 AR 1.0000
Epoch 1425 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7392 AR 0.9800
Epoch 1425 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6796 AR 0.9500
Epoch 1425 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6898 AR 0.9667
Epoch 1425 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6667 AR 0.9500
Epoch 1425 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7667 AR 1.0000
Epoch 1425 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7695 AR 0.9000
Epoch 1425 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7738 AR 0.9750
Epoch 1425 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6858 AR 0.8600
Epoch 1425 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7210 AR 0.8600
Epoch 1425 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8452 AR 0.9667
Epoch 1426 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7005 AR 0.9250
Epoch 1426 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7690 AR 0.9467
Epoch 1426 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6467 AR 0.9000
Epoch 1426 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7050 AR 0.9750
Epoch 1426 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7142 AR 0.9750
Epoch 1426 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7400 AR 0.9550
Epoch 1426 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6338 AR 0.8217
Epoch 1426 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7163 AR 0.9000
Epoch 1426 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8139 AR 1.0000
Epoch 1426 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7526 AR 0.9550
Epoch 1427 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8267 AR 1.0000
Epoch 1427 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7925 AR 0.9667
Epoch 1427 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7421 AR 1.0000
Epoch 1427 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6939 AR 1.0000
Epoch 1427 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6062 AR 0.9000
Epoch 1427 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7467 AR 0.8550
Epoch 1427 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7583 AR 0.9500
Epoch 1427 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7702 AR 0.9500
Epoch 1427 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7152 AR 0.9467
Epoch 1427 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6815 AR 0.8467
Epoch 1428 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7048 AR 0.8467
Epoch 1428 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6602 AR 1.0000
Epoch 1428 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7964 AR 0.8750
Epoch 1428 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5317 AR 0.8000
Epoch 1428 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6355 AR 0.9600
Epoch 1428 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8145 AR 0.9750
Epoch 1428 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7121 AR 0.9250
Epoch 1428 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8436 AR 1.0000
Epoch 1428 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7819 AR 0.9750
Epoch 1428 batch 00010: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7117 AR 0.9550
Epoch 1429 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7998 AR 0.9800
Epoch 1429 batch 00002: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.8481 AR 0.9750
Epoch 1429 batch 00003: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7826 AR 0.9800
Epoch 1429 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6973 AR 0.9500
Epoch 1429 batch 00005: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.7588 AR 0.9750
Epoch 1429 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7231 AR 0.9500
Epoch 1429 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6356 AR 0.8500
Epoch 1429 batch 00008: Loss 0.0015 Regression loss 0.0014 Classification loss 0.0001 AP 0.6912 AR 0.9250
Epoch 1429 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.7655 AR 1.0000
Epoch 1429 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7298 AR 0.8800
Epoch 1430 batch 00001: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.8671 AR 1.0000
Epoch 1430 batch 00002: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6587 AR 0.9800
Epoch 1430 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6983 AR 0.8750
Epoch 1430 batch 00004: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7845 AR 0.9550
Epoch 1430 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8438 AR 1.0000
Epoch 1430 batch 00006: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7348 AR 0.9300
Epoch 1430 batch 00007: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.8538 AR 1.0000
Epoch 1430 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6256 AR 0.9000
Epoch 1430 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7350 AR 1.0000
Epoch 1430 batch 00010: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.5277 AR 0.8300
Epoch 1431 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7692 AR 0.9800
Epoch 1431 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7850 AR 0.8667
Epoch 1431 batch 00003: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0000 AP 0.7214 AR 0.9750
Epoch 1431 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6857 AR 0.9750
Epoch 1431 batch 00005: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.7198 AR 0.9550
Epoch 1431 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.8523 AR 1.0000
Epoch 1431 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7850 AR 0.9300
Epoch 1431 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6738 AR 0.9750
Epoch 1431 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6684 AR 0.9000
Epoch 1431 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6881 AR 0.9000
Epoch 1432 batch 00001: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6322 AR 0.9000
Epoch 1432 batch 00002: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7453 AR 0.9500
Epoch 1432 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8098 AR 0.9800
Epoch 1432 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.8052 AR 0.9550
Epoch 1432 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7567 AR 0.9800
Epoch 1432 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7712 AR 0.9750
Epoch 1432 batch 00007: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7448 AR 0.9750
Epoch 1432 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6386 AR 0.8300
Epoch 1432 batch 00009: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6383 AR 0.8750
Epoch 1432 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7580 AR 0.9750
Epoch 1433 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7500 AR 0.9750
Epoch 1433 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8200 AR 1.0000
Epoch 1433 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8083 AR 1.0000
Epoch 1433 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6896 AR 0.9750
Epoch 1433 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6169 AR 0.8800
Epoch 1433 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8100 AR 0.8750
Epoch 1433 batch 00007: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6513 AR 0.8867
Epoch 1433 batch 00008: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7606 AR 0.9300
Epoch 1433 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6625 AR 0.9000
Epoch 1433 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.7088 AR 0.9750
Epoch 1434 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7895 AR 1.0000
Epoch 1434 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7060 AR 0.9500
Epoch 1434 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7000 AR 0.8000
Epoch 1434 batch 00004: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7546 AR 0.9550
Epoch 1434 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8102 AR 0.9667
Epoch 1434 batch 00006: Loss 0.0009 Regression loss 0.0007 Classification loss 0.0001 AP 0.7364 AR 0.9800
Epoch 1434 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8029 AR 1.0000
Epoch 1434 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7492 AR 1.0000
Epoch 1434 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8148 AR 0.9750
Epoch 1434 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6693 AR 0.9800
Epoch 1435 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6481 AR 0.8500
Epoch 1435 batch 00002: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6433 AR 0.9000
Epoch 1435 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6786 AR 0.9667
Epoch 1435 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7310 AR 0.9600
Epoch 1435 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8667 AR 0.9750
Epoch 1435 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7417 AR 1.0000
Epoch 1435 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6875 AR 0.9100
Epoch 1435 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8017 AR 1.0000
Epoch 1435 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8614 AR 0.9750
Epoch 1435 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7661 AR 1.0000
Epoch 1436 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8931 AR 0.9600
Epoch 1436 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7669 AR 1.0000
Epoch 1436 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6917 AR 0.8750
Epoch 1436 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6962 AR 0.9250
Epoch 1436 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7550 AR 0.9800
Epoch 1436 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.5800 AR 0.8500
Epoch 1436 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.8276 AR 1.0000
Epoch 1436 batch 00008: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.6805 AR 0.9750
Epoch 1436 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7006 AR 1.0000
Epoch 1436 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6714 AR 0.8550
Epoch 1437 batch 00001: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6905 AR 0.9500
Epoch 1437 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7086 AR 0.8667
Epoch 1437 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.7479 AR 0.9000
Epoch 1437 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8433 AR 0.9800
Epoch 1437 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7171 AR 0.8767
Epoch 1437 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6503 AR 0.9167
Epoch 1437 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7608 AR 1.0000
Epoch 1437 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7710 AR 0.9750
Epoch 1437 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7192 AR 0.9750
Epoch 1437 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7421 AR 0.8800
Epoch 1438 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7833 AR 0.9000
Epoch 1438 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6783 AR 0.9217
Epoch 1438 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7583 AR 0.9800
Epoch 1438 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6865 AR 0.9000
Epoch 1438 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8598 AR 1.0000
Epoch 1438 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7600 AR 0.9000
Epoch 1438 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6663 AR 0.9100
Epoch 1438 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6769 AR 0.9750
Epoch 1438 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7225 AR 0.9417
Epoch 1438 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6030 AR 0.9667
Epoch 1439 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6938 AR 0.9000
Epoch 1439 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7080 AR 0.9600
Epoch 1439 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8333 AR 1.0000
Epoch 1439 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7238 AR 0.8550
Epoch 1439 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7764 AR 1.0000
Epoch 1439 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7881 AR 1.0000
Epoch 1439 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7657 AR 0.9800
Epoch 1439 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8164 AR 1.0000
Epoch 1439 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7083 AR 0.9667
Epoch 1439 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7083 AR 1.0000
Epoch 1440 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7000 AR 0.9467
Epoch 1440 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8150 AR 0.8750
Epoch 1440 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6245 AR 0.8550
Epoch 1440 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7631 AR 0.9000
Epoch 1440 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6198 AR 1.0000
Epoch 1440 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7342 AR 0.9417
Epoch 1440 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7543 AR 1.0000
Epoch 1440 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7446 AR 0.9400
Epoch 1440 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7219 AR 0.9750
Epoch 1440 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8367 AR 0.9750
Epoch 1441 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6481 AR 0.8000
Epoch 1441 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8625 AR 1.0000
Epoch 1441 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7600 AR 0.9750
Epoch 1441 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6445 AR 1.0000
Epoch 1441 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6986 AR 1.0000
Epoch 1441 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8217 AR 0.9550
Epoch 1441 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8598 AR 1.0000
Epoch 1441 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6983 AR 0.9800
Epoch 1441 batch 00009: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6352 AR 0.9050
Epoch 1441 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7488 AR 0.9467
Epoch 1442 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7217 AR 0.9800
Epoch 1442 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7392 AR 0.9300
Epoch 1442 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7952 AR 1.0000
Epoch 1442 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7631 AR 0.9000
Epoch 1442 batch 00005: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.6355 AR 1.0000
Epoch 1442 batch 00006: Loss 0.0006 Regression loss 0.0004 Classification loss 0.0001 AP 0.7683 AR 0.9300
Epoch 1442 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6602 AR 0.8333
Epoch 1442 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7850 AR 0.9800
Epoch 1442 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6802 AR 0.9350
Epoch 1442 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8133 AR 1.0000
Epoch 1443 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8167 AR 1.0000
Epoch 1443 batch 00002: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6929 AR 0.9417
Epoch 1443 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7167 AR 0.9500
Epoch 1443 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8375 AR 0.9000
Epoch 1443 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6929 AR 0.9800
Epoch 1443 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7733 AR 0.9500
Epoch 1443 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6793 AR 1.0000
Epoch 1443 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6580 AR 0.8800
Epoch 1443 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6738 AR 0.8667
Epoch 1443 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6988 AR 0.9267
Epoch 1444 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7633 AR 1.0000
Epoch 1444 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7300 AR 0.9000
Epoch 1444 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7921 AR 0.9350
Epoch 1444 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7273 AR 1.0000
Epoch 1444 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6492 AR 0.8267
Epoch 1444 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6424 AR 0.9667
Epoch 1444 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7213 AR 0.9467
Epoch 1444 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7455 AR 0.9000
Epoch 1444 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8833 AR 0.9750
Epoch 1444 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6756 AR 1.0000
Epoch 1445 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7173 AR 0.9000
Epoch 1445 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8667 AR 0.9750
Epoch 1445 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6411 AR 0.9800
Epoch 1445 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7171 AR 1.0000
Epoch 1445 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7881 AR 1.0000
Epoch 1445 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6850 AR 1.0000
Epoch 1445 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8333 AR 0.9800
Epoch 1445 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6350 AR 0.8550
Epoch 1445 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7014 AR 0.9417
Epoch 1445 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7425 AR 0.8600
Epoch 1446 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7281 AR 0.9800
Epoch 1446 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7256 AR 0.9800
Epoch 1446 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7300 AR 0.9750
Epoch 1446 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7788 AR 0.9800
Epoch 1446 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8026 AR 1.0000
Epoch 1446 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7376 AR 1.0000
Epoch 1446 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7264 AR 1.0000
Epoch 1446 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7500 AR 0.8800
Epoch 1446 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7267 AR 0.9133
Epoch 1446 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6950 AR 0.8750
Epoch 1447 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7342 AR 0.9500
Epoch 1447 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6463 AR 0.9667
Epoch 1447 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7781 AR 0.9800
Epoch 1447 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7271 AR 1.0000
Epoch 1447 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7555 AR 1.0000
Epoch 1447 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6208 AR 0.8667
Epoch 1447 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7800 AR 0.9750
Epoch 1447 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8179 AR 0.8750
Epoch 1447 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8183 AR 0.9350
Epoch 1447 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6358 AR 0.9150
Epoch 1448 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7167 AR 0.9800
Epoch 1448 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7567 AR 0.9500
Epoch 1448 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7889 AR 1.0000
Epoch 1448 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6771 AR 0.9500
Epoch 1448 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6938 AR 1.0000
Epoch 1448 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7383 AR 0.9050
Epoch 1448 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8655 AR 0.9800
Epoch 1448 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6148 AR 0.9000
Epoch 1448 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8245 AR 0.9550
Epoch 1448 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6613 AR 0.8800
Epoch 1449 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7083 AR 0.8800
Epoch 1449 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7650 AR 0.9217
Epoch 1449 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6255 AR 1.0000
Epoch 1449 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7308 AR 1.0000
Epoch 1449 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6333 AR 0.9750
Epoch 1449 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7100 AR 0.8500
Epoch 1449 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8264 AR 0.9750
Epoch 1449 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7664 AR 0.9350
Epoch 1449 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7361 AR 0.9667
Epoch 1449 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7717 AR 1.0000
Epoch 1450 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7731 AR 1.0000
Epoch 1450 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6814 AR 0.9500
Epoch 1450 batch 00003: Loss 0.0005 Regression loss 0.0003 Classification loss 0.0001 AP 0.8131 AR 0.9600
Epoch 1450 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7033 AR 0.9417
Epoch 1450 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7113 AR 1.0000
Epoch 1450 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7488 AR 0.9550
Epoch 1450 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7631 AR 1.0000
Epoch 1450 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8298 AR 1.0000
Epoch 1450 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7342 AR 1.0000
Epoch 1450 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6317 AR 0.7750
Epoch 1451 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7369 AR 1.0000
Epoch 1451 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7650 AR 1.0000
Epoch 1451 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7717 AR 0.9000
Epoch 1451 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7844 AR 0.9667
Epoch 1451 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6871 AR 0.8750
Epoch 1451 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7858 AR 1.0000
Epoch 1451 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6667 AR 0.9800
Epoch 1451 batch 00008: Loss 0.0007 Regression loss 0.0005 Classification loss 0.0001 AP 0.8200 AR 0.9600
Epoch 1451 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7737 AR 0.9750
Epoch 1451 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7286 AR 0.9500
Epoch 1452 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8383 AR 1.0000
Epoch 1452 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6456 AR 0.9000
Epoch 1452 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7267 AR 0.8500
Epoch 1452 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6850 AR 0.9800
Epoch 1452 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6538 AR 0.8667
Epoch 1452 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8525 AR 0.9800
Epoch 1452 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7798 AR 0.9750
Epoch 1452 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6905 AR 0.9350
Epoch 1452 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6865 AR 1.0000
Epoch 1452 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7168 AR 0.9217
Epoch 1453 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7238 AR 1.0000
Epoch 1453 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7354 AR 0.9467
Epoch 1453 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6723 AR 0.9600
Epoch 1453 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7195 AR 0.9750
Epoch 1453 batch 00005: Loss 0.0005 Regression loss 0.0003 Classification loss 0.0001 AP 0.7221 AR 0.9467
Epoch 1453 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7600 AR 0.8250
Epoch 1453 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8933 AR 1.0000
Epoch 1453 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7000 AR 0.8667
Epoch 1453 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7883 AR 0.9600
Epoch 1453 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6649 AR 0.9750
Epoch 1454 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6789 AR 0.9500
Epoch 1454 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6687 AR 0.9600
Epoch 1454 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7267 AR 0.8667
Epoch 1454 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7500 AR 0.8750
Epoch 1454 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7336 AR 1.0000
Epoch 1454 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7288 AR 0.9800
Epoch 1454 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7742 AR 0.9800
Epoch 1454 batch 00008: Loss 0.0005 Regression loss 0.0003 Classification loss 0.0001 AP 0.6586 AR 0.9467
Epoch 1454 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7383 AR 0.9350
Epoch 1454 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7508 AR 0.9750
Epoch 1455 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7869 AR 1.0000
Epoch 1455 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.9183 AR 1.0000
Epoch 1455 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6552 AR 0.8217
Epoch 1455 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7517 AR 0.9800
Epoch 1455 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5597 AR 0.8267
Epoch 1455 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6067 AR 0.8500
Epoch 1455 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7244 AR 1.0000
Epoch 1455 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7804 AR 1.0000
Epoch 1455 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6755 AR 0.9500
Epoch 1455 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.9050 AR 1.0000
Epoch 1456 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8333 AR 1.0000
Epoch 1456 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6964 AR 0.9500
Epoch 1456 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7481 AR 1.0000
Epoch 1456 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5550 AR 0.7500
Epoch 1456 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8573 AR 0.9750
Epoch 1456 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6881 AR 0.9550
Epoch 1456 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6871 AR 0.8800
Epoch 1456 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8217 AR 0.9800
Epoch 1456 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7183 AR 0.9250
Epoch 1456 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6485 AR 0.9600
Epoch 1457 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7514 AR 0.8667
Epoch 1457 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7038 AR 0.9600
Epoch 1457 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7464 AR 0.9000
Epoch 1457 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6742 AR 0.9550
Epoch 1457 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6742 AR 1.0000
Epoch 1457 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7758 AR 0.9667
Epoch 1457 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7349 AR 0.9800
Epoch 1457 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7338 AR 0.9750
Epoch 1457 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8131 AR 0.9667
Epoch 1457 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7500 AR 0.9800
Epoch 1458 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7154 AR 0.9467
Epoch 1458 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6869 AR 1.0000
Epoch 1458 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.9333 AR 0.9800
Epoch 1458 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6883 AR 0.9750
Epoch 1458 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5105 AR 0.7167
Epoch 1458 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6881 AR 0.9500
Epoch 1458 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8122 AR 0.9750
Epoch 1458 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6842 AR 0.9600
Epoch 1458 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8086 AR 1.0000
Epoch 1458 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7083 AR 0.8433
Epoch 1459 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7014 AR 0.9600
Epoch 1459 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7719 AR 0.9550
Epoch 1459 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7700 AR 0.9550
Epoch 1459 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6262 AR 0.8667
Epoch 1459 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7767 AR 0.9800
Epoch 1459 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6256 AR 0.8550
Epoch 1459 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7683 AR 1.0000
Epoch 1459 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7533 AR 0.9800
Epoch 1459 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8056 AR 1.0000
Epoch 1459 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7814 AR 0.9550
Epoch 1460 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8517 AR 0.9800
Epoch 1460 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7848 AR 0.9750
Epoch 1460 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6105 AR 0.8267
Epoch 1460 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8393 AR 1.0000
Epoch 1460 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8548 AR 1.0000
Epoch 1460 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6600 AR 0.9000
Epoch 1460 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5767 AR 0.7800
Epoch 1460 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5752 AR 0.9417
Epoch 1460 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7189 AR 0.9100
Epoch 1460 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7881 AR 0.9500
Epoch 1461 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6821 AR 0.8600
Epoch 1461 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7583 AR 0.9800
Epoch 1461 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6325 AR 0.8500
Epoch 1461 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6310 AR 0.9667
Epoch 1461 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8681 AR 1.0000
Epoch 1461 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7945 AR 1.0000
Epoch 1461 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7350 AR 0.9467
Epoch 1461 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6768 AR 0.9000
Epoch 1461 batch 00009: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8417 AR 0.9500
Epoch 1461 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7150 AR 0.9800
Epoch 1462 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7905 AR 1.0000
Epoch 1462 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7268 AR 1.0000
Epoch 1462 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8183 AR 0.9550
Epoch 1462 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7393 AR 0.9750
Epoch 1462 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7892 AR 0.9800
Epoch 1462 batch 00006: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.5398 AR 0.9000
Epoch 1462 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7117 AR 0.8917
Epoch 1462 batch 00008: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6558 AR 0.8300
Epoch 1462 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.8048 AR 1.0000
Epoch 1462 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.8219 AR 0.9667
Epoch 1463 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7917 AR 0.9667
Epoch 1463 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7567 AR 0.9550
Epoch 1463 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7155 AR 1.0000
Epoch 1463 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7750 AR 0.9300
Epoch 1463 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8094 AR 1.0000
Epoch 1463 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6217 AR 0.9000
Epoch 1463 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6839 AR 0.8167
Epoch 1463 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6671 AR 0.9350
Epoch 1463 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7362 AR 0.9500
Epoch 1463 batch 00010: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.7771 AR 0.9800
Epoch 1464 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7381 AR 0.9300
Epoch 1464 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.8538 AR 0.9750
Epoch 1464 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7375 AR 0.9300
Epoch 1464 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7888 AR 1.0000
Epoch 1464 batch 00005: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7020 AR 1.0000
Epoch 1464 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6262 AR 0.8550
Epoch 1464 batch 00007: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7778 AR 0.9500
Epoch 1464 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8017 AR 0.9550
Epoch 1464 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6607 AR 0.9300
Epoch 1464 batch 00010: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6648 AR 0.9800
Epoch 1465 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7226 AR 0.9550
Epoch 1465 batch 00002: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6720 AR 0.9300
Epoch 1465 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6881 AR 0.9000
Epoch 1465 batch 00004: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.7667 AR 0.8800
Epoch 1465 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.6198 AR 0.8750
Epoch 1465 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7981 AR 1.0000
Epoch 1465 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7967 AR 0.9750
Epoch 1465 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7226 AR 0.9417
Epoch 1465 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8667 AR 1.0000
Epoch 1465 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6386 AR 0.9300
Epoch 1466 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8095 AR 0.9750
Epoch 1466 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7321 AR 1.0000
Epoch 1466 batch 00003: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7481 AR 0.8800
Epoch 1466 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7689 AR 0.9750
Epoch 1466 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7700 AR 0.9000
Epoch 1466 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6614 AR 1.0000
Epoch 1466 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7369 AR 0.9500
Epoch 1466 batch 00008: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7183 AR 0.9800
Epoch 1466 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.8583 AR 1.0000
Epoch 1466 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.6449 AR 0.8500
Epoch 1467 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7000 AR 0.9417
Epoch 1467 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7092 AR 0.9550
Epoch 1467 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7431 AR 0.9467
Epoch 1467 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7239 AR 0.9300
Epoch 1467 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8600 AR 1.0000
Epoch 1467 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7452 AR 0.9500
Epoch 1467 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7055 AR 0.9600
Epoch 1467 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8217 AR 0.9750
Epoch 1467 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7022 AR 1.0000
Epoch 1467 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7693 AR 1.0000
Epoch 1468 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7608 AR 0.9550
Epoch 1468 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7792 AR 0.9750
Epoch 1468 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7074 AR 0.9267
Epoch 1468 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8200 AR 1.0000
Epoch 1468 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6914 AR 0.9000
Epoch 1468 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6254 AR 0.9400
Epoch 1468 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7948 AR 0.9550
Epoch 1468 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7111 AR 0.8750
Epoch 1468 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6099 AR 0.9250
Epoch 1468 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7617 AR 0.9667
Epoch 1469 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6869 AR 0.8750
Epoch 1469 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7977 AR 1.0000
Epoch 1469 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.6583 AR 1.0000
Epoch 1469 batch 00004: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6917 AR 0.9467
Epoch 1469 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7808 AR 0.9550
Epoch 1469 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8014 AR 0.9800
Epoch 1469 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7481 AR 1.0000
Epoch 1469 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7198 AR 0.9000
Epoch 1469 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7286 AR 0.8917
Epoch 1469 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7400 AR 1.0000
Epoch 1470 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7310 AR 1.0000
Epoch 1470 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8436 AR 0.9550
Epoch 1470 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7470 AR 1.0000
Epoch 1470 batch 00004: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7071 AR 0.9300
Epoch 1470 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6533 AR 0.9167
Epoch 1470 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7648 AR 0.9550
Epoch 1470 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7950 AR 1.0000
Epoch 1470 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8733 AR 0.9750
Epoch 1470 batch 00009: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.5696 AR 0.9100
Epoch 1470 batch 00010: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7417 AR 0.8417
Epoch 1471 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7429 AR 1.0000
Epoch 1471 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7913 AR 0.9800
Epoch 1471 batch 00003: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.6731 AR 0.8750
Epoch 1471 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8033 AR 0.9750
Epoch 1471 batch 00005: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.6889 AR 0.9750
Epoch 1471 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7517 AR 1.0000
Epoch 1471 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8288 AR 0.9800
Epoch 1471 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6144 AR 0.9000
Epoch 1471 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7060 AR 0.9400
Epoch 1471 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7661 AR 0.8750
Epoch 1472 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7288 AR 0.9800
Epoch 1472 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7664 AR 0.9550
Epoch 1472 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6983 AR 0.9800
Epoch 1472 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7619 AR 0.9300
Epoch 1472 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6488 AR 0.8750
Epoch 1472 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7785 AR 0.9550
Epoch 1472 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7160 AR 0.9750
Epoch 1472 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.6683 AR 0.9000
Epoch 1472 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8083 AR 0.9750
Epoch 1472 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8389 AR 0.9550
Epoch 1473 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6631 AR 0.9000
Epoch 1473 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6817 AR 0.8550
Epoch 1473 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8302 AR 0.9750
Epoch 1473 batch 00004: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7394 AR 0.9750
Epoch 1473 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7333 AR 0.9800
Epoch 1473 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6067 AR 0.7750
Epoch 1473 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7583 AR 1.0000
Epoch 1473 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7804 AR 0.9500
Epoch 1473 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7555 AR 1.0000
Epoch 1473 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6694 AR 0.9350
Epoch 1474 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6594 AR 0.9300
Epoch 1474 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7810 AR 0.9800
Epoch 1474 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6937 AR 0.9667
Epoch 1474 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7100 AR 0.9000
Epoch 1474 batch 00005: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7578 AR 0.9800
Epoch 1474 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7988 AR 0.9550
Epoch 1474 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7792 AR 1.0000
Epoch 1474 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0000 AP 0.6667 AR 0.8800
Epoch 1474 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7762 AR 0.9750
Epoch 1474 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6333 AR 0.8417
Epoch 1475 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7005 AR 0.9000
Epoch 1475 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6583 AR 0.8350
Epoch 1475 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6945 AR 1.0000
Epoch 1475 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7508 AR 0.9750
Epoch 1475 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7260 AR 0.9750
Epoch 1475 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5800 AR 0.7917
Epoch 1475 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8064 AR 1.0000
Epoch 1475 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7089 AR 0.9800
Epoch 1475 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7927 AR 0.9800
Epoch 1475 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7773 AR 1.0000
Epoch 1476 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7067 AR 1.0000
Epoch 1476 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.7800 AR 0.9500
Epoch 1476 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7079 AR 0.8550
Epoch 1476 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7705 AR 1.0000
Epoch 1476 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7071 AR 1.0000
Epoch 1476 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8325 AR 1.0000
Epoch 1476 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5838 AR 0.8150
Epoch 1476 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8333 AR 0.9500
Epoch 1476 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8205 AR 0.9800
Epoch 1476 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7643 AR 1.0000
Epoch 1477 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8150 AR 0.9750
Epoch 1477 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7981 AR 1.0000
Epoch 1477 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7088 AR 0.9750
Epoch 1477 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6871 AR 0.9300
Epoch 1477 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7121 AR 0.9600
Epoch 1477 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7021 AR 0.9500
Epoch 1477 batch 00007: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7475 AR 0.9500
Epoch 1477 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.9000 AR 0.9800
Epoch 1477 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7469 AR 0.9500
Epoch 1477 batch 00010: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.6006 AR 0.9000
Epoch 1478 batch 00001: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7238 AR 0.9800
Epoch 1478 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7142 AR 0.8800
Epoch 1478 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7488 AR 1.0000
Epoch 1478 batch 00004: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.8025 AR 0.9500
Epoch 1478 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7638 AR 0.9467
Epoch 1478 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7481 AR 0.9800
Epoch 1478 batch 00007: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0001 AP 0.6964 AR 0.9000
Epoch 1478 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7417 AR 0.9550
Epoch 1478 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7067 AR 0.9500
Epoch 1478 batch 00010: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.7600 AR 0.9300
Epoch 1479 batch 00001: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.6395 AR 1.0000
Epoch 1479 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6369 AR 0.8300
Epoch 1479 batch 00003: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8029 AR 0.9500
Epoch 1479 batch 00004: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0000 AP 0.6883 AR 0.9350
Epoch 1479 batch 00005: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7833 AR 0.9750
Epoch 1479 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7350 AR 1.0000
Epoch 1479 batch 00007: Loss 0.0011 Regression loss 0.0011 Classification loss 0.0000 AP 0.6952 AR 0.9250
Epoch 1479 batch 00008: Loss 0.0012 Regression loss 0.0012 Classification loss 0.0001 AP 0.8127 AR 0.9600
Epoch 1479 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7477 AR 1.0000
Epoch 1479 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.6933 AR 0.8500
Epoch 1480 batch 00001: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7702 AR 0.9750
Epoch 1480 batch 00002: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6033 AR 0.9800
Epoch 1480 batch 00003: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0000 AP 0.7850 AR 1.0000
Epoch 1480 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7667 AR 0.9550
Epoch 1480 batch 00005: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0001 AP 0.7237 AR 1.0000
Epoch 1480 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7029 AR 1.0000
Epoch 1480 batch 00007: Loss 0.0013 Regression loss 0.0012 Classification loss 0.0001 AP 0.7650 AR 0.9300
Epoch 1480 batch 00008: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.7083 AR 0.8550
Epoch 1480 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.8836 AR 1.0000
Epoch 1480 batch 00010: Loss 0.0014 Regression loss 0.0013 Classification loss 0.0001 AP 0.7558 AR 0.9500
Epoch 1481 batch 00001: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7945 AR 1.0000
Epoch 1481 batch 00002: Loss 0.0010 Regression loss 0.0010 Classification loss 0.0001 AP 0.6821 AR 0.9400
Epoch 1481 batch 00003: Loss 0.0015 Regression loss 0.0015 Classification loss 0.0000 AP 0.6531 AR 0.9000
Epoch 1481 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7506 AR 0.9750
Epoch 1481 batch 00005: Loss 0.0016 Regression loss 0.0015 Classification loss 0.0001 AP 0.6989 AR 0.9000
Epoch 1481 batch 00006: Loss 0.0017 Regression loss 0.0016 Classification loss 0.0000 AP 0.7967 AR 1.0000
Epoch 1481 batch 00007: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.7325 AR 0.9300
Epoch 1481 batch 00008: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.6876 AR 0.9417
Epoch 1481 batch 00009: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.7705 AR 0.9800
Epoch 1481 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7517 AR 1.0000
Epoch 1482 batch 00001: Loss 0.0009 Regression loss 0.0009 Classification loss 0.0000 AP 0.8064 AR 1.0000
Epoch 1482 batch 00002: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.6317 AR 0.9667
Epoch 1482 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7533 AR 0.9750
Epoch 1482 batch 00004: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7510 AR 0.9550
Epoch 1482 batch 00005: Loss 0.0009 Regression loss 0.0008 Classification loss 0.0001 AP 0.8064 AR 1.0000
Epoch 1482 batch 00006: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.5550 AR 0.7500
Epoch 1482 batch 00007: Loss 0.0012 Regression loss 0.0011 Classification loss 0.0001 AP 0.5972 AR 0.9000
Epoch 1482 batch 00008: Loss 0.0007 Regression loss 0.0006 Classification loss 0.0001 AP 0.8162 AR 0.9800
Epoch 1482 batch 00009: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0000 AP 0.8931 AR 0.9800
Epoch 1482 batch 00010: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.7236 AR 0.9500
Epoch 1483 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.7156 AR 0.9000
Epoch 1483 batch 00002: Loss 0.0007 Regression loss 0.0007 Classification loss 0.0001 AP 0.9050 AR 0.9550
Epoch 1483 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7079 AR 0.9750
Epoch 1483 batch 00004: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0000 AP 0.6152 AR 0.8750
Epoch 1483 batch 00005: Loss 0.0010 Regression loss 0.0009 Classification loss 0.0001 AP 0.8064 AR 1.0000
Epoch 1483 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6758 AR 0.9550
Epoch 1483 batch 00007: Loss 0.0008 Regression loss 0.0008 Classification loss 0.0000 AP 0.7437 AR 1.0000
Epoch 1483 batch 00008: Loss 0.0011 Regression loss 0.0010 Classification loss 0.0001 AP 0.7246 AR 0.9350
Epoch 1483 batch 00009: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6860 AR 0.9800
Epoch 1483 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8500 AR 0.9750
Epoch 1484 batch 00001: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8006 AR 1.0000
Epoch 1484 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8028 AR 0.9550
Epoch 1484 batch 00003: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0001 AP 0.8000 AR 0.9550
Epoch 1484 batch 00004: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.6286 AR 0.9750
Epoch 1484 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7923 AR 1.0000
Epoch 1484 batch 00006: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.6817 AR 0.8800
Epoch 1484 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.7363 AR 0.9667
Epoch 1484 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7669 AR 0.9600
Epoch 1484 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8167 AR 0.9550
Epoch 1484 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6105 AR 0.9500
Epoch 1485 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.5588 AR 0.8800
Epoch 1485 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8517 AR 1.0000
Epoch 1485 batch 00003: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7592 AR 1.0000
Epoch 1485 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7275 AR 0.9800
Epoch 1485 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8317 AR 0.9750
Epoch 1485 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6289 AR 0.8500
Epoch 1485 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8631 AR 0.9750
Epoch 1485 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7016 AR 0.9167
Epoch 1485 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6417 AR 0.8800
Epoch 1485 batch 00010: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7755 AR 0.9550
Epoch 1486 batch 00001: Loss 0.0008 Regression loss 0.0007 Classification loss 0.0001 AP 0.5718 AR 0.8467
Epoch 1486 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7839 AR 0.9300
Epoch 1486 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7783 AR 1.0000
Epoch 1486 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8500 AR 0.9750
Epoch 1486 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8617 AR 0.9750
Epoch 1486 batch 00006: Loss 0.0006 Regression loss 0.0006 Classification loss 0.0000 AP 0.5471 AR 1.0000
Epoch 1486 batch 00007: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0000 AP 0.7088 AR 0.9750
Epoch 1486 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7667 AR 0.9667
Epoch 1486 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7883 AR 1.0000
Epoch 1486 batch 00010: Loss 0.0006 Regression loss 0.0004 Classification loss 0.0001 AP 0.7895 AR 0.8800
Epoch 1487 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7088 AR 0.9250
Epoch 1487 batch 00002: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6917 AR 0.9800
Epoch 1487 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8183 AR 1.0000
Epoch 1487 batch 00004: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.5830 AR 0.7350
Epoch 1487 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6548 AR 0.9000
Epoch 1487 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7871 AR 0.9667
Epoch 1487 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8186 AR 0.9800
Epoch 1487 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7731 AR 0.9750
Epoch 1487 batch 00009: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7005 AR 0.8667
Epoch 1487 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6900 AR 0.9600
Epoch 1488 batch 00001: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6867 AR 0.9600
Epoch 1488 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7967 AR 0.9750
Epoch 1488 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6821 AR 0.9300
Epoch 1488 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7356 AR 1.0000
Epoch 1488 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7138 AR 0.8750
Epoch 1488 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7898 AR 1.0000
Epoch 1488 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7314 AR 0.8550
Epoch 1488 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7417 AR 1.0000
Epoch 1488 batch 00009: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8044 AR 0.9800
Epoch 1488 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7131 AR 1.0000
Epoch 1489 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8076 AR 0.9800
Epoch 1489 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7898 AR 1.0000
Epoch 1489 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.6481 AR 0.9550
Epoch 1489 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6083 AR 0.9417
Epoch 1489 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7119 AR 0.9400
Epoch 1489 batch 00006: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8217 AR 0.9750
Epoch 1489 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7822 AR 0.9500
Epoch 1489 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7833 AR 1.0000
Epoch 1489 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7598 AR 0.9000
Epoch 1489 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6314 AR 0.8000
Epoch 1490 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7679 AR 1.0000
Epoch 1490 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6755 AR 0.9000
Epoch 1490 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8288 AR 1.0000
Epoch 1490 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7014 AR 0.9600
Epoch 1490 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7555 AR 0.8517
Epoch 1490 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6542 AR 0.9800
Epoch 1490 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7000 AR 0.9250
Epoch 1490 batch 00008: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7375 AR 0.9000
Epoch 1490 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7364 AR 0.9500
Epoch 1490 batch 00010: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7719 AR 0.9800
Epoch 1491 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7445 AR 1.0000
Epoch 1491 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7908 AR 1.0000
Epoch 1491 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7258 AR 0.9300
Epoch 1491 batch 00004: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.8283 AR 0.9550
Epoch 1491 batch 00005: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.8383 AR 1.0000
Epoch 1491 batch 00006: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7238 AR 0.9000
Epoch 1491 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.8498 AR 0.9750
Epoch 1491 batch 00008: Loss 0.0006 Regression loss 0.0005 Classification loss 0.0001 AP 0.7905 AR 0.9800
Epoch 1491 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.5543 AR 0.8550
Epoch 1491 batch 00010: Loss 0.0005 Regression loss 0.0005 Classification loss 0.0001 AP 0.6500 AR 0.9667
Epoch 1492 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7645 AR 0.9550
Epoch 1492 batch 00002: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7405 AR 1.0000
Epoch 1492 batch 00003: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8833 AR 0.9750
Epoch 1492 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.8550 AR 1.0000
Epoch 1492 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7181 AR 0.9800
Epoch 1492 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7372 AR 0.9750
Epoch 1492 batch 00007: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0000 AP 0.7040 AR 0.9500
Epoch 1492 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7483 AR 0.9467
Epoch 1492 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6981 AR 0.8750
Epoch 1492 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5248 AR 0.8300
Epoch 1493 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6429 AR 0.9750
Epoch 1493 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7417 AR 1.0000
Epoch 1493 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6167 AR 0.8500
Epoch 1493 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7033 AR 0.9600
Epoch 1493 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7714 AR 0.9800
Epoch 1493 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7900 AR 0.9750
Epoch 1493 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8633 AR 0.9800
Epoch 1493 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7893 AR 0.9550
Epoch 1493 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7788 AR 0.9000
Epoch 1493 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7119 AR 0.9800
Epoch 1494 batch 00001: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.6952 AR 0.8550
Epoch 1494 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8108 AR 0.9800
Epoch 1494 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7314 AR 1.0000
Epoch 1494 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7907 AR 1.0000
Epoch 1494 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8048 AR 0.9800
Epoch 1494 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6542 AR 0.9250
Epoch 1494 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8271 AR 0.9500
Epoch 1494 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6844 AR 0.9750
Epoch 1494 batch 00009: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.5767 AR 0.9000
Epoch 1494 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8131 AR 0.9667
Epoch 1495 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.6458 AR 0.8500
Epoch 1495 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6220 AR 0.9550
Epoch 1495 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8417 AR 0.9500
Epoch 1495 batch 00004: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8471 AR 1.0000
Epoch 1495 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7196 AR 0.9550
Epoch 1495 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6575 AR 0.8567
Epoch 1495 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7121 AR 0.9000
Epoch 1495 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6627 AR 0.9800
Epoch 1495 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8133 AR 1.0000
Epoch 1495 batch 00010: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.8150 AR 1.0000
Epoch 1496 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8071 AR 0.8667
Epoch 1496 batch 00002: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7371 AR 0.9000
Epoch 1496 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7900 AR 0.9750
Epoch 1496 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7298 AR 0.9050
Epoch 1496 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6812 AR 0.9000
Epoch 1496 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6929 AR 0.8750
Epoch 1496 batch 00007: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0000 AP 0.6687 AR 0.9800
Epoch 1496 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.6963 AR 0.9300
Epoch 1496 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6583 AR 0.9100
Epoch 1496 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6686 AR 1.0000
Epoch 1497 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7292 AR 0.9800
Epoch 1497 batch 00002: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0000 AP 0.7556 AR 1.0000
Epoch 1497 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5958 AR 0.9250
Epoch 1497 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8150 AR 0.9000
Epoch 1497 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6731 AR 0.8800
Epoch 1497 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7433 AR 0.9500
Epoch 1497 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7536 AR 0.9800
Epoch 1497 batch 00008: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7424 AR 1.0000
Epoch 1497 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7798 AR 1.0000
Epoch 1497 batch 00010: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8217 AR 0.8600
Epoch 1498 batch 00001: Loss 0.0003 Regression loss 0.0002 Classification loss 0.0001 AP 0.8614 AR 0.9800
Epoch 1498 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6722 AR 0.8750
Epoch 1498 batch 00003: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7878 AR 1.0000
Epoch 1498 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8467 AR 1.0000
Epoch 1498 batch 00005: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7858 AR 0.9667
Epoch 1498 batch 00006: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7371 AR 0.9600
Epoch 1498 batch 00007: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7438 AR 0.9550
Epoch 1498 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.5921 AR 0.8550
Epoch 1498 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6631 AR 0.9500
Epoch 1498 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.8048 AR 0.9750
Epoch 1499 batch 00001: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7111 AR 0.8317
Epoch 1499 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6258 AR 0.9300
Epoch 1499 batch 00003: Loss 0.0005 Regression loss 0.0004 Classification loss 0.0001 AP 0.7167 AR 0.9000
Epoch 1499 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7150 AR 0.9000
Epoch 1499 batch 00005: Loss 0.0004 Regression loss 0.0004 Classification loss 0.0001 AP 0.7370 AR 0.9750
Epoch 1499 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7500 AR 0.9550
Epoch 1499 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7000 AR 0.9500
Epoch 1499 batch 00008: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.6771 AR 0.9000
Epoch 1499 batch 00009: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7883 AR 0.9750
Epoch 1499 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7782 AR 0.9600
Epoch 1500 batch 00001: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.8139 AR 0.9500
Epoch 1500 batch 00002: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.5707 AR 0.9000
Epoch 1500 batch 00003: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8131 AR 1.0000
Epoch 1500 batch 00004: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0001 AP 0.7173 AR 0.9750
Epoch 1500 batch 00005: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.8530 AR 0.9800
Epoch 1500 batch 00006: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.7008 AR 0.9300
Epoch 1500 batch 00007: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7833 AR 1.0000
Epoch 1500 batch 00008: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0000 AP 0.7026 AR 0.9500
Epoch 1500 batch 00009: Loss 0.0004 Regression loss 0.0003 Classification loss 0.0001 AP 0.6914 AR 0.9000
Epoch 1500 batch 00010: Loss 0.0003 Regression loss 0.0003 Classification loss 0.0000 AP 0.7167 AR 0.8550
