Epoch 001 batch 00001: Loss 51.0728 Regression loss 0.6168 Classification loss 50.4560 AP 0.0000 AR 0.0000
Epoch 001 batch 00002: Loss 57.7873 Regression loss 0.4551 Classification loss 57.3322 AP 0.0000 AR 0.0000
Epoch 001 batch 00003: Loss 63.9553 Regression loss 0.3020 Classification loss 63.6533 AP 0.0000 AR 0.0000
Epoch 001 batch 00004: Loss 51.0192 Regression loss 0.2149 Classification loss 50.8043 AP 0.0000 AR 0.0000
Epoch 001 batch 00005: Loss 42.7986 Regression loss 0.1899 Classification loss 42.6087 AP 0.0007 AR 0.0250
Epoch 001 batch 00006: Loss 33.5617 Regression loss 0.1688 Classification loss 33.3929 AP 0.0000 AR 0.0000
Epoch 001 batch 00007: Loss 42.4993 Regression loss 0.1727 Classification loss 42.3266 AP 0.0000 AR 0.0000
Epoch 001 batch 00008: Loss 35.8370 Regression loss 0.1862 Classification loss 35.6508 AP 0.0000 AR 0.0000
Epoch 001 batch 00009: Loss 32.0859 Regression loss 0.2170 Classification loss 31.8689 AP 0.0000 AR 0.0000
Epoch 001 batch 00010: Loss 25.3141 Regression loss 0.2617 Classification loss 25.0524 AP 0.0000 AR 0.0000
Epoch 002 batch 00001: Loss 29.5798 Regression loss 0.3539 Classification loss 29.2259 AP 0.0000 AR 0.0000
Epoch 002 batch 00002: Loss 16.1594 Regression loss 0.4389 Classification loss 15.7205 AP 0.0000 AR 0.0000
Epoch 002 batch 00003: Loss 12.5818 Regression loss 0.4997 Classification loss 12.0821 AP 0.0000 AR 0.0000
Epoch 002 batch 00004: Loss 5.8004 Regression loss 0.6333 Classification loss 5.1671 AP 0.0000 AR 0.0000
Epoch 002 batch 00005: Loss 5.4236 Regression loss 0.7224 Classification loss 4.7013 AP 0.0000 AR 0.0000
Epoch 002 batch 00006: Loss 4.4064 Regression loss 0.7605 Classification loss 3.6459 AP 0.0000 AR 0.0000
Epoch 002 batch 00007: Loss 3.6645 Regression loss 0.8022 Classification loss 2.8623 AP 0.0000 AR 0.0000
Epoch 002 batch 00008: Loss 3.9164 Regression loss 0.7774 Classification loss 3.1390 AP 1.0000 AR 0.0000
Epoch 002 batch 00009: Loss 4.7887 Regression loss 0.7574 Classification loss 4.0313 AP 1.0000 AR 0.0000
Epoch 002 batch 00010: Loss 4.6992 Regression loss 0.7000 Classification loss 3.9992 AP 1.0000 AR 0.0000
Epoch 003 batch 00001: Loss 4.7462 Regression loss 0.6752 Classification loss 4.0710 AP 1.0000 AR 0.0000
Epoch 003 batch 00002: Loss 5.4716 Regression loss 0.6256 Classification loss 4.8461 AP 1.0000 AR 0.0000
Epoch 003 batch 00003: Loss 5.5960 Regression loss 0.5218 Classification loss 5.0742 AP 1.0000 AR 0.0000
Epoch 003 batch 00004: Loss 5.3003 Regression loss 0.4001 Classification loss 4.9002 AP 1.0000 AR 0.0000
Epoch 003 batch 00005: Loss 5.0429 Regression loss 0.2530 Classification loss 4.7899 AP 1.0000 AR 0.0000
Epoch 003 batch 00006: Loss 5.7259 Regression loss 0.1259 Classification loss 5.6000 AP 1.0000 AR 0.0000
Epoch 003 batch 00007: Loss 5.3961 Regression loss 0.0942 Classification loss 5.3019 AP 1.0000 AR 0.0000
Epoch 003 batch 00008: Loss 5.3143 Regression loss 0.1614 Classification loss 5.1529 AP 1.0000 AR 0.0000
Epoch 003 batch 00009: Loss 5.5317 Regression loss 0.1817 Classification loss 5.3500 AP 1.0000 AR 0.0000
Epoch 003 batch 00010: Loss 4.9938 Regression loss 0.2559 Classification loss 4.7379 AP 1.0000 AR 0.0000
Epoch 004 batch 00001: Loss 4.9684 Regression loss 0.2533 Classification loss 4.7151 AP 1.0000 AR 0.0000
Epoch 004 batch 00002: Loss 5.0945 Regression loss 0.3324 Classification loss 4.7622 AP 1.0000 AR 0.0000
Epoch 004 batch 00003: Loss 5.2741 Regression loss 0.3353 Classification loss 4.9388 AP 1.0000 AR 0.0000
Epoch 004 batch 00004: Loss 4.8155 Regression loss 0.2733 Classification loss 4.5422 AP 1.0000 AR 0.0000
Epoch 004 batch 00005: Loss 4.8179 Regression loss 0.2521 Classification loss 4.5657 AP 1.0000 AR 0.0000
Epoch 004 batch 00006: Loss 4.2641 Regression loss 0.1792 Classification loss 4.0850 AP 1.0000 AR 0.0000
Epoch 004 batch 00007: Loss 3.8916 Regression loss 0.1163 Classification loss 3.7753 AP 1.0000 AR 0.0000
Epoch 004 batch 00008: Loss 3.8815 Regression loss 0.0831 Classification loss 3.7984 AP 1.0000 AR 0.0000
Epoch 004 batch 00009: Loss 4.0428 Regression loss 0.0778 Classification loss 3.9650 AP 1.0000 AR 0.0000
Epoch 004 batch 00010: Loss 3.8520 Regression loss 0.0552 Classification loss 3.7969 AP 1.0000 AR 0.0000
Epoch 005 batch 00001: Loss 3.4599 Regression loss 0.0544 Classification loss 3.4055 AP 1.0000 AR 0.0000
Epoch 005 batch 00002: Loss 3.4808 Regression loss 0.0600 Classification loss 3.4208 AP 1.0000 AR 0.0000
Epoch 005 batch 00003: Loss 3.0451 Regression loss 0.0475 Classification loss 2.9976 AP 0.0000 AR 0.0000
Epoch 005 batch 00004: Loss 3.0156 Regression loss 0.0450 Classification loss 2.9706 AP 0.0000 AR 0.0000
Epoch 005 batch 00005: Loss 2.9389 Regression loss 0.0444 Classification loss 2.8945 AP 0.0000 AR 0.0000
Epoch 005 batch 00006: Loss 2.9194 Regression loss 0.0453 Classification loss 2.8741 AP 0.0000 AR 0.0000
Epoch 005 batch 00007: Loss 2.5903 Regression loss 0.0368 Classification loss 2.5535 AP 0.0000 AR 0.0000
Epoch 005 batch 00008: Loss 2.5754 Regression loss 0.0535 Classification loss 2.5219 AP 0.0000 AR 0.0000
Epoch 005 batch 00009: Loss 2.6848 Regression loss 0.0495 Classification loss 2.6354 AP 0.0000 AR 0.0000
Epoch 005 batch 00010: Loss 2.5842 Regression loss 0.0477 Classification loss 2.5364 AP 0.0000 AR 0.0000
Epoch 006 batch 00001: Loss 2.7617 Regression loss 0.0536 Classification loss 2.7081 AP 0.0000 AR 0.0000
Epoch 006 batch 00002: Loss 2.7439 Regression loss 0.0603 Classification loss 2.6836 AP 0.0000 AR 0.0000
Epoch 006 batch 00003: Loss 3.1017 Regression loss 0.0684 Classification loss 3.0333 AP 0.0000 AR 0.0000
Epoch 006 batch 00004: Loss 2.7084 Regression loss 0.0721 Classification loss 2.6362 AP 0.0000 AR 0.0000
Epoch 006 batch 00005: Loss 3.0187 Regression loss 0.0804 Classification loss 2.9383 AP 0.0000 AR 0.0000
Epoch 006 batch 00006: Loss 2.3176 Regression loss 0.0885 Classification loss 2.2291 AP 0.0000 AR 0.0000
Epoch 006 batch 00007: Loss 2.5504 Regression loss 0.1017 Classification loss 2.4487 AP 0.0000 AR 0.0000
Epoch 006 batch 00008: Loss 2.2735 Regression loss 0.1035 Classification loss 2.1700 AP 0.0000 AR 0.0000
Epoch 006 batch 00009: Loss 2.4615 Regression loss 0.1199 Classification loss 2.3416 AP 0.0000 AR 0.0000
Epoch 006 batch 00010: Loss 2.4690 Regression loss 0.1005 Classification loss 2.3684 AP 0.0000 AR 0.0000
Epoch 007 batch 00001: Loss 2.2364 Regression loss 0.0922 Classification loss 2.1443 AP 0.0000 AR 0.0000
Epoch 007 batch 00002: Loss 2.3610 Regression loss 0.0914 Classification loss 2.2696 AP 0.0000 AR 0.0000
Epoch 007 batch 00003: Loss 2.3885 Regression loss 0.0749 Classification loss 2.3135 AP 0.0000 AR 0.0000
Epoch 007 batch 00004: Loss 2.1966 Regression loss 0.0614 Classification loss 2.1351 AP 0.0000 AR 0.0000
Epoch 007 batch 00005: Loss 2.3761 Regression loss 0.0563 Classification loss 2.3198 AP 0.0000 AR 0.0000
Epoch 007 batch 00006: Loss 2.3662 Regression loss 0.0479 Classification loss 2.3183 AP 0.0000 AR 0.0000
Epoch 007 batch 00007: Loss 2.2541 Regression loss 0.0450 Classification loss 2.2091 AP 0.0000 AR 0.0000
Epoch 007 batch 00008: Loss 2.5988 Regression loss 0.0401 Classification loss 2.5587 AP 0.0000 AR 0.0000
Epoch 007 batch 00009: Loss 2.2822 Regression loss 0.0301 Classification loss 2.2521 AP 0.0000 AR 0.0000
Epoch 007 batch 00010: Loss 2.2117 Regression loss 0.0338 Classification loss 2.1779 AP 0.0000 AR 0.0000
Epoch 008 batch 00001: Loss 2.1457 Regression loss 0.0376 Classification loss 2.1081 AP 0.0000 AR 0.0000
Epoch 008 batch 00002: Loss 2.4465 Regression loss 0.0343 Classification loss 2.4122 AP 1.0000 AR 0.0000
Epoch 008 batch 00003: Loss 2.2389 Regression loss 0.0337 Classification loss 2.2052 AP 1.0000 AR 0.0000
Epoch 008 batch 00004: Loss 2.2094 Regression loss 0.0344 Classification loss 2.1750 AP 1.0000 AR 0.0000
Epoch 008 batch 00005: Loss 2.1228 Regression loss 0.0319 Classification loss 2.0910 AP 1.0000 AR 0.0000
Epoch 008 batch 00006: Loss 2.1393 Regression loss 0.0395 Classification loss 2.0997 AP 1.0000 AR 0.0000
Epoch 008 batch 00007: Loss 2.1858 Regression loss 0.0349 Classification loss 2.1509 AP 1.0000 AR 0.0000
Epoch 008 batch 00008: Loss 2.0409 Regression loss 0.0309 Classification loss 2.0100 AP 1.0000 AR 0.0000
Epoch 008 batch 00009: Loss 2.3127 Regression loss 0.0428 Classification loss 2.2699 AP 1.0000 AR 0.0000
Epoch 008 batch 00010: Loss 1.9509 Regression loss 0.0377 Classification loss 1.9132 AP 1.0000 AR 0.0000
Epoch 009 batch 00001: Loss 2.1475 Regression loss 0.0387 Classification loss 2.1088 AP 1.0000 AR 0.0000
Epoch 009 batch 00002: Loss 2.0753 Regression loss 0.0341 Classification loss 2.0413 AP 1.0000 AR 0.0000
Epoch 009 batch 00003: Loss 2.0582 Regression loss 0.0387 Classification loss 2.0196 AP 1.0000 AR 0.0000
Epoch 009 batch 00004: Loss 1.8990 Regression loss 0.0392 Classification loss 1.8599 AP 1.0000 AR 0.0000
Epoch 009 batch 00005: Loss 1.9686 Regression loss 0.0389 Classification loss 1.9297 AP 1.0000 AR 0.0000
Epoch 009 batch 00006: Loss 2.1453 Regression loss 0.0320 Classification loss 2.1133 AP 1.0000 AR 0.0000
Epoch 009 batch 00007: Loss 2.0266 Regression loss 0.0320 Classification loss 1.9946 AP 1.0000 AR 0.0000
Epoch 009 batch 00008: Loss 1.9927 Regression loss 0.0333 Classification loss 1.9595 AP 1.0000 AR 0.0000
Epoch 009 batch 00009: Loss 2.0429 Regression loss 0.0300 Classification loss 2.0129 AP 1.0000 AR 0.0000
Epoch 009 batch 00010: Loss 2.0455 Regression loss 0.0317 Classification loss 2.0138 AP 1.0000 AR 0.0000
Epoch 010 batch 00001: Loss 1.9022 Regression loss 0.0377 Classification loss 1.8645 AP 1.0000 AR 0.0000
Epoch 010 batch 00002: Loss 1.9388 Regression loss 0.0287 Classification loss 1.9101 AP 1.0000 AR 0.0000
Epoch 010 batch 00003: Loss 1.9099 Regression loss 0.0275 Classification loss 1.8824 AP 1.0000 AR 0.0000
Epoch 010 batch 00004: Loss 1.9953 Regression loss 0.0292 Classification loss 1.9661 AP 1.0000 AR 0.0000
Epoch 010 batch 00005: Loss 1.8628 Regression loss 0.0279 Classification loss 1.8349 AP 1.0000 AR 0.0000
Epoch 010 batch 00006: Loss 2.1148 Regression loss 0.0329 Classification loss 2.0820 AP 1.0000 AR 0.0000
Epoch 010 batch 00007: Loss 1.8842 Regression loss 0.0320 Classification loss 1.8522 AP 1.0000 AR 0.0000
Epoch 010 batch 00008: Loss 1.9085 Regression loss 0.0324 Classification loss 1.8761 AP 1.0000 AR 0.0000
Epoch 010 batch 00009: Loss 1.7837 Regression loss 0.0328 Classification loss 1.7509 AP 1.0000 AR 0.0000
Epoch 010 batch 00010: Loss 1.8934 Regression loss 0.0279 Classification loss 1.8655 AP 1.0000 AR 0.0000
Epoch 011 batch 00001: Loss 1.7722 Regression loss 0.0300 Classification loss 1.7423 AP 1.0000 AR 0.0000
Epoch 011 batch 00002: Loss 1.7940 Regression loss 0.0342 Classification loss 1.7598 AP 1.0000 AR 0.0000
Epoch 011 batch 00003: Loss 1.7920 Regression loss 0.0321 Classification loss 1.7599 AP 1.0000 AR 0.0000
Epoch 011 batch 00004: Loss 1.8770 Regression loss 0.0302 Classification loss 1.8468 AP 1.0000 AR 0.0000
Epoch 011 batch 00005: Loss 1.8326 Regression loss 0.0311 Classification loss 1.8015 AP 1.0000 AR 0.0000
Epoch 011 batch 00006: Loss 2.0256 Regression loss 0.0415 Classification loss 1.9841 AP 1.0000 AR 0.0000
Epoch 011 batch 00007: Loss 1.7534 Regression loss 0.0353 Classification loss 1.7181 AP 1.0000 AR 0.0000
Epoch 011 batch 00008: Loss 1.8522 Regression loss 0.0359 Classification loss 1.8163 AP 1.0000 AR 0.0000
Epoch 011 batch 00009: Loss 1.6547 Regression loss 0.0379 Classification loss 1.6168 AP 1.0000 AR 0.0000
Epoch 011 batch 00010: Loss 1.7061 Regression loss 0.0317 Classification loss 1.6744 AP 1.0000 AR 0.0000
Epoch 012 batch 00001: Loss 1.9426 Regression loss 0.0396 Classification loss 1.9030 AP 1.0000 AR 0.0000
Epoch 012 batch 00002: Loss 1.7539 Regression loss 0.0309 Classification loss 1.7229 AP 1.0000 AR 0.0000
Epoch 012 batch 00003: Loss 1.6383 Regression loss 0.0306 Classification loss 1.6077 AP 1.0000 AR 0.0000
Epoch 012 batch 00004: Loss 1.7259 Regression loss 0.0307 Classification loss 1.6952 AP 1.0000 AR 0.0000
Epoch 012 batch 00005: Loss 1.6450 Regression loss 0.0333 Classification loss 1.6116 AP 1.0000 AR 0.0000
Epoch 012 batch 00006: Loss 1.6489 Regression loss 0.0283 Classification loss 1.6205 AP 1.0000 AR 0.0000
Epoch 012 batch 00007: Loss 1.7079 Regression loss 0.0301 Classification loss 1.6778 AP 1.0000 AR 0.0000
Epoch 012 batch 00008: Loss 1.7043 Regression loss 0.0338 Classification loss 1.6705 AP 1.0000 AR 0.0000
Epoch 012 batch 00009: Loss 1.6004 Regression loss 0.0331 Classification loss 1.5673 AP 1.0000 AR 0.0000
Epoch 012 batch 00010: Loss 1.6086 Regression loss 0.0297 Classification loss 1.5789 AP 1.0000 AR 0.0000
Epoch 013 batch 00001: Loss 1.6701 Regression loss 0.0358 Classification loss 1.6342 AP 1.0000 AR 0.0000
Epoch 013 batch 00002: Loss 1.6230 Regression loss 0.0318 Classification loss 1.5912 AP 1.0000 AR 0.0000
Epoch 013 batch 00003: Loss 1.6235 Regression loss 0.0334 Classification loss 1.5902 AP 1.0000 AR 0.0000
Epoch 013 batch 00004: Loss 1.5344 Regression loss 0.0368 Classification loss 1.4976 AP 1.0000 AR 0.0000
Epoch 013 batch 00005: Loss 1.6484 Regression loss 0.0285 Classification loss 1.6199 AP 1.0000 AR 0.0000
Epoch 013 batch 00006: Loss 1.5488 Regression loss 0.0359 Classification loss 1.5129 AP 1.0000 AR 0.0000
Epoch 013 batch 00007: Loss 1.4655 Regression loss 0.0297 Classification loss 1.4357 AP 1.0000 AR 0.0000
Epoch 013 batch 00008: Loss 1.5774 Regression loss 0.0338 Classification loss 1.5436 AP 1.0000 AR 0.0000
Epoch 013 batch 00009: Loss 1.4506 Regression loss 0.0343 Classification loss 1.4162 AP 1.0000 AR 0.0000
Epoch 013 batch 00010: Loss 1.4216 Regression loss 0.0322 Classification loss 1.3894 AP 1.0000 AR 0.0000
Epoch 014 batch 00001: Loss 1.4756 Regression loss 0.0327 Classification loss 1.4429 AP 1.0000 AR 0.0000
Epoch 014 batch 00002: Loss 1.4626 Regression loss 0.0344 Classification loss 1.4282 AP 1.0000 AR 0.0000
Epoch 014 batch 00003: Loss 1.4473 Regression loss 0.0304 Classification loss 1.4168 AP 1.0000 AR 0.0000
Epoch 014 batch 00004: Loss 1.3866 Regression loss 0.0314 Classification loss 1.3552 AP 1.0000 AR 0.0000
Epoch 014 batch 00005: Loss 1.4562 Regression loss 0.0388 Classification loss 1.4174 AP 1.0000 AR 0.0000
Epoch 014 batch 00006: Loss 1.4513 Regression loss 0.0371 Classification loss 1.4142 AP 1.0000 AR 0.0000
Epoch 014 batch 00007: Loss 1.2924 Regression loss 0.0323 Classification loss 1.2602 AP 1.0000 AR 0.0000
Epoch 014 batch 00008: Loss 1.3124 Regression loss 0.0291 Classification loss 1.2833 AP 1.0000 AR 0.0000
Epoch 014 batch 00009: Loss 1.2815 Regression loss 0.0342 Classification loss 1.2473 AP 1.0000 AR 0.0000
Epoch 014 batch 00010: Loss 1.1928 Regression loss 0.0308 Classification loss 1.1619 AP 1.0000 AR 0.0000
Epoch 015 batch 00001: Loss 1.2189 Regression loss 0.0350 Classification loss 1.1839 AP 1.0000 AR 0.0000
Epoch 015 batch 00002: Loss 1.1583 Regression loss 0.0354 Classification loss 1.1229 AP 1.0000 AR 0.0000
Epoch 015 batch 00003: Loss 1.2461 Regression loss 0.0305 Classification loss 1.2156 AP 1.0000 AR 0.0000
Epoch 015 batch 00004: Loss 1.1615 Regression loss 0.0299 Classification loss 1.1316 AP 1.0000 AR 0.0000
Epoch 015 batch 00005: Loss 1.0927 Regression loss 0.0271 Classification loss 1.0656 AP 1.0000 AR 0.0000
Epoch 015 batch 00006: Loss 1.1325 Regression loss 0.0296 Classification loss 1.1029 AP 1.0000 AR 0.0000
Epoch 015 batch 00007: Loss 1.1603 Regression loss 0.0346 Classification loss 1.1257 AP 1.0000 AR 0.0000
Epoch 015 batch 00008: Loss 1.1646 Regression loss 0.0374 Classification loss 1.1272 AP 1.0000 AR 0.0000
Epoch 015 batch 00009: Loss 1.1230 Regression loss 0.0330 Classification loss 1.0900 AP 1.0000 AR 0.0000
Epoch 015 batch 00010: Loss 1.1004 Regression loss 0.0354 Classification loss 1.0649 AP 1.0000 AR 0.0000
Epoch 016 batch 00001: Loss 1.0766 Regression loss 0.0346 Classification loss 1.0421 AP 1.0000 AR 0.0000
Epoch 016 batch 00002: Loss 1.0924 Regression loss 0.0277 Classification loss 1.0647 AP 0.9000 AR 0.0000
Epoch 016 batch 00003: Loss 0.9838 Regression loss 0.0316 Classification loss 0.9521 AP 0.9000 AR 0.0500
Epoch 016 batch 00004: Loss 0.9494 Regression loss 0.0345 Classification loss 0.9149 AP 0.7000 AR 0.0000
Epoch 016 batch 00005: Loss 0.9390 Regression loss 0.0382 Classification loss 0.9009 AP 0.9000 AR 0.0000
Epoch 016 batch 00006: Loss 0.9901 Regression loss 0.0374 Classification loss 0.9528 AP 0.8000 AR 0.0000
Epoch 016 batch 00007: Loss 0.9390 Regression loss 0.0365 Classification loss 0.9025 AP 0.7000 AR 0.0000
Epoch 016 batch 00008: Loss 0.9784 Regression loss 0.0297 Classification loss 0.9487 AP 0.8000 AR 0.0000
Epoch 016 batch 00009: Loss 0.9134 Regression loss 0.0287 Classification loss 0.8846 AP 0.7000 AR 0.1000
Epoch 016 batch 00010: Loss 0.9078 Regression loss 0.0283 Classification loss 0.8795 AP 0.2000 AR 0.0000
Epoch 017 batch 00001: Loss 0.9012 Regression loss 0.0358 Classification loss 0.8655 AP 0.5500 AR 0.0250
Epoch 017 batch 00002: Loss 0.8753 Regression loss 0.0327 Classification loss 0.8426 AP 0.2000 AR 0.0500
Epoch 017 batch 00003: Loss 0.9699 Regression loss 0.0311 Classification loss 0.9388 AP 0.9000 AR 0.0000
Epoch 017 batch 00004: Loss 0.8984 Regression loss 0.0407 Classification loss 0.8576 AP 0.4000 AR 0.0000
Epoch 017 batch 00005: Loss 0.8852 Regression loss 0.0318 Classification loss 0.8534 AP 0.5000 AR 0.0000
Epoch 017 batch 00006: Loss 0.8788 Regression loss 0.0362 Classification loss 0.8425 AP 0.7000 AR 0.0000
Epoch 017 batch 00007: Loss 0.8879 Regression loss 0.0322 Classification loss 0.8558 AP 0.3000 AR 0.0000
Epoch 017 batch 00008: Loss 0.8451 Regression loss 0.0324 Classification loss 0.8127 AP 0.3000 AR 0.0500
Epoch 017 batch 00009: Loss 0.8491 Regression loss 0.0327 Classification loss 0.8164 AP 0.2500 AR 0.0333
Epoch 017 batch 00010: Loss 0.8726 Regression loss 0.0321 Classification loss 0.8406 AP 0.2000 AR 0.0000
Epoch 018 batch 00001: Loss 0.8676 Regression loss 0.0333 Classification loss 0.8342 AP 0.3000 AR 0.0000
Epoch 018 batch 00002: Loss 0.8564 Regression loss 0.0323 Classification loss 0.8240 AP 0.3500 AR 0.0333
Epoch 018 batch 00003: Loss 0.8252 Regression loss 0.0345 Classification loss 0.7908 AP 0.3000 AR 0.0000
Epoch 018 batch 00004: Loss 0.8650 Regression loss 0.0360 Classification loss 0.8290 AP 0.3250 AR 0.0250
Epoch 018 batch 00005: Loss 0.8339 Regression loss 0.0341 Classification loss 0.7998 AP 0.4000 AR 0.0000
Epoch 018 batch 00006: Loss 0.8914 Regression loss 0.0385 Classification loss 0.8528 AP 0.4000 AR 0.0000
Epoch 018 batch 00007: Loss 0.7881 Regression loss 0.0311 Classification loss 0.7570 AP 0.3333 AR 0.0250
Epoch 018 batch 00008: Loss 0.8106 Regression loss 0.0353 Classification loss 0.7754 AP 0.1000 AR 0.0000
Epoch 018 batch 00009: Loss 0.7759 Regression loss 0.0385 Classification loss 0.7374 AP 0.1000 AR 0.0000
Epoch 018 batch 00010: Loss 0.7922 Regression loss 0.0302 Classification loss 0.7620 AP 0.0333 AR 0.0333
Epoch 019 batch 00001: Loss 0.7870 Regression loss 0.0388 Classification loss 0.7482 AP 0.2000 AR 0.0000
Epoch 019 batch 00002: Loss 0.7880 Regression loss 0.0313 Classification loss 0.7567 AP 0.1000 AR 0.0000
Epoch 019 batch 00003: Loss 0.7825 Regression loss 0.0371 Classification loss 0.7454 AP 0.2333 AR 0.0333
Epoch 019 batch 00004: Loss 0.8119 Regression loss 0.0387 Classification loss 0.7732 AP 0.2000 AR 0.0000
Epoch 019 batch 00005: Loss 0.8141 Regression loss 0.0401 Classification loss 0.7740 AP 0.2500 AR 0.0333
Epoch 019 batch 00006: Loss 0.8429 Regression loss 0.0358 Classification loss 0.8071 AP 0.2000 AR 0.0000
Epoch 019 batch 00007: Loss 0.7767 Regression loss 0.0328 Classification loss 0.7440 AP 0.1000 AR 0.0000
Epoch 019 batch 00008: Loss 0.7826 Regression loss 0.0351 Classification loss 0.7475 AP 0.1000 AR 0.0000
Epoch 019 batch 00009: Loss 0.7995 Regression loss 0.0310 Classification loss 0.7685 AP 0.2000 AR 0.0000
Epoch 019 batch 00010: Loss 0.8184 Regression loss 0.0354 Classification loss 0.7830 AP 0.2000 AR 0.0000
Epoch 020 batch 00001: Loss 0.7944 Regression loss 0.0368 Classification loss 0.7577 AP 0.2000 AR 0.0000
Epoch 020 batch 00002: Loss 0.7688 Regression loss 0.0334 Classification loss 0.7353 AP 0.1000 AR 0.0000
Epoch 020 batch 00003: Loss 0.7733 Regression loss 0.0386 Classification loss 0.7347 AP 0.1000 AR 0.0000
Epoch 020 batch 00004: Loss 0.8434 Regression loss 0.0341 Classification loss 0.8093 AP 0.1000 AR 0.0000
Epoch 020 batch 00005: Loss 0.7971 Regression loss 0.0398 Classification loss 0.7573 AP 0.2000 AR 0.0000
Epoch 020 batch 00006: Loss 0.7768 Regression loss 0.0301 Classification loss 0.7467 AP 0.4500 AR 0.1500
Epoch 020 batch 00007: Loss 0.7650 Regression loss 0.0347 Classification loss 0.7302 AP 0.3500 AR 0.0533
Epoch 020 batch 00008: Loss 0.7298 Regression loss 0.0337 Classification loss 0.6961 AP 0.2000 AR 0.0000
Epoch 020 batch 00009: Loss 0.8025 Regression loss 0.0392 Classification loss 0.7632 AP 0.2000 AR 0.0000
Epoch 020 batch 00010: Loss 0.7236 Regression loss 0.0312 Classification loss 0.6923 AP 0.2083 AR 0.1500
Epoch 021 batch 00001: Loss 0.7238 Regression loss 0.0332 Classification loss 0.6906 AP 0.1000 AR 0.0000
Epoch 021 batch 00002: Loss 0.7853 Regression loss 0.0378 Classification loss 0.7475 AP 0.2000 AR 0.0000
Epoch 021 batch 00003: Loss 0.7984 Regression loss 0.0342 Classification loss 0.7641 AP 0.2500 AR 0.0333
Epoch 021 batch 00004: Loss 0.7594 Regression loss 0.0374 Classification loss 0.7220 AP 0.3000 AR 0.0000
Epoch 021 batch 00005: Loss 0.7386 Regression loss 0.0345 Classification loss 0.7041 AP 0.1333 AR 0.0833
Epoch 021 batch 00006: Loss 0.7580 Regression loss 0.0335 Classification loss 0.7244 AP 0.1000 AR 0.0000
Epoch 021 batch 00007: Loss 0.7487 Regression loss 0.0386 Classification loss 0.7101 AP 0.3000 AR 0.0000
Epoch 021 batch 00008: Loss 0.7685 Regression loss 0.0368 Classification loss 0.7317 AP 0.1333 AR 0.0250
Epoch 021 batch 00009: Loss 0.7700 Regression loss 0.0345 Classification loss 0.7355 AP 0.2000 AR 0.0000
Epoch 021 batch 00010: Loss 0.6937 Regression loss 0.0378 Classification loss 0.6559 AP 0.1333 AR 0.0250
Epoch 022 batch 00001: Loss 0.7346 Regression loss 0.0401 Classification loss 0.6944 AP 0.2000 AR 0.0000
Epoch 022 batch 00002: Loss 0.7736 Regression loss 0.0400 Classification loss 0.7336 AP 0.1000 AR 0.0000
Epoch 022 batch 00003: Loss 0.7260 Regression loss 0.0381 Classification loss 0.6879 AP 0.2000 AR 0.0000
Epoch 022 batch 00004: Loss 0.6951 Regression loss 0.0329 Classification loss 0.6622 AP 0.2000 AR 0.0500
Epoch 022 batch 00005: Loss 0.7237 Regression loss 0.0417 Classification loss 0.6820 AP 0.1000 AR 0.0000
Epoch 022 batch 00006: Loss 0.7093 Regression loss 0.0337 Classification loss 0.6756 AP 0.2200 AR 0.0250
Epoch 022 batch 00007: Loss 0.7404 Regression loss 0.0362 Classification loss 0.7042 AP 0.0375 AR 0.0583
Epoch 022 batch 00008: Loss 0.7471 Regression loss 0.0381 Classification loss 0.7089 AP 0.3333 AR 0.0333
Epoch 022 batch 00009: Loss 0.7769 Regression loss 0.0337 Classification loss 0.7432 AP 0.1000 AR 0.0000
Epoch 022 batch 00010: Loss 0.7005 Regression loss 0.0314 Classification loss 0.6690 AP 0.2200 AR 0.0833
Epoch 023 batch 00001: Loss 0.6932 Regression loss 0.0355 Classification loss 0.6577 AP 0.1833 AR 0.0833
Epoch 023 batch 00002: Loss 0.7066 Regression loss 0.0349 Classification loss 0.6717 AP 0.1000 AR 0.0000
Epoch 023 batch 00003: Loss 0.7157 Regression loss 0.0350 Classification loss 0.6807 AP 0.2333 AR 0.1000
Epoch 023 batch 00004: Loss 0.7421 Regression loss 0.0416 Classification loss 0.7005 AP 0.2000 AR 0.0000
Epoch 023 batch 00005: Loss 0.7989 Regression loss 0.0384 Classification loss 0.7605 AP 0.1000 AR 0.0000
Epoch 023 batch 00006: Loss 0.7254 Regression loss 0.0339 Classification loss 0.6915 AP 0.1750 AR 0.0500
Epoch 023 batch 00007: Loss 0.6885 Regression loss 0.0471 Classification loss 0.6414 AP 0.1643 AR 0.0750
Epoch 023 batch 00008: Loss 0.7487 Regression loss 0.0332 Classification loss 0.7155 AP 0.0167 AR 0.0250
Epoch 023 batch 00009: Loss 0.7117 Regression loss 0.0375 Classification loss 0.6742 AP 0.2250 AR 0.1250
Epoch 023 batch 00010: Loss 0.7494 Regression loss 0.0361 Classification loss 0.7133 AP 0.4000 AR 0.0500
Epoch 024 batch 00001: Loss 0.6993 Regression loss 0.0342 Classification loss 0.6651 AP 0.1543 AR 0.0600
Epoch 024 batch 00002: Loss 0.7613 Regression loss 0.0386 Classification loss 0.7227 AP 0.2000 AR 0.1333
Epoch 024 batch 00003: Loss 0.7102 Regression loss 0.0283 Classification loss 0.6819 AP 0.3000 AR 0.1000
Epoch 024 batch 00004: Loss 0.7485 Regression loss 0.0413 Classification loss 0.7072 AP 0.0000 AR 0.0000
Epoch 024 batch 00005: Loss 0.6967 Regression loss 0.0465 Classification loss 0.6501 AP 0.1667 AR 0.0583
Epoch 024 batch 00006: Loss 0.7026 Regression loss 0.0353 Classification loss 0.6673 AP 0.4000 AR 0.0000
Epoch 024 batch 00007: Loss 0.6900 Regression loss 0.0354 Classification loss 0.6547 AP 0.1400 AR 0.1500
Epoch 024 batch 00008: Loss 0.7331 Regression loss 0.0330 Classification loss 0.7000 AP 0.3000 AR 0.0250
Epoch 024 batch 00009: Loss 0.6968 Regression loss 0.0422 Classification loss 0.6546 AP 0.1000 AR 0.0000
Epoch 024 batch 00010: Loss 0.6880 Regression loss 0.0346 Classification loss 0.6535 AP 0.2000 AR 0.0000
Epoch 025 batch 00001: Loss 0.7103 Regression loss 0.0380 Classification loss 0.6723 AP 0.0417 AR 0.0500
Epoch 025 batch 00002: Loss 0.7216 Regression loss 0.0361 Classification loss 0.6855 AP 0.0250 AR 0.0333
Epoch 025 batch 00003: Loss 0.6484 Regression loss 0.0367 Classification loss 0.6117 AP 0.1200 AR 0.0200
Epoch 025 batch 00004: Loss 0.7212 Regression loss 0.0364 Classification loss 0.6849 AP 0.3167 AR 0.0250
Epoch 025 batch 00005: Loss 0.7094 Regression loss 0.0358 Classification loss 0.6736 AP 0.1000 AR 0.0000
Epoch 025 batch 00006: Loss 0.6646 Regression loss 0.0463 Classification loss 0.6183 AP 0.1000 AR 0.0000
Epoch 025 batch 00007: Loss 0.6085 Regression loss 0.0339 Classification loss 0.5747 AP 0.1700 AR 0.1250
Epoch 025 batch 00008: Loss 0.7134 Regression loss 0.0349 Classification loss 0.6785 AP 0.2250 AR 0.0500
Epoch 025 batch 00009: Loss 0.6623 Regression loss 0.0360 Classification loss 0.6263 AP 0.2125 AR 0.0250
Epoch 025 batch 00010: Loss 0.6844 Regression loss 0.0351 Classification loss 0.6492 AP 0.2000 AR 0.1000
Epoch 026 batch 00001: Loss 0.6576 Regression loss 0.0337 Classification loss 0.6239 AP 0.1250 AR 0.0200
Epoch 026 batch 00002: Loss 0.6730 Regression loss 0.0329 Classification loss 0.6401 AP 0.3200 AR 0.0250
Epoch 026 batch 00003: Loss 0.6530 Regression loss 0.0374 Classification loss 0.6156 AP 0.1000 AR 0.0000
Epoch 026 batch 00004: Loss 0.6945 Regression loss 0.0393 Classification loss 0.6553 AP 0.2650 AR 0.0700
Epoch 026 batch 00005: Loss 0.6585 Regression loss 0.0371 Classification loss 0.6214 AP 0.0500 AR 0.0333
Epoch 026 batch 00006: Loss 0.6524 Regression loss 0.0320 Classification loss 0.6204 AP 0.1000 AR 0.0000
Epoch 026 batch 00007: Loss 0.6301 Regression loss 0.0416 Classification loss 0.5885 AP 0.0000 AR 0.0000
Epoch 026 batch 00008: Loss 0.6625 Regression loss 0.0342 Classification loss 0.6283 AP 0.1450 AR 0.0583
Epoch 026 batch 00009: Loss 0.6488 Regression loss 0.0411 Classification loss 0.6077 AP 0.1000 AR 0.0000
Epoch 026 batch 00010: Loss 0.6503 Regression loss 0.0346 Classification loss 0.6156 AP 0.1750 AR 0.1500
Epoch 027 batch 00001: Loss 0.6831 Regression loss 0.0485 Classification loss 0.6347 AP 0.1000 AR 0.0000
Epoch 027 batch 00002: Loss 0.6677 Regression loss 0.0348 Classification loss 0.6329 AP 0.1583 AR 0.0583
Epoch 027 batch 00003: Loss 0.6525 Regression loss 0.0324 Classification loss 0.6201 AP 0.1250 AR 0.0500
Epoch 027 batch 00004: Loss 0.6461 Regression loss 0.0326 Classification loss 0.6135 AP 0.0833 AR 0.0750
Epoch 027 batch 00005: Loss 0.6551 Regression loss 0.0368 Classification loss 0.6183 AP 0.2393 AR 0.1400
Epoch 027 batch 00006: Loss 0.5598 Regression loss 0.0336 Classification loss 0.5263 AP 0.3200 AR 0.0250
Epoch 027 batch 00007: Loss 0.6554 Regression loss 0.0422 Classification loss 0.6133 AP 0.3500 AR 0.1000
Epoch 027 batch 00008: Loss 0.6585 Regression loss 0.0378 Classification loss 0.6206 AP 0.0000 AR 0.0000
Epoch 027 batch 00009: Loss 0.6308 Regression loss 0.0364 Classification loss 0.5944 AP 0.0500 AR 0.0333
Epoch 027 batch 00010: Loss 0.5942 Regression loss 0.0340 Classification loss 0.5603 AP 0.1417 AR 0.0533
Epoch 028 batch 00001: Loss 0.6467 Regression loss 0.0334 Classification loss 0.6133 AP 0.0694 AR 0.1033
Epoch 028 batch 00002: Loss 0.5875 Regression loss 0.0345 Classification loss 0.5529 AP 0.1250 AR 0.0333
Epoch 028 batch 00003: Loss 0.6022 Regression loss 0.0432 Classification loss 0.5590 AP 0.1200 AR 0.0200
Epoch 028 batch 00004: Loss 0.5974 Regression loss 0.0320 Classification loss 0.5654 AP 0.1750 AR 0.0583
Epoch 028 batch 00005: Loss 0.6915 Regression loss 0.0339 Classification loss 0.6575 AP 0.0333 AR 0.0250
Epoch 028 batch 00006: Loss 0.6048 Regression loss 0.0329 Classification loss 0.5719 AP 0.1667 AR 0.0500
Epoch 028 batch 00007: Loss 0.6134 Regression loss 0.0393 Classification loss 0.5741 AP 0.1867 AR 0.1450
Epoch 028 batch 00008: Loss 0.6830 Regression loss 0.0364 Classification loss 0.6467 AP 0.2000 AR 0.0000
Epoch 028 batch 00009: Loss 0.6237 Regression loss 0.0340 Classification loss 0.5898 AP 0.1250 AR 0.0250
Epoch 028 batch 00010: Loss 0.6414 Regression loss 0.0358 Classification loss 0.6055 AP 0.1000 AR 0.0000
Epoch 029 batch 00001: Loss 0.6701 Regression loss 0.0378 Classification loss 0.6323 AP 0.1500 AR 0.0200
Epoch 029 batch 00002: Loss 0.6005 Regression loss 0.0438 Classification loss 0.5567 AP 0.3500 AR 0.0333
Epoch 029 batch 00003: Loss 0.6141 Regression loss 0.0345 Classification loss 0.5796 AP 0.0450 AR 0.0583
Epoch 029 batch 00004: Loss 0.6607 Regression loss 0.0324 Classification loss 0.6283 AP 0.0000 AR 0.0000
Epoch 029 batch 00005: Loss 0.6187 Regression loss 0.0343 Classification loss 0.5844 AP 0.1143 AR 0.0200
Epoch 029 batch 00006: Loss 0.6340 Regression loss 0.0360 Classification loss 0.5980 AP 0.0333 AR 0.0333
Epoch 029 batch 00007: Loss 0.6139 Regression loss 0.0386 Classification loss 0.5754 AP 0.1400 AR 0.0583
Epoch 029 batch 00008: Loss 0.5582 Regression loss 0.0313 Classification loss 0.5269 AP 0.0667 AR 0.1250
Epoch 029 batch 00009: Loss 0.5560 Regression loss 0.0327 Classification loss 0.5233 AP 0.1393 AR 0.0450
Epoch 029 batch 00010: Loss 0.5992 Regression loss 0.0383 Classification loss 0.5608 AP 0.2333 AR 0.0333
Epoch 030 batch 00001: Loss 0.5999 Regression loss 0.0373 Classification loss 0.5626 AP 0.0254 AR 0.0450
Epoch 030 batch 00002: Loss 0.5683 Regression loss 0.0362 Classification loss 0.5321 AP 0.0500 AR 0.0750
Epoch 030 batch 00003: Loss 0.6207 Regression loss 0.0333 Classification loss 0.5873 AP 0.0167 AR 0.0250
Epoch 030 batch 00004: Loss 0.6432 Regression loss 0.0373 Classification loss 0.6060 AP 0.4450 AR 0.1583
Epoch 030 batch 00005: Loss 0.6120 Regression loss 0.0347 Classification loss 0.5773 AP 0.2367 AR 0.0450
Epoch 030 batch 00006: Loss 0.5542 Regression loss 0.0310 Classification loss 0.5232 AP 0.0500 AR 0.1000
Epoch 030 batch 00007: Loss 0.5776 Regression loss 0.0306 Classification loss 0.5470 AP 0.1250 AR 0.0333
Epoch 030 batch 00008: Loss 0.5891 Regression loss 0.0331 Classification loss 0.5560 AP 0.2143 AR 0.0167
Epoch 030 batch 00009: Loss 0.5912 Regression loss 0.0432 Classification loss 0.5480 AP 0.0200 AR 0.0200
Epoch 030 batch 00010: Loss 0.5376 Regression loss 0.0352 Classification loss 0.5024 AP 0.1667 AR 0.0667
Epoch 031 batch 00001: Loss 0.5606 Regression loss 0.0373 Classification loss 0.5233 AP 0.0333 AR 0.0450
Epoch 031 batch 00002: Loss 0.5977 Regression loss 0.0329 Classification loss 0.5648 AP 0.1333 AR 0.0500
Epoch 031 batch 00003: Loss 0.5314 Regression loss 0.0365 Classification loss 0.4949 AP 0.1125 AR 0.0200
Epoch 031 batch 00004: Loss 0.5900 Regression loss 0.0310 Classification loss 0.5590 AP 0.0250 AR 0.0333
Epoch 031 batch 00005: Loss 0.5845 Regression loss 0.0298 Classification loss 0.5547 AP 0.1143 AR 0.0200
Epoch 031 batch 00006: Loss 0.5921 Regression loss 0.0394 Classification loss 0.5527 AP 0.1000 AR 0.0000
Epoch 031 batch 00007: Loss 0.5954 Regression loss 0.0425 Classification loss 0.5529 AP 0.0310 AR 0.0500
Epoch 031 batch 00008: Loss 0.5809 Regression loss 0.0350 Classification loss 0.5459 AP 0.2000 AR 0.1000
Epoch 031 batch 00009: Loss 0.5742 Regression loss 0.0367 Classification loss 0.5375 AP 0.2200 AR 0.0200
Epoch 031 batch 00010: Loss 0.5619 Regression loss 0.0326 Classification loss 0.5294 AP 0.0167 AR 0.0250
Epoch 032 batch 00001: Loss 0.6018 Regression loss 0.0295 Classification loss 0.5723 AP 0.1250 AR 0.0500
Epoch 032 batch 00002: Loss 0.5656 Regression loss 0.0347 Classification loss 0.5309 AP 0.2000 AR 0.0000
Epoch 032 batch 00003: Loss 0.5565 Regression loss 0.0382 Classification loss 0.5182 AP 0.1222 AR 0.0500
Epoch 032 batch 00004: Loss 0.5632 Regression loss 0.0346 Classification loss 0.5286 AP 0.1000 AR 0.0000
Epoch 032 batch 00005: Loss 0.5218 Regression loss 0.0305 Classification loss 0.4913 AP 0.0310 AR 0.0450
Epoch 032 batch 00006: Loss 0.5786 Regression loss 0.0385 Classification loss 0.5401 AP 0.0450 AR 0.0833
Epoch 032 batch 00007: Loss 0.5928 Regression loss 0.0393 Classification loss 0.5535 AP 0.2700 AR 0.0533
Epoch 032 batch 00008: Loss 0.5548 Regression loss 0.0367 Classification loss 0.5181 AP 0.0167 AR 0.0200
Epoch 032 batch 00009: Loss 0.5221 Regression loss 0.0364 Classification loss 0.4857 AP 0.0000 AR 0.0000
Epoch 032 batch 00010: Loss 0.5685 Regression loss 0.0369 Classification loss 0.5316 AP 0.0200 AR 0.0200
Epoch 033 batch 00001: Loss 0.6094 Regression loss 0.0332 Classification loss 0.5761 AP 0.1167 AR 0.0250
Epoch 033 batch 00002: Loss 0.5355 Regression loss 0.0359 Classification loss 0.4996 AP 0.0000 AR 0.0000
Epoch 033 batch 00003: Loss 0.5965 Regression loss 0.0330 Classification loss 0.5635 AP 0.0111 AR 0.0200
Epoch 033 batch 00004: Loss 0.5490 Regression loss 0.0330 Classification loss 0.5159 AP 0.1625 AR 0.0533
Epoch 033 batch 00005: Loss 0.5115 Regression loss 0.0355 Classification loss 0.4761 AP 0.2333 AR 0.0450
Epoch 033 batch 00006: Loss 0.5563 Regression loss 0.0382 Classification loss 0.5181 AP 0.1400 AR 0.0500
Epoch 033 batch 00007: Loss 0.5577 Regression loss 0.0321 Classification loss 0.5256 AP 0.1733 AR 0.1033
Epoch 033 batch 00008: Loss 0.5209 Regression loss 0.0311 Classification loss 0.4898 AP 0.0143 AR 0.0200
Epoch 033 batch 00009: Loss 0.5159 Regression loss 0.0340 Classification loss 0.4819 AP 0.0783 AR 0.1333
Epoch 033 batch 00010: Loss 0.5298 Regression loss 0.0391 Classification loss 0.4908 AP 0.0167 AR 0.0250
Epoch 034 batch 00001: Loss 0.5113 Regression loss 0.0345 Classification loss 0.4768 AP 0.0439 AR 0.1000
Epoch 034 batch 00002: Loss 0.5760 Regression loss 0.0372 Classification loss 0.5388 AP 0.1200 AR 0.0500
Epoch 034 batch 00003: Loss 0.5559 Regression loss 0.0316 Classification loss 0.5242 AP 0.1333 AR 0.0500
Epoch 034 batch 00004: Loss 0.5396 Regression loss 0.0337 Classification loss 0.5059 AP 0.1125 AR 0.0200
Epoch 034 batch 00005: Loss 0.4985 Regression loss 0.0337 Classification loss 0.4647 AP 0.1000 AR 0.0000
Epoch 034 batch 00006: Loss 0.5557 Regression loss 0.0363 Classification loss 0.5195 AP 0.1167 AR 0.0250
Epoch 034 batch 00007: Loss 0.5756 Regression loss 0.0406 Classification loss 0.5350 AP 0.0000 AR 0.0000
Epoch 034 batch 00008: Loss 0.5024 Regression loss 0.0359 Classification loss 0.4665 AP 0.1333 AR 0.0500
Epoch 034 batch 00009: Loss 0.5166 Regression loss 0.0300 Classification loss 0.4866 AP 0.0417 AR 0.0533
Epoch 034 batch 00010: Loss 0.5012 Regression loss 0.0290 Classification loss 0.4721 AP 0.0310 AR 0.0450
Epoch 035 batch 00001: Loss 0.5079 Regression loss 0.0311 Classification loss 0.4768 AP 0.1250 AR 0.0333
Epoch 035 batch 00002: Loss 0.5273 Regression loss 0.0339 Classification loss 0.4935 AP 0.0467 AR 0.0700
Epoch 035 batch 00003: Loss 0.5201 Regression loss 0.0327 Classification loss 0.4874 AP 0.0869 AR 0.1400
Epoch 035 batch 00004: Loss 0.5067 Regression loss 0.0286 Classification loss 0.4781 AP 0.0000 AR 0.0000
Epoch 035 batch 00005: Loss 0.5518 Regression loss 0.0394 Classification loss 0.5124 AP 0.1533 AR 0.0950
Epoch 035 batch 00006: Loss 0.5321 Regression loss 0.0347 Classification loss 0.4974 AP 0.1167 AR 0.0250
Epoch 035 batch 00007: Loss 0.5418 Regression loss 0.0369 Classification loss 0.5049 AP 0.1167 AR 0.0250
Epoch 035 batch 00008: Loss 0.4971 Regression loss 0.0311 Classification loss 0.4659 AP 0.0575 AR 0.1083
Epoch 035 batch 00009: Loss 0.5252 Regression loss 0.0376 Classification loss 0.4876 AP 0.0343 AR 0.0400
Epoch 035 batch 00010: Loss 0.4895 Regression loss 0.0375 Classification loss 0.4520 AP 0.1000 AR 0.0000
Epoch 036 batch 00001: Loss 0.5189 Regression loss 0.0333 Classification loss 0.4856 AP 0.0182 AR 0.0500
Epoch 036 batch 00002: Loss 0.5336 Regression loss 0.0300 Classification loss 0.5035 AP 0.0167 AR 0.0250
Epoch 036 batch 00003: Loss 0.4822 Regression loss 0.0370 Classification loss 0.4452 AP 0.0200 AR 0.0200
Epoch 036 batch 00004: Loss 0.5290 Regression loss 0.0362 Classification loss 0.4927 AP 0.1367 AR 0.0583
Epoch 036 batch 00005: Loss 0.5489 Regression loss 0.0354 Classification loss 0.5135 AP 0.1000 AR 0.0000
Epoch 036 batch 00006: Loss 0.4754 Regression loss 0.0360 Classification loss 0.4393 AP 0.1000 AR 0.0000
Epoch 036 batch 00007: Loss 0.4804 Regression loss 0.0335 Classification loss 0.4469 AP 0.0667 AR 0.0783
Epoch 036 batch 00008: Loss 0.5210 Regression loss 0.0341 Classification loss 0.4869 AP 0.0476 AR 0.0700
Epoch 036 batch 00009: Loss 0.5155 Regression loss 0.0346 Classification loss 0.4809 AP 0.0167 AR 0.0250
Epoch 036 batch 00010: Loss 0.5260 Regression loss 0.0373 Classification loss 0.4887 AP 0.1819 AR 0.1400
Epoch 037 batch 00001: Loss 0.5183 Regression loss 0.0357 Classification loss 0.4826 AP 0.1650 AR 0.0917
Epoch 037 batch 00002: Loss 0.5163 Regression loss 0.0344 Classification loss 0.4819 AP 0.0417 AR 0.0533
Epoch 037 batch 00003: Loss 0.4897 Regression loss 0.0322 Classification loss 0.4575 AP 0.0143 AR 0.0250
Epoch 037 batch 00004: Loss 0.5418 Regression loss 0.0399 Classification loss 0.5018 AP 0.0200 AR 0.0500
Epoch 037 batch 00005: Loss 0.4972 Regression loss 0.0356 Classification loss 0.4615 AP 0.0598 AR 0.0950
Epoch 037 batch 00006: Loss 0.4828 Regression loss 0.0394 Classification loss 0.4434 AP 0.0593 AR 0.0783
Epoch 037 batch 00007: Loss 0.4814 Regression loss 0.0320 Classification loss 0.4495 AP 0.1000 AR 0.0000
Epoch 037 batch 00008: Loss 0.4520 Regression loss 0.0321 Classification loss 0.4199 AP 0.0710 AR 0.1117
Epoch 037 batch 00009: Loss 0.4864 Regression loss 0.0330 Classification loss 0.4534 AP 0.1444 AR 0.0533
Epoch 037 batch 00010: Loss 0.4993 Regression loss 0.0371 Classification loss 0.4622 AP 0.0125 AR 0.0200
Epoch 038 batch 00001: Loss 0.4733 Regression loss 0.0350 Classification loss 0.4383 AP 0.1100 AR 0.1250
Epoch 038 batch 00002: Loss 0.4692 Regression loss 0.0328 Classification loss 0.4364 AP 0.0417 AR 0.0700
Epoch 038 batch 00003: Loss 0.4829 Regression loss 0.0356 Classification loss 0.4472 AP 0.0625 AR 0.0867
Epoch 038 batch 00004: Loss 0.4654 Regression loss 0.0338 Classification loss 0.4316 AP 0.0650 AR 0.1000
Epoch 038 batch 00005: Loss 0.4885 Regression loss 0.0363 Classification loss 0.4522 AP 0.0000 AR 0.0000
Epoch 038 batch 00006: Loss 0.4672 Regression loss 0.0356 Classification loss 0.4316 AP 0.0125 AR 0.0200
Epoch 038 batch 00007: Loss 0.5156 Regression loss 0.0389 Classification loss 0.4767 AP 0.2268 AR 0.1450
Epoch 038 batch 00008: Loss 0.4896 Regression loss 0.0393 Classification loss 0.4503 AP 0.0992 AR 0.1250
Epoch 038 batch 00009: Loss 0.4787 Regression loss 0.0378 Classification loss 0.4409 AP 0.1833 AR 0.1500
Epoch 038 batch 00010: Loss 0.4878 Regression loss 0.0355 Classification loss 0.4523 AP 0.0250 AR 0.0450
Epoch 039 batch 00001: Loss 0.4628 Regression loss 0.0338 Classification loss 0.4290 AP 0.0616 AR 0.1167
Epoch 039 batch 00002: Loss 0.4634 Regression loss 0.0364 Classification loss 0.4270 AP 0.0767 AR 0.1000
Epoch 039 batch 00003: Loss 0.4524 Regression loss 0.0388 Classification loss 0.4136 AP 0.1917 AR 0.1250
Epoch 039 batch 00004: Loss 0.4624 Regression loss 0.0360 Classification loss 0.4264 AP 0.0450 AR 0.0667
Epoch 039 batch 00005: Loss 0.4836 Regression loss 0.0381 Classification loss 0.4455 AP 0.0167 AR 0.0200
Epoch 039 batch 00006: Loss 0.4584 Regression loss 0.0336 Classification loss 0.4248 AP 0.0000 AR 0.0000
Epoch 039 batch 00007: Loss 0.4695 Regression loss 0.0342 Classification loss 0.4353 AP 0.2125 AR 0.0250
Epoch 039 batch 00008: Loss 0.4723 Regression loss 0.0314 Classification loss 0.4409 AP 0.0375 AR 0.0533
Epoch 039 batch 00009: Loss 0.4527 Regression loss 0.0351 Classification loss 0.4175 AP 0.0143 AR 0.0200
Epoch 039 batch 00010: Loss 0.4658 Regression loss 0.0362 Classification loss 0.4296 AP 0.0393 AR 0.0600
Epoch 040 batch 00001: Loss 0.4582 Regression loss 0.0356 Classification loss 0.4226 AP 0.0143 AR 0.0500
Epoch 040 batch 00002: Loss 0.4396 Regression loss 0.0322 Classification loss 0.4074 AP 0.1122 AR 0.1483
Epoch 040 batch 00003: Loss 0.4468 Regression loss 0.0376 Classification loss 0.4092 AP 0.0167 AR 0.0333
Epoch 040 batch 00004: Loss 0.4792 Regression loss 0.0349 Classification loss 0.4443 AP 0.1100 AR 0.0250
Epoch 040 batch 00005: Loss 0.4664 Regression loss 0.0360 Classification loss 0.4304 AP 0.1167 AR 0.0200
Epoch 040 batch 00006: Loss 0.4157 Regression loss 0.0326 Classification loss 0.3832 AP 0.0667 AR 0.0700
Epoch 040 batch 00007: Loss 0.4284 Regression loss 0.0357 Classification loss 0.3927 AP 0.0143 AR 0.0200
Epoch 040 batch 00008: Loss 0.4656 Regression loss 0.0380 Classification loss 0.4276 AP 0.0211 AR 0.0450
Epoch 040 batch 00009: Loss 0.5027 Regression loss 0.0347 Classification loss 0.4680 AP 0.1000 AR 0.0000
Epoch 040 batch 00010: Loss 0.4508 Regression loss 0.0386 Classification loss 0.4122 AP 0.0200 AR 0.0333
Epoch 041 batch 00001: Loss 0.4848 Regression loss 0.0314 Classification loss 0.4534 AP 0.0250 AR 0.0250
Epoch 041 batch 00002: Loss 0.4466 Regression loss 0.0384 Classification loss 0.4082 AP 0.0250 AR 0.0500
Epoch 041 batch 00003: Loss 0.4452 Regression loss 0.0338 Classification loss 0.4113 AP 0.0635 AR 0.1200
Epoch 041 batch 00004: Loss 0.4384 Regression loss 0.0333 Classification loss 0.4050 AP 0.0667 AR 0.0833
Epoch 041 batch 00005: Loss 0.4081 Regression loss 0.0369 Classification loss 0.3711 AP 0.1393 AR 0.1750
Epoch 041 batch 00006: Loss 0.4268 Regression loss 0.0402 Classification loss 0.3865 AP 0.2417 AR 0.1833
Epoch 041 batch 00007: Loss 0.4070 Regression loss 0.0329 Classification loss 0.3740 AP 0.2250 AR 0.1583
Epoch 041 batch 00008: Loss 0.4286 Regression loss 0.0374 Classification loss 0.3911 AP 0.0417 AR 0.0583
Epoch 041 batch 00009: Loss 0.4788 Regression loss 0.0363 Classification loss 0.4425 AP 0.0510 AR 0.0900
Epoch 041 batch 00010: Loss 0.4293 Regression loss 0.0334 Classification loss 0.3958 AP 0.0300 AR 0.0583
Epoch 042 batch 00001: Loss 0.4272 Regression loss 0.0354 Classification loss 0.3917 AP 0.0536 AR 0.1450
Epoch 042 batch 00002: Loss 0.4171 Regression loss 0.0354 Classification loss 0.3818 AP 0.0676 AR 0.0983
Epoch 042 batch 00003: Loss 0.4392 Regression loss 0.0321 Classification loss 0.4071 AP 0.1243 AR 0.0400
Epoch 042 batch 00004: Loss 0.4556 Regression loss 0.0382 Classification loss 0.4174 AP 0.0450 AR 0.0833
Epoch 042 batch 00005: Loss 0.3870 Regression loss 0.0327 Classification loss 0.3543 AP 0.2167 AR 0.1200
Epoch 042 batch 00006: Loss 0.4654 Regression loss 0.0373 Classification loss 0.4281 AP 0.0658 AR 0.1083
Epoch 042 batch 00007: Loss 0.4288 Regression loss 0.0355 Classification loss 0.3933 AP 0.0667 AR 0.1333
Epoch 042 batch 00008: Loss 0.4083 Regression loss 0.0331 Classification loss 0.3753 AP 0.0583 AR 0.1083
Epoch 042 batch 00009: Loss 0.4473 Regression loss 0.0376 Classification loss 0.4096 AP 0.0458 AR 0.0783
Epoch 042 batch 00010: Loss 0.4038 Regression loss 0.0335 Classification loss 0.3703 AP 0.0792 AR 0.1000
Epoch 043 batch 00001: Loss 0.4286 Regression loss 0.0360 Classification loss 0.3926 AP 0.0676 AR 0.0867
Epoch 043 batch 00002: Loss 0.4425 Regression loss 0.0325 Classification loss 0.4100 AP 0.1450 AR 0.0700
Epoch 043 batch 00003: Loss 0.4172 Regression loss 0.0347 Classification loss 0.3825 AP 0.0286 AR 0.0500
Epoch 043 batch 00004: Loss 0.4292 Regression loss 0.0374 Classification loss 0.3918 AP 0.0476 AR 0.0750
Epoch 043 batch 00005: Loss 0.3733 Regression loss 0.0344 Classification loss 0.3388 AP 0.0653 AR 0.1083
Epoch 043 batch 00006: Loss 0.4381 Regression loss 0.0377 Classification loss 0.4004 AP 0.0167 AR 0.0250
Epoch 043 batch 00007: Loss 0.4664 Regression loss 0.0428 Classification loss 0.4235 AP 0.1033 AR 0.1667
Epoch 043 batch 00008: Loss 0.4051 Regression loss 0.0378 Classification loss 0.3673 AP 0.1601 AR 0.1117
Epoch 043 batch 00009: Loss 0.4247 Regression loss 0.0390 Classification loss 0.3857 AP 0.0292 AR 0.0450
Epoch 043 batch 00010: Loss 0.4223 Regression loss 0.0376 Classification loss 0.3848 AP 0.0250 AR 0.0500
Epoch 044 batch 00001: Loss 0.3914 Regression loss 0.0354 Classification loss 0.3560 AP 0.0458 AR 0.0700
Epoch 044 batch 00002: Loss 0.3845 Regression loss 0.0373 Classification loss 0.3472 AP 0.0254 AR 0.0450
Epoch 044 batch 00003: Loss 0.3750 Regression loss 0.0334 Classification loss 0.3416 AP 0.0491 AR 0.1083
Epoch 044 batch 00004: Loss 0.4270 Regression loss 0.0414 Classification loss 0.3856 AP 0.1533 AR 0.0667
Epoch 044 batch 00005: Loss 0.4448 Regression loss 0.0370 Classification loss 0.4078 AP 0.1000 AR 0.0000
Epoch 044 batch 00006: Loss 0.4247 Regression loss 0.0424 Classification loss 0.3824 AP 0.0687 AR 0.1417
Epoch 044 batch 00007: Loss 0.4305 Regression loss 0.0351 Classification loss 0.3953 AP 0.0225 AR 0.0400
Epoch 044 batch 00008: Loss 0.4181 Regression loss 0.0333 Classification loss 0.3847 AP 0.0125 AR 0.0200
Epoch 044 batch 00009: Loss 0.4295 Regression loss 0.0325 Classification loss 0.3970 AP 0.0100 AR 0.0200
Epoch 044 batch 00010: Loss 0.4266 Regression loss 0.0358 Classification loss 0.3907 AP 0.1817 AR 0.1250
Epoch 045 batch 00001: Loss 0.3933 Regression loss 0.0306 Classification loss 0.3627 AP 0.0500 AR 0.0667
Epoch 045 batch 00002: Loss 0.3999 Regression loss 0.0431 Classification loss 0.3568 AP 0.0367 AR 0.0533
Epoch 045 batch 00003: Loss 0.3775 Regression loss 0.0337 Classification loss 0.3438 AP 0.0350 AR 0.0700
Epoch 045 batch 00004: Loss 0.3805 Regression loss 0.0331 Classification loss 0.3473 AP 0.0941 AR 0.1767
Epoch 045 batch 00005: Loss 0.4273 Regression loss 0.0411 Classification loss 0.3862 AP 0.2268 AR 0.1400
Epoch 045 batch 00006: Loss 0.3804 Regression loss 0.0395 Classification loss 0.3409 AP 0.0861 AR 0.1167
Epoch 045 batch 00007: Loss 0.4186 Regression loss 0.0302 Classification loss 0.3884 AP 0.0111 AR 0.0250
Epoch 045 batch 00008: Loss 0.3890 Regression loss 0.0357 Classification loss 0.3534 AP 0.0125 AR 0.0250
Epoch 045 batch 00009: Loss 0.4217 Regression loss 0.0433 Classification loss 0.3784 AP 0.0167 AR 0.0333
Epoch 045 batch 00010: Loss 0.4320 Regression loss 0.0383 Classification loss 0.3937 AP 0.0978 AR 0.2083
Epoch 046 batch 00001: Loss 0.4034 Regression loss 0.0381 Classification loss 0.3653 AP 0.0700 AR 0.1500
Epoch 046 batch 00002: Loss 0.4080 Regression loss 0.0374 Classification loss 0.3706 AP 0.0367 AR 0.0583
Epoch 046 batch 00003: Loss 0.4108 Regression loss 0.0387 Classification loss 0.3720 AP 0.0551 AR 0.0983
Epoch 046 batch 00004: Loss 0.3735 Regression loss 0.0358 Classification loss 0.3377 AP 0.0569 AR 0.0950
Epoch 046 batch 00005: Loss 0.3727 Regression loss 0.0357 Classification loss 0.3370 AP 0.0643 AR 0.0950
Epoch 046 batch 00006: Loss 0.3750 Regression loss 0.0320 Classification loss 0.3430 AP 0.0000 AR 0.0000
Epoch 046 batch 00007: Loss 0.3894 Regression loss 0.0358 Classification loss 0.3537 AP 0.1389 AR 0.0733
Epoch 046 batch 00008: Loss 0.4123 Regression loss 0.0423 Classification loss 0.3699 AP 0.1412 AR 0.2083
Epoch 046 batch 00009: Loss 0.4008 Regression loss 0.0404 Classification loss 0.3604 AP 0.0111 AR 0.0250
Epoch 046 batch 00010: Loss 0.3994 Regression loss 0.0406 Classification loss 0.3588 AP 0.0583 AR 0.0733
Epoch 047 batch 00001: Loss 0.3907 Regression loss 0.0386 Classification loss 0.3520 AP 0.0369 AR 0.0750
Epoch 047 batch 00002: Loss 0.3719 Regression loss 0.0364 Classification loss 0.3355 AP 0.0734 AR 0.1517
Epoch 047 batch 00003: Loss 0.4052 Regression loss 0.0452 Classification loss 0.3599 AP 0.1593 AR 0.0933
Epoch 047 batch 00004: Loss 0.3746 Regression loss 0.0402 Classification loss 0.3344 AP 0.0867 AR 0.1333
Epoch 047 batch 00005: Loss 0.3928 Regression loss 0.0345 Classification loss 0.3582 AP 0.0760 AR 0.1283
Epoch 047 batch 00006: Loss 0.3889 Regression loss 0.0359 Classification loss 0.3530 AP 0.0417 AR 0.0700
Epoch 047 batch 00007: Loss 0.3915 Regression loss 0.0325 Classification loss 0.3591 AP 0.0518 AR 0.1000
Epoch 047 batch 00008: Loss 0.3793 Regression loss 0.0385 Classification loss 0.3408 AP 0.0549 AR 0.1117
Epoch 047 batch 00009: Loss 0.3705 Regression loss 0.0333 Classification loss 0.3372 AP 0.0000 AR 0.0000
Epoch 047 batch 00010: Loss 0.3764 Regression loss 0.0335 Classification loss 0.3429 AP 0.1143 AR 0.2200
Epoch 048 batch 00001: Loss 0.3978 Regression loss 0.0327 Classification loss 0.3651 AP 0.0624 AR 0.1083
Epoch 048 batch 00002: Loss 0.3791 Regression loss 0.0377 Classification loss 0.3414 AP 0.1250 AR 0.0333
Epoch 048 batch 00003: Loss 0.3746 Regression loss 0.0297 Classification loss 0.3449 AP 0.0543 AR 0.0917
Epoch 048 batch 00004: Loss 0.3946 Regression loss 0.0377 Classification loss 0.3569 AP 0.0528 AR 0.1083
Epoch 048 batch 00005: Loss 0.3808 Regression loss 0.0346 Classification loss 0.3461 AP 0.0397 AR 0.0733
Epoch 048 batch 00006: Loss 0.3580 Regression loss 0.0329 Classification loss 0.3251 AP 0.1208 AR 0.2750
Epoch 048 batch 00007: Loss 0.3722 Regression loss 0.0357 Classification loss 0.3365 AP 0.0672 AR 0.1350
Epoch 048 batch 00008: Loss 0.3739 Regression loss 0.0356 Classification loss 0.3382 AP 0.0435 AR 0.0700
Epoch 048 batch 00009: Loss 0.3687 Regression loss 0.0381 Classification loss 0.3305 AP 0.1244 AR 0.1783
Epoch 048 batch 00010: Loss 0.3676 Regression loss 0.0482 Classification loss 0.3193 AP 0.0587 AR 0.1117
Epoch 049 batch 00001: Loss 0.3677 Regression loss 0.0337 Classification loss 0.3340 AP 0.0436 AR 0.0917
Epoch 049 batch 00002: Loss 0.3712 Regression loss 0.0293 Classification loss 0.3419 AP 0.0575 AR 0.1200
Epoch 049 batch 00003: Loss 0.3465 Regression loss 0.0320 Classification loss 0.3145 AP 0.0786 AR 0.1500
Epoch 049 batch 00004: Loss 0.3822 Regression loss 0.0422 Classification loss 0.3401 AP 0.1200 AR 0.0500
Epoch 049 batch 00005: Loss 0.3801 Regression loss 0.0404 Classification loss 0.3397 AP 0.0292 AR 0.0533
Epoch 049 batch 00006: Loss 0.3541 Regression loss 0.0353 Classification loss 0.3188 AP 0.0268 AR 0.0533
Epoch 049 batch 00007: Loss 0.3786 Regression loss 0.0372 Classification loss 0.3414 AP 0.0643 AR 0.0917
Epoch 049 batch 00008: Loss 0.3957 Regression loss 0.0430 Classification loss 0.3528 AP 0.0286 AR 0.0667
Epoch 049 batch 00009: Loss 0.3617 Regression loss 0.0361 Classification loss 0.3257 AP 0.2095 AR 0.3350
Epoch 049 batch 00010: Loss 0.4055 Regression loss 0.0419 Classification loss 0.3636 AP 0.0236 AR 0.0583
Epoch 050 batch 00001: Loss 0.3725 Regression loss 0.0406 Classification loss 0.3320 AP 0.0125 AR 0.0200
Epoch 050 batch 00002: Loss 0.4037 Regression loss 0.0404 Classification loss 0.3633 AP 0.0486 AR 0.0950
Epoch 050 batch 00003: Loss 0.3517 Regression loss 0.0376 Classification loss 0.3141 AP 0.1483 AR 0.1867
Epoch 050 batch 00004: Loss 0.4037 Regression loss 0.0370 Classification loss 0.3667 AP 0.0667 AR 0.0900
Epoch 050 batch 00005: Loss 0.3893 Regression loss 0.0400 Classification loss 0.3494 AP 0.0643 AR 0.1167
Epoch 050 batch 00006: Loss 0.3323 Regression loss 0.0388 Classification loss 0.2935 AP 0.0801 AR 0.1367
Epoch 050 batch 00007: Loss 0.3674 Regression loss 0.0300 Classification loss 0.3373 AP 0.0792 AR 0.0867
Epoch 050 batch 00008: Loss 0.3534 Regression loss 0.0319 Classification loss 0.3215 AP 0.0250 AR 0.0500
Epoch 050 batch 00009: Loss 0.3110 Regression loss 0.0335 Classification loss 0.2775 AP 0.0740 AR 0.1233
Epoch 050 batch 00010: Loss 0.3740 Regression loss 0.0387 Classification loss 0.3353 AP 0.0278 AR 0.0500
Epoch 051 batch 00001: Loss 0.3513 Regression loss 0.0362 Classification loss 0.3151 AP 0.0200 AR 0.0200
Epoch 051 batch 00002: Loss 0.3382 Regression loss 0.0358 Classification loss 0.3025 AP 0.0771 AR 0.1467
Epoch 051 batch 00003: Loss 0.3509 Regression loss 0.0374 Classification loss 0.3135 AP 0.0833 AR 0.1667
Epoch 051 batch 00004: Loss 0.3309 Regression loss 0.0349 Classification loss 0.2961 AP 0.0397 AR 0.0783
Epoch 051 batch 00005: Loss 0.3306 Regression loss 0.0416 Classification loss 0.2890 AP 0.1250 AR 0.1500
Epoch 051 batch 00006: Loss 0.3760 Regression loss 0.0427 Classification loss 0.3333 AP 0.0250 AR 0.0500
Epoch 051 batch 00007: Loss 0.3660 Regression loss 0.0411 Classification loss 0.3249 AP 0.0333 AR 0.0500
Epoch 051 batch 00008: Loss 0.3432 Regression loss 0.0396 Classification loss 0.3036 AP 0.0533 AR 0.1167
Epoch 051 batch 00009: Loss 0.4103 Regression loss 0.0336 Classification loss 0.3767 AP 0.0361 AR 0.1200
Epoch 051 batch 00010: Loss 0.3511 Regression loss 0.0331 Classification loss 0.3180 AP 0.1271 AR 0.2250
Epoch 052 batch 00001: Loss 0.3971 Regression loss 0.0382 Classification loss 0.3589 AP 0.0458 AR 0.1250
Epoch 052 batch 00002: Loss 0.3664 Regression loss 0.0432 Classification loss 0.3232 AP 0.0000 AR 0.0000
Epoch 052 batch 00003: Loss 0.3579 Regression loss 0.0485 Classification loss 0.3094 AP 0.0500 AR 0.0667
Epoch 052 batch 00004: Loss 0.3433 Regression loss 0.0353 Classification loss 0.3080 AP 0.0591 AR 0.1050
Epoch 052 batch 00005: Loss 0.3492 Regression loss 0.0449 Classification loss 0.3043 AP 0.1103 AR 0.1783
Epoch 052 batch 00006: Loss 0.3341 Regression loss 0.0374 Classification loss 0.2967 AP 0.1069 AR 0.2100
Epoch 052 batch 00007: Loss 0.3395 Regression loss 0.0384 Classification loss 0.3011 AP 0.0182 AR 0.0500
Epoch 052 batch 00008: Loss 0.3425 Regression loss 0.0366 Classification loss 0.3058 AP 0.0493 AR 0.1000
Epoch 052 batch 00009: Loss 0.3451 Regression loss 0.0345 Classification loss 0.3107 AP 0.1411 AR 0.1917
Epoch 052 batch 00010: Loss 0.3741 Regression loss 0.0399 Classification loss 0.3342 AP 0.0750 AR 0.1500
Epoch 053 batch 00001: Loss 0.3311 Regression loss 0.0367 Classification loss 0.2944 AP 0.0560 AR 0.1000
Epoch 053 batch 00002: Loss 0.3714 Regression loss 0.0339 Classification loss 0.3375 AP 0.0250 AR 0.0500
Epoch 053 batch 00003: Loss 0.3344 Regression loss 0.0341 Classification loss 0.3004 AP 0.0744 AR 0.1500
Epoch 053 batch 00004: Loss 0.3579 Regression loss 0.0414 Classification loss 0.3165 AP 0.0705 AR 0.1567
Epoch 053 batch 00005: Loss 0.3792 Regression loss 0.0418 Classification loss 0.3374 AP 0.0589 AR 0.1750
Epoch 053 batch 00006: Loss 0.3554 Regression loss 0.0379 Classification loss 0.3175 AP 0.0327 AR 0.1200
Epoch 053 batch 00007: Loss 0.3041 Regression loss 0.0350 Classification loss 0.2692 AP 0.0486 AR 0.0950
Epoch 053 batch 00008: Loss 0.3456 Regression loss 0.0337 Classification loss 0.3119 AP 0.1000 AR 0.1533
Epoch 053 batch 00009: Loss 0.3097 Regression loss 0.0401 Classification loss 0.2696 AP 0.0867 AR 0.1333
Epoch 053 batch 00010: Loss 0.3731 Regression loss 0.0375 Classification loss 0.3356 AP 0.1075 AR 0.1783
Epoch 054 batch 00001: Loss 0.3287 Regression loss 0.0374 Classification loss 0.2913 AP 0.0475 AR 0.1083
Epoch 054 batch 00002: Loss 0.3071 Regression loss 0.0309 Classification loss 0.2761 AP 0.0310 AR 0.0533
Epoch 054 batch 00003: Loss 0.3299 Regression loss 0.0429 Classification loss 0.2869 AP 0.0867 AR 0.1500
Epoch 054 batch 00004: Loss 0.3180 Regression loss 0.0360 Classification loss 0.2820 AP 0.0743 AR 0.0900
Epoch 054 batch 00005: Loss 0.3471 Regression loss 0.0354 Classification loss 0.3117 AP 0.0681 AR 0.1150
Epoch 054 batch 00006: Loss 0.3479 Regression loss 0.0444 Classification loss 0.3036 AP 0.0411 AR 0.0783
Epoch 054 batch 00007: Loss 0.3364 Regression loss 0.0364 Classification loss 0.2999 AP 0.0825 AR 0.1750
Epoch 054 batch 00008: Loss 0.3607 Regression loss 0.0379 Classification loss 0.3228 AP 0.0365 AR 0.0750
Epoch 054 batch 00009: Loss 0.3656 Regression loss 0.0361 Classification loss 0.3295 AP 0.0643 AR 0.1200
Epoch 054 batch 00010: Loss 0.3515 Regression loss 0.0376 Classification loss 0.3139 AP 0.0736 AR 0.1033
Epoch 055 batch 00001: Loss 0.3568 Regression loss 0.0354 Classification loss 0.3215 AP 0.0476 AR 0.1333
Epoch 055 batch 00002: Loss 0.3302 Regression loss 0.0390 Classification loss 0.2912 AP 0.0772 AR 0.1483
Epoch 055 batch 00003: Loss 0.3111 Regression loss 0.0370 Classification loss 0.2741 AP 0.0508 AR 0.1033
Epoch 055 batch 00004: Loss 0.3393 Regression loss 0.0364 Classification loss 0.3029 AP 0.0900 AR 0.2500
Epoch 055 batch 00005: Loss 0.3467 Regression loss 0.0362 Classification loss 0.3105 AP 0.0825 AR 0.1583
Epoch 055 batch 00006: Loss 0.3312 Regression loss 0.0377 Classification loss 0.2935 AP 0.0325 AR 0.0750
Epoch 055 batch 00007: Loss 0.3393 Regression loss 0.0385 Classification loss 0.3007 AP 0.0843 AR 0.1583
Epoch 055 batch 00008: Loss 0.3518 Regression loss 0.0402 Classification loss 0.3116 AP 0.0333 AR 0.0333
Epoch 055 batch 00009: Loss 0.3466 Regression loss 0.0311 Classification loss 0.3155 AP 0.0624 AR 0.1083
Epoch 055 batch 00010: Loss 0.3003 Regression loss 0.0392 Classification loss 0.2611 AP 0.0643 AR 0.1333
Epoch 056 batch 00001: Loss 0.3121 Regression loss 0.0359 Classification loss 0.2762 AP 0.0851 AR 0.1433
Epoch 056 batch 00002: Loss 0.3001 Regression loss 0.0341 Classification loss 0.2660 AP 0.0783 AR 0.1483
Epoch 056 batch 00003: Loss 0.3132 Regression loss 0.0419 Classification loss 0.2714 AP 0.0536 AR 0.1033
Epoch 056 batch 00004: Loss 0.3206 Regression loss 0.0370 Classification loss 0.2836 AP 0.0875 AR 0.1750
Epoch 056 batch 00005: Loss 0.3282 Regression loss 0.0435 Classification loss 0.2847 AP 0.0367 AR 0.0533
Epoch 056 batch 00006: Loss 0.3454 Regression loss 0.0379 Classification loss 0.3075 AP 0.1429 AR 0.3000
Epoch 056 batch 00007: Loss 0.3438 Regression loss 0.0347 Classification loss 0.3091 AP 0.0243 AR 0.0500
Epoch 056 batch 00008: Loss 0.3605 Regression loss 0.0411 Classification loss 0.3195 AP 0.0450 AR 0.0667
Epoch 056 batch 00009: Loss 0.3764 Regression loss 0.0368 Classification loss 0.3396 AP 0.0561 AR 0.1200
Epoch 056 batch 00010: Loss 0.3181 Regression loss 0.0316 Classification loss 0.2865 AP 0.1100 AR 0.1750
Epoch 057 batch 00001: Loss 0.3183 Regression loss 0.0368 Classification loss 0.2815 AP 0.0736 AR 0.1233
Epoch 057 batch 00002: Loss 0.3099 Regression loss 0.0379 Classification loss 0.2720 AP 0.1661 AR 0.2233
Epoch 057 batch 00003: Loss 0.3352 Regression loss 0.0338 Classification loss 0.3014 AP 0.0700 AR 0.1250
Epoch 057 batch 00004: Loss 0.3341 Regression loss 0.0377 Classification loss 0.2964 AP 0.0350 AR 0.0733
Epoch 057 batch 00005: Loss 0.3116 Regression loss 0.0339 Classification loss 0.2777 AP 0.0810 AR 0.1667
Epoch 057 batch 00006: Loss 0.3226 Regression loss 0.0356 Classification loss 0.2870 AP 0.0476 AR 0.0833
Epoch 057 batch 00007: Loss 0.3284 Regression loss 0.0359 Classification loss 0.2925 AP 0.1475 AR 0.1283
Epoch 057 batch 00008: Loss 0.3000 Regression loss 0.0379 Classification loss 0.2621 AP 0.0347 AR 0.0750
Epoch 057 batch 00009: Loss 0.3529 Regression loss 0.0315 Classification loss 0.3214 AP 0.0903 AR 0.1600
Epoch 057 batch 00010: Loss 0.3500 Regression loss 0.0367 Classification loss 0.3132 AP 0.0778 AR 0.1083
Epoch 058 batch 00001: Loss 0.3258 Regression loss 0.0391 Classification loss 0.2868 AP 0.0111 AR 0.0333
Epoch 058 batch 00002: Loss 0.3283 Regression loss 0.0322 Classification loss 0.2961 AP 0.1067 AR 0.1917
Epoch 058 batch 00003: Loss 0.3323 Regression loss 0.0385 Classification loss 0.2938 AP 0.0310 AR 0.0533
Epoch 058 batch 00004: Loss 0.2830 Regression loss 0.0350 Classification loss 0.2480 AP 0.0500 AR 0.0900
Epoch 058 batch 00005: Loss 0.3351 Regression loss 0.0365 Classification loss 0.2985 AP 0.0608 AR 0.1400
Epoch 058 batch 00006: Loss 0.3115 Regression loss 0.0418 Classification loss 0.2697 AP 0.0783 AR 0.1000
Epoch 058 batch 00007: Loss 0.3395 Regression loss 0.0353 Classification loss 0.3041 AP 0.0411 AR 0.0833
Epoch 058 batch 00008: Loss 0.3313 Regression loss 0.0306 Classification loss 0.3007 AP 0.0700 AR 0.1750
Epoch 058 batch 00009: Loss 0.3246 Regression loss 0.0356 Classification loss 0.2890 AP 0.1365 AR 0.2600
Epoch 058 batch 00010: Loss 0.3218 Regression loss 0.0364 Classification loss 0.2854 AP 0.0347 AR 0.0833
Epoch 059 batch 00001: Loss 0.3123 Regression loss 0.0374 Classification loss 0.2749 AP 0.0601 AR 0.1000
Epoch 059 batch 00002: Loss 0.3441 Regression loss 0.0425 Classification loss 0.3015 AP 0.1018 AR 0.2450
Epoch 059 batch 00003: Loss 0.3429 Regression loss 0.0463 Classification loss 0.2965 AP 0.0452 AR 0.1083
Epoch 059 batch 00004: Loss 0.3225 Regression loss 0.0380 Classification loss 0.2845 AP 0.1083 AR 0.1733
Epoch 059 batch 00005: Loss 0.3044 Regression loss 0.0336 Classification loss 0.2709 AP 0.0533 AR 0.1167
Epoch 059 batch 00006: Loss 0.2891 Regression loss 0.0378 Classification loss 0.2513 AP 0.0617 AR 0.1667
Epoch 059 batch 00007: Loss 0.3540 Regression loss 0.0396 Classification loss 0.3144 AP 0.0922 AR 0.1833
Epoch 059 batch 00008: Loss 0.3229 Regression loss 0.0334 Classification loss 0.2896 AP 0.0379 AR 0.0783
Epoch 059 batch 00009: Loss 0.3149 Regression loss 0.0379 Classification loss 0.2770 AP 0.0347 AR 0.0833
Epoch 059 batch 00010: Loss 0.3219 Regression loss 0.0338 Classification loss 0.2881 AP 0.0601 AR 0.1500
Epoch 060 batch 00001: Loss 0.2978 Regression loss 0.0357 Classification loss 0.2621 AP 0.1008 AR 0.1533
Epoch 060 batch 00002: Loss 0.3381 Regression loss 0.0370 Classification loss 0.3011 AP 0.0411 AR 0.0917
Epoch 060 batch 00003: Loss 0.3515 Regression loss 0.0421 Classification loss 0.3094 AP 0.1100 AR 0.1200
Epoch 060 batch 00004: Loss 0.3444 Regression loss 0.0423 Classification loss 0.3020 AP 0.0111 AR 0.0200
Epoch 060 batch 00005: Loss 0.2863 Regression loss 0.0326 Classification loss 0.2537 AP 0.0611 AR 0.1283
Epoch 060 batch 00006: Loss 0.2966 Regression loss 0.0349 Classification loss 0.2618 AP 0.1075 AR 0.2583
Epoch 060 batch 00007: Loss 0.3375 Regression loss 0.0373 Classification loss 0.3003 AP 0.0575 AR 0.1083
Epoch 060 batch 00008: Loss 0.3142 Regression loss 0.0374 Classification loss 0.2768 AP 0.0500 AR 0.0583
Epoch 060 batch 00009: Loss 0.3339 Regression loss 0.0396 Classification loss 0.2943 AP 0.0311 AR 0.0750
Epoch 060 batch 00010: Loss 0.3113 Regression loss 0.0400 Classification loss 0.2713 AP 0.0643 AR 0.1333
Epoch 061 batch 00001: Loss 0.3034 Regression loss 0.0352 Classification loss 0.2682 AP 0.1101 AR 0.1917
Epoch 061 batch 00002: Loss 0.2889 Regression loss 0.0396 Classification loss 0.2493 AP 0.0528 AR 0.1667
Epoch 061 batch 00003: Loss 0.3323 Regression loss 0.0357 Classification loss 0.2966 AP 0.0488 AR 0.0950
Epoch 061 batch 00004: Loss 0.3383 Regression loss 0.0397 Classification loss 0.2986 AP 0.0325 AR 0.0700
Epoch 061 batch 00005: Loss 0.3180 Regression loss 0.0406 Classification loss 0.2774 AP 0.0167 AR 0.0200
Epoch 061 batch 00006: Loss 0.3005 Regression loss 0.0418 Classification loss 0.2587 AP 0.0936 AR 0.1667
Epoch 061 batch 00007: Loss 0.2953 Regression loss 0.0375 Classification loss 0.2578 AP 0.0827 AR 0.1617
Epoch 061 batch 00008: Loss 0.3028 Regression loss 0.0338 Classification loss 0.2691 AP 0.0637 AR 0.1183
Epoch 061 batch 00009: Loss 0.3349 Regression loss 0.0345 Classification loss 0.3005 AP 0.0211 AR 0.0500
Epoch 061 batch 00010: Loss 0.3046 Regression loss 0.0363 Classification loss 0.2683 AP 0.0433 AR 0.1200
Epoch 062 batch 00001: Loss 0.2932 Regression loss 0.0312 Classification loss 0.2620 AP 0.1042 AR 0.1900
Epoch 062 batch 00002: Loss 0.3193 Regression loss 0.0456 Classification loss 0.2737 AP 0.0325 AR 0.0700
Epoch 062 batch 00003: Loss 0.3300 Regression loss 0.0375 Classification loss 0.2925 AP 0.1476 AR 0.2983
Epoch 062 batch 00004: Loss 0.2928 Regression loss 0.0350 Classification loss 0.2578 AP 0.0661 AR 0.1250
Epoch 062 batch 00005: Loss 0.2692 Regression loss 0.0352 Classification loss 0.2340 AP 0.0967 AR 0.1867
Epoch 062 batch 00006: Loss 0.3004 Regression loss 0.0343 Classification loss 0.2661 AP 0.0549 AR 0.1367
Epoch 062 batch 00007: Loss 0.3170 Regression loss 0.0376 Classification loss 0.2794 AP 0.0322 AR 0.0650
Epoch 062 batch 00008: Loss 0.3413 Regression loss 0.0376 Classification loss 0.3037 AP 0.0125 AR 0.0333
Epoch 062 batch 00009: Loss 0.3187 Regression loss 0.0386 Classification loss 0.2801 AP 0.0167 AR 0.0333
Epoch 062 batch 00010: Loss 0.2718 Regression loss 0.0367 Classification loss 0.2351 AP 0.0625 AR 0.1200
Epoch 063 batch 00001: Loss 0.2769 Regression loss 0.0375 Classification loss 0.2394 AP 0.1200 AR 0.2117
Epoch 063 batch 00002: Loss 0.3080 Regression loss 0.0372 Classification loss 0.2708 AP 0.0950 AR 0.1833
Epoch 063 batch 00003: Loss 0.3026 Regression loss 0.0359 Classification loss 0.2667 AP 0.0733 AR 0.1083
Epoch 063 batch 00004: Loss 0.3107 Regression loss 0.0391 Classification loss 0.2716 AP 0.0507 AR 0.1417
Epoch 063 batch 00005: Loss 0.3207 Regression loss 0.0359 Classification loss 0.2848 AP 0.0683 AR 0.1150
Epoch 063 batch 00006: Loss 0.3059 Regression loss 0.0359 Classification loss 0.2699 AP 0.1025 AR 0.2167
Epoch 063 batch 00007: Loss 0.3033 Regression loss 0.0361 Classification loss 0.2672 AP 0.0897 AR 0.1700
Epoch 063 batch 00008: Loss 0.2683 Regression loss 0.0370 Classification loss 0.2313 AP 0.0841 AR 0.1483
Epoch 063 batch 00009: Loss 0.2829 Regression loss 0.0329 Classification loss 0.2500 AP 0.1294 AR 0.1200
Epoch 063 batch 00010: Loss 0.3326 Regression loss 0.0376 Classification loss 0.2951 AP 0.0895 AR 0.1567
Epoch 064 batch 00001: Loss 0.2999 Regression loss 0.0343 Classification loss 0.2656 AP 0.1533 AR 0.1950
Epoch 064 batch 00002: Loss 0.3110 Regression loss 0.0402 Classification loss 0.2709 AP 0.1222 AR 0.1500
Epoch 064 batch 00003: Loss 0.2860 Regression loss 0.0306 Classification loss 0.2554 AP 0.0400 AR 0.1000
Epoch 064 batch 00004: Loss 0.3033 Regression loss 0.0348 Classification loss 0.2685 AP 0.0236 AR 0.0500
Epoch 064 batch 00005: Loss 0.3211 Regression loss 0.0373 Classification loss 0.2838 AP 0.0233 AR 0.0583
Epoch 064 batch 00006: Loss 0.2754 Regression loss 0.0394 Classification loss 0.2361 AP 0.0341 AR 0.0533
Epoch 064 batch 00007: Loss 0.2907 Regression loss 0.0399 Classification loss 0.2507 AP 0.0587 AR 0.1033
Epoch 064 batch 00008: Loss 0.3361 Regression loss 0.0369 Classification loss 0.2992 AP 0.0311 AR 0.0750
Epoch 064 batch 00009: Loss 0.3114 Regression loss 0.0392 Classification loss 0.2722 AP 0.0702 AR 0.1783
Epoch 064 batch 00010: Loss 0.3214 Regression loss 0.0371 Classification loss 0.2843 AP 0.0700 AR 0.1533
Epoch 065 batch 00001: Loss 0.3392 Regression loss 0.0354 Classification loss 0.3038 AP 0.0867 AR 0.1367
Epoch 065 batch 00002: Loss 0.3151 Regression loss 0.0370 Classification loss 0.2781 AP 0.0458 AR 0.0833
Epoch 065 batch 00003: Loss 0.2834 Regression loss 0.0427 Classification loss 0.2406 AP 0.0619 AR 0.1250
Epoch 065 batch 00004: Loss 0.2724 Regression loss 0.0368 Classification loss 0.2356 AP 0.0424 AR 0.0750
Epoch 065 batch 00005: Loss 0.2660 Regression loss 0.0422 Classification loss 0.2238 AP 0.1619 AR 0.2583
Epoch 065 batch 00006: Loss 0.2801 Regression loss 0.0325 Classification loss 0.2476 AP 0.1333 AR 0.1750
Epoch 065 batch 00007: Loss 0.3097 Regression loss 0.0344 Classification loss 0.2752 AP 0.1086 AR 0.2350
Epoch 065 batch 00008: Loss 0.3028 Regression loss 0.0362 Classification loss 0.2665 AP 0.0508 AR 0.0950
Epoch 065 batch 00009: Loss 0.3067 Regression loss 0.0399 Classification loss 0.2669 AP 0.0071 AR 0.0200
Epoch 065 batch 00010: Loss 0.2709 Regression loss 0.0452 Classification loss 0.2258 AP 0.0278 AR 0.0533
Epoch 066 batch 00001: Loss 0.3530 Regression loss 0.0413 Classification loss 0.3116 AP 0.0236 AR 0.0583
Epoch 066 batch 00002: Loss 0.2879 Regression loss 0.0419 Classification loss 0.2460 AP 0.0878 AR 0.1333
Epoch 066 batch 00003: Loss 0.3149 Regression loss 0.0417 Classification loss 0.2732 AP 0.0619 AR 0.0733
Epoch 066 batch 00004: Loss 0.3141 Regression loss 0.0329 Classification loss 0.2812 AP 0.0250 AR 0.0583
Epoch 066 batch 00005: Loss 0.2862 Regression loss 0.0297 Classification loss 0.2565 AP 0.0543 AR 0.0917
Epoch 066 batch 00006: Loss 0.2727 Regression loss 0.0429 Classification loss 0.2298 AP 0.1244 AR 0.2200
Epoch 066 batch 00007: Loss 0.2839 Regression loss 0.0482 Classification loss 0.2357 AP 0.0091 AR 0.0200
Epoch 066 batch 00008: Loss 0.2720 Regression loss 0.0374 Classification loss 0.2346 AP 0.0922 AR 0.1767
Epoch 066 batch 00009: Loss 0.3035 Regression loss 0.0362 Classification loss 0.2673 AP 0.0468 AR 0.1083
Epoch 066 batch 00010: Loss 0.2875 Regression loss 0.0378 Classification loss 0.2497 AP 0.1325 AR 0.1700
Epoch 067 batch 00001: Loss 0.2596 Regression loss 0.0369 Classification loss 0.2228 AP 0.0504 AR 0.1083
Epoch 067 batch 00002: Loss 0.2882 Regression loss 0.0331 Classification loss 0.2551 AP 0.0300 AR 0.0700
Epoch 067 batch 00003: Loss 0.2780 Regression loss 0.0422 Classification loss 0.2358 AP 0.0733 AR 0.1450
Epoch 067 batch 00004: Loss 0.2733 Regression loss 0.0393 Classification loss 0.2339 AP 0.0433 AR 0.0700
Epoch 067 batch 00005: Loss 0.3274 Regression loss 0.0418 Classification loss 0.2856 AP 0.0600 AR 0.1000
Epoch 067 batch 00006: Loss 0.2549 Regression loss 0.0265 Classification loss 0.2284 AP 0.1222 AR 0.2167
Epoch 067 batch 00007: Loss 0.2729 Regression loss 0.0387 Classification loss 0.2341 AP 0.0397 AR 0.0783
Epoch 067 batch 00008: Loss 0.3072 Regression loss 0.0379 Classification loss 0.2692 AP 0.0698 AR 0.1733
Epoch 067 batch 00009: Loss 0.3004 Regression loss 0.0431 Classification loss 0.2573 AP 0.0650 AR 0.1200
Epoch 067 batch 00010: Loss 0.3229 Regression loss 0.0311 Classification loss 0.2918 AP 0.0292 AR 0.0650
Epoch 068 batch 00001: Loss 0.2744 Regression loss 0.0376 Classification loss 0.2368 AP 0.2055 AR 0.3750
Epoch 068 batch 00002: Loss 0.2896 Regression loss 0.0440 Classification loss 0.2456 AP 0.0500 AR 0.0833
Epoch 068 batch 00003: Loss 0.2924 Regression loss 0.0363 Classification loss 0.2561 AP 0.1219 AR 0.1933
Epoch 068 batch 00004: Loss 0.3000 Regression loss 0.0390 Classification loss 0.2610 AP 0.0851 AR 0.1350
Epoch 068 batch 00005: Loss 0.2442 Regression loss 0.0379 Classification loss 0.2062 AP 0.0500 AR 0.0983
Epoch 068 batch 00006: Loss 0.3075 Regression loss 0.0342 Classification loss 0.2733 AP 0.1136 AR 0.2000
Epoch 068 batch 00007: Loss 0.2700 Regression loss 0.0356 Classification loss 0.2344 AP 0.0810 AR 0.1833
Epoch 068 batch 00008: Loss 0.3051 Regression loss 0.0361 Classification loss 0.2690 AP 0.0769 AR 0.1500
Epoch 068 batch 00009: Loss 0.2815 Regression loss 0.0358 Classification loss 0.2458 AP 0.0268 AR 0.0583
Epoch 068 batch 00010: Loss 0.2766 Regression loss 0.0387 Classification loss 0.2379 AP 0.0450 AR 0.0800
Epoch 069 batch 00001: Loss 0.2616 Regression loss 0.0361 Classification loss 0.2255 AP 0.0927 AR 0.1783
Epoch 069 batch 00002: Loss 0.2541 Regression loss 0.0330 Classification loss 0.2212 AP 0.1385 AR 0.2033
Epoch 069 batch 00003: Loss 0.3122 Regression loss 0.0374 Classification loss 0.2748 AP 0.0655 AR 0.1833
Epoch 069 batch 00004: Loss 0.2756 Regression loss 0.0390 Classification loss 0.2366 AP 0.0843 AR 0.1167
Epoch 069 batch 00005: Loss 0.3135 Regression loss 0.0356 Classification loss 0.2779 AP 0.0468 AR 0.1200
Epoch 069 batch 00006: Loss 0.3027 Regression loss 0.0348 Classification loss 0.2679 AP 0.0191 AR 0.0400
Epoch 069 batch 00007: Loss 0.2872 Regression loss 0.0308 Classification loss 0.2564 AP 0.1258 AR 0.1533
Epoch 069 batch 00008: Loss 0.2710 Regression loss 0.0402 Classification loss 0.2308 AP 0.1080 AR 0.2583
Epoch 069 batch 00009: Loss 0.2658 Regression loss 0.0344 Classification loss 0.2314 AP 0.0803 AR 0.1917
Epoch 069 batch 00010: Loss 0.2490 Regression loss 0.0381 Classification loss 0.2108 AP 0.1611 AR 0.2300
Epoch 070 batch 00001: Loss 0.2604 Regression loss 0.0338 Classification loss 0.2266 AP 0.0410 AR 0.1250
Epoch 070 batch 00002: Loss 0.2823 Regression loss 0.0329 Classification loss 0.2494 AP 0.1268 AR 0.1667
Epoch 070 batch 00003: Loss 0.3015 Regression loss 0.0371 Classification loss 0.2644 AP 0.0306 AR 0.0700
Epoch 070 batch 00004: Loss 0.2906 Regression loss 0.0369 Classification loss 0.2537 AP 0.1771 AR 0.2233
Epoch 070 batch 00005: Loss 0.2645 Regression loss 0.0370 Classification loss 0.2275 AP 0.0667 AR 0.1417
Epoch 070 batch 00006: Loss 0.2533 Regression loss 0.0350 Classification loss 0.2184 AP 0.0254 AR 0.0583
Epoch 070 batch 00007: Loss 0.2912 Regression loss 0.0373 Classification loss 0.2539 AP 0.1050 AR 0.2267
Epoch 070 batch 00008: Loss 0.2571 Regression loss 0.0337 Classification loss 0.2234 AP 0.0533 AR 0.1000
Epoch 070 batch 00009: Loss 0.2579 Regression loss 0.0402 Classification loss 0.2177 AP 0.0728 AR 0.1150
Epoch 070 batch 00010: Loss 0.3009 Regression loss 0.0387 Classification loss 0.2622 AP 0.0389 AR 0.0950
Epoch 071 batch 00001: Loss 0.2513 Regression loss 0.0379 Classification loss 0.2133 AP 0.0617 AR 0.2000
Epoch 071 batch 00002: Loss 0.2608 Regression loss 0.0360 Classification loss 0.2247 AP 0.0598 AR 0.1400
Epoch 071 batch 00003: Loss 0.2374 Regression loss 0.0343 Classification loss 0.2030 AP 0.0633 AR 0.1250
Epoch 071 batch 00004: Loss 0.2662 Regression loss 0.0370 Classification loss 0.2292 AP 0.0576 AR 0.1200
Epoch 071 batch 00005: Loss 0.2918 Regression loss 0.0394 Classification loss 0.2524 AP 0.0674 AR 0.1550
Epoch 071 batch 00006: Loss 0.2650 Regression loss 0.0359 Classification loss 0.2291 AP 0.1250 AR 0.1667
Epoch 071 batch 00007: Loss 0.2798 Regression loss 0.0396 Classification loss 0.2402 AP 0.0874 AR 0.2167
Epoch 071 batch 00008: Loss 0.2765 Regression loss 0.0328 Classification loss 0.2437 AP 0.0865 AR 0.1950
Epoch 071 batch 00009: Loss 0.3226 Regression loss 0.0396 Classification loss 0.2830 AP 0.1403 AR 0.1700
Epoch 071 batch 00010: Loss 0.2779 Regression loss 0.0356 Classification loss 0.2423 AP 0.0472 AR 0.0983
Epoch 072 batch 00001: Loss 0.2861 Regression loss 0.0329 Classification loss 0.2532 AP 0.1056 AR 0.1900
Epoch 072 batch 00002: Loss 0.3056 Regression loss 0.0404 Classification loss 0.2652 AP 0.0587 AR 0.0783
Epoch 072 batch 00003: Loss 0.2758 Regression loss 0.0393 Classification loss 0.2364 AP 0.1110 AR 0.2283
Epoch 072 batch 00004: Loss 0.2685 Regression loss 0.0348 Classification loss 0.2336 AP 0.1416 AR 0.3900
Epoch 072 batch 00005: Loss 0.2689 Regression loss 0.0404 Classification loss 0.2285 AP 0.1938 AR 0.2867
Epoch 072 batch 00006: Loss 0.2486 Regression loss 0.0337 Classification loss 0.2149 AP 0.0740 AR 0.1650
Epoch 072 batch 00007: Loss 0.2680 Regression loss 0.0346 Classification loss 0.2334 AP 0.0564 AR 0.1100
Epoch 072 batch 00008: Loss 0.2668 Regression loss 0.0389 Classification loss 0.2280 AP 0.0950 AR 0.1700
Epoch 072 batch 00009: Loss 0.2432 Regression loss 0.0342 Classification loss 0.2090 AP 0.0393 AR 0.0833
Epoch 072 batch 00010: Loss 0.3001 Regression loss 0.0376 Classification loss 0.2624 AP 0.0794 AR 0.1700
Epoch 073 batch 00001: Loss 0.2606 Regression loss 0.0334 Classification loss 0.2272 AP 0.0572 AR 0.1317
Epoch 073 batch 00002: Loss 0.3006 Regression loss 0.0350 Classification loss 0.2656 AP 0.1000 AR 0.1000
Epoch 073 batch 00003: Loss 0.2452 Regression loss 0.0265 Classification loss 0.2187 AP 0.1000 AR 0.2000
Epoch 073 batch 00004: Loss 0.2558 Regression loss 0.0410 Classification loss 0.2148 AP 0.0655 AR 0.2200
Epoch 073 batch 00005: Loss 0.2883 Regression loss 0.0354 Classification loss 0.2529 AP 0.0322 AR 0.0783
Epoch 073 batch 00006: Loss 0.3103 Regression loss 0.0371 Classification loss 0.2732 AP 0.1202 AR 0.1450
Epoch 073 batch 00007: Loss 0.2477 Regression loss 0.0339 Classification loss 0.2138 AP 0.0956 AR 0.2500
Epoch 073 batch 00008: Loss 0.2661 Regression loss 0.0393 Classification loss 0.2268 AP 0.0611 AR 0.1417
Epoch 073 batch 00009: Loss 0.2651 Regression loss 0.0401 Classification loss 0.2250 AP 0.1089 AR 0.2283
Epoch 073 batch 00010: Loss 0.2664 Regression loss 0.0372 Classification loss 0.2291 AP 0.0591 AR 0.1650
Epoch 074 batch 00001: Loss 0.2963 Regression loss 0.0331 Classification loss 0.2633 AP 0.0936 AR 0.2400
Epoch 074 batch 00002: Loss 0.2502 Regression loss 0.0314 Classification loss 0.2189 AP 0.0493 AR 0.1083
Epoch 074 batch 00003: Loss 0.2847 Regression loss 0.0378 Classification loss 0.2469 AP 0.2000 AR 0.3283
Epoch 074 batch 00004: Loss 0.2632 Regression loss 0.0405 Classification loss 0.2227 AP 0.0811 AR 0.1983
Epoch 074 batch 00005: Loss 0.2789 Regression loss 0.0389 Classification loss 0.2400 AP 0.0713 AR 0.1517
Epoch 074 batch 00006: Loss 0.2492 Regression loss 0.0362 Classification loss 0.2130 AP 0.0458 AR 0.0900
Epoch 074 batch 00007: Loss 0.2795 Regression loss 0.0396 Classification loss 0.2399 AP 0.0311 AR 0.0750
Epoch 074 batch 00008: Loss 0.2647 Regression loss 0.0387 Classification loss 0.2260 AP 0.0000 AR 0.0000
Epoch 074 batch 00009: Loss 0.2645 Regression loss 0.0360 Classification loss 0.2286 AP 0.0855 AR 0.1667
Epoch 074 batch 00010: Loss 0.2681 Regression loss 0.0336 Classification loss 0.2345 AP 0.0425 AR 0.0950
Epoch 075 batch 00001: Loss 0.2326 Regression loss 0.0369 Classification loss 0.1957 AP 0.0905 AR 0.1667
Epoch 075 batch 00002: Loss 0.2596 Regression loss 0.0366 Classification loss 0.2229 AP 0.0503 AR 0.0983
Epoch 075 batch 00003: Loss 0.2280 Regression loss 0.0296 Classification loss 0.1983 AP 0.2078 AR 0.4033
Epoch 075 batch 00004: Loss 0.2520 Regression loss 0.0365 Classification loss 0.2155 AP 0.1989 AR 0.3317
Epoch 075 batch 00005: Loss 0.2560 Regression loss 0.0404 Classification loss 0.2156 AP 0.0444 AR 0.1200
Epoch 075 batch 00006: Loss 0.2602 Regression loss 0.0362 Classification loss 0.2240 AP 0.0655 AR 0.1300
Epoch 075 batch 00007: Loss 0.2967 Regression loss 0.0347 Classification loss 0.2621 AP 0.0071 AR 0.0250
Epoch 075 batch 00008: Loss 0.3072 Regression loss 0.0376 Classification loss 0.2696 AP 0.0462 AR 0.1100
Epoch 075 batch 00009: Loss 0.2660 Regression loss 0.0397 Classification loss 0.2263 AP 0.0636 AR 0.1450
Epoch 075 batch 00010: Loss 0.2755 Regression loss 0.0386 Classification loss 0.2368 AP 0.0893 AR 0.1433
Epoch 076 batch 00001: Loss 0.2444 Regression loss 0.0307 Classification loss 0.2137 AP 0.1450 AR 0.1833
Epoch 076 batch 00002: Loss 0.2692 Regression loss 0.0377 Classification loss 0.2315 AP 0.1041 AR 0.2017
Epoch 076 batch 00003: Loss 0.2692 Regression loss 0.0314 Classification loss 0.2378 AP 0.2094 AR 0.2983
Epoch 076 batch 00004: Loss 0.2463 Regression loss 0.0345 Classification loss 0.2118 AP 0.1147 AR 0.2483
Epoch 076 batch 00005: Loss 0.2676 Regression loss 0.0406 Classification loss 0.2270 AP 0.0739 AR 0.1617
Epoch 076 batch 00006: Loss 0.2419 Regression loss 0.0344 Classification loss 0.2075 AP 0.2988 AR 0.3533
Epoch 076 batch 00007: Loss 0.3031 Regression loss 0.0444 Classification loss 0.2587 AP 0.1194 AR 0.1450
Epoch 076 batch 00008: Loss 0.2650 Regression loss 0.0401 Classification loss 0.2249 AP 0.0921 AR 0.2283
Epoch 076 batch 00009: Loss 0.2353 Regression loss 0.0330 Classification loss 0.2023 AP 0.1310 AR 0.2867
Epoch 076 batch 00010: Loss 0.2573 Regression loss 0.0367 Classification loss 0.2206 AP 0.0679 AR 0.1283
Epoch 077 batch 00001: Loss 0.2357 Regression loss 0.0386 Classification loss 0.1971 AP 0.0672 AR 0.1900
Epoch 077 batch 00002: Loss 0.2547 Regression loss 0.0380 Classification loss 0.2166 AP 0.0933 AR 0.1733
Epoch 077 batch 00003: Loss 0.2865 Regression loss 0.0327 Classification loss 0.2539 AP 0.1243 AR 0.1583
Epoch 077 batch 00004: Loss 0.2584 Regression loss 0.0399 Classification loss 0.2185 AP 0.1194 AR 0.2117
Epoch 077 batch 00005: Loss 0.2617 Regression loss 0.0364 Classification loss 0.2253 AP 0.0345 AR 0.0783
Epoch 077 batch 00006: Loss 0.2331 Regression loss 0.0384 Classification loss 0.1947 AP 0.1383 AR 0.3200
Epoch 077 batch 00007: Loss 0.2693 Regression loss 0.0374 Classification loss 0.2319 AP 0.1116 AR 0.1850
Epoch 077 batch 00008: Loss 0.2629 Regression loss 0.0321 Classification loss 0.2308 AP 0.0569 AR 0.1000
Epoch 077 batch 00009: Loss 0.2643 Regression loss 0.0365 Classification loss 0.2278 AP 0.0589 AR 0.0850
Epoch 077 batch 00010: Loss 0.2520 Regression loss 0.0345 Classification loss 0.2175 AP 0.2062 AR 0.4017
Epoch 078 batch 00001: Loss 0.2562 Regression loss 0.0373 Classification loss 0.2189 AP 0.0512 AR 0.1400
Epoch 078 batch 00002: Loss 0.2178 Regression loss 0.0376 Classification loss 0.1802 AP 0.0167 AR 0.0333
Epoch 078 batch 00003: Loss 0.2697 Regression loss 0.0401 Classification loss 0.2296 AP 0.0310 AR 0.0650
Epoch 078 batch 00004: Loss 0.2430 Regression loss 0.0348 Classification loss 0.2082 AP 0.1178 AR 0.2150
Epoch 078 batch 00005: Loss 0.2288 Regression loss 0.0332 Classification loss 0.1956 AP 0.1311 AR 0.1700
Epoch 078 batch 00006: Loss 0.2747 Regression loss 0.0391 Classification loss 0.2356 AP 0.0125 AR 0.0200
Epoch 078 batch 00007: Loss 0.2441 Regression loss 0.0403 Classification loss 0.2038 AP 0.1182 AR 0.2200
Epoch 078 batch 00008: Loss 0.2289 Regression loss 0.0364 Classification loss 0.1925 AP 0.1348 AR 0.2833
Epoch 078 batch 00009: Loss 0.3221 Regression loss 0.0299 Classification loss 0.2922 AP 0.0125 AR 0.0250
Epoch 078 batch 00010: Loss 0.2573 Regression loss 0.0329 Classification loss 0.2244 AP 0.1795 AR 0.2450
Epoch 079 batch 00001: Loss 0.2611 Regression loss 0.0394 Classification loss 0.2217 AP 0.0688 AR 0.1333
Epoch 079 batch 00002: Loss 0.2726 Regression loss 0.0425 Classification loss 0.2301 AP 0.0919 AR 0.1900
Epoch 079 batch 00003: Loss 0.2342 Regression loss 0.0343 Classification loss 0.1999 AP 0.1060 AR 0.2233
Epoch 079 batch 00004: Loss 0.2719 Regression loss 0.0416 Classification loss 0.2304 AP 0.0111 AR 0.0250
Epoch 079 batch 00005: Loss 0.2187 Regression loss 0.0326 Classification loss 0.1861 AP 0.1536 AR 0.1917
Epoch 079 batch 00006: Loss 0.2770 Regression loss 0.0378 Classification loss 0.2392 AP 0.0930 AR 0.1733
Epoch 079 batch 00007: Loss 0.2395 Regression loss 0.0375 Classification loss 0.2020 AP 0.0417 AR 0.0950
Epoch 079 batch 00008: Loss 0.2696 Regression loss 0.0390 Classification loss 0.2307 AP 0.0475 AR 0.1417
Epoch 079 batch 00009: Loss 0.2565 Regression loss 0.0381 Classification loss 0.2184 AP 0.0486 AR 0.1250
Epoch 079 batch 00010: Loss 0.2613 Regression loss 0.0352 Classification loss 0.2261 AP 0.1446 AR 0.3783
Epoch 080 batch 00001: Loss 0.2616 Regression loss 0.0401 Classification loss 0.2215 AP 0.0976 AR 0.2567
Epoch 080 batch 00002: Loss 0.2327 Regression loss 0.0400 Classification loss 0.1927 AP 0.1291 AR 0.1600
Epoch 080 batch 00003: Loss 0.2752 Regression loss 0.0367 Classification loss 0.2385 AP 0.0403 AR 0.0650
Epoch 080 batch 00004: Loss 0.2644 Regression loss 0.0369 Classification loss 0.2275 AP 0.0622 AR 0.1133
Epoch 080 batch 00005: Loss 0.2541 Regression loss 0.0378 Classification loss 0.2162 AP 0.1322 AR 0.3067
Epoch 080 batch 00006: Loss 0.2192 Regression loss 0.0385 Classification loss 0.1807 AP 0.0643 AR 0.1233
Epoch 080 batch 00007: Loss 0.2195 Regression loss 0.0341 Classification loss 0.1853 AP 0.0913 AR 0.1983
Epoch 080 batch 00008: Loss 0.2486 Regression loss 0.0401 Classification loss 0.2085 AP 0.1268 AR 0.1583
Epoch 080 batch 00009: Loss 0.2603 Regression loss 0.0297 Classification loss 0.2306 AP 0.0667 AR 0.1833
Epoch 080 batch 00010: Loss 0.2541 Regression loss 0.0299 Classification loss 0.2243 AP 0.0952 AR 0.1667
Epoch 081 batch 00001: Loss 0.2744 Regression loss 0.0399 Classification loss 0.2344 AP 0.1388 AR 0.2033
Epoch 081 batch 00002: Loss 0.2605 Regression loss 0.0345 Classification loss 0.2260 AP 0.0334 AR 0.0650
Epoch 081 batch 00003: Loss 0.2349 Regression loss 0.0375 Classification loss 0.1974 AP 0.0277 AR 0.0700
Epoch 081 batch 00004: Loss 0.2686 Regression loss 0.0296 Classification loss 0.2390 AP 0.0250 AR 0.0667
Epoch 081 batch 00005: Loss 0.2707 Regression loss 0.0354 Classification loss 0.2354 AP 0.0501 AR 0.1283
Epoch 081 batch 00006: Loss 0.2311 Regression loss 0.0370 Classification loss 0.1942 AP 0.0667 AR 0.1667
Epoch 081 batch 00007: Loss 0.2484 Regression loss 0.0328 Classification loss 0.2157 AP 0.0891 AR 0.1867
Epoch 081 batch 00008: Loss 0.2177 Regression loss 0.0334 Classification loss 0.1843 AP 0.1706 AR 0.3567
Epoch 081 batch 00009: Loss 0.2498 Regression loss 0.0377 Classification loss 0.2120 AP 0.1091 AR 0.2067
Epoch 081 batch 00010: Loss 0.2458 Regression loss 0.0366 Classification loss 0.2092 AP 0.1033 AR 0.2200
Epoch 082 batch 00001: Loss 0.2480 Regression loss 0.0337 Classification loss 0.2143 AP 0.0311 AR 0.0700
Epoch 082 batch 00002: Loss 0.2418 Regression loss 0.0353 Classification loss 0.2065 AP 0.0635 AR 0.1333
Epoch 082 batch 00003: Loss 0.2075 Regression loss 0.0339 Classification loss 0.1736 AP 0.0890 AR 0.1733
Epoch 082 batch 00004: Loss 0.2429 Regression loss 0.0344 Classification loss 0.2085 AP 0.1167 AR 0.3000
Epoch 082 batch 00005: Loss 0.2471 Regression loss 0.0342 Classification loss 0.2128 AP 0.1285 AR 0.2533
Epoch 082 batch 00006: Loss 0.2866 Regression loss 0.0383 Classification loss 0.2483 AP 0.0271 AR 0.0650
Epoch 082 batch 00007: Loss 0.2433 Regression loss 0.0332 Classification loss 0.2101 AP 0.1459 AR 0.2150
Epoch 082 batch 00008: Loss 0.2377 Regression loss 0.0353 Classification loss 0.2024 AP 0.0589 AR 0.1333
Epoch 082 batch 00009: Loss 0.2607 Regression loss 0.0378 Classification loss 0.2229 AP 0.0896 AR 0.1767
Epoch 082 batch 00010: Loss 0.2550 Regression loss 0.0333 Classification loss 0.2217 AP 0.0167 AR 0.0250
Epoch 083 batch 00001: Loss 0.2122 Regression loss 0.0339 Classification loss 0.1783 AP 0.2433 AR 0.3833
Epoch 083 batch 00002: Loss 0.2428 Regression loss 0.0322 Classification loss 0.2106 AP 0.0910 AR 0.1700
Epoch 083 batch 00003: Loss 0.2492 Regression loss 0.0405 Classification loss 0.2087 AP 0.0754 AR 0.2167
Epoch 083 batch 00004: Loss 0.2487 Regression loss 0.0316 Classification loss 0.2172 AP 0.0739 AR 0.1600
Epoch 083 batch 00005: Loss 0.2503 Regression loss 0.0368 Classification loss 0.2135 AP 0.0971 AR 0.2250
Epoch 083 batch 00006: Loss 0.2126 Regression loss 0.0333 Classification loss 0.1794 AP 0.0583 AR 0.1000
Epoch 083 batch 00007: Loss 0.2523 Regression loss 0.0431 Classification loss 0.2092 AP 0.1576 AR 0.2183
Epoch 083 batch 00008: Loss 0.2595 Regression loss 0.0343 Classification loss 0.2252 AP 0.0760 AR 0.1417
Epoch 083 batch 00009: Loss 0.2566 Regression loss 0.0399 Classification loss 0.2168 AP 0.0220 AR 0.0583
Epoch 083 batch 00010: Loss 0.2756 Regression loss 0.0379 Classification loss 0.2377 AP 0.0972 AR 0.2000
Epoch 084 batch 00001: Loss 0.2301 Regression loss 0.0362 Classification loss 0.1939 AP 0.0744 AR 0.1450
Epoch 084 batch 00002: Loss 0.2500 Regression loss 0.0331 Classification loss 0.2170 AP 0.0803 AR 0.1883
Epoch 084 batch 00003: Loss 0.2655 Regression loss 0.0331 Classification loss 0.2324 AP 0.1494 AR 0.2200
Epoch 084 batch 00004: Loss 0.2549 Regression loss 0.0391 Classification loss 0.2158 AP 0.0311 AR 0.0650
Epoch 084 batch 00005: Loss 0.2570 Regression loss 0.0365 Classification loss 0.2205 AP 0.1021 AR 0.2200
Epoch 084 batch 00006: Loss 0.2263 Regression loss 0.0358 Classification loss 0.1905 AP 0.1356 AR 0.3033
Epoch 084 batch 00007: Loss 0.2411 Regression loss 0.0388 Classification loss 0.2023 AP 0.1637 AR 0.2833
Epoch 084 batch 00008: Loss 0.2110 Regression loss 0.0370 Classification loss 0.1739 AP 0.1658 AR 0.2750
Epoch 084 batch 00009: Loss 0.2128 Regression loss 0.0345 Classification loss 0.1784 AP 0.1062 AR 0.2367
Epoch 084 batch 00010: Loss 0.2324 Regression loss 0.0363 Classification loss 0.1961 AP 0.0250 AR 0.0500
Epoch 085 batch 00001: Loss 0.2326 Regression loss 0.0339 Classification loss 0.1987 AP 0.0887 AR 0.2000
Epoch 085 batch 00002: Loss 0.2341 Regression loss 0.0373 Classification loss 0.1968 AP 0.1541 AR 0.2467
Epoch 085 batch 00003: Loss 0.2277 Regression loss 0.0349 Classification loss 0.1928 AP 0.2444 AR 0.3533
Epoch 085 batch 00004: Loss 0.2519 Regression loss 0.0326 Classification loss 0.2193 AP 0.0836 AR 0.2167
Epoch 085 batch 00005: Loss 0.2440 Regression loss 0.0381 Classification loss 0.2059 AP 0.0806 AR 0.2083
Epoch 085 batch 00006: Loss 0.2611 Regression loss 0.0326 Classification loss 0.2285 AP 0.0354 AR 0.0750
Epoch 085 batch 00007: Loss 0.2435 Regression loss 0.0326 Classification loss 0.2110 AP 0.1663 AR 0.2383
Epoch 085 batch 00008: Loss 0.2479 Regression loss 0.0405 Classification loss 0.2074 AP 0.0250 AR 0.0333
Epoch 085 batch 00009: Loss 0.2339 Regression loss 0.0365 Classification loss 0.1974 AP 0.0571 AR 0.1200
Epoch 085 batch 00010: Loss 0.2328 Regression loss 0.0343 Classification loss 0.1985 AP 0.0717 AR 0.1483
Epoch 086 batch 00001: Loss 0.2260 Regression loss 0.0266 Classification loss 0.1994 AP 0.2006 AR 0.3533
Epoch 086 batch 00002: Loss 0.2363 Regression loss 0.0373 Classification loss 0.1990 AP 0.1494 AR 0.3433
Epoch 086 batch 00003: Loss 0.2364 Regression loss 0.0338 Classification loss 0.2026 AP 0.1072 AR 0.2000
Epoch 086 batch 00004: Loss 0.2382 Regression loss 0.0333 Classification loss 0.2050 AP 0.0674 AR 0.1200
Epoch 086 batch 00005: Loss 0.2245 Regression loss 0.0367 Classification loss 0.1878 AP 0.0664 AR 0.1783
Epoch 086 batch 00006: Loss 0.2035 Regression loss 0.0336 Classification loss 0.1699 AP 0.0397 AR 0.0750
Epoch 086 batch 00007: Loss 0.2393 Regression loss 0.0388 Classification loss 0.2006 AP 0.0787 AR 0.1833
Epoch 086 batch 00008: Loss 0.2428 Regression loss 0.0362 Classification loss 0.2066 AP 0.0950 AR 0.2000
Epoch 086 batch 00009: Loss 0.2293 Regression loss 0.0301 Classification loss 0.1992 AP 0.2508 AR 0.2950
Epoch 086 batch 00010: Loss 0.2725 Regression loss 0.0417 Classification loss 0.2309 AP 0.1103 AR 0.2567
Epoch 087 batch 00001: Loss 0.2177 Regression loss 0.0330 Classification loss 0.1847 AP 0.0976 AR 0.1917
Epoch 087 batch 00002: Loss 0.2465 Regression loss 0.0318 Classification loss 0.2147 AP 0.3067 AR 0.3917
Epoch 087 batch 00003: Loss 0.2340 Regression loss 0.0374 Classification loss 0.1966 AP 0.0733 AR 0.1833
Epoch 087 batch 00004: Loss 0.2295 Regression loss 0.0337 Classification loss 0.1958 AP 0.1757 AR 0.2367
Epoch 087 batch 00005: Loss 0.2466 Regression loss 0.0354 Classification loss 0.2113 AP 0.1154 AR 0.3600
Epoch 087 batch 00006: Loss 0.2516 Regression loss 0.0362 Classification loss 0.2154 AP 0.0571 AR 0.1200
Epoch 087 batch 00007: Loss 0.2284 Regression loss 0.0367 Classification loss 0.1916 AP 0.0643 AR 0.1583
Epoch 087 batch 00008: Loss 0.2423 Regression loss 0.0298 Classification loss 0.2125 AP 0.0493 AR 0.1150
Epoch 087 batch 00009: Loss 0.2375 Regression loss 0.0353 Classification loss 0.2022 AP 0.1135 AR 0.2600
Epoch 087 batch 00010: Loss 0.2285 Regression loss 0.0346 Classification loss 0.1939 AP 0.1576 AR 0.3700
Epoch 088 batch 00001: Loss 0.2202 Regression loss 0.0361 Classification loss 0.1842 AP 0.1218 AR 0.2750
Epoch 088 batch 00002: Loss 0.2140 Regression loss 0.0366 Classification loss 0.1774 AP 0.0702 AR 0.1700
Epoch 088 batch 00003: Loss 0.2298 Regression loss 0.0418 Classification loss 0.1880 AP 0.0758 AR 0.1750
Epoch 088 batch 00004: Loss 0.2212 Regression loss 0.0335 Classification loss 0.1877 AP 0.1092 AR 0.2250
Epoch 088 batch 00005: Loss 0.2375 Regression loss 0.0304 Classification loss 0.2070 AP 0.1504 AR 0.2167
Epoch 088 batch 00006: Loss 0.2508 Regression loss 0.0316 Classification loss 0.2192 AP 0.1604 AR 0.3733
Epoch 088 batch 00007: Loss 0.2552 Regression loss 0.0350 Classification loss 0.2203 AP 0.1546 AR 0.2250
Epoch 088 batch 00008: Loss 0.2140 Regression loss 0.0305 Classification loss 0.1835 AP 0.1613 AR 0.3183
Epoch 088 batch 00009: Loss 0.2365 Regression loss 0.0386 Classification loss 0.1979 AP 0.0636 AR 0.1383
Epoch 088 batch 00010: Loss 0.2622 Regression loss 0.0431 Classification loss 0.2191 AP 0.0543 AR 0.0917
Epoch 089 batch 00001: Loss 0.2316 Regression loss 0.0402 Classification loss 0.1914 AP 0.0733 AR 0.1000
Epoch 089 batch 00002: Loss 0.2720 Regression loss 0.0386 Classification loss 0.2334 AP 0.2250 AR 0.2500
Epoch 089 batch 00003: Loss 0.2085 Regression loss 0.0422 Classification loss 0.1663 AP 0.1501 AR 0.2067
Epoch 089 batch 00004: Loss 0.2458 Regression loss 0.0392 Classification loss 0.2066 AP 0.0830 AR 0.2200
Epoch 089 batch 00005: Loss 0.2304 Regression loss 0.0362 Classification loss 0.1942 AP 0.1137 AR 0.3033
Epoch 089 batch 00006: Loss 0.2194 Regression loss 0.0325 Classification loss 0.1868 AP 0.1336 AR 0.3167
Epoch 089 batch 00007: Loss 0.2225 Regression loss 0.0360 Classification loss 0.1865 AP 0.0960 AR 0.2283
Epoch 089 batch 00008: Loss 0.2463 Regression loss 0.0373 Classification loss 0.2090 AP 0.2325 AR 0.4533
Epoch 089 batch 00009: Loss 0.2273 Regression loss 0.0407 Classification loss 0.1866 AP 0.1628 AR 0.3650
Epoch 089 batch 00010: Loss 0.2380 Regression loss 0.0351 Classification loss 0.2029 AP 0.1402 AR 0.2033
Epoch 090 batch 00001: Loss 0.2069 Regression loss 0.0390 Classification loss 0.1679 AP 0.1253 AR 0.2200
Epoch 090 batch 00002: Loss 0.2529 Regression loss 0.0437 Classification loss 0.2092 AP 0.0733 AR 0.1750
Epoch 090 batch 00003: Loss 0.2047 Regression loss 0.0351 Classification loss 0.1696 AP 0.0735 AR 0.1600
Epoch 090 batch 00004: Loss 0.2424 Regression loss 0.0339 Classification loss 0.2085 AP 0.0506 AR 0.1100
Epoch 090 batch 00005: Loss 0.2159 Regression loss 0.0330 Classification loss 0.1829 AP 0.0143 AR 0.0333
Epoch 090 batch 00006: Loss 0.1957 Regression loss 0.0338 Classification loss 0.1619 AP 0.1948 AR 0.3500
Epoch 090 batch 00007: Loss 0.2564 Regression loss 0.0352 Classification loss 0.2212 AP 0.0393 AR 0.0783
Epoch 090 batch 00008: Loss 0.2241 Regression loss 0.0364 Classification loss 0.1877 AP 0.0915 AR 0.1983
Epoch 090 batch 00009: Loss 0.2588 Regression loss 0.0373 Classification loss 0.2215 AP 0.1437 AR 0.3550
Epoch 090 batch 00010: Loss 0.2520 Regression loss 0.0321 Classification loss 0.2200 AP 0.0868 AR 0.1950
Epoch 091 batch 00001: Loss 0.1953 Regression loss 0.0382 Classification loss 0.1571 AP 0.0821 AR 0.1533
Epoch 091 batch 00002: Loss 0.2087 Regression loss 0.0292 Classification loss 0.1795 AP 0.1146 AR 0.2283
Epoch 091 batch 00003: Loss 0.2281 Regression loss 0.0368 Classification loss 0.1913 AP 0.1900 AR 0.2900
Epoch 091 batch 00004: Loss 0.2356 Regression loss 0.0313 Classification loss 0.2043 AP 0.0610 AR 0.1100
Epoch 091 batch 00005: Loss 0.2025 Regression loss 0.0368 Classification loss 0.1657 AP 0.0991 AR 0.1533
Epoch 091 batch 00006: Loss 0.2378 Regression loss 0.0418 Classification loss 0.1960 AP 0.0711 AR 0.1433
Epoch 091 batch 00007: Loss 0.2501 Regression loss 0.0360 Classification loss 0.2142 AP 0.1186 AR 0.2483
Epoch 091 batch 00008: Loss 0.2523 Regression loss 0.0294 Classification loss 0.2228 AP 0.0726 AR 0.1500
Epoch 091 batch 00009: Loss 0.2534 Regression loss 0.0361 Classification loss 0.2173 AP 0.1409 AR 0.1983
Epoch 091 batch 00010: Loss 0.2210 Regression loss 0.0330 Classification loss 0.1880 AP 0.0658 AR 0.1750
Epoch 092 batch 00001: Loss 0.2084 Regression loss 0.0370 Classification loss 0.1714 AP 0.0533 AR 0.1267
Epoch 092 batch 00002: Loss 0.2191 Regression loss 0.0382 Classification loss 0.1809 AP 0.1445 AR 0.2250
Epoch 092 batch 00003: Loss 0.2115 Regression loss 0.0357 Classification loss 0.1758 AP 0.0083 AR 0.0200
Epoch 092 batch 00004: Loss 0.2211 Regression loss 0.0330 Classification loss 0.1881 AP 0.0077 AR 0.0200
Epoch 092 batch 00005: Loss 0.2104 Regression loss 0.0287 Classification loss 0.1816 AP 0.2693 AR 0.3283
Epoch 092 batch 00006: Loss 0.2483 Regression loss 0.0387 Classification loss 0.2096 AP 0.0560 AR 0.0950
Epoch 092 batch 00007: Loss 0.2336 Regression loss 0.0340 Classification loss 0.1996 AP 0.1179 AR 0.2533
Epoch 092 batch 00008: Loss 0.2316 Regression loss 0.0398 Classification loss 0.1919 AP 0.1162 AR 0.2533
Epoch 092 batch 00009: Loss 0.2356 Regression loss 0.0350 Classification loss 0.2006 AP 0.1477 AR 0.3767
Epoch 092 batch 00010: Loss 0.2230 Regression loss 0.0355 Classification loss 0.1874 AP 0.1132 AR 0.2083
Epoch 093 batch 00001: Loss 0.2372 Regression loss 0.0374 Classification loss 0.1998 AP 0.0684 AR 0.1233
Epoch 093 batch 00002: Loss 0.2168 Regression loss 0.0335 Classification loss 0.1833 AP 0.0690 AR 0.1600
Epoch 093 batch 00003: Loss 0.2842 Regression loss 0.0433 Classification loss 0.2409 AP 0.0383 AR 0.0733
Epoch 093 batch 00004: Loss 0.1880 Regression loss 0.0306 Classification loss 0.1574 AP 0.0488 AR 0.1033
Epoch 093 batch 00005: Loss 0.1968 Regression loss 0.0325 Classification loss 0.1643 AP 0.2289 AR 0.3900
Epoch 093 batch 00006: Loss 0.2043 Regression loss 0.0252 Classification loss 0.1792 AP 0.2231 AR 0.3750
Epoch 093 batch 00007: Loss 0.2177 Regression loss 0.0329 Classification loss 0.1848 AP 0.2012 AR 0.3417
Epoch 093 batch 00008: Loss 0.2212 Regression loss 0.0378 Classification loss 0.1834 AP 0.0425 AR 0.0850
Epoch 093 batch 00009: Loss 0.2249 Regression loss 0.0403 Classification loss 0.1846 AP 0.1858 AR 0.2900
Epoch 093 batch 00010: Loss 0.2264 Regression loss 0.0362 Classification loss 0.1902 AP 0.1566 AR 0.2250
Epoch 094 batch 00001: Loss 0.1973 Regression loss 0.0338 Classification loss 0.1635 AP 0.0760 AR 0.1483
Epoch 094 batch 00002: Loss 0.2089 Regression loss 0.0321 Classification loss 0.1768 AP 0.2022 AR 0.3483
Epoch 094 batch 00003: Loss 0.2202 Regression loss 0.0337 Classification loss 0.1865 AP 0.1067 AR 0.3400
Epoch 094 batch 00004: Loss 0.2395 Regression loss 0.0401 Classification loss 0.1995 AP 0.1297 AR 0.1850
Epoch 094 batch 00005: Loss 0.2081 Regression loss 0.0331 Classification loss 0.1750 AP 0.1369 AR 0.2867
Epoch 094 batch 00006: Loss 0.2169 Regression loss 0.0294 Classification loss 0.1875 AP 0.2241 AR 0.3917
Epoch 094 batch 00007: Loss 0.2161 Regression loss 0.0374 Classification loss 0.1788 AP 0.1439 AR 0.4200
Epoch 094 batch 00008: Loss 0.1819 Regression loss 0.0344 Classification loss 0.1475 AP 0.0337 AR 0.0700
Epoch 094 batch 00009: Loss 0.2473 Regression loss 0.0405 Classification loss 0.2068 AP 0.0234 AR 0.0583
Epoch 094 batch 00010: Loss 0.2232 Regression loss 0.0325 Classification loss 0.1907 AP 0.1250 AR 0.2483
Epoch 095 batch 00001: Loss 0.2464 Regression loss 0.0301 Classification loss 0.2163 AP 0.0856 AR 0.2200
Epoch 095 batch 00002: Loss 0.1893 Regression loss 0.0387 Classification loss 0.1506 AP 0.1469 AR 0.3650
Epoch 095 batch 00003: Loss 0.2357 Regression loss 0.0362 Classification loss 0.1995 AP 0.0965 AR 0.2983
Epoch 095 batch 00004: Loss 0.1851 Regression loss 0.0368 Classification loss 0.1483 AP 0.0503 AR 0.1033
Epoch 095 batch 00005: Loss 0.2264 Regression loss 0.0334 Classification loss 0.1929 AP 0.1150 AR 0.2117
Epoch 095 batch 00006: Loss 0.1969 Regression loss 0.0361 Classification loss 0.1607 AP 0.0625 AR 0.0700
Epoch 095 batch 00007: Loss 0.2217 Regression loss 0.0376 Classification loss 0.1841 AP 0.1222 AR 0.2867
Epoch 095 batch 00008: Loss 0.2576 Regression loss 0.0403 Classification loss 0.2173 AP 0.0985 AR 0.2150
Epoch 095 batch 00009: Loss 0.2275 Regression loss 0.0362 Classification loss 0.1912 AP 0.1518 AR 0.1983
Epoch 095 batch 00010: Loss 0.2177 Regression loss 0.0358 Classification loss 0.1818 AP 0.1136 AR 0.2850
Epoch 096 batch 00001: Loss 0.2158 Regression loss 0.0386 Classification loss 0.1772 AP 0.0484 AR 0.1200
Epoch 096 batch 00002: Loss 0.2295 Regression loss 0.0484 Classification loss 0.1811 AP 0.0686 AR 0.1667
Epoch 096 batch 00003: Loss 0.2040 Regression loss 0.0335 Classification loss 0.1706 AP 0.1786 AR 0.3917
Epoch 096 batch 00004: Loss 0.2347 Regression loss 0.0416 Classification loss 0.1931 AP 0.0650 AR 0.1333
Epoch 096 batch 00005: Loss 0.1924 Regression loss 0.0352 Classification loss 0.1572 AP 0.1958 AR 0.3000
Epoch 096 batch 00006: Loss 0.2244 Regression loss 0.0374 Classification loss 0.1870 AP 0.0313 AR 0.0700
Epoch 096 batch 00007: Loss 0.2283 Regression loss 0.0320 Classification loss 0.1964 AP 0.1081 AR 0.2433
Epoch 096 batch 00008: Loss 0.2173 Regression loss 0.0369 Classification loss 0.1804 AP 0.0686 AR 0.1400
Epoch 096 batch 00009: Loss 0.2477 Regression loss 0.0325 Classification loss 0.2151 AP 0.1062 AR 0.2433
Epoch 096 batch 00010: Loss 0.1663 Regression loss 0.0292 Classification loss 0.1371 AP 0.0656 AR 0.1683
Epoch 097 batch 00001: Loss 0.2136 Regression loss 0.0334 Classification loss 0.1803 AP 0.1096 AR 0.2283
Epoch 097 batch 00002: Loss 0.2190 Regression loss 0.0383 Classification loss 0.1807 AP 0.1687 AR 0.2650
Epoch 097 batch 00003: Loss 0.1901 Regression loss 0.0421 Classification loss 0.1480 AP 0.2662 AR 0.3567
Epoch 097 batch 00004: Loss 0.2477 Regression loss 0.0404 Classification loss 0.2073 AP 0.0893 AR 0.1750
Epoch 097 batch 00005: Loss 0.2013 Regression loss 0.0329 Classification loss 0.1684 AP 0.1339 AR 0.3083
Epoch 097 batch 00006: Loss 0.2130 Regression loss 0.0338 Classification loss 0.1792 AP 0.0511 AR 0.1100
Epoch 097 batch 00007: Loss 0.1914 Regression loss 0.0343 Classification loss 0.1571 AP 0.0759 AR 0.1850
Epoch 097 batch 00008: Loss 0.2325 Regression loss 0.0354 Classification loss 0.1971 AP 0.1108 AR 0.3000
Epoch 097 batch 00009: Loss 0.2461 Regression loss 0.0377 Classification loss 0.2084 AP 0.0805 AR 0.2283
Epoch 097 batch 00010: Loss 0.2202 Regression loss 0.0391 Classification loss 0.1811 AP 0.0443 AR 0.1167
Epoch 098 batch 00001: Loss 0.2142 Regression loss 0.0353 Classification loss 0.1788 AP 0.1725 AR 0.2900
Epoch 098 batch 00002: Loss 0.2187 Regression loss 0.0360 Classification loss 0.1826 AP 0.0865 AR 0.1700
Epoch 098 batch 00003: Loss 0.2078 Regression loss 0.0359 Classification loss 0.1719 AP 0.2325 AR 0.3833
Epoch 098 batch 00004: Loss 0.2129 Regression loss 0.0412 Classification loss 0.1716 AP 0.0767 AR 0.1600
Epoch 098 batch 00005: Loss 0.2133 Regression loss 0.0340 Classification loss 0.1792 AP 0.1313 AR 0.2450
Epoch 098 batch 00006: Loss 0.2353 Regression loss 0.0384 Classification loss 0.1969 AP 0.2105 AR 0.3933
Epoch 098 batch 00007: Loss 0.2294 Regression loss 0.0291 Classification loss 0.2003 AP 0.1097 AR 0.3083
Epoch 098 batch 00008: Loss 0.1686 Regression loss 0.0301 Classification loss 0.1385 AP 0.1200 AR 0.2333
Epoch 098 batch 00009: Loss 0.2165 Regression loss 0.0376 Classification loss 0.1789 AP 0.0602 AR 0.1567
Epoch 098 batch 00010: Loss 0.1860 Regression loss 0.0313 Classification loss 0.1547 AP 0.0871 AR 0.1783
Epoch 099 batch 00001: Loss 0.2284 Regression loss 0.0375 Classification loss 0.1909 AP 0.1472 AR 0.2083
Epoch 099 batch 00002: Loss 0.2068 Regression loss 0.0309 Classification loss 0.1759 AP 0.1535 AR 0.2450
Epoch 099 batch 00003: Loss 0.1888 Regression loss 0.0293 Classification loss 0.1595 AP 0.1800 AR 0.3450
Epoch 099 batch 00004: Loss 0.2111 Regression loss 0.0344 Classification loss 0.1767 AP 0.0518 AR 0.1083
Epoch 099 batch 00005: Loss 0.1849 Regression loss 0.0394 Classification loss 0.1455 AP 0.0510 AR 0.1667
Epoch 099 batch 00006: Loss 0.2009 Regression loss 0.0328 Classification loss 0.1682 AP 0.2131 AR 0.4517
Epoch 099 batch 00007: Loss 0.2224 Regression loss 0.0337 Classification loss 0.1886 AP 0.1589 AR 0.3150
Epoch 099 batch 00008: Loss 0.1898 Regression loss 0.0380 Classification loss 0.1518 AP 0.0291 AR 0.0700
Epoch 099 batch 00009: Loss 0.2503 Regression loss 0.0322 Classification loss 0.2181 AP 0.0746 AR 0.1633
Epoch 099 batch 00010: Loss 0.2233 Regression loss 0.0400 Classification loss 0.1833 AP 0.0437 AR 0.1000
Epoch 100 batch 00001: Loss 0.2206 Regression loss 0.0398 Classification loss 0.1807 AP 0.1033 AR 0.2200
Epoch 100 batch 00002: Loss 0.2183 Regression loss 0.0347 Classification loss 0.1837 AP 0.0265 AR 0.0783
Epoch 100 batch 00003: Loss 0.2092 Regression loss 0.0325 Classification loss 0.1767 AP 0.1092 AR 0.3000
Epoch 100 batch 00004: Loss 0.1914 Regression loss 0.0314 Classification loss 0.1599 AP 0.1948 AR 0.3033
Epoch 100 batch 00005: Loss 0.1991 Regression loss 0.0307 Classification loss 0.1685 AP 0.0429 AR 0.0783
Epoch 100 batch 00006: Loss 0.1874 Regression loss 0.0287 Classification loss 0.1587 AP 0.0754 AR 0.1750
Epoch 100 batch 00007: Loss 0.1758 Regression loss 0.0365 Classification loss 0.1393 AP 0.1151 AR 0.2183
Epoch 100 batch 00008: Loss 0.1956 Regression loss 0.0368 Classification loss 0.1588 AP 0.0656 AR 0.1700
Epoch 100 batch 00009: Loss 0.2404 Regression loss 0.0386 Classification loss 0.2018 AP 0.0861 AR 0.1400
Epoch 100 batch 00010: Loss 0.2334 Regression loss 0.0363 Classification loss 0.1971 AP 0.0747 AR 0.1800
Epoch 101 batch 00001: Loss 0.1763 Regression loss 0.0295 Classification loss 0.1467 AP 0.1850 AR 0.2683
Epoch 101 batch 00002: Loss 0.2098 Regression loss 0.0341 Classification loss 0.1757 AP 0.1433 AR 0.2833
Epoch 101 batch 00003: Loss 0.2544 Regression loss 0.0443 Classification loss 0.2101 AP 0.0476 AR 0.1450
Epoch 101 batch 00004: Loss 0.2026 Regression loss 0.0364 Classification loss 0.1662 AP 0.0547 AR 0.1833
Epoch 101 batch 00005: Loss 0.2220 Regression loss 0.0302 Classification loss 0.1918 AP 0.1154 AR 0.2400
Epoch 101 batch 00006: Loss 0.1855 Regression loss 0.0296 Classification loss 0.1559 AP 0.0569 AR 0.1333
Epoch 101 batch 00007: Loss 0.1849 Regression loss 0.0392 Classification loss 0.1457 AP 0.2558 AR 0.4250
Epoch 101 batch 00008: Loss 0.2211 Regression loss 0.0370 Classification loss 0.1841 AP 0.0703 AR 0.1933
Epoch 101 batch 00009: Loss 0.2137 Regression loss 0.0320 Classification loss 0.1818 AP 0.2404 AR 0.3600
Epoch 101 batch 00010: Loss 0.2125 Regression loss 0.0319 Classification loss 0.1806 AP 0.0933 AR 0.1800
Epoch 102 batch 00001: Loss 0.1826 Regression loss 0.0296 Classification loss 0.1530 AP 0.1573 AR 0.3900
Epoch 102 batch 00002: Loss 0.2089 Regression loss 0.0359 Classification loss 0.1730 AP 0.1439 AR 0.2750
Epoch 102 batch 00003: Loss 0.2110 Regression loss 0.0357 Classification loss 0.1753 AP 0.0705 AR 0.1450
Epoch 102 batch 00004: Loss 0.1935 Regression loss 0.0336 Classification loss 0.1599 AP 0.0768 AR 0.1550
Epoch 102 batch 00005: Loss 0.1920 Regression loss 0.0365 Classification loss 0.1555 AP 0.0902 AR 0.1867
Epoch 102 batch 00006: Loss 0.2044 Regression loss 0.0368 Classification loss 0.1676 AP 0.1775 AR 0.2333
Epoch 102 batch 00007: Loss 0.2400 Regression loss 0.0319 Classification loss 0.2081 AP 0.1640 AR 0.3017
Epoch 102 batch 00008: Loss 0.2048 Regression loss 0.0354 Classification loss 0.1695 AP 0.1572 AR 0.1933
Epoch 102 batch 00009: Loss 0.2093 Regression loss 0.0333 Classification loss 0.1760 AP 0.1021 AR 0.2617
Epoch 102 batch 00010: Loss 0.1969 Regression loss 0.0309 Classification loss 0.1661 AP 0.1208 AR 0.3400
Epoch 103 batch 00001: Loss 0.2153 Regression loss 0.0345 Classification loss 0.1808 AP 0.0576 AR 0.1000
Epoch 103 batch 00002: Loss 0.1945 Regression loss 0.0277 Classification loss 0.1668 AP 0.1356 AR 0.3333
Epoch 103 batch 00003: Loss 0.2115 Regression loss 0.0340 Classification loss 0.1774 AP 0.0386 AR 0.1117
Epoch 103 batch 00004: Loss 0.2111 Regression loss 0.0339 Classification loss 0.1772 AP 0.0935 AR 0.2350
Epoch 103 batch 00005: Loss 0.1988 Regression loss 0.0329 Classification loss 0.1659 AP 0.2384 AR 0.2850
Epoch 103 batch 00006: Loss 0.2102 Regression loss 0.0321 Classification loss 0.1782 AP 0.1080 AR 0.2100
Epoch 103 batch 00007: Loss 0.1968 Regression loss 0.0375 Classification loss 0.1593 AP 0.1444 AR 0.1900
Epoch 103 batch 00008: Loss 0.2041 Regression loss 0.0391 Classification loss 0.1649 AP 0.0980 AR 0.1683
Epoch 103 batch 00009: Loss 0.1843 Regression loss 0.0372 Classification loss 0.1471 AP 0.0817 AR 0.2033
Epoch 103 batch 00010: Loss 0.2111 Regression loss 0.0369 Classification loss 0.1742 AP 0.1192 AR 0.2667
Epoch 104 batch 00001: Loss 0.1962 Regression loss 0.0407 Classification loss 0.1555 AP 0.0375 AR 0.0750
Epoch 104 batch 00002: Loss 0.2086 Regression loss 0.0282 Classification loss 0.1804 AP 0.1425 AR 0.3267
Epoch 104 batch 00003: Loss 0.1988 Regression loss 0.0307 Classification loss 0.1681 AP 0.1625 AR 0.2250
Epoch 104 batch 00004: Loss 0.2111 Regression loss 0.0410 Classification loss 0.1701 AP 0.0671 AR 0.2067
Epoch 104 batch 00005: Loss 0.2289 Regression loss 0.0369 Classification loss 0.1920 AP 0.1177 AR 0.2550
Epoch 104 batch 00006: Loss 0.2096 Regression loss 0.0358 Classification loss 0.1737 AP 0.0844 AR 0.1733
Epoch 104 batch 00007: Loss 0.1948 Regression loss 0.0394 Classification loss 0.1554 AP 0.0783 AR 0.1700
Epoch 104 batch 00008: Loss 0.2054 Regression loss 0.0302 Classification loss 0.1752 AP 0.1124 AR 0.2117
Epoch 104 batch 00009: Loss 0.2044 Regression loss 0.0313 Classification loss 0.1731 AP 0.1146 AR 0.2900
Epoch 104 batch 00010: Loss 0.1866 Regression loss 0.0367 Classification loss 0.1500 AP 0.1161 AR 0.2250
Epoch 105 batch 00001: Loss 0.2016 Regression loss 0.0403 Classification loss 0.1613 AP 0.1433 AR 0.2250
Epoch 105 batch 00002: Loss 0.2333 Regression loss 0.0378 Classification loss 0.1955 AP 0.0815 AR 0.1483
Epoch 105 batch 00003: Loss 0.1680 Regression loss 0.0340 Classification loss 0.1340 AP 0.0250 AR 0.0667
Epoch 105 batch 00004: Loss 0.2112 Regression loss 0.0362 Classification loss 0.1749 AP 0.1532 AR 0.3417
Epoch 105 batch 00005: Loss 0.2047 Regression loss 0.0366 Classification loss 0.1681 AP 0.0894 AR 0.1700
Epoch 105 batch 00006: Loss 0.1978 Regression loss 0.0316 Classification loss 0.1662 AP 0.0668 AR 0.1750
Epoch 105 batch 00007: Loss 0.2196 Regression loss 0.0446 Classification loss 0.1750 AP 0.0667 AR 0.1400
Epoch 105 batch 00008: Loss 0.1776 Regression loss 0.0368 Classification loss 0.1408 AP 0.0448 AR 0.1150
Epoch 105 batch 00009: Loss 0.1759 Regression loss 0.0256 Classification loss 0.1503 AP 0.0974 AR 0.2283
Epoch 105 batch 00010: Loss 0.2110 Regression loss 0.0353 Classification loss 0.1757 AP 0.1378 AR 0.1900
Epoch 106 batch 00001: Loss 0.2051 Regression loss 0.0334 Classification loss 0.1718 AP 0.2753 AR 0.3633
Epoch 106 batch 00002: Loss 0.2116 Regression loss 0.0327 Classification loss 0.1788 AP 0.1402 AR 0.3233
Epoch 106 batch 00003: Loss 0.2020 Regression loss 0.0390 Classification loss 0.1630 AP 0.0333 AR 0.1000
Epoch 106 batch 00004: Loss 0.1988 Regression loss 0.0319 Classification loss 0.1669 AP 0.1087 AR 0.2650
Epoch 106 batch 00005: Loss 0.1983 Regression loss 0.0341 Classification loss 0.1642 AP 0.1349 AR 0.2850
Epoch 106 batch 00006: Loss 0.1833 Regression loss 0.0351 Classification loss 0.1481 AP 0.1454 AR 0.3267
Epoch 106 batch 00007: Loss 0.2025 Regression loss 0.0351 Classification loss 0.1674 AP 0.0767 AR 0.1250
Epoch 106 batch 00008: Loss 0.2083 Regression loss 0.0344 Classification loss 0.1739 AP 0.0810 AR 0.1600
Epoch 106 batch 00009: Loss 0.1596 Regression loss 0.0354 Classification loss 0.1242 AP 0.0833 AR 0.2500
Epoch 106 batch 00010: Loss 0.1898 Regression loss 0.0313 Classification loss 0.1585 AP 0.2129 AR 0.2983
Epoch 107 batch 00001: Loss 0.1767 Regression loss 0.0330 Classification loss 0.1437 AP 0.1561 AR 0.2317
Epoch 107 batch 00002: Loss 0.1986 Regression loss 0.0309 Classification loss 0.1677 AP 0.1493 AR 0.2567
Epoch 107 batch 00003: Loss 0.2045 Regression loss 0.0365 Classification loss 0.1680 AP 0.0904 AR 0.2617
Epoch 107 batch 00004: Loss 0.2070 Regression loss 0.0324 Classification loss 0.1746 AP 0.1750 AR 0.2667
Epoch 107 batch 00005: Loss 0.2007 Regression loss 0.0305 Classification loss 0.1703 AP 0.1424 AR 0.2917
Epoch 107 batch 00006: Loss 0.1989 Regression loss 0.0363 Classification loss 0.1627 AP 0.0937 AR 0.2050
Epoch 107 batch 00007: Loss 0.1680 Regression loss 0.0338 Classification loss 0.1342 AP 0.2192 AR 0.3950
Epoch 107 batch 00008: Loss 0.2139 Regression loss 0.0336 Classification loss 0.1803 AP 0.1226 AR 0.2567
Epoch 107 batch 00009: Loss 0.1882 Regression loss 0.0329 Classification loss 0.1553 AP 0.1167 AR 0.2350
Epoch 107 batch 00010: Loss 0.2086 Regression loss 0.0363 Classification loss 0.1722 AP 0.1325 AR 0.1983
Epoch 108 batch 00001: Loss 0.1756 Regression loss 0.0347 Classification loss 0.1409 AP 0.1162 AR 0.2950
Epoch 108 batch 00002: Loss 0.1910 Regression loss 0.0301 Classification loss 0.1609 AP 0.0453 AR 0.1267
Epoch 108 batch 00003: Loss 0.1938 Regression loss 0.0366 Classification loss 0.1571 AP 0.0981 AR 0.2250
Epoch 108 batch 00004: Loss 0.2081 Regression loss 0.0404 Classification loss 0.1677 AP 0.1017 AR 0.1533
Epoch 108 batch 00005: Loss 0.1879 Regression loss 0.0321 Classification loss 0.1559 AP 0.1158 AR 0.2533
Epoch 108 batch 00006: Loss 0.2023 Regression loss 0.0287 Classification loss 0.1736 AP 0.1583 AR 0.2200
Epoch 108 batch 00007: Loss 0.2220 Regression loss 0.0310 Classification loss 0.1910 AP 0.1402 AR 0.1783
Epoch 108 batch 00008: Loss 0.2240 Regression loss 0.0318 Classification loss 0.1922 AP 0.1098 AR 0.2233
Epoch 108 batch 00009: Loss 0.1719 Regression loss 0.0340 Classification loss 0.1380 AP 0.1686 AR 0.2350
Epoch 108 batch 00010: Loss 0.2032 Regression loss 0.0472 Classification loss 0.1560 AP 0.0283 AR 0.0700
Epoch 109 batch 00001: Loss 0.1982 Regression loss 0.0298 Classification loss 0.1685 AP 0.1279 AR 0.2650
Epoch 109 batch 00002: Loss 0.1503 Regression loss 0.0333 Classification loss 0.1169 AP 0.2208 AR 0.4583
Epoch 109 batch 00003: Loss 0.2152 Regression loss 0.0303 Classification loss 0.1850 AP 0.1003 AR 0.2400
Epoch 109 batch 00004: Loss 0.1950 Regression loss 0.0328 Classification loss 0.1622 AP 0.0602 AR 0.1233
Epoch 109 batch 00005: Loss 0.2062 Regression loss 0.0309 Classification loss 0.1754 AP 0.2337 AR 0.3683
Epoch 109 batch 00006: Loss 0.2179 Regression loss 0.0369 Classification loss 0.1809 AP 0.0715 AR 0.2100
Epoch 109 batch 00007: Loss 0.1631 Regression loss 0.0328 Classification loss 0.1303 AP 0.2226 AR 0.3417
Epoch 109 batch 00008: Loss 0.1786 Regression loss 0.0307 Classification loss 0.1479 AP 0.0865 AR 0.1783
Epoch 109 batch 00009: Loss 0.1949 Regression loss 0.0333 Classification loss 0.1616 AP 0.1557 AR 0.3167
Epoch 109 batch 00010: Loss 0.2204 Regression loss 0.0390 Classification loss 0.1814 AP 0.1421 AR 0.4317
Epoch 110 batch 00001: Loss 0.1883 Regression loss 0.0324 Classification loss 0.1559 AP 0.0410 AR 0.1100
Epoch 110 batch 00002: Loss 0.1894 Regression loss 0.0375 Classification loss 0.1519 AP 0.0643 AR 0.1733
Epoch 110 batch 00003: Loss 0.2276 Regression loss 0.0297 Classification loss 0.1979 AP 0.1992 AR 0.3667
Epoch 110 batch 00004: Loss 0.1764 Regression loss 0.0332 Classification loss 0.1433 AP 0.1417 AR 0.3417
Epoch 110 batch 00005: Loss 0.1928 Regression loss 0.0317 Classification loss 0.1611 AP 0.1896 AR 0.2633
Epoch 110 batch 00006: Loss 0.1951 Regression loss 0.0307 Classification loss 0.1643 AP 0.1872 AR 0.3467
Epoch 110 batch 00007: Loss 0.2121 Regression loss 0.0345 Classification loss 0.1776 AP 0.1098 AR 0.2250
Epoch 110 batch 00008: Loss 0.1959 Regression loss 0.0323 Classification loss 0.1636 AP 0.1001 AR 0.2067
Epoch 110 batch 00009: Loss 0.1852 Regression loss 0.0332 Classification loss 0.1520 AP 0.0710 AR 0.1317
Epoch 110 batch 00010: Loss 0.1663 Regression loss 0.0322 Classification loss 0.1342 AP 0.1828 AR 0.4500
Epoch 111 batch 00001: Loss 0.1988 Regression loss 0.0341 Classification loss 0.1647 AP 0.0525 AR 0.0950
Epoch 111 batch 00002: Loss 0.2260 Regression loss 0.0333 Classification loss 0.1927 AP 0.0392 AR 0.0700
Epoch 111 batch 00003: Loss 0.1599 Regression loss 0.0326 Classification loss 0.1274 AP 0.1020 AR 0.2667
Epoch 111 batch 00004: Loss 0.1893 Regression loss 0.0287 Classification loss 0.1606 AP 0.1692 AR 0.3767
Epoch 111 batch 00005: Loss 0.2079 Regression loss 0.0329 Classification loss 0.1750 AP 0.0882 AR 0.2133
Epoch 111 batch 00006: Loss 0.1659 Regression loss 0.0334 Classification loss 0.1325 AP 0.1708 AR 0.2750
Epoch 111 batch 00007: Loss 0.1793 Regression loss 0.0343 Classification loss 0.1449 AP 0.2330 AR 0.4083
Epoch 111 batch 00008: Loss 0.2008 Regression loss 0.0367 Classification loss 0.1641 AP 0.1394 AR 0.2883
Epoch 111 batch 00009: Loss 0.1900 Regression loss 0.0300 Classification loss 0.1600 AP 0.1694 AR 0.2950
Epoch 111 batch 00010: Loss 0.1780 Regression loss 0.0290 Classification loss 0.1490 AP 0.1889 AR 0.3333
Epoch 112 batch 00001: Loss 0.1694 Regression loss 0.0314 Classification loss 0.1381 AP 0.1935 AR 0.4583
Epoch 112 batch 00002: Loss 0.1867 Regression loss 0.0356 Classification loss 0.1510 AP 0.2053 AR 0.4617
Epoch 112 batch 00003: Loss 0.1869 Regression loss 0.0323 Classification loss 0.1547 AP 0.1115 AR 0.2567
Epoch 112 batch 00004: Loss 0.1492 Regression loss 0.0315 Classification loss 0.1177 AP 0.1182 AR 0.2750
Epoch 112 batch 00005: Loss 0.1630 Regression loss 0.0329 Classification loss 0.1301 AP 0.2167 AR 0.3883
Epoch 112 batch 00006: Loss 0.2095 Regression loss 0.0388 Classification loss 0.1707 AP 0.1918 AR 0.3400
Epoch 112 batch 00007: Loss 0.2377 Regression loss 0.0336 Classification loss 0.2041 AP 0.0518 AR 0.1250
Epoch 112 batch 00008: Loss 0.2256 Regression loss 0.0357 Classification loss 0.1899 AP 0.0501 AR 0.1050
Epoch 112 batch 00009: Loss 0.1568 Regression loss 0.0329 Classification loss 0.1239 AP 0.2208 AR 0.3283
Epoch 112 batch 00010: Loss 0.1830 Regression loss 0.0289 Classification loss 0.1541 AP 0.1943 AR 0.2983
Epoch 113 batch 00001: Loss 0.1744 Regression loss 0.0336 Classification loss 0.1409 AP 0.0752 AR 0.1850
Epoch 113 batch 00002: Loss 0.1886 Regression loss 0.0299 Classification loss 0.1588 AP 0.1594 AR 0.3283
Epoch 113 batch 00003: Loss 0.1849 Regression loss 0.0336 Classification loss 0.1513 AP 0.1126 AR 0.2733
Epoch 113 batch 00004: Loss 0.1870 Regression loss 0.0322 Classification loss 0.1548 AP 0.0333 AR 0.1000
Epoch 113 batch 00005: Loss 0.1997 Regression loss 0.0306 Classification loss 0.1691 AP 0.1951 AR 0.4700
Epoch 113 batch 00006: Loss 0.2041 Regression loss 0.0317 Classification loss 0.1724 AP 0.1869 AR 0.4133
Epoch 113 batch 00007: Loss 0.1485 Regression loss 0.0332 Classification loss 0.1153 AP 0.2242 AR 0.4167
Epoch 113 batch 00008: Loss 0.2048 Regression loss 0.0368 Classification loss 0.1681 AP 0.0979 AR 0.2300
Epoch 113 batch 00009: Loss 0.1679 Regression loss 0.0353 Classification loss 0.1326 AP 0.0552 AR 0.1033
Epoch 113 batch 00010: Loss 0.1867 Regression loss 0.0298 Classification loss 0.1570 AP 0.1007 AR 0.2383
Epoch 114 batch 00001: Loss 0.1537 Regression loss 0.0318 Classification loss 0.1219 AP 0.0950 AR 0.2167
Epoch 114 batch 00002: Loss 0.1733 Regression loss 0.0341 Classification loss 0.1392 AP 0.1073 AR 0.2700
Epoch 114 batch 00003: Loss 0.2101 Regression loss 0.0314 Classification loss 0.1786 AP 0.0961 AR 0.2917
Epoch 114 batch 00004: Loss 0.1600 Regression loss 0.0305 Classification loss 0.1295 AP 0.2098 AR 0.3300
Epoch 114 batch 00005: Loss 0.1874 Regression loss 0.0360 Classification loss 0.1515 AP 0.1878 AR 0.3133
Epoch 114 batch 00006: Loss 0.2205 Regression loss 0.0276 Classification loss 0.1929 AP 0.1489 AR 0.3350
Epoch 114 batch 00007: Loss 0.1726 Regression loss 0.0322 Classification loss 0.1404 AP 0.0832 AR 0.2150
Epoch 114 batch 00008: Loss 0.1950 Regression loss 0.0342 Classification loss 0.1608 AP 0.1873 AR 0.3533
Epoch 114 batch 00009: Loss 0.2185 Regression loss 0.0327 Classification loss 0.1859 AP 0.0458 AR 0.0700
Epoch 114 batch 00010: Loss 0.1773 Regression loss 0.0317 Classification loss 0.1456 AP 0.0466 AR 0.1083
Epoch 115 batch 00001: Loss 0.1568 Regression loss 0.0310 Classification loss 0.1258 AP 0.0769 AR 0.1833
Epoch 115 batch 00002: Loss 0.1783 Regression loss 0.0301 Classification loss 0.1482 AP 0.2142 AR 0.4267
Epoch 115 batch 00003: Loss 0.2075 Regression loss 0.0283 Classification loss 0.1792 AP 0.1833 AR 0.2500
Epoch 115 batch 00004: Loss 0.1701 Regression loss 0.0310 Classification loss 0.1391 AP 0.2142 AR 0.3483
Epoch 115 batch 00005: Loss 0.1919 Regression loss 0.0342 Classification loss 0.1578 AP 0.1186 AR 0.2333
Epoch 115 batch 00006: Loss 0.1562 Regression loss 0.0397 Classification loss 0.1165 AP 0.1126 AR 0.2483
Epoch 115 batch 00007: Loss 0.2116 Regression loss 0.0351 Classification loss 0.1764 AP 0.0917 AR 0.2450
Epoch 115 batch 00008: Loss 0.1862 Regression loss 0.0354 Classification loss 0.1508 AP 0.0618 AR 0.1550
Epoch 115 batch 00009: Loss 0.2304 Regression loss 0.0391 Classification loss 0.1913 AP 0.0234 AR 0.0450
Epoch 115 batch 00010: Loss 0.2027 Regression loss 0.0275 Classification loss 0.1753 AP 0.0508 AR 0.1083
Epoch 116 batch 00001: Loss 0.1575 Regression loss 0.0303 Classification loss 0.1271 AP 0.0250 AR 0.0500
Epoch 116 batch 00002: Loss 0.1637 Regression loss 0.0278 Classification loss 0.1358 AP 0.1401 AR 0.2733
Epoch 116 batch 00003: Loss 0.2172 Regression loss 0.0319 Classification loss 0.1853 AP 0.0988 AR 0.1633
Epoch 116 batch 00004: Loss 0.1801 Regression loss 0.0324 Classification loss 0.1477 AP 0.1681 AR 0.3733
Epoch 116 batch 00005: Loss 0.1746 Regression loss 0.0360 Classification loss 0.1386 AP 0.0612 AR 0.1650
Epoch 116 batch 00006: Loss 0.1992 Regression loss 0.0313 Classification loss 0.1679 AP 0.1167 AR 0.2500
Epoch 116 batch 00007: Loss 0.1908 Regression loss 0.0373 Classification loss 0.1535 AP 0.1092 AR 0.3450
Epoch 116 batch 00008: Loss 0.1945 Regression loss 0.0384 Classification loss 0.1561 AP 0.1504 AR 0.2133
Epoch 116 batch 00009: Loss 0.1955 Regression loss 0.0364 Classification loss 0.1591 AP 0.0986 AR 0.2400
Epoch 116 batch 00010: Loss 0.1940 Regression loss 0.0399 Classification loss 0.1541 AP 0.0611 AR 0.1250
Epoch 117 batch 00001: Loss 0.1950 Regression loss 0.0340 Classification loss 0.1610 AP 0.1823 AR 0.3650
Epoch 117 batch 00002: Loss 0.1954 Regression loss 0.0337 Classification loss 0.1617 AP 0.0939 AR 0.1750
Epoch 117 batch 00003: Loss 0.1857 Regression loss 0.0311 Classification loss 0.1546 AP 0.1140 AR 0.2983
Epoch 117 batch 00004: Loss 0.1775 Regression loss 0.0331 Classification loss 0.1444 AP 0.1687 AR 0.2700
Epoch 117 batch 00005: Loss 0.1945 Regression loss 0.0371 Classification loss 0.1574 AP 0.0729 AR 0.2067
Epoch 117 batch 00006: Loss 0.1686 Regression loss 0.0347 Classification loss 0.1338 AP 0.0699 AR 0.2300
Epoch 117 batch 00007: Loss 0.2005 Regression loss 0.0349 Classification loss 0.1656 AP 0.0917 AR 0.1983
Epoch 117 batch 00008: Loss 0.1587 Regression loss 0.0283 Classification loss 0.1303 AP 0.0883 AR 0.1833
Epoch 117 batch 00009: Loss 0.1817 Regression loss 0.0298 Classification loss 0.1519 AP 0.1258 AR 0.3333
Epoch 117 batch 00010: Loss 0.1619 Regression loss 0.0303 Classification loss 0.1316 AP 0.1025 AR 0.2083
Epoch 118 batch 00001: Loss 0.1780 Regression loss 0.0382 Classification loss 0.1398 AP 0.0234 AR 0.0533
Epoch 118 batch 00002: Loss 0.1911 Regression loss 0.0294 Classification loss 0.1617 AP 0.0777 AR 0.1583
Epoch 118 batch 00003: Loss 0.2044 Regression loss 0.0335 Classification loss 0.1709 AP 0.1334 AR 0.3033
Epoch 118 batch 00004: Loss 0.1581 Regression loss 0.0289 Classification loss 0.1293 AP 0.0948 AR 0.2533
Epoch 118 batch 00005: Loss 0.1985 Regression loss 0.0325 Classification loss 0.1661 AP 0.0731 AR 0.1550
Epoch 118 batch 00006: Loss 0.1744 Regression loss 0.0307 Classification loss 0.1437 AP 0.1950 AR 0.3750
Epoch 118 batch 00007: Loss 0.1642 Regression loss 0.0319 Classification loss 0.1323 AP 0.2363 AR 0.3567
Epoch 118 batch 00008: Loss 0.1848 Regression loss 0.0333 Classification loss 0.1515 AP 0.1620 AR 0.3333
Epoch 118 batch 00009: Loss 0.1802 Regression loss 0.0344 Classification loss 0.1458 AP 0.0524 AR 0.1450
Epoch 118 batch 00010: Loss 0.2129 Regression loss 0.0420 Classification loss 0.1709 AP 0.1017 AR 0.1783
Epoch 119 batch 00001: Loss 0.1615 Regression loss 0.0323 Classification loss 0.1291 AP 0.1272 AR 0.3200
Epoch 119 batch 00002: Loss 0.1995 Regression loss 0.0354 Classification loss 0.1642 AP 0.0731 AR 0.1850
Epoch 119 batch 00003: Loss 0.1744 Regression loss 0.0313 Classification loss 0.1431 AP 0.0615 AR 0.2083
Epoch 119 batch 00004: Loss 0.1565 Regression loss 0.0282 Classification loss 0.1283 AP 0.2158 AR 0.3333
Epoch 119 batch 00005: Loss 0.1532 Regression loss 0.0339 Classification loss 0.1193 AP 0.1618 AR 0.3400
Epoch 119 batch 00006: Loss 0.1595 Regression loss 0.0339 Classification loss 0.1256 AP 0.1557 AR 0.2950
Epoch 119 batch 00007: Loss 0.2200 Regression loss 0.0366 Classification loss 0.1835 AP 0.1258 AR 0.2817
Epoch 119 batch 00008: Loss 0.1688 Regression loss 0.0329 Classification loss 0.1359 AP 0.1332 AR 0.3267
Epoch 119 batch 00009: Loss 0.2089 Regression loss 0.0332 Classification loss 0.1758 AP 0.1054 AR 0.2150
Epoch 119 batch 00010: Loss 0.1787 Regression loss 0.0334 Classification loss 0.1453 AP 0.1161 AR 0.2367
Epoch 120 batch 00001: Loss 0.1580 Regression loss 0.0324 Classification loss 0.1256 AP 0.1405 AR 0.1900
Epoch 120 batch 00002: Loss 0.1885 Regression loss 0.0373 Classification loss 0.1511 AP 0.0348 AR 0.0900
Epoch 120 batch 00003: Loss 0.1876 Regression loss 0.0354 Classification loss 0.1522 AP 0.1719 AR 0.3317
Epoch 120 batch 00004: Loss 0.1463 Regression loss 0.0329 Classification loss 0.1134 AP 0.1889 AR 0.3250
Epoch 120 batch 00005: Loss 0.1749 Regression loss 0.0310 Classification loss 0.1439 AP 0.1976 AR 0.3967
Epoch 120 batch 00006: Loss 0.1712 Regression loss 0.0301 Classification loss 0.1411 AP 0.1021 AR 0.2000
Epoch 120 batch 00007: Loss 0.1649 Regression loss 0.0319 Classification loss 0.1330 AP 0.1742 AR 0.3450
Epoch 120 batch 00008: Loss 0.1660 Regression loss 0.0323 Classification loss 0.1336 AP 0.1452 AR 0.4150
Epoch 120 batch 00009: Loss 0.1935 Regression loss 0.0388 Classification loss 0.1548 AP 0.1233 AR 0.2583
Epoch 120 batch 00010: Loss 0.2015 Regression loss 0.0289 Classification loss 0.1726 AP 0.1603 AR 0.3983
Epoch 121 batch 00001: Loss 0.2002 Regression loss 0.0299 Classification loss 0.1703 AP 0.0908 AR 0.2467
Epoch 121 batch 00002: Loss 0.1603 Regression loss 0.0318 Classification loss 0.1285 AP 0.1377 AR 0.3150
Epoch 121 batch 00003: Loss 0.1693 Regression loss 0.0349 Classification loss 0.1344 AP 0.1483 AR 0.3850
Epoch 121 batch 00004: Loss 0.1878 Regression loss 0.0331 Classification loss 0.1547 AP 0.0500 AR 0.1250
Epoch 121 batch 00005: Loss 0.1683 Regression loss 0.0299 Classification loss 0.1384 AP 0.2356 AR 0.3750
Epoch 121 batch 00006: Loss 0.1625 Regression loss 0.0316 Classification loss 0.1309 AP 0.0841 AR 0.2450
Epoch 121 batch 00007: Loss 0.1446 Regression loss 0.0275 Classification loss 0.1171 AP 0.1517 AR 0.3650
Epoch 121 batch 00008: Loss 0.1796 Regression loss 0.0315 Classification loss 0.1481 AP 0.1883 AR 0.4350
Epoch 121 batch 00009: Loss 0.2002 Regression loss 0.0346 Classification loss 0.1656 AP 0.1125 AR 0.2050
Epoch 121 batch 00010: Loss 0.1505 Regression loss 0.0289 Classification loss 0.1217 AP 0.2634 AR 0.4117
Epoch 122 batch 00001: Loss 0.1773 Regression loss 0.0291 Classification loss 0.1482 AP 0.2081 AR 0.3883
Epoch 122 batch 00002: Loss 0.1858 Regression loss 0.0329 Classification loss 0.1529 AP 0.1230 AR 0.2767
Epoch 122 batch 00003: Loss 0.1763 Regression loss 0.0268 Classification loss 0.1495 AP 0.0836 AR 0.1983
Epoch 122 batch 00004: Loss 0.1819 Regression loss 0.0351 Classification loss 0.1468 AP 0.0924 AR 0.2100
Epoch 122 batch 00005: Loss 0.1587 Regression loss 0.0316 Classification loss 0.1271 AP 0.1293 AR 0.3350
Epoch 122 batch 00006: Loss 0.1728 Regression loss 0.0342 Classification loss 0.1385 AP 0.0333 AR 0.0533
Epoch 122 batch 00007: Loss 0.1469 Regression loss 0.0318 Classification loss 0.1151 AP 0.1067 AR 0.2233
Epoch 122 batch 00008: Loss 0.1840 Regression loss 0.0331 Classification loss 0.1510 AP 0.1568 AR 0.2150
Epoch 122 batch 00009: Loss 0.1745 Regression loss 0.0333 Classification loss 0.1412 AP 0.2516 AR 0.5033
Epoch 122 batch 00010: Loss 0.1560 Regression loss 0.0287 Classification loss 0.1273 AP 0.2464 AR 0.4233
Epoch 123 batch 00001: Loss 0.1640 Regression loss 0.0318 Classification loss 0.1322 AP 0.1246 AR 0.2717
Epoch 123 batch 00002: Loss 0.1583 Regression loss 0.0344 Classification loss 0.1238 AP 0.0740 AR 0.2000
Epoch 123 batch 00003: Loss 0.1782 Regression loss 0.0339 Classification loss 0.1442 AP 0.1687 AR 0.2767
Epoch 123 batch 00004: Loss 0.1607 Regression loss 0.0299 Classification loss 0.1308 AP 0.1143 AR 0.2617
Epoch 123 batch 00005: Loss 0.1948 Regression loss 0.0328 Classification loss 0.1620 AP 0.0607 AR 0.1567
Epoch 123 batch 00006: Loss 0.1730 Regression loss 0.0329 Classification loss 0.1401 AP 0.0778 AR 0.2000
Epoch 123 batch 00007: Loss 0.1486 Regression loss 0.0312 Classification loss 0.1174 AP 0.1286 AR 0.3333
Epoch 123 batch 00008: Loss 0.2209 Regression loss 0.0381 Classification loss 0.1828 AP 0.1493 AR 0.1900
Epoch 123 batch 00009: Loss 0.1821 Regression loss 0.0399 Classification loss 0.1422 AP 0.1194 AR 0.2617
Epoch 123 batch 00010: Loss 0.1671 Regression loss 0.0340 Classification loss 0.1331 AP 0.1843 AR 0.4333
Epoch 124 batch 00001: Loss 0.1698 Regression loss 0.0325 Classification loss 0.1373 AP 0.0620 AR 0.1283
Epoch 124 batch 00002: Loss 0.1509 Regression loss 0.0342 Classification loss 0.1167 AP 0.1167 AR 0.3300
Epoch 124 batch 00003: Loss 0.1788 Regression loss 0.0276 Classification loss 0.1512 AP 0.1090 AR 0.2783
Epoch 124 batch 00004: Loss 0.1620 Regression loss 0.0352 Classification loss 0.1268 AP 0.0807 AR 0.2167
Epoch 124 batch 00005: Loss 0.1518 Regression loss 0.0326 Classification loss 0.1192 AP 0.1702 AR 0.4283
Epoch 124 batch 00006: Loss 0.1799 Regression loss 0.0310 Classification loss 0.1489 AP 0.1311 AR 0.3400
Epoch 124 batch 00007: Loss 0.1843 Regression loss 0.0361 Classification loss 0.1482 AP 0.1870 AR 0.3717
Epoch 124 batch 00008: Loss 0.1757 Regression loss 0.0379 Classification loss 0.1378 AP 0.1718 AR 0.2400
Epoch 124 batch 00009: Loss 0.1470 Regression loss 0.0249 Classification loss 0.1221 AP 0.2706 AR 0.4733
Epoch 124 batch 00010: Loss 0.2151 Regression loss 0.0355 Classification loss 0.1796 AP 0.1680 AR 0.2750
Epoch 125 batch 00001: Loss 0.1754 Regression loss 0.0337 Classification loss 0.1417 AP 0.0768 AR 0.1567
Epoch 125 batch 00002: Loss 0.1625 Regression loss 0.0300 Classification loss 0.1325 AP 0.0566 AR 0.1350
Epoch 125 batch 00003: Loss 0.1741 Regression loss 0.0317 Classification loss 0.1425 AP 0.0996 AR 0.2450
Epoch 125 batch 00004: Loss 0.1949 Regression loss 0.0412 Classification loss 0.1537 AP 0.0355 AR 0.0950
Epoch 125 batch 00005: Loss 0.1675 Regression loss 0.0320 Classification loss 0.1354 AP 0.1163 AR 0.2250
Epoch 125 batch 00006: Loss 0.1636 Regression loss 0.0342 Classification loss 0.1294 AP 0.1865 AR 0.3567
Epoch 125 batch 00007: Loss 0.1451 Regression loss 0.0363 Classification loss 0.1088 AP 0.0936 AR 0.1750
Epoch 125 batch 00008: Loss 0.1543 Regression loss 0.0291 Classification loss 0.1252 AP 0.1332 AR 0.3500
Epoch 125 batch 00009: Loss 0.1664 Regression loss 0.0337 Classification loss 0.1327 AP 0.1433 AR 0.2033
Epoch 125 batch 00010: Loss 0.1938 Regression loss 0.0316 Classification loss 0.1622 AP 0.0208 AR 0.0450
Epoch 126 batch 00001: Loss 0.1580 Regression loss 0.0309 Classification loss 0.1270 AP 0.1087 AR 0.2733
Epoch 126 batch 00002: Loss 0.1485 Regression loss 0.0331 Classification loss 0.1154 AP 0.2369 AR 0.4583
Epoch 126 batch 00003: Loss 0.1781 Regression loss 0.0311 Classification loss 0.1470 AP 0.0705 AR 0.1950
Epoch 126 batch 00004: Loss 0.1685 Regression loss 0.0329 Classification loss 0.1356 AP 0.1160 AR 0.2100
Epoch 126 batch 00005: Loss 0.1927 Regression loss 0.0367 Classification loss 0.1560 AP 0.0710 AR 0.1850
Epoch 126 batch 00006: Loss 0.1698 Regression loss 0.0291 Classification loss 0.1406 AP 0.1948 AR 0.3100
Epoch 126 batch 00007: Loss 0.1523 Regression loss 0.0264 Classification loss 0.1260 AP 0.1214 AR 0.3417
Epoch 126 batch 00008: Loss 0.1693 Regression loss 0.0332 Classification loss 0.1361 AP 0.1556 AR 0.3783
Epoch 126 batch 00009: Loss 0.1704 Regression loss 0.0297 Classification loss 0.1407 AP 0.0608 AR 0.1550
Epoch 126 batch 00010: Loss 0.1772 Regression loss 0.0403 Classification loss 0.1369 AP 0.1226 AR 0.3083
Epoch 127 batch 00001: Loss 0.1573 Regression loss 0.0290 Classification loss 0.1283 AP 0.1477 AR 0.3133
Epoch 127 batch 00002: Loss 0.1814 Regression loss 0.0325 Classification loss 0.1489 AP 0.1078 AR 0.2183
Epoch 127 batch 00003: Loss 0.1493 Regression loss 0.0347 Classification loss 0.1146 AP 0.0458 AR 0.0850
Epoch 127 batch 00004: Loss 0.1512 Regression loss 0.0322 Classification loss 0.1190 AP 0.1654 AR 0.2400
Epoch 127 batch 00005: Loss 0.1507 Regression loss 0.0342 Classification loss 0.1165 AP 0.1458 AR 0.3000
Epoch 127 batch 00006: Loss 0.1465 Regression loss 0.0292 Classification loss 0.1173 AP 0.0766 AR 0.1950
Epoch 127 batch 00007: Loss 0.1715 Regression loss 0.0316 Classification loss 0.1398 AP 0.1026 AR 0.2000
Epoch 127 batch 00008: Loss 0.1865 Regression loss 0.0369 Classification loss 0.1496 AP 0.1355 AR 0.4100
Epoch 127 batch 00009: Loss 0.2010 Regression loss 0.0315 Classification loss 0.1694 AP 0.0556 AR 0.1317
Epoch 127 batch 00010: Loss 0.1858 Regression loss 0.0332 Classification loss 0.1526 AP 0.0731 AR 0.2783
Epoch 128 batch 00001: Loss 0.1568 Regression loss 0.0296 Classification loss 0.1271 AP 0.0890 AR 0.2233
Epoch 128 batch 00002: Loss 0.1675 Regression loss 0.0315 Classification loss 0.1361 AP 0.2582 AR 0.6067
Epoch 128 batch 00003: Loss 0.1672 Regression loss 0.0345 Classification loss 0.1328 AP 0.1487 AR 0.2250
Epoch 128 batch 00004: Loss 0.1580 Regression loss 0.0343 Classification loss 0.1237 AP 0.1469 AR 0.2000
Epoch 128 batch 00005: Loss 0.1689 Regression loss 0.0303 Classification loss 0.1386 AP 0.1753 AR 0.3750
Epoch 128 batch 00006: Loss 0.1464 Regression loss 0.0312 Classification loss 0.1152 AP 0.1495 AR 0.3233
Epoch 128 batch 00007: Loss 0.1711 Regression loss 0.0331 Classification loss 0.1380 AP 0.1837 AR 0.2933
Epoch 128 batch 00008: Loss 0.1673 Regression loss 0.0350 Classification loss 0.1322 AP 0.0768 AR 0.1733
Epoch 128 batch 00009: Loss 0.1625 Regression loss 0.0327 Classification loss 0.1298 AP 0.1107 AR 0.3200
Epoch 128 batch 00010: Loss 0.1477 Regression loss 0.0306 Classification loss 0.1171 AP 0.1311 AR 0.1917
Epoch 129 batch 00001: Loss 0.1651 Regression loss 0.0353 Classification loss 0.1298 AP 0.0771 AR 0.1881
Epoch 129 batch 00002: Loss 0.1790 Regression loss 0.0327 Classification loss 0.1463 AP 0.1202 AR 0.2583
Epoch 129 batch 00003: Loss 0.1514 Regression loss 0.0265 Classification loss 0.1249 AP 0.2353 AR 0.4150
Epoch 129 batch 00004: Loss 0.1556 Regression loss 0.0342 Classification loss 0.1215 AP 0.1768 AR 0.2167
Epoch 129 batch 00005: Loss 0.1792 Regression loss 0.0341 Classification loss 0.1451 AP 0.1150 AR 0.2500
Epoch 129 batch 00006: Loss 0.1785 Regression loss 0.0344 Classification loss 0.1442 AP 0.1158 AR 0.3200
Epoch 129 batch 00007: Loss 0.1470 Regression loss 0.0334 Classification loss 0.1136 AP 0.1109 AR 0.2533
Epoch 129 batch 00008: Loss 0.1292 Regression loss 0.0318 Classification loss 0.0974 AP 0.1422 AR 0.3067
Epoch 129 batch 00009: Loss 0.1386 Regression loss 0.0286 Classification loss 0.1100 AP 0.1646 AR 0.3383
Epoch 129 batch 00010: Loss 0.1704 Regression loss 0.0296 Classification loss 0.1407 AP 0.1206 AR 0.2567
Epoch 130 batch 00001: Loss 0.1547 Regression loss 0.0285 Classification loss 0.1262 AP 0.1944 AR 0.3150
Epoch 130 batch 00002: Loss 0.1627 Regression loss 0.0315 Classification loss 0.1312 AP 0.0893 AR 0.1917
Epoch 130 batch 00003: Loss 0.1691 Regression loss 0.0347 Classification loss 0.1344 AP 0.0632 AR 0.1483
Epoch 130 batch 00004: Loss 0.1508 Regression loss 0.0281 Classification loss 0.1227 AP 0.1528 AR 0.3283
Epoch 130 batch 00005: Loss 0.1564 Regression loss 0.0339 Classification loss 0.1225 AP 0.1796 AR 0.2517
Epoch 130 batch 00006: Loss 0.1490 Regression loss 0.0304 Classification loss 0.1186 AP 0.1182 AR 0.2400
Epoch 130 batch 00007: Loss 0.1739 Regression loss 0.0323 Classification loss 0.1416 AP 0.0889 AR 0.2517
Epoch 130 batch 00008: Loss 0.1441 Regression loss 0.0315 Classification loss 0.1127 AP 0.1640 AR 0.4983
Epoch 130 batch 00009: Loss 0.1621 Regression loss 0.0303 Classification loss 0.1318 AP 0.1145 AR 0.3133
Epoch 130 batch 00010: Loss 0.1514 Regression loss 0.0338 Classification loss 0.1176 AP 0.1060 AR 0.2083
Epoch 131 batch 00001: Loss 0.1575 Regression loss 0.0346 Classification loss 0.1229 AP 0.2113 AR 0.3483
Epoch 131 batch 00002: Loss 0.1536 Regression loss 0.0317 Classification loss 0.1219 AP 0.1965 AR 0.3117
Epoch 131 batch 00003: Loss 0.1747 Regression loss 0.0295 Classification loss 0.1452 AP 0.0976 AR 0.2200
Epoch 131 batch 00004: Loss 0.1588 Regression loss 0.0287 Classification loss 0.1301 AP 0.1006 AR 0.1900
Epoch 131 batch 00005: Loss 0.1464 Regression loss 0.0340 Classification loss 0.1124 AP 0.0656 AR 0.1817
Epoch 131 batch 00006: Loss 0.1553 Regression loss 0.0304 Classification loss 0.1249 AP 0.1080 AR 0.2500
Epoch 131 batch 00007: Loss 0.1562 Regression loss 0.0308 Classification loss 0.1254 AP 0.1927 AR 0.4667
Epoch 131 batch 00008: Loss 0.1434 Regression loss 0.0318 Classification loss 0.1116 AP 0.1806 AR 0.3817
Epoch 131 batch 00009: Loss 0.1549 Regression loss 0.0333 Classification loss 0.1215 AP 0.1755 AR 0.4267
Epoch 131 batch 00010: Loss 0.1771 Regression loss 0.0394 Classification loss 0.1377 AP 0.0590 AR 0.2117
Epoch 132 batch 00001: Loss 0.1400 Regression loss 0.0306 Classification loss 0.1094 AP 0.2443 AR 0.4817
Epoch 132 batch 00002: Loss 0.1598 Regression loss 0.0281 Classification loss 0.1317 AP 0.1332 AR 0.3367
Epoch 132 batch 00003: Loss 0.1754 Regression loss 0.0388 Classification loss 0.1366 AP 0.0513 AR 0.1033
Epoch 132 batch 00004: Loss 0.1559 Regression loss 0.0345 Classification loss 0.1214 AP 0.1143 AR 0.3083
Epoch 132 batch 00005: Loss 0.1592 Regression loss 0.0328 Classification loss 0.1264 AP 0.1186 AR 0.2950
Epoch 132 batch 00006: Loss 0.1393 Regression loss 0.0316 Classification loss 0.1077 AP 0.1135 AR 0.2333
Epoch 132 batch 00007: Loss 0.1514 Regression loss 0.0369 Classification loss 0.1144 AP 0.0639 AR 0.1583
Epoch 132 batch 00008: Loss 0.1781 Regression loss 0.0340 Classification loss 0.1441 AP 0.0410 AR 0.1117
Epoch 132 batch 00009: Loss 0.1373 Regression loss 0.0323 Classification loss 0.1050 AP 0.2300 AR 0.2583
Epoch 132 batch 00010: Loss 0.1660 Regression loss 0.0327 Classification loss 0.1333 AP 0.1028 AR 0.1733
Epoch 133 batch 00001: Loss 0.1866 Regression loss 0.0384 Classification loss 0.1482 AP 0.1289 AR 0.3033
Epoch 133 batch 00002: Loss 0.1672 Regression loss 0.0333 Classification loss 0.1340 AP 0.2886 AR 0.5017
Epoch 133 batch 00003: Loss 0.1624 Regression loss 0.0339 Classification loss 0.1284 AP 0.1127 AR 0.2617
Epoch 133 batch 00004: Loss 0.1595 Regression loss 0.0291 Classification loss 0.1304 AP 0.1437 AR 0.3333
Epoch 133 batch 00005: Loss 0.1426 Regression loss 0.0332 Classification loss 0.1094 AP 0.1105 AR 0.2600
Epoch 133 batch 00006: Loss 0.1718 Regression loss 0.0319 Classification loss 0.1399 AP 0.1271 AR 0.3567
Epoch 133 batch 00007: Loss 0.1581 Regression loss 0.0312 Classification loss 0.1269 AP 0.1533 AR 0.2733
Epoch 133 batch 00008: Loss 0.1451 Regression loss 0.0338 Classification loss 0.1113 AP 0.1489 AR 0.2700
Epoch 133 batch 00009: Loss 0.1326 Regression loss 0.0315 Classification loss 0.1011 AP 0.1207 AR 0.2600
Epoch 133 batch 00010: Loss 0.1483 Regression loss 0.0325 Classification loss 0.1158 AP 0.1478 AR 0.1900
Epoch 134 batch 00001: Loss 0.1508 Regression loss 0.0322 Classification loss 0.1186 AP 0.1210 AR 0.2467
Epoch 134 batch 00002: Loss 0.1518 Regression loss 0.0293 Classification loss 0.1225 AP 0.1223 AR 0.2933
Epoch 134 batch 00003: Loss 0.1265 Regression loss 0.0286 Classification loss 0.0979 AP 0.1719 AR 0.4250
Epoch 134 batch 00004: Loss 0.1666 Regression loss 0.0317 Classification loss 0.1349 AP 0.2507 AR 0.3200
Epoch 134 batch 00005: Loss 0.1523 Regression loss 0.0321 Classification loss 0.1201 AP 0.0994 AR 0.2167
Epoch 134 batch 00006: Loss 0.1581 Regression loss 0.0379 Classification loss 0.1202 AP 0.0411 AR 0.1167
Epoch 134 batch 00007: Loss 0.1709 Regression loss 0.0315 Classification loss 0.1394 AP 0.1067 AR 0.2450
Epoch 134 batch 00008: Loss 0.1479 Regression loss 0.0277 Classification loss 0.1201 AP 0.0833 AR 0.1567
Epoch 134 batch 00009: Loss 0.1475 Regression loss 0.0318 Classification loss 0.1157 AP 0.1426 AR 0.3050
Epoch 134 batch 00010: Loss 0.1564 Regression loss 0.0290 Classification loss 0.1274 AP 0.1092 AR 0.2283
Epoch 135 batch 00001: Loss 0.1635 Regression loss 0.0322 Classification loss 0.1313 AP 0.0413 AR 0.1000
Epoch 135 batch 00002: Loss 0.1645 Regression loss 0.0305 Classification loss 0.1340 AP 0.1193 AR 0.2233
Epoch 135 batch 00003: Loss 0.1568 Regression loss 0.0258 Classification loss 0.1309 AP 0.2133 AR 0.5200
Epoch 135 batch 00004: Loss 0.1558 Regression loss 0.0289 Classification loss 0.1269 AP 0.1710 AR 0.4600
Epoch 135 batch 00005: Loss 0.1505 Regression loss 0.0299 Classification loss 0.1206 AP 0.1750 AR 0.3883
Epoch 135 batch 00006: Loss 0.1355 Regression loss 0.0245 Classification loss 0.1110 AP 0.0361 AR 0.0750
Epoch 135 batch 00007: Loss 0.1611 Regression loss 0.0289 Classification loss 0.1323 AP 0.1646 AR 0.2617
Epoch 135 batch 00008: Loss 0.1471 Regression loss 0.0340 Classification loss 0.1131 AP 0.1333 AR 0.3305
Epoch 135 batch 00009: Loss 0.1367 Regression loss 0.0286 Classification loss 0.1080 AP 0.2008 AR 0.3250
Epoch 135 batch 00010: Loss 0.1421 Regression loss 0.0322 Classification loss 0.1100 AP 0.1723 AR 0.4050
Epoch 136 batch 00001: Loss 0.1618 Regression loss 0.0287 Classification loss 0.1331 AP 0.3135 AR 0.5583
Epoch 136 batch 00002: Loss 0.1379 Regression loss 0.0309 Classification loss 0.1070 AP 0.0840 AR 0.2400
Epoch 136 batch 00003: Loss 0.1404 Regression loss 0.0297 Classification loss 0.1107 AP 0.1051 AR 0.2650
Epoch 136 batch 00004: Loss 0.1553 Regression loss 0.0319 Classification loss 0.1234 AP 0.2058 AR 0.2800
Epoch 136 batch 00005: Loss 0.1332 Regression loss 0.0289 Classification loss 0.1043 AP 0.1714 AR 0.4850
Epoch 136 batch 00006: Loss 0.1688 Regression loss 0.0320 Classification loss 0.1369 AP 0.1869 AR 0.2783
Epoch 136 batch 00007: Loss 0.1374 Regression loss 0.0286 Classification loss 0.1088 AP 0.1393 AR 0.3767
Epoch 136 batch 00008: Loss 0.1610 Regression loss 0.0299 Classification loss 0.1311 AP 0.1144 AR 0.2950
Epoch 136 batch 00009: Loss 0.1543 Regression loss 0.0306 Classification loss 0.1237 AP 0.0893 AR 0.2000
Epoch 136 batch 00010: Loss 0.1358 Regression loss 0.0281 Classification loss 0.1077 AP 0.0821 AR 0.2033
Epoch 137 batch 00001: Loss 0.1489 Regression loss 0.0278 Classification loss 0.1210 AP 0.0807 AR 0.1733
Epoch 137 batch 00002: Loss 0.1234 Regression loss 0.0301 Classification loss 0.0933 AP 0.1077 AR 0.2333
Epoch 137 batch 00003: Loss 0.1526 Regression loss 0.0308 Classification loss 0.1219 AP 0.0970 AR 0.2333
Epoch 137 batch 00004: Loss 0.1506 Regression loss 0.0332 Classification loss 0.1175 AP 0.0944 AR 0.2233
Epoch 137 batch 00005: Loss 0.1609 Regression loss 0.0312 Classification loss 0.1297 AP 0.1223 AR 0.2450
Epoch 137 batch 00006: Loss 0.1557 Regression loss 0.0266 Classification loss 0.1291 AP 0.3703 AR 0.5867
Epoch 137 batch 00007: Loss 0.1646 Regression loss 0.0315 Classification loss 0.1331 AP 0.0994 AR 0.2150
Epoch 137 batch 00008: Loss 0.1364 Regression loss 0.0298 Classification loss 0.1065 AP 0.2231 AR 0.3683
Epoch 137 batch 00009: Loss 0.1610 Regression loss 0.0340 Classification loss 0.1269 AP 0.0561 AR 0.1250
Epoch 137 batch 00010: Loss 0.1426 Regression loss 0.0305 Classification loss 0.1121 AP 0.1681 AR 0.3583
Epoch 138 batch 00001: Loss 0.1599 Regression loss 0.0313 Classification loss 0.1286 AP 0.1152 AR 0.3167
Epoch 138 batch 00002: Loss 0.1371 Regression loss 0.0305 Classification loss 0.1067 AP 0.0589 AR 0.1233
Epoch 138 batch 00003: Loss 0.1564 Regression loss 0.0302 Classification loss 0.1262 AP 0.1387 AR 0.2700
Epoch 138 batch 00004: Loss 0.1436 Regression loss 0.0291 Classification loss 0.1145 AP 0.0724 AR 0.1650
Epoch 138 batch 00005: Loss 0.1375 Regression loss 0.0335 Classification loss 0.1040 AP 0.1659 AR 0.3833
Epoch 138 batch 00006: Loss 0.1606 Regression loss 0.0264 Classification loss 0.1343 AP 0.1904 AR 0.3083
Epoch 138 batch 00007: Loss 0.1259 Regression loss 0.0255 Classification loss 0.1004 AP 0.2662 AR 0.4333
Epoch 138 batch 00008: Loss 0.1397 Regression loss 0.0306 Classification loss 0.1091 AP 0.2227 AR 0.3800
Epoch 138 batch 00009: Loss 0.1817 Regression loss 0.0322 Classification loss 0.1495 AP 0.0375 AR 0.0750
Epoch 138 batch 00010: Loss 0.1422 Regression loss 0.0306 Classification loss 0.1116 AP 0.2014 AR 0.5300
Epoch 139 batch 00001: Loss 0.1372 Regression loss 0.0304 Classification loss 0.1068 AP 0.0836 AR 0.2467
Epoch 139 batch 00002: Loss 0.1587 Regression loss 0.0309 Classification loss 0.1278 AP 0.1855 AR 0.4283
Epoch 139 batch 00003: Loss 0.1550 Regression loss 0.0341 Classification loss 0.1209 AP 0.0483 AR 0.1267
Epoch 139 batch 00004: Loss 0.1344 Regression loss 0.0313 Classification loss 0.1031 AP 0.2278 AR 0.2833
Epoch 139 batch 00005: Loss 0.1497 Regression loss 0.0319 Classification loss 0.1179 AP 0.1431 AR 0.2850
Epoch 139 batch 00006: Loss 0.1518 Regression loss 0.0330 Classification loss 0.1187 AP 0.1046 AR 0.2433
Epoch 139 batch 00007: Loss 0.1570 Regression loss 0.0247 Classification loss 0.1323 AP 0.1473 AR 0.2900
Epoch 139 batch 00008: Loss 0.1399 Regression loss 0.0276 Classification loss 0.1123 AP 0.2757 AR 0.4800
Epoch 139 batch 00009: Loss 0.1493 Regression loss 0.0295 Classification loss 0.1198 AP 0.1487 AR 0.2783
Epoch 139 batch 00010: Loss 0.1462 Regression loss 0.0304 Classification loss 0.1158 AP 0.1324 AR 0.2783
Epoch 140 batch 00001: Loss 0.1192 Regression loss 0.0296 Classification loss 0.0896 AP 0.0984 AR 0.2917
Epoch 140 batch 00002: Loss 0.1557 Regression loss 0.0314 Classification loss 0.1243 AP 0.1007 AR 0.2917
Epoch 140 batch 00003: Loss 0.1473 Regression loss 0.0266 Classification loss 0.1207 AP 0.1821 AR 0.3133
Epoch 140 batch 00004: Loss 0.1658 Regression loss 0.0296 Classification loss 0.1361 AP 0.0855 AR 0.2433
Epoch 140 batch 00005: Loss 0.1277 Regression loss 0.0308 Classification loss 0.0968 AP 0.3003 AR 0.4450
Epoch 140 batch 00006: Loss 0.1436 Regression loss 0.0279 Classification loss 0.1157 AP 0.1472 AR 0.3533
Epoch 140 batch 00007: Loss 0.1598 Regression loss 0.0269 Classification loss 0.1330 AP 0.2517 AR 0.3950
Epoch 140 batch 00008: Loss 0.1368 Regression loss 0.0273 Classification loss 0.1095 AP 0.0828 AR 0.2183
Epoch 140 batch 00009: Loss 0.1604 Regression loss 0.0285 Classification loss 0.1319 AP 0.0940 AR 0.2400
Epoch 140 batch 00010: Loss 0.1387 Regression loss 0.0330 Classification loss 0.1057 AP 0.1403 AR 0.3350
Epoch 141 batch 00001: Loss 0.1409 Regression loss 0.0259 Classification loss 0.1150 AP 0.2719 AR 0.3983
Epoch 141 batch 00002: Loss 0.1405 Regression loss 0.0317 Classification loss 0.1088 AP 0.1624 AR 0.4000
Epoch 141 batch 00003: Loss 0.1284 Regression loss 0.0283 Classification loss 0.1001 AP 0.4019 AR 0.5833
Epoch 141 batch 00004: Loss 0.1737 Regression loss 0.0360 Classification loss 0.1378 AP 0.0868 AR 0.2850
Epoch 141 batch 00005: Loss 0.1503 Regression loss 0.0290 Classification loss 0.1214 AP 0.1347 AR 0.2783
Epoch 141 batch 00006: Loss 0.1483 Regression loss 0.0322 Classification loss 0.1162 AP 0.1354 AR 0.2733
Epoch 141 batch 00007: Loss 0.1393 Regression loss 0.0376 Classification loss 0.1017 AP 0.0893 AR 0.1750
Epoch 141 batch 00008: Loss 0.1739 Regression loss 0.0268 Classification loss 0.1471 AP 0.0571 AR 0.1667
Epoch 141 batch 00009: Loss 0.1502 Regression loss 0.0290 Classification loss 0.1212 AP 0.1147 AR 0.2517
Epoch 141 batch 00010: Loss 0.1389 Regression loss 0.0391 Classification loss 0.0998 AP 0.0864 AR 0.2083
Epoch 142 batch 00001: Loss 0.1575 Regression loss 0.0318 Classification loss 0.1257 AP 0.2117 AR 0.3950
Epoch 142 batch 00002: Loss 0.1549 Regression loss 0.0335 Classification loss 0.1214 AP 0.0909 AR 0.2833
Epoch 142 batch 00003: Loss 0.1485 Regression loss 0.0315 Classification loss 0.1170 AP 0.1189 AR 0.2900
Epoch 142 batch 00004: Loss 0.1217 Regression loss 0.0322 Classification loss 0.0895 AP 0.0833 AR 0.1500
Epoch 142 batch 00005: Loss 0.1380 Regression loss 0.0284 Classification loss 0.1096 AP 0.1133 AR 0.2467
Epoch 142 batch 00006: Loss 0.1475 Regression loss 0.0334 Classification loss 0.1141 AP 0.0625 AR 0.1683
Epoch 142 batch 00007: Loss 0.1906 Regression loss 0.0324 Classification loss 0.1582 AP 0.0694 AR 0.1583
Epoch 142 batch 00008: Loss 0.1624 Regression loss 0.0379 Classification loss 0.1246 AP 0.1491 AR 0.3600
Epoch 142 batch 00009: Loss 0.1470 Regression loss 0.0264 Classification loss 0.1205 AP 0.2431 AR 0.5717
Epoch 142 batch 00010: Loss 0.1228 Regression loss 0.0275 Classification loss 0.0953 AP 0.1194 AR 0.3000
Epoch 143 batch 00001: Loss 0.1385 Regression loss 0.0280 Classification loss 0.1105 AP 0.1436 AR 0.3550
Epoch 143 batch 00002: Loss 0.1590 Regression loss 0.0320 Classification loss 0.1269 AP 0.0302 AR 0.0783
Epoch 143 batch 00003: Loss 0.1227 Regression loss 0.0317 Classification loss 0.0910 AP 0.0867 AR 0.2350
Epoch 143 batch 00004: Loss 0.1435 Regression loss 0.0322 Classification loss 0.1114 AP 0.0363 AR 0.0900
Epoch 143 batch 00005: Loss 0.1450 Regression loss 0.0303 Classification loss 0.1147 AP 0.1083 AR 0.2367
Epoch 143 batch 00006: Loss 0.1270 Regression loss 0.0278 Classification loss 0.0992 AP 0.2101 AR 0.4000
Epoch 143 batch 00007: Loss 0.1567 Regression loss 0.0358 Classification loss 0.1209 AP 0.1597 AR 0.3467
Epoch 143 batch 00008: Loss 0.1286 Regression loss 0.0287 Classification loss 0.0999 AP 0.1848 AR 0.3750
Epoch 143 batch 00009: Loss 0.1357 Regression loss 0.0356 Classification loss 0.1001 AP 0.2094 AR 0.2633
Epoch 143 batch 00010: Loss 0.1514 Regression loss 0.0261 Classification loss 0.1253 AP 0.1810 AR 0.3900
Epoch 144 batch 00001: Loss 0.1160 Regression loss 0.0298 Classification loss 0.0862 AP 0.2356 AR 0.4000
Epoch 144 batch 00002: Loss 0.1571 Regression loss 0.0368 Classification loss 0.1204 AP 0.1078 AR 0.2100
Epoch 144 batch 00003: Loss 0.1490 Regression loss 0.0313 Classification loss 0.1176 AP 0.1682 AR 0.4483
Epoch 144 batch 00004: Loss 0.1301 Regression loss 0.0270 Classification loss 0.1031 AP 0.1864 AR 0.3817
Epoch 144 batch 00005: Loss 0.1594 Regression loss 0.0341 Classification loss 0.1253 AP 0.0560 AR 0.1400
Epoch 144 batch 00006: Loss 0.1298 Regression loss 0.0325 Classification loss 0.0974 AP 0.1212 AR 0.3033
Epoch 144 batch 00007: Loss 0.1343 Regression loss 0.0308 Classification loss 0.1035 AP 0.0672 AR 0.1750
Epoch 144 batch 00008: Loss 0.1497 Regression loss 0.0318 Classification loss 0.1179 AP 0.1760 AR 0.3650
Epoch 144 batch 00009: Loss 0.1313 Regression loss 0.0310 Classification loss 0.1004 AP 0.1192 AR 0.3750
Epoch 144 batch 00010: Loss 0.1494 Regression loss 0.0288 Classification loss 0.1206 AP 0.1222 AR 0.2150
Epoch 145 batch 00001: Loss 0.1612 Regression loss 0.0350 Classification loss 0.1262 AP 0.1343 AR 0.3100
Epoch 145 batch 00002: Loss 0.1499 Regression loss 0.0278 Classification loss 0.1221 AP 0.1851 AR 0.3900
Epoch 145 batch 00003: Loss 0.1425 Regression loss 0.0295 Classification loss 0.1131 AP 0.2297 AR 0.4217
Epoch 145 batch 00004: Loss 0.1561 Regression loss 0.0253 Classification loss 0.1308 AP 0.1740 AR 0.3833
Epoch 145 batch 00005: Loss 0.1288 Regression loss 0.0318 Classification loss 0.0970 AP 0.1339 AR 0.3633
Epoch 145 batch 00006: Loss 0.1465 Regression loss 0.0316 Classification loss 0.1150 AP 0.1113 AR 0.3150
Epoch 145 batch 00007: Loss 0.1160 Regression loss 0.0272 Classification loss 0.0888 AP 0.0975 AR 0.2450
Epoch 145 batch 00008: Loss 0.1435 Regression loss 0.0308 Classification loss 0.1127 AP 0.0867 AR 0.1800
Epoch 145 batch 00009: Loss 0.1288 Regression loss 0.0308 Classification loss 0.0980 AP 0.1680 AR 0.3583
Epoch 145 batch 00010: Loss 0.1412 Regression loss 0.0303 Classification loss 0.1110 AP 0.0683 AR 0.1500
Epoch 146 batch 00001: Loss 0.1229 Regression loss 0.0321 Classification loss 0.0908 AP 0.1196 AR 0.3167
Epoch 146 batch 00002: Loss 0.1379 Regression loss 0.0269 Classification loss 0.1110 AP 0.2133 AR 0.5033
Epoch 146 batch 00003: Loss 0.1521 Regression loss 0.0333 Classification loss 0.1188 AP 0.0958 AR 0.2333
Epoch 146 batch 00004: Loss 0.1306 Regression loss 0.0285 Classification loss 0.1021 AP 0.1169 AR 0.2900
Epoch 146 batch 00005: Loss 0.1436 Regression loss 0.0323 Classification loss 0.1114 AP 0.1286 AR 0.4050
Epoch 146 batch 00006: Loss 0.1196 Regression loss 0.0302 Classification loss 0.0894 AP 0.0632 AR 0.1867
Epoch 146 batch 00007: Loss 0.1515 Regression loss 0.0289 Classification loss 0.1226 AP 0.1225 AR 0.2750
Epoch 146 batch 00008: Loss 0.1259 Regression loss 0.0282 Classification loss 0.0977 AP 0.1237 AR 0.3150
Epoch 146 batch 00009: Loss 0.1549 Regression loss 0.0323 Classification loss 0.1226 AP 0.1926 AR 0.3867
Epoch 146 batch 00010: Loss 0.1427 Regression loss 0.0293 Classification loss 0.1133 AP 0.1700 AR 0.3300
Epoch 147 batch 00001: Loss 0.1308 Regression loss 0.0264 Classification loss 0.1044 AP 0.1776 AR 0.3150
Epoch 147 batch 00002: Loss 0.1501 Regression loss 0.0320 Classification loss 0.1181 AP 0.1004 AR 0.2767
Epoch 147 batch 00003: Loss 0.1316 Regression loss 0.0297 Classification loss 0.1020 AP 0.1653 AR 0.4117
Epoch 147 batch 00004: Loss 0.1536 Regression loss 0.0311 Classification loss 0.1225 AP 0.1669 AR 0.2617
Epoch 147 batch 00005: Loss 0.1538 Regression loss 0.0310 Classification loss 0.1227 AP 0.1698 AR 0.4483
Epoch 147 batch 00006: Loss 0.1300 Regression loss 0.0285 Classification loss 0.1015 AP 0.1124 AR 0.2550
Epoch 147 batch 00007: Loss 0.1261 Regression loss 0.0299 Classification loss 0.0962 AP 0.0773 AR 0.1850
Epoch 147 batch 00008: Loss 0.1255 Regression loss 0.0319 Classification loss 0.0937 AP 0.1563 AR 0.2250
Epoch 147 batch 00009: Loss 0.1323 Regression loss 0.0307 Classification loss 0.1016 AP 0.0738 AR 0.1350
Epoch 147 batch 00010: Loss 0.1502 Regression loss 0.0319 Classification loss 0.1183 AP 0.1569 AR 0.3200
Epoch 148 batch 00001: Loss 0.1132 Regression loss 0.0289 Classification loss 0.0843 AP 0.2256 AR 0.4833
Epoch 148 batch 00002: Loss 0.1605 Regression loss 0.0281 Classification loss 0.1324 AP 0.2036 AR 0.3600
Epoch 148 batch 00003: Loss 0.1155 Regression loss 0.0273 Classification loss 0.0882 AP 0.0882 AR 0.1983
Epoch 148 batch 00004: Loss 0.1494 Regression loss 0.0344 Classification loss 0.1150 AP 0.1071 AR 0.2733
Epoch 148 batch 00005: Loss 0.1463 Regression loss 0.0335 Classification loss 0.1127 AP 0.1293 AR 0.3600
Epoch 148 batch 00006: Loss 0.1366 Regression loss 0.0313 Classification loss 0.1052 AP 0.0916 AR 0.2367
Epoch 148 batch 00007: Loss 0.1269 Regression loss 0.0295 Classification loss 0.0974 AP 0.1243 AR 0.3200
Epoch 148 batch 00008: Loss 0.1458 Regression loss 0.0279 Classification loss 0.1178 AP 0.1821 AR 0.4183
Epoch 148 batch 00009: Loss 0.1481 Regression loss 0.0327 Classification loss 0.1154 AP 0.1041 AR 0.2517
Epoch 148 batch 00010: Loss 0.1402 Regression loss 0.0278 Classification loss 0.1124 AP 0.0328 AR 0.0900
Epoch 149 batch 00001: Loss 0.1250 Regression loss 0.0301 Classification loss 0.0949 AP 0.1237 AR 0.2783
Epoch 149 batch 00002: Loss 0.1216 Regression loss 0.0261 Classification loss 0.0956 AP 0.1956 AR 0.4833
Epoch 149 batch 00003: Loss 0.1621 Regression loss 0.0264 Classification loss 0.1357 AP 0.1395 AR 0.3567
Epoch 149 batch 00004: Loss 0.1327 Regression loss 0.0328 Classification loss 0.0999 AP 0.1009 AR 0.2200
Epoch 149 batch 00005: Loss 0.1404 Regression loss 0.0276 Classification loss 0.1128 AP 0.0900 AR 0.2150
Epoch 149 batch 00006: Loss 0.1270 Regression loss 0.0269 Classification loss 0.1001 AP 0.0968 AR 0.2600
Epoch 149 batch 00007: Loss 0.1553 Regression loss 0.0310 Classification loss 0.1243 AP 0.0413 AR 0.1117
Epoch 149 batch 00008: Loss 0.1460 Regression loss 0.0324 Classification loss 0.1136 AP 0.1322 AR 0.3233
Epoch 149 batch 00009: Loss 0.1314 Regression loss 0.0338 Classification loss 0.0976 AP 0.0676 AR 0.2033
Epoch 149 batch 00010: Loss 0.1228 Regression loss 0.0310 Classification loss 0.0918 AP 0.1472 AR 0.2817
Epoch 150 batch 00001: Loss 0.1290 Regression loss 0.0320 Classification loss 0.0970 AP 0.0782 AR 0.1750
Epoch 150 batch 00002: Loss 0.1798 Regression loss 0.0348 Classification loss 0.1450 AP 0.0778 AR 0.1650
Epoch 150 batch 00003: Loss 0.1655 Regression loss 0.0369 Classification loss 0.1286 AP 0.0896 AR 0.1783
Epoch 150 batch 00004: Loss 0.1219 Regression loss 0.0327 Classification loss 0.0892 AP 0.0994 AR 0.2150
Epoch 150 batch 00005: Loss 0.1418 Regression loss 0.0286 Classification loss 0.1132 AP 0.1148 AR 0.2750
Epoch 150 batch 00006: Loss 0.1471 Regression loss 0.0300 Classification loss 0.1172 AP 0.2385 AR 0.4450
Epoch 150 batch 00007: Loss 0.1334 Regression loss 0.0318 Classification loss 0.1016 AP 0.1078 AR 0.2150
Epoch 150 batch 00008: Loss 0.1051 Regression loss 0.0329 Classification loss 0.0722 AP 0.0792 AR 0.1750
Epoch 150 batch 00009: Loss 0.1320 Regression loss 0.0317 Classification loss 0.1003 AP 0.0858 AR 0.1817
Epoch 150 batch 00010: Loss 0.1403 Regression loss 0.0364 Classification loss 0.1039 AP 0.0900 AR 0.2150
Epoch 151 batch 00001: Loss 0.1358 Regression loss 0.0284 Classification loss 0.1074 AP 0.1021 AR 0.2900
Epoch 151 batch 00002: Loss 0.1441 Regression loss 0.0316 Classification loss 0.1125 AP 0.0725 AR 0.1583
Epoch 151 batch 00003: Loss 0.1319 Regression loss 0.0311 Classification loss 0.1009 AP 0.0960 AR 0.2050
Epoch 151 batch 00004: Loss 0.1260 Regression loss 0.0321 Classification loss 0.0940 AP 0.1778 AR 0.3533
Epoch 151 batch 00005: Loss 0.1197 Regression loss 0.0356 Classification loss 0.0841 AP 0.1106 AR 0.2867
Epoch 151 batch 00006: Loss 0.1167 Regression loss 0.0346 Classification loss 0.0821 AP 0.1033 AR 0.2250
Epoch 151 batch 00007: Loss 0.1375 Regression loss 0.0340 Classification loss 0.1036 AP 0.1900 AR 0.2900
Epoch 151 batch 00008: Loss 0.1591 Regression loss 0.0278 Classification loss 0.1313 AP 0.1484 AR 0.3033
Epoch 151 batch 00009: Loss 0.1401 Regression loss 0.0301 Classification loss 0.1101 AP 0.1604 AR 0.3817
Epoch 151 batch 00010: Loss 0.1481 Regression loss 0.0326 Classification loss 0.1155 AP 0.1073 AR 0.3117
Epoch 152 batch 00001: Loss 0.1490 Regression loss 0.0303 Classification loss 0.1187 AP 0.1750 AR 0.4733
Epoch 152 batch 00002: Loss 0.1226 Regression loss 0.0263 Classification loss 0.0962 AP 0.1306 AR 0.2000
Epoch 152 batch 00003: Loss 0.1444 Regression loss 0.0292 Classification loss 0.1152 AP 0.1685 AR 0.3167
Epoch 152 batch 00004: Loss 0.1210 Regression loss 0.0293 Classification loss 0.0917 AP 0.0978 AR 0.2083
Epoch 152 batch 00005: Loss 0.1362 Regression loss 0.0301 Classification loss 0.1061 AP 0.1052 AR 0.2417
Epoch 152 batch 00006: Loss 0.1293 Regression loss 0.0357 Classification loss 0.0936 AP 0.0636 AR 0.1983
Epoch 152 batch 00007: Loss 0.1505 Regression loss 0.0292 Classification loss 0.1212 AP 0.1299 AR 0.3283
Epoch 152 batch 00008: Loss 0.1160 Regression loss 0.0287 Classification loss 0.0874 AP 0.1471 AR 0.3783
Epoch 152 batch 00009: Loss 0.1474 Regression loss 0.0321 Classification loss 0.1153 AP 0.3208 AR 0.5533
Epoch 152 batch 00010: Loss 0.1501 Regression loss 0.0374 Classification loss 0.1127 AP 0.0810 AR 0.2283
Epoch 153 batch 00001: Loss 0.1303 Regression loss 0.0316 Classification loss 0.0987 AP 0.1249 AR 0.2483
Epoch 153 batch 00002: Loss 0.1199 Regression loss 0.0290 Classification loss 0.0909 AP 0.1563 AR 0.2650
Epoch 153 batch 00003: Loss 0.1319 Regression loss 0.0330 Classification loss 0.0989 AP 0.0875 AR 0.1900
Epoch 153 batch 00004: Loss 0.1255 Regression loss 0.0304 Classification loss 0.0951 AP 0.1933 AR 0.4333
Epoch 153 batch 00005: Loss 0.1612 Regression loss 0.0311 Classification loss 0.1301 AP 0.1434 AR 0.4000
Epoch 153 batch 00006: Loss 0.1217 Regression loss 0.0308 Classification loss 0.0909 AP 0.0867 AR 0.1533
Epoch 153 batch 00007: Loss 0.1162 Regression loss 0.0335 Classification loss 0.0826 AP 0.1673 AR 0.3917
Epoch 153 batch 00008: Loss 0.1489 Regression loss 0.0292 Classification loss 0.1197 AP 0.0732 AR 0.1650
Epoch 153 batch 00009: Loss 0.1477 Regression loss 0.0338 Classification loss 0.1139 AP 0.0637 AR 0.1533
Epoch 153 batch 00010: Loss 0.1359 Regression loss 0.0317 Classification loss 0.1042 AP 0.0885 AR 0.2233
Epoch 154 batch 00001: Loss 0.1296 Regression loss 0.0311 Classification loss 0.0985 AP 0.1499 AR 0.2883
Epoch 154 batch 00002: Loss 0.1148 Regression loss 0.0294 Classification loss 0.0853 AP 0.1706 AR 0.3833
Epoch 154 batch 00003: Loss 0.1180 Regression loss 0.0345 Classification loss 0.0835 AP 0.0998 AR 0.1700
Epoch 154 batch 00004: Loss 0.1195 Regression loss 0.0305 Classification loss 0.0891 AP 0.0786 AR 0.1900
Epoch 154 batch 00005: Loss 0.1173 Regression loss 0.0299 Classification loss 0.0875 AP 0.1600 AR 0.3583
Epoch 154 batch 00006: Loss 0.1534 Regression loss 0.0349 Classification loss 0.1186 AP 0.1725 AR 0.4550
Epoch 154 batch 00007: Loss 0.1305 Regression loss 0.0340 Classification loss 0.0965 AP 0.1459 AR 0.3750
Epoch 154 batch 00008: Loss 0.1126 Regression loss 0.0291 Classification loss 0.0835 AP 0.1400 AR 0.3650
Epoch 154 batch 00009: Loss 0.1566 Regression loss 0.0249 Classification loss 0.1317 AP 0.1359 AR 0.3000
Epoch 154 batch 00010: Loss 0.1329 Regression loss 0.0327 Classification loss 0.1002 AP 0.1258 AR 0.3000
Epoch 155 batch 00001: Loss 0.1399 Regression loss 0.0277 Classification loss 0.1123 AP 0.0929 AR 0.1750
Epoch 155 batch 00002: Loss 0.1265 Regression loss 0.0270 Classification loss 0.0995 AP 0.1969 AR 0.4083
Epoch 155 batch 00003: Loss 0.1451 Regression loss 0.0312 Classification loss 0.1138 AP 0.1218 AR 0.2700
Epoch 155 batch 00004: Loss 0.1063 Regression loss 0.0294 Classification loss 0.0770 AP 0.0955 AR 0.2600
Epoch 155 batch 00005: Loss 0.1490 Regression loss 0.0329 Classification loss 0.1162 AP 0.0696 AR 0.1950
Epoch 155 batch 00006: Loss 0.1368 Regression loss 0.0300 Classification loss 0.1068 AP 0.1397 AR 0.2700
Epoch 155 batch 00007: Loss 0.1339 Regression loss 0.0326 Classification loss 0.1013 AP 0.1760 AR 0.3667
Epoch 155 batch 00008: Loss 0.1313 Regression loss 0.0280 Classification loss 0.1033 AP 0.1073 AR 0.2650
Epoch 155 batch 00009: Loss 0.1014 Regression loss 0.0325 Classification loss 0.0689 AP 0.0350 AR 0.0800
Epoch 155 batch 00010: Loss 0.1255 Regression loss 0.0264 Classification loss 0.0991 AP 0.1783 AR 0.3350
Epoch 156 batch 00001: Loss 0.1246 Regression loss 0.0304 Classification loss 0.0942 AP 0.1692 AR 0.4483
Epoch 156 batch 00002: Loss 0.1140 Regression loss 0.0279 Classification loss 0.0861 AP 0.1634 AR 0.3850
Epoch 156 batch 00003: Loss 0.1413 Regression loss 0.0301 Classification loss 0.1113 AP 0.1360 AR 0.3367
Epoch 156 batch 00004: Loss 0.1472 Regression loss 0.0269 Classification loss 0.1203 AP 0.0944 AR 0.2500
Epoch 156 batch 00005: Loss 0.1360 Regression loss 0.0283 Classification loss 0.1077 AP 0.1305 AR 0.2800
Epoch 156 batch 00006: Loss 0.1305 Regression loss 0.0343 Classification loss 0.0962 AP 0.0742 AR 0.2233
Epoch 156 batch 00007: Loss 0.1237 Regression loss 0.0292 Classification loss 0.0945 AP 0.0980 AR 0.2300
Epoch 156 batch 00008: Loss 0.1289 Regression loss 0.0339 Classification loss 0.0949 AP 0.1277 AR 0.2850
Epoch 156 batch 00009: Loss 0.0940 Regression loss 0.0329 Classification loss 0.0611 AP 0.0872 AR 0.1900
Epoch 156 batch 00010: Loss 0.1387 Regression loss 0.0315 Classification loss 0.1072 AP 0.1194 AR 0.3083
Epoch 157 batch 00001: Loss 0.1424 Regression loss 0.0336 Classification loss 0.1088 AP 0.0879 AR 0.1833
Epoch 157 batch 00002: Loss 0.1130 Regression loss 0.0290 Classification loss 0.0840 AP 0.0877 AR 0.1917
Epoch 157 batch 00003: Loss 0.1081 Regression loss 0.0275 Classification loss 0.0806 AP 0.1556 AR 0.3233
Epoch 157 batch 00004: Loss 0.1659 Regression loss 0.0335 Classification loss 0.1323 AP 0.1363 AR 0.3000
Epoch 157 batch 00005: Loss 0.1371 Regression loss 0.0308 Classification loss 0.1063 AP 0.1381 AR 0.3417
Epoch 157 batch 00006: Loss 0.1225 Regression loss 0.0271 Classification loss 0.0954 AP 0.2236 AR 0.4317
Epoch 157 batch 00007: Loss 0.1110 Regression loss 0.0283 Classification loss 0.0827 AP 0.3052 AR 0.5950
Epoch 157 batch 00008: Loss 0.1271 Regression loss 0.0329 Classification loss 0.0942 AP 0.0671 AR 0.1650
Epoch 157 batch 00009: Loss 0.1093 Regression loss 0.0349 Classification loss 0.0744 AP 0.2002 AR 0.4450
Epoch 157 batch 00010: Loss 0.1311 Regression loss 0.0296 Classification loss 0.1015 AP 0.2191 AR 0.4433
Epoch 158 batch 00001: Loss 0.1114 Regression loss 0.0256 Classification loss 0.0858 AP 0.2000 AR 0.4500
Epoch 158 batch 00002: Loss 0.1215 Regression loss 0.0325 Classification loss 0.0890 AP 0.0822 AR 0.2483
Epoch 158 batch 00003: Loss 0.1154 Regression loss 0.0318 Classification loss 0.0836 AP 0.0933 AR 0.2633
Epoch 158 batch 00004: Loss 0.1356 Regression loss 0.0293 Classification loss 0.1063 AP 0.2142 AR 0.4050
Epoch 158 batch 00005: Loss 0.1375 Regression loss 0.0312 Classification loss 0.1063 AP 0.2792 AR 0.5417
Epoch 158 batch 00006: Loss 0.1194 Regression loss 0.0281 Classification loss 0.0914 AP 0.1573 AR 0.3250
Epoch 158 batch 00007: Loss 0.1060 Regression loss 0.0273 Classification loss 0.0787 AP 0.2538 AR 0.5250
Epoch 158 batch 00008: Loss 0.1485 Regression loss 0.0300 Classification loss 0.1185 AP 0.0817 AR 0.1733
Epoch 158 batch 00009: Loss 0.1475 Regression loss 0.0287 Classification loss 0.1188 AP 0.0987 AR 0.2650
Epoch 158 batch 00010: Loss 0.1166 Regression loss 0.0266 Classification loss 0.0900 AP 0.1833 AR 0.3717
Epoch 159 batch 00001: Loss 0.1189 Regression loss 0.0315 Classification loss 0.0874 AP 0.1264 AR 0.2683
Epoch 159 batch 00002: Loss 0.1277 Regression loss 0.0311 Classification loss 0.0966 AP 0.0724 AR 0.2100
Epoch 159 batch 00003: Loss 0.1215 Regression loss 0.0300 Classification loss 0.0916 AP 0.1519 AR 0.3933
Epoch 159 batch 00004: Loss 0.1354 Regression loss 0.0325 Classification loss 0.1028 AP 0.2018 AR 0.3950
Epoch 159 batch 00005: Loss 0.1014 Regression loss 0.0251 Classification loss 0.0762 AP 0.2046 AR 0.4100
Epoch 159 batch 00006: Loss 0.1186 Regression loss 0.0300 Classification loss 0.0887 AP 0.2032 AR 0.4667
Epoch 159 batch 00007: Loss 0.1493 Regression loss 0.0297 Classification loss 0.1196 AP 0.2628 AR 0.4833
Epoch 159 batch 00008: Loss 0.1456 Regression loss 0.0302 Classification loss 0.1153 AP 0.1032 AR 0.2733
Epoch 159 batch 00009: Loss 0.1375 Regression loss 0.0235 Classification loss 0.1140 AP 0.1319 AR 0.2667
Epoch 159 batch 00010: Loss 0.1087 Regression loss 0.0254 Classification loss 0.0833 AP 0.1322 AR 0.3000
Epoch 160 batch 00001: Loss 0.1216 Regression loss 0.0268 Classification loss 0.0948 AP 0.1702 AR 0.4550
Epoch 160 batch 00002: Loss 0.1539 Regression loss 0.0280 Classification loss 0.1259 AP 0.0936 AR 0.1583
Epoch 160 batch 00003: Loss 0.1094 Regression loss 0.0261 Classification loss 0.0833 AP 0.1751 AR 0.3867
Epoch 160 batch 00004: Loss 0.0986 Regression loss 0.0259 Classification loss 0.0726 AP 0.2000 AR 0.4333
Epoch 160 batch 00005: Loss 0.1340 Regression loss 0.0262 Classification loss 0.1078 AP 0.0772 AR 0.2000
Epoch 160 batch 00006: Loss 0.1350 Regression loss 0.0329 Classification loss 0.1021 AP 0.1381 AR 0.2950
Epoch 160 batch 00007: Loss 0.1208 Regression loss 0.0302 Classification loss 0.0905 AP 0.2059 AR 0.4467
Epoch 160 batch 00008: Loss 0.1182 Regression loss 0.0316 Classification loss 0.0867 AP 0.1327 AR 0.3233
Epoch 160 batch 00009: Loss 0.1404 Regression loss 0.0325 Classification loss 0.1079 AP 0.0524 AR 0.1400
Epoch 160 batch 00010: Loss 0.1190 Regression loss 0.0286 Classification loss 0.0904 AP 0.1608 AR 0.3483
Epoch 161 batch 00001: Loss 0.1275 Regression loss 0.0295 Classification loss 0.0980 AP 0.1134 AR 0.2250
Epoch 161 batch 00002: Loss 0.1429 Regression loss 0.0279 Classification loss 0.1150 AP 0.2172 AR 0.4933
Epoch 161 batch 00003: Loss 0.1176 Regression loss 0.0244 Classification loss 0.0932 AP 0.2366 AR 0.5233
Epoch 161 batch 00004: Loss 0.1290 Regression loss 0.0275 Classification loss 0.1015 AP 0.1273 AR 0.2600
Epoch 161 batch 00005: Loss 0.0887 Regression loss 0.0277 Classification loss 0.0611 AP 0.1347 AR 0.2833
Epoch 161 batch 00006: Loss 0.1194 Regression loss 0.0268 Classification loss 0.0926 AP 0.1595 AR 0.3333
Epoch 161 batch 00007: Loss 0.1102 Regression loss 0.0298 Classification loss 0.0804 AP 0.1384 AR 0.3133
Epoch 161 batch 00008: Loss 0.1264 Regression loss 0.0312 Classification loss 0.0952 AP 0.1683 AR 0.3750
Epoch 161 batch 00009: Loss 0.1243 Regression loss 0.0298 Classification loss 0.0944 AP 0.1971 AR 0.4433
Epoch 161 batch 00010: Loss 0.1204 Regression loss 0.0263 Classification loss 0.0942 AP 0.2428 AR 0.4633
Epoch 162 batch 00001: Loss 0.0986 Regression loss 0.0271 Classification loss 0.0715 AP 0.1807 AR 0.3750
Epoch 162 batch 00002: Loss 0.1102 Regression loss 0.0259 Classification loss 0.0842 AP 0.1633 AR 0.4167
Epoch 162 batch 00003: Loss 0.1118 Regression loss 0.0291 Classification loss 0.0827 AP 0.1022 AR 0.2400
Epoch 162 batch 00004: Loss 0.0996 Regression loss 0.0292 Classification loss 0.0704 AP 0.1256 AR 0.2900
Epoch 162 batch 00005: Loss 0.1202 Regression loss 0.0274 Classification loss 0.0928 AP 0.2244 AR 0.4417
Epoch 162 batch 00006: Loss 0.1337 Regression loss 0.0356 Classification loss 0.0982 AP 0.1731 AR 0.4433
Epoch 162 batch 00007: Loss 0.1464 Regression loss 0.0268 Classification loss 0.1196 AP 0.1510 AR 0.3150
Epoch 162 batch 00008: Loss 0.1441 Regression loss 0.0308 Classification loss 0.1133 AP 0.1221 AR 0.2800
Epoch 162 batch 00009: Loss 0.1227 Regression loss 0.0310 Classification loss 0.0916 AP 0.1264 AR 0.2950
Epoch 162 batch 00010: Loss 0.1255 Regression loss 0.0305 Classification loss 0.0950 AP 0.0953 AR 0.1817
Epoch 163 batch 00001: Loss 0.1126 Regression loss 0.0281 Classification loss 0.0845 AP 0.1301 AR 0.3250
Epoch 163 batch 00002: Loss 0.1295 Regression loss 0.0303 Classification loss 0.0992 AP 0.1500 AR 0.2333
Epoch 163 batch 00003: Loss 0.1011 Regression loss 0.0252 Classification loss 0.0759 AP 0.1975 AR 0.4767
Epoch 163 batch 00004: Loss 0.1170 Regression loss 0.0283 Classification loss 0.0888 AP 0.1144 AR 0.2583
Epoch 163 batch 00005: Loss 0.1456 Regression loss 0.0301 Classification loss 0.1155 AP 0.1898 AR 0.4650
Epoch 163 batch 00006: Loss 0.1206 Regression loss 0.0382 Classification loss 0.0824 AP 0.0745 AR 0.2250
Epoch 163 batch 00007: Loss 0.1220 Regression loss 0.0284 Classification loss 0.0936 AP 0.1472 AR 0.2583
Epoch 163 batch 00008: Loss 0.1043 Regression loss 0.0276 Classification loss 0.0766 AP 0.1556 AR 0.3400
Epoch 163 batch 00009: Loss 0.1142 Regression loss 0.0340 Classification loss 0.0802 AP 0.0629 AR 0.1650
Epoch 163 batch 00010: Loss 0.1298 Regression loss 0.0322 Classification loss 0.0976 AP 0.1884 AR 0.4050
Epoch 164 batch 00001: Loss 0.1308 Regression loss 0.0322 Classification loss 0.0985 AP 0.1273 AR 0.2700
Epoch 164 batch 00002: Loss 0.1271 Regression loss 0.0281 Classification loss 0.0990 AP 0.1452 AR 0.3283
Epoch 164 batch 00003: Loss 0.0956 Regression loss 0.0285 Classification loss 0.0671 AP 0.1226 AR 0.3283
Epoch 164 batch 00004: Loss 0.1120 Regression loss 0.0280 Classification loss 0.0840 AP 0.0782 AR 0.1917
Epoch 164 batch 00005: Loss 0.1154 Regression loss 0.0290 Classification loss 0.0864 AP 0.1351 AR 0.2583
Epoch 164 batch 00006: Loss 0.1069 Regression loss 0.0285 Classification loss 0.0784 AP 0.1896 AR 0.4333
Epoch 164 batch 00007: Loss 0.1091 Regression loss 0.0267 Classification loss 0.0824 AP 0.1019 AR 0.2533
Epoch 164 batch 00008: Loss 0.1277 Regression loss 0.0309 Classification loss 0.0968 AP 0.0867 AR 0.2500
Epoch 164 batch 00009: Loss 0.1098 Regression loss 0.0292 Classification loss 0.0806 AP 0.2558 AR 0.5567
Epoch 164 batch 00010: Loss 0.1330 Regression loss 0.0296 Classification loss 0.1033 AP 0.1394 AR 0.3000
Epoch 165 batch 00001: Loss 0.1190 Regression loss 0.0239 Classification loss 0.0951 AP 0.2402 AR 0.4767
Epoch 165 batch 00002: Loss 0.1221 Regression loss 0.0304 Classification loss 0.0917 AP 0.1183 AR 0.3183
Epoch 165 batch 00003: Loss 0.1144 Regression loss 0.0292 Classification loss 0.0852 AP 0.1868 AR 0.4950
Epoch 165 batch 00004: Loss 0.1301 Regression loss 0.0279 Classification loss 0.1021 AP 0.0587 AR 0.0917
Epoch 165 batch 00005: Loss 0.1114 Regression loss 0.0267 Classification loss 0.0847 AP 0.2345 AR 0.5283
Epoch 165 batch 00006: Loss 0.1169 Regression loss 0.0280 Classification loss 0.0889 AP 0.1630 AR 0.3583
Epoch 165 batch 00007: Loss 0.1069 Regression loss 0.0293 Classification loss 0.0776 AP 0.1449 AR 0.3067
Epoch 165 batch 00008: Loss 0.1214 Regression loss 0.0298 Classification loss 0.0916 AP 0.0880 AR 0.2117
Epoch 165 batch 00009: Loss 0.1056 Regression loss 0.0329 Classification loss 0.0727 AP 0.0922 AR 0.2033
Epoch 165 batch 00010: Loss 0.1142 Regression loss 0.0271 Classification loss 0.0871 AP 0.1501 AR 0.2883
Epoch 166 batch 00001: Loss 0.0965 Regression loss 0.0313 Classification loss 0.0652 AP 0.1444 AR 0.3983
Epoch 166 batch 00002: Loss 0.0980 Regression loss 0.0330 Classification loss 0.0649 AP 0.1332 AR 0.3033
Epoch 166 batch 00003: Loss 0.1177 Regression loss 0.0294 Classification loss 0.0883 AP 0.1936 AR 0.4050
Epoch 166 batch 00004: Loss 0.0982 Regression loss 0.0284 Classification loss 0.0698 AP 0.2174 AR 0.3733
Epoch 166 batch 00005: Loss 0.1235 Regression loss 0.0282 Classification loss 0.0953 AP 0.1159 AR 0.3017
Epoch 166 batch 00006: Loss 0.1368 Regression loss 0.0288 Classification loss 0.1080 AP 0.1977 AR 0.3033
Epoch 166 batch 00007: Loss 0.1138 Regression loss 0.0312 Classification loss 0.0826 AP 0.1115 AR 0.3333
Epoch 166 batch 00008: Loss 0.1149 Regression loss 0.0304 Classification loss 0.0846 AP 0.0904 AR 0.1450
Epoch 166 batch 00009: Loss 0.1586 Regression loss 0.0312 Classification loss 0.1273 AP 0.0625 AR 0.1250
Epoch 166 batch 00010: Loss 0.1158 Regression loss 0.0323 Classification loss 0.0835 AP 0.0469 AR 0.1117
Epoch 167 batch 00001: Loss 0.0934 Regression loss 0.0284 Classification loss 0.0650 AP 0.1647 AR 0.3817
Epoch 167 batch 00002: Loss 0.1283 Regression loss 0.0346 Classification loss 0.0938 AP 0.3011 AR 0.5833
Epoch 167 batch 00003: Loss 0.1149 Regression loss 0.0273 Classification loss 0.0876 AP 0.0941 AR 0.1400
Epoch 167 batch 00004: Loss 0.1632 Regression loss 0.0307 Classification loss 0.1326 AP 0.1426 AR 0.3567
Epoch 167 batch 00005: Loss 0.1218 Regression loss 0.0274 Classification loss 0.0944 AP 0.1054 AR 0.2033
Epoch 167 batch 00006: Loss 0.1035 Regression loss 0.0312 Classification loss 0.0723 AP 0.1236 AR 0.2700
Epoch 167 batch 00007: Loss 0.1205 Regression loss 0.0290 Classification loss 0.0915 AP 0.0828 AR 0.2450
Epoch 167 batch 00008: Loss 0.1295 Regression loss 0.0283 Classification loss 0.1012 AP 0.1072 AR 0.3117
Epoch 167 batch 00009: Loss 0.1045 Regression loss 0.0311 Classification loss 0.0735 AP 0.1020 AR 0.3017
Epoch 167 batch 00010: Loss 0.1210 Regression loss 0.0257 Classification loss 0.0953 AP 0.1258 AR 0.3500
Epoch 168 batch 00001: Loss 0.1205 Regression loss 0.0275 Classification loss 0.0930 AP 0.1473 AR 0.2533
Epoch 168 batch 00002: Loss 0.1173 Regression loss 0.0280 Classification loss 0.0893 AP 0.1388 AR 0.3033
Epoch 168 batch 00003: Loss 0.1041 Regression loss 0.0294 Classification loss 0.0746 AP 0.1992 AR 0.2833
Epoch 168 batch 00004: Loss 0.1054 Regression loss 0.0281 Classification loss 0.0773 AP 0.1754 AR 0.3783
Epoch 168 batch 00005: Loss 0.1108 Regression loss 0.0276 Classification loss 0.0832 AP 0.1698 AR 0.3517
Epoch 168 batch 00006: Loss 0.1322 Regression loss 0.0333 Classification loss 0.0989 AP 0.0992 AR 0.3183
Epoch 168 batch 00007: Loss 0.1323 Regression loss 0.0335 Classification loss 0.0988 AP 0.0835 AR 0.2417
Epoch 168 batch 00008: Loss 0.1237 Regression loss 0.0346 Classification loss 0.0891 AP 0.0904 AR 0.2267
Epoch 168 batch 00009: Loss 0.0957 Regression loss 0.0289 Classification loss 0.0668 AP 0.1421 AR 0.3483
Epoch 168 batch 00010: Loss 0.1172 Regression loss 0.0290 Classification loss 0.0882 AP 0.1849 AR 0.3817
Epoch 169 batch 00001: Loss 0.1478 Regression loss 0.0277 Classification loss 0.1202 AP 0.1713 AR 0.3450
Epoch 169 batch 00002: Loss 0.0957 Regression loss 0.0291 Classification loss 0.0665 AP 0.2139 AR 0.4200
Epoch 169 batch 00003: Loss 0.1190 Regression loss 0.0276 Classification loss 0.0914 AP 0.1875 AR 0.2933
Epoch 169 batch 00004: Loss 0.1009 Regression loss 0.0249 Classification loss 0.0760 AP 0.0758 AR 0.1667
Epoch 169 batch 00005: Loss 0.1233 Regression loss 0.0348 Classification loss 0.0885 AP 0.0654 AR 0.1667
Epoch 169 batch 00006: Loss 0.1132 Regression loss 0.0268 Classification loss 0.0864 AP 0.1275 AR 0.3050
Epoch 169 batch 00007: Loss 0.0929 Regression loss 0.0292 Classification loss 0.0638 AP 0.1548 AR 0.3667
Epoch 169 batch 00008: Loss 0.1094 Regression loss 0.0271 Classification loss 0.0823 AP 0.1151 AR 0.2500
Epoch 169 batch 00009: Loss 0.1360 Regression loss 0.0274 Classification loss 0.1086 AP 0.2172 AR 0.4033
Epoch 169 batch 00010: Loss 0.1020 Regression loss 0.0281 Classification loss 0.0739 AP 0.2826 AR 0.5833
Epoch 170 batch 00001: Loss 0.0990 Regression loss 0.0268 Classification loss 0.0722 AP 0.1774 AR 0.4367
Epoch 170 batch 00002: Loss 0.1059 Regression loss 0.0321 Classification loss 0.0738 AP 0.1057 AR 0.2333
Epoch 170 batch 00003: Loss 0.0857 Regression loss 0.0230 Classification loss 0.0627 AP 0.2168 AR 0.4833
Epoch 170 batch 00004: Loss 0.1104 Regression loss 0.0220 Classification loss 0.0884 AP 0.2211 AR 0.5233
Epoch 170 batch 00005: Loss 0.1197 Regression loss 0.0287 Classification loss 0.0910 AP 0.1863 AR 0.3483
Epoch 170 batch 00006: Loss 0.1283 Regression loss 0.0260 Classification loss 0.1023 AP 0.2060 AR 0.4950
Epoch 170 batch 00007: Loss 0.1088 Regression loss 0.0347 Classification loss 0.0742 AP 0.0922 AR 0.2900
Epoch 170 batch 00008: Loss 0.1057 Regression loss 0.0294 Classification loss 0.0763 AP 0.0880 AR 0.2283
Epoch 170 batch 00009: Loss 0.1130 Regression loss 0.0257 Classification loss 0.0873 AP 0.1255 AR 0.3367
Epoch 170 batch 00010: Loss 0.1074 Regression loss 0.0333 Classification loss 0.0741 AP 0.1431 AR 0.3000
Epoch 171 batch 00001: Loss 0.1066 Regression loss 0.0216 Classification loss 0.0851 AP 0.3213 AR 0.5483
Epoch 171 batch 00002: Loss 0.1104 Regression loss 0.0229 Classification loss 0.0875 AP 0.2970 AR 0.5617
Epoch 171 batch 00003: Loss 0.1141 Regression loss 0.0274 Classification loss 0.0867 AP 0.0971 AR 0.2750
Epoch 171 batch 00004: Loss 0.1018 Regression loss 0.0305 Classification loss 0.0712 AP 0.1715 AR 0.3383
Epoch 171 batch 00005: Loss 0.0934 Regression loss 0.0274 Classification loss 0.0659 AP 0.2184 AR 0.5850
Epoch 171 batch 00006: Loss 0.1190 Regression loss 0.0300 Classification loss 0.0890 AP 0.2325 AR 0.5533
Epoch 171 batch 00007: Loss 0.1126 Regression loss 0.0319 Classification loss 0.0807 AP 0.1476 AR 0.3167
Epoch 171 batch 00008: Loss 0.0876 Regression loss 0.0256 Classification loss 0.0620 AP 0.1292 AR 0.3500
Epoch 171 batch 00009: Loss 0.1188 Regression loss 0.0351 Classification loss 0.0837 AP 0.0995 AR 0.2850
Epoch 171 batch 00010: Loss 0.1184 Regression loss 0.0251 Classification loss 0.0932 AP 0.1610 AR 0.3217
Epoch 172 batch 00001: Loss 0.0905 Regression loss 0.0267 Classification loss 0.0639 AP 0.1113 AR 0.2417
Epoch 172 batch 00002: Loss 0.0794 Regression loss 0.0261 Classification loss 0.0533 AP 0.1044 AR 0.1917
Epoch 172 batch 00003: Loss 0.1169 Regression loss 0.0291 Classification loss 0.0878 AP 0.2995 AR 0.5200
Epoch 172 batch 00004: Loss 0.0934 Regression loss 0.0286 Classification loss 0.0648 AP 0.1667 AR 0.3950
Epoch 172 batch 00005: Loss 0.1199 Regression loss 0.0282 Classification loss 0.0916 AP 0.1399 AR 0.3833
Epoch 172 batch 00006: Loss 0.1226 Regression loss 0.0301 Classification loss 0.0925 AP 0.1201 AR 0.2950
Epoch 172 batch 00007: Loss 0.1034 Regression loss 0.0287 Classification loss 0.0746 AP 0.2084 AR 0.3800
Epoch 172 batch 00008: Loss 0.1204 Regression loss 0.0323 Classification loss 0.0882 AP 0.0998 AR 0.2433
Epoch 172 batch 00009: Loss 0.1032 Regression loss 0.0263 Classification loss 0.0769 AP 0.1756 AR 0.3500
Epoch 172 batch 00010: Loss 0.1087 Regression loss 0.0263 Classification loss 0.0824 AP 0.1228 AR 0.2733
Epoch 173 batch 00001: Loss 0.1490 Regression loss 0.0363 Classification loss 0.1128 AP 0.0937 AR 0.2950
Epoch 173 batch 00002: Loss 0.1046 Regression loss 0.0326 Classification loss 0.0720 AP 0.0808 AR 0.1850
Epoch 173 batch 00003: Loss 0.0902 Regression loss 0.0247 Classification loss 0.0654 AP 0.1327 AR 0.3433
Epoch 173 batch 00004: Loss 0.1052 Regression loss 0.0267 Classification loss 0.0785 AP 0.2450 AR 0.3700
Epoch 173 batch 00005: Loss 0.0900 Regression loss 0.0276 Classification loss 0.0623 AP 0.2192 AR 0.4900
Epoch 173 batch 00006: Loss 0.0921 Regression loss 0.0218 Classification loss 0.0703 AP 0.3002 AR 0.5167
Epoch 173 batch 00007: Loss 0.0991 Regression loss 0.0236 Classification loss 0.0756 AP 0.2244 AR 0.5167
Epoch 173 batch 00008: Loss 0.1065 Regression loss 0.0274 Classification loss 0.0791 AP 0.1172 AR 0.3000
Epoch 173 batch 00009: Loss 0.1073 Regression loss 0.0299 Classification loss 0.0774 AP 0.1851 AR 0.4750
Epoch 173 batch 00010: Loss 0.1422 Regression loss 0.0267 Classification loss 0.1155 AP 0.1302 AR 0.2600
Epoch 174 batch 00001: Loss 0.0875 Regression loss 0.0267 Classification loss 0.0608 AP 0.1148 AR 0.3100
Epoch 174 batch 00002: Loss 0.1040 Regression loss 0.0247 Classification loss 0.0793 AP 0.1563 AR 0.4067
Epoch 174 batch 00003: Loss 0.1053 Regression loss 0.0270 Classification loss 0.0783 AP 0.1186 AR 0.2400
Epoch 174 batch 00004: Loss 0.1251 Regression loss 0.0282 Classification loss 0.0969 AP 0.1262 AR 0.2683
Epoch 174 batch 00005: Loss 0.1035 Regression loss 0.0281 Classification loss 0.0755 AP 0.1902 AR 0.3650
Epoch 174 batch 00006: Loss 0.1056 Regression loss 0.0286 Classification loss 0.0770 AP 0.1857 AR 0.3350
Epoch 174 batch 00007: Loss 0.1144 Regression loss 0.0307 Classification loss 0.0837 AP 0.2300 AR 0.5000
Epoch 174 batch 00008: Loss 0.1215 Regression loss 0.0278 Classification loss 0.0937 AP 0.1910 AR 0.3900
Epoch 174 batch 00009: Loss 0.1027 Regression loss 0.0275 Classification loss 0.0752 AP 0.1438 AR 0.3150
Epoch 174 batch 00010: Loss 0.0988 Regression loss 0.0275 Classification loss 0.0713 AP 0.1795 AR 0.4867
Epoch 175 batch 00001: Loss 0.0849 Regression loss 0.0270 Classification loss 0.0579 AP 0.1399 AR 0.3517
Epoch 175 batch 00002: Loss 0.1017 Regression loss 0.0268 Classification loss 0.0749 AP 0.1478 AR 0.3333
Epoch 175 batch 00003: Loss 0.1130 Regression loss 0.0268 Classification loss 0.0862 AP 0.2047 AR 0.2950
Epoch 175 batch 00004: Loss 0.1025 Regression loss 0.0240 Classification loss 0.0785 AP 0.3426 AR 0.6083
Epoch 175 batch 00005: Loss 0.1080 Regression loss 0.0289 Classification loss 0.0791 AP 0.1705 AR 0.3617
Epoch 175 batch 00006: Loss 0.1165 Regression loss 0.0263 Classification loss 0.0902 AP 0.1136 AR 0.3017
Epoch 175 batch 00007: Loss 0.0951 Regression loss 0.0269 Classification loss 0.0683 AP 0.1108 AR 0.2767
Epoch 175 batch 00008: Loss 0.1018 Regression loss 0.0257 Classification loss 0.0760 AP 0.2501 AR 0.4967
Epoch 175 batch 00009: Loss 0.1122 Regression loss 0.0324 Classification loss 0.0798 AP 0.0916 AR 0.2133
Epoch 175 batch 00010: Loss 0.0984 Regression loss 0.0292 Classification loss 0.0692 AP 0.1284 AR 0.3717
Epoch 176 batch 00001: Loss 0.1092 Regression loss 0.0257 Classification loss 0.0835 AP 0.1542 AR 0.3050
Epoch 176 batch 00002: Loss 0.1137 Regression loss 0.0307 Classification loss 0.0829 AP 0.1612 AR 0.5133
Epoch 176 batch 00003: Loss 0.0940 Regression loss 0.0256 Classification loss 0.0685 AP 0.2107 AR 0.4233
Epoch 176 batch 00004: Loss 0.0895 Regression loss 0.0235 Classification loss 0.0660 AP 0.1549 AR 0.4083
Epoch 176 batch 00005: Loss 0.1191 Regression loss 0.0335 Classification loss 0.0855 AP 0.1462 AR 0.3583
Epoch 176 batch 00006: Loss 0.1070 Regression loss 0.0265 Classification loss 0.0805 AP 0.1390 AR 0.3017
Epoch 176 batch 00007: Loss 0.0956 Regression loss 0.0270 Classification loss 0.0686 AP 0.1869 AR 0.3250
Epoch 176 batch 00008: Loss 0.1153 Regression loss 0.0297 Classification loss 0.0856 AP 0.1403 AR 0.3483
Epoch 176 batch 00009: Loss 0.1094 Regression loss 0.0240 Classification loss 0.0854 AP 0.1533 AR 0.3250
Epoch 176 batch 00010: Loss 0.1040 Regression loss 0.0294 Classification loss 0.0746 AP 0.0536 AR 0.1083
Epoch 177 batch 00001: Loss 0.0989 Regression loss 0.0318 Classification loss 0.0671 AP 0.0859 AR 0.1917
Epoch 177 batch 00002: Loss 0.0979 Regression loss 0.0275 Classification loss 0.0703 AP 0.1486 AR 0.3033
Epoch 177 batch 00003: Loss 0.1099 Regression loss 0.0300 Classification loss 0.0799 AP 0.1125 AR 0.2750
Epoch 177 batch 00004: Loss 0.0986 Regression loss 0.0262 Classification loss 0.0724 AP 0.1521 AR 0.2800
Epoch 177 batch 00005: Loss 0.1232 Regression loss 0.0342 Classification loss 0.0890 AP 0.1854 AR 0.3883
Epoch 177 batch 00006: Loss 0.1108 Regression loss 0.0298 Classification loss 0.0810 AP 0.1427 AR 0.2483
Epoch 177 batch 00007: Loss 0.1078 Regression loss 0.0258 Classification loss 0.0820 AP 0.1883 AR 0.4317
Epoch 177 batch 00008: Loss 0.0938 Regression loss 0.0272 Classification loss 0.0665 AP 0.1233 AR 0.3300
Epoch 177 batch 00009: Loss 0.0987 Regression loss 0.0226 Classification loss 0.0761 AP 0.1697 AR 0.4100
Epoch 177 batch 00010: Loss 0.1102 Regression loss 0.0296 Classification loss 0.0806 AP 0.2097 AR 0.3483
Epoch 178 batch 00001: Loss 0.1107 Regression loss 0.0274 Classification loss 0.0832 AP 0.1896 AR 0.3267
Epoch 178 batch 00002: Loss 0.0898 Regression loss 0.0271 Classification loss 0.0627 AP 0.1953 AR 0.3350
Epoch 178 batch 00003: Loss 0.1282 Regression loss 0.0285 Classification loss 0.0997 AP 0.1279 AR 0.2750
Epoch 178 batch 00004: Loss 0.0988 Regression loss 0.0293 Classification loss 0.0695 AP 0.1538 AR 0.3783
Epoch 178 batch 00005: Loss 0.0973 Regression loss 0.0230 Classification loss 0.0742 AP 0.1236 AR 0.2800
Epoch 178 batch 00006: Loss 0.0823 Regression loss 0.0256 Classification loss 0.0568 AP 0.1679 AR 0.3750
Epoch 178 batch 00007: Loss 0.1219 Regression loss 0.0296 Classification loss 0.0922 AP 0.0604 AR 0.1567
Epoch 178 batch 00008: Loss 0.0843 Regression loss 0.0309 Classification loss 0.0533 AP 0.2489 AR 0.4600
Epoch 178 batch 00009: Loss 0.1288 Regression loss 0.0357 Classification loss 0.0931 AP 0.1083 AR 0.2883
Epoch 178 batch 00010: Loss 0.1036 Regression loss 0.0269 Classification loss 0.0766 AP 0.1563 AR 0.4567
Epoch 179 batch 00001: Loss 0.0986 Regression loss 0.0240 Classification loss 0.0745 AP 0.1821 AR 0.3617
Epoch 179 batch 00002: Loss 0.0962 Regression loss 0.0255 Classification loss 0.0707 AP 0.1514 AR 0.3617
Epoch 179 batch 00003: Loss 0.1073 Regression loss 0.0247 Classification loss 0.0826 AP 0.1463 AR 0.3533
Epoch 179 batch 00004: Loss 0.1171 Regression loss 0.0314 Classification loss 0.0857 AP 0.2197 AR 0.3650
Epoch 179 batch 00005: Loss 0.1182 Regression loss 0.0251 Classification loss 0.0930 AP 0.1517 AR 0.3500
Epoch 179 batch 00006: Loss 0.0921 Regression loss 0.0300 Classification loss 0.0622 AP 0.0411 AR 0.1183
Epoch 179 batch 00007: Loss 0.0865 Regression loss 0.0297 Classification loss 0.0567 AP 0.0848 AR 0.1917
Epoch 179 batch 00008: Loss 0.0977 Regression loss 0.0245 Classification loss 0.0732 AP 0.1685 AR 0.3400
Epoch 179 batch 00009: Loss 0.0993 Regression loss 0.0274 Classification loss 0.0719 AP 0.1494 AR 0.3400
Epoch 179 batch 00010: Loss 0.1114 Regression loss 0.0281 Classification loss 0.0833 AP 0.1842 AR 0.4000
Epoch 180 batch 00001: Loss 0.1091 Regression loss 0.0276 Classification loss 0.0814 AP 0.1602 AR 0.4183
Epoch 180 batch 00002: Loss 0.1135 Regression loss 0.0341 Classification loss 0.0794 AP 0.1770 AR 0.4017
Epoch 180 batch 00003: Loss 0.1142 Regression loss 0.0230 Classification loss 0.0912 AP 0.1551 AR 0.3883
Epoch 180 batch 00004: Loss 0.1210 Regression loss 0.0306 Classification loss 0.0904 AP 0.1117 AR 0.2917
Epoch 180 batch 00005: Loss 0.1105 Regression loss 0.0267 Classification loss 0.0838 AP 0.2073 AR 0.4567
Epoch 180 batch 00006: Loss 0.0837 Regression loss 0.0238 Classification loss 0.0599 AP 0.1254 AR 0.2850
Epoch 180 batch 00007: Loss 0.0807 Regression loss 0.0260 Classification loss 0.0547 AP 0.1151 AR 0.2250
Epoch 180 batch 00008: Loss 0.1057 Regression loss 0.0254 Classification loss 0.0803 AP 0.1207 AR 0.2800
Epoch 180 batch 00009: Loss 0.0961 Regression loss 0.0278 Classification loss 0.0683 AP 0.2134 AR 0.4900
Epoch 180 batch 00010: Loss 0.1247 Regression loss 0.0326 Classification loss 0.0920 AP 0.1386 AR 0.3000
Epoch 181 batch 00001: Loss 0.1172 Regression loss 0.0267 Classification loss 0.0905 AP 0.1577 AR 0.3950
Epoch 181 batch 00002: Loss 0.0920 Regression loss 0.0262 Classification loss 0.0658 AP 0.2165 AR 0.5000
Epoch 181 batch 00003: Loss 0.1082 Regression loss 0.0336 Classification loss 0.0747 AP 0.0625 AR 0.1833
Epoch 181 batch 00004: Loss 0.1088 Regression loss 0.0302 Classification loss 0.0785 AP 0.1579 AR 0.3517
Epoch 181 batch 00005: Loss 0.1015 Regression loss 0.0322 Classification loss 0.0693 AP 0.1818 AR 0.3917
Epoch 181 batch 00006: Loss 0.1235 Regression loss 0.0371 Classification loss 0.0864 AP 0.1213 AR 0.2417
Epoch 181 batch 00007: Loss 0.1084 Regression loss 0.0299 Classification loss 0.0785 AP 0.2121 AR 0.4233
Epoch 181 batch 00008: Loss 0.1172 Regression loss 0.0301 Classification loss 0.0871 AP 0.1123 AR 0.2433
Epoch 181 batch 00009: Loss 0.1014 Regression loss 0.0293 Classification loss 0.0721 AP 0.2626 AR 0.4617
Epoch 181 batch 00010: Loss 0.0941 Regression loss 0.0322 Classification loss 0.0619 AP 0.1049 AR 0.2667
Epoch 182 batch 00001: Loss 0.1034 Regression loss 0.0282 Classification loss 0.0753 AP 0.2245 AR 0.3333
Epoch 182 batch 00002: Loss 0.0945 Regression loss 0.0249 Classification loss 0.0697 AP 0.2730 AR 0.6983
Epoch 182 batch 00003: Loss 0.1052 Regression loss 0.0291 Classification loss 0.0761 AP 0.1358 AR 0.3717
Epoch 182 batch 00004: Loss 0.1095 Regression loss 0.0300 Classification loss 0.0795 AP 0.1091 AR 0.2733
Epoch 182 batch 00005: Loss 0.0874 Regression loss 0.0310 Classification loss 0.0565 AP 0.0754 AR 0.2250
Epoch 182 batch 00006: Loss 0.1145 Regression loss 0.0269 Classification loss 0.0877 AP 0.2852 AR 0.6333
Epoch 182 batch 00007: Loss 0.0891 Regression loss 0.0276 Classification loss 0.0616 AP 0.1344 AR 0.2633
Epoch 182 batch 00008: Loss 0.0950 Regression loss 0.0304 Classification loss 0.0646 AP 0.1290 AR 0.2800
Epoch 182 batch 00009: Loss 0.1029 Regression loss 0.0269 Classification loss 0.0760 AP 0.1351 AR 0.2783
Epoch 182 batch 00010: Loss 0.0858 Regression loss 0.0281 Classification loss 0.0577 AP 0.1767 AR 0.3133
Epoch 183 batch 00001: Loss 0.1054 Regression loss 0.0336 Classification loss 0.0718 AP 0.1254 AR 0.2367
Epoch 183 batch 00002: Loss 0.0773 Regression loss 0.0221 Classification loss 0.0552 AP 0.1943 AR 0.5433
Epoch 183 batch 00003: Loss 0.1120 Regression loss 0.0245 Classification loss 0.0875 AP 0.1793 AR 0.4900
Epoch 183 batch 00004: Loss 0.0794 Regression loss 0.0243 Classification loss 0.0551 AP 0.1256 AR 0.2600
Epoch 183 batch 00005: Loss 0.0990 Regression loss 0.0276 Classification loss 0.0714 AP 0.1314 AR 0.3083
Epoch 183 batch 00006: Loss 0.0855 Regression loss 0.0273 Classification loss 0.0583 AP 0.1027 AR 0.2333
Epoch 183 batch 00007: Loss 0.1110 Regression loss 0.0266 Classification loss 0.0844 AP 0.1671 AR 0.3800
Epoch 183 batch 00008: Loss 0.1122 Regression loss 0.0286 Classification loss 0.0836 AP 0.1982 AR 0.3900
Epoch 183 batch 00009: Loss 0.1000 Regression loss 0.0320 Classification loss 0.0680 AP 0.1799 AR 0.3167
Epoch 183 batch 00010: Loss 0.0943 Regression loss 0.0278 Classification loss 0.0665 AP 0.2179 AR 0.5150
Epoch 184 batch 00001: Loss 0.0919 Regression loss 0.0273 Classification loss 0.0646 AP 0.0856 AR 0.2300
Epoch 184 batch 00002: Loss 0.1035 Regression loss 0.0281 Classification loss 0.0754 AP 0.1429 AR 0.3550
Epoch 184 batch 00003: Loss 0.1060 Regression loss 0.0283 Classification loss 0.0777 AP 0.0952 AR 0.2067
Epoch 184 batch 00004: Loss 0.0971 Regression loss 0.0242 Classification loss 0.0729 AP 0.1817 AR 0.4500
Epoch 184 batch 00005: Loss 0.0975 Regression loss 0.0247 Classification loss 0.0728 AP 0.1311 AR 0.2417
Epoch 184 batch 00006: Loss 0.1158 Regression loss 0.0322 Classification loss 0.0835 AP 0.1441 AR 0.2533
Epoch 184 batch 00007: Loss 0.0875 Regression loss 0.0250 Classification loss 0.0626 AP 0.2203 AR 0.5267
Epoch 184 batch 00008: Loss 0.1039 Regression loss 0.0253 Classification loss 0.0785 AP 0.2781 AR 0.5283
Epoch 184 batch 00009: Loss 0.1016 Regression loss 0.0286 Classification loss 0.0730 AP 0.2246 AR 0.5067
Epoch 184 batch 00010: Loss 0.0775 Regression loss 0.0270 Classification loss 0.0505 AP 0.1493 AR 0.3500
Epoch 185 batch 00001: Loss 0.0950 Regression loss 0.0285 Classification loss 0.0665 AP 0.1071 AR 0.2617
Epoch 185 batch 00002: Loss 0.0992 Regression loss 0.0260 Classification loss 0.0732 AP 0.2267 AR 0.3267
Epoch 185 batch 00003: Loss 0.0884 Regression loss 0.0199 Classification loss 0.0685 AP 0.2394 AR 0.5417
Epoch 185 batch 00004: Loss 0.0997 Regression loss 0.0268 Classification loss 0.0729 AP 0.1235 AR 0.2833
Epoch 185 batch 00005: Loss 0.0881 Regression loss 0.0238 Classification loss 0.0643 AP 0.3378 AR 0.4700
Epoch 185 batch 00006: Loss 0.1193 Regression loss 0.0275 Classification loss 0.0917 AP 0.1214 AR 0.2917
Epoch 185 batch 00007: Loss 0.0795 Regression loss 0.0259 Classification loss 0.0537 AP 0.1894 AR 0.4817
Epoch 185 batch 00008: Loss 0.0959 Regression loss 0.0316 Classification loss 0.0642 AP 0.1037 AR 0.3167
Epoch 185 batch 00009: Loss 0.0973 Regression loss 0.0298 Classification loss 0.0675 AP 0.1995 AR 0.5617
Epoch 185 batch 00010: Loss 0.0980 Regression loss 0.0258 Classification loss 0.0722 AP 0.1532 AR 0.3500
Epoch 186 batch 00001: Loss 0.0785 Regression loss 0.0294 Classification loss 0.0492 AP 0.1523 AR 0.3500
Epoch 186 batch 00002: Loss 0.0993 Regression loss 0.0263 Classification loss 0.0729 AP 0.1966 AR 0.4533
Epoch 186 batch 00003: Loss 0.0970 Regression loss 0.0244 Classification loss 0.0726 AP 0.1368 AR 0.3183
Epoch 186 batch 00004: Loss 0.1088 Regression loss 0.0273 Classification loss 0.0816 AP 0.1597 AR 0.3250
Epoch 186 batch 00005: Loss 0.0810 Regression loss 0.0247 Classification loss 0.0563 AP 0.2368 AR 0.5333
Epoch 186 batch 00006: Loss 0.0864 Regression loss 0.0252 Classification loss 0.0611 AP 0.1381 AR 0.3117
Epoch 186 batch 00007: Loss 0.0987 Regression loss 0.0287 Classification loss 0.0701 AP 0.3421 AR 0.5733
Epoch 186 batch 00008: Loss 0.1078 Regression loss 0.0237 Classification loss 0.0841 AP 0.1608 AR 0.3750
Epoch 186 batch 00009: Loss 0.0947 Regression loss 0.0273 Classification loss 0.0674 AP 0.1220 AR 0.2850
Epoch 186 batch 00010: Loss 0.0865 Regression loss 0.0267 Classification loss 0.0598 AP 0.2689 AR 0.4950
Epoch 187 batch 00001: Loss 0.0872 Regression loss 0.0245 Classification loss 0.0627 AP 0.1611 AR 0.3333
Epoch 187 batch 00002: Loss 0.0838 Regression loss 0.0243 Classification loss 0.0594 AP 0.1870 AR 0.5100
Epoch 187 batch 00003: Loss 0.1047 Regression loss 0.0277 Classification loss 0.0769 AP 0.1817 AR 0.4133
Epoch 187 batch 00004: Loss 0.1076 Regression loss 0.0260 Classification loss 0.0816 AP 0.1893 AR 0.2533
Epoch 187 batch 00005: Loss 0.0861 Regression loss 0.0340 Classification loss 0.0521 AP 0.1507 AR 0.3617
Epoch 187 batch 00006: Loss 0.0977 Regression loss 0.0271 Classification loss 0.0706 AP 0.1643 AR 0.3133
Epoch 187 batch 00007: Loss 0.1066 Regression loss 0.0263 Classification loss 0.0803 AP 0.1479 AR 0.3033
Epoch 187 batch 00008: Loss 0.1120 Regression loss 0.0297 Classification loss 0.0823 AP 0.1252 AR 0.3083
Epoch 187 batch 00009: Loss 0.0846 Regression loss 0.0281 Classification loss 0.0565 AP 0.1884 AR 0.4133
Epoch 187 batch 00010: Loss 0.0872 Regression loss 0.0289 Classification loss 0.0583 AP 0.1265 AR 0.2950
Epoch 188 batch 00001: Loss 0.1072 Regression loss 0.0233 Classification loss 0.0838 AP 0.1862 AR 0.3500
Epoch 188 batch 00002: Loss 0.0777 Regression loss 0.0308 Classification loss 0.0469 AP 0.1003 AR 0.2933
Epoch 188 batch 00003: Loss 0.0771 Regression loss 0.0264 Classification loss 0.0507 AP 0.2180 AR 0.4450
Epoch 188 batch 00004: Loss 0.1022 Regression loss 0.0259 Classification loss 0.0764 AP 0.1873 AR 0.3817
Epoch 188 batch 00005: Loss 0.1016 Regression loss 0.0317 Classification loss 0.0699 AP 0.1624 AR 0.3217
Epoch 188 batch 00006: Loss 0.0993 Regression loss 0.0313 Classification loss 0.0681 AP 0.0933 AR 0.1950
Epoch 188 batch 00007: Loss 0.0999 Regression loss 0.0350 Classification loss 0.0649 AP 0.0636 AR 0.1733
Epoch 188 batch 00008: Loss 0.0994 Regression loss 0.0283 Classification loss 0.0712 AP 0.1291 AR 0.2850
Epoch 188 batch 00009: Loss 0.0957 Regression loss 0.0273 Classification loss 0.0683 AP 0.1280 AR 0.2867
Epoch 188 batch 00010: Loss 0.0722 Regression loss 0.0256 Classification loss 0.0465 AP 0.2457 AR 0.4667
Epoch 189 batch 00001: Loss 0.0911 Regression loss 0.0257 Classification loss 0.0654 AP 0.2710 AR 0.4733
Epoch 189 batch 00002: Loss 0.0870 Regression loss 0.0247 Classification loss 0.0623 AP 0.1300 AR 0.1750
Epoch 189 batch 00003: Loss 0.0887 Regression loss 0.0293 Classification loss 0.0595 AP 0.1446 AR 0.3400
Epoch 189 batch 00004: Loss 0.0849 Regression loss 0.0297 Classification loss 0.0552 AP 0.1783 AR 0.3350
Epoch 189 batch 00005: Loss 0.0946 Regression loss 0.0294 Classification loss 0.0652 AP 0.1382 AR 0.3133
Epoch 189 batch 00006: Loss 0.1179 Regression loss 0.0344 Classification loss 0.0835 AP 0.1100 AR 0.3000
Epoch 189 batch 00007: Loss 0.1114 Regression loss 0.0286 Classification loss 0.0828 AP 0.1593 AR 0.3433
Epoch 189 batch 00008: Loss 0.0889 Regression loss 0.0230 Classification loss 0.0659 AP 0.1891 AR 0.4817
Epoch 189 batch 00009: Loss 0.0962 Regression loss 0.0260 Classification loss 0.0703 AP 0.1307 AR 0.2283
Epoch 189 batch 00010: Loss 0.0787 Regression loss 0.0259 Classification loss 0.0528 AP 0.1864 AR 0.3983
Epoch 190 batch 00001: Loss 0.0918 Regression loss 0.0264 Classification loss 0.0654 AP 0.3439 AR 0.6350
Epoch 190 batch 00002: Loss 0.1095 Regression loss 0.0322 Classification loss 0.0773 AP 0.1029 AR 0.1817
Epoch 190 batch 00003: Loss 0.0867 Regression loss 0.0223 Classification loss 0.0644 AP 0.1440 AR 0.3417
Epoch 190 batch 00004: Loss 0.0920 Regression loss 0.0258 Classification loss 0.0662 AP 0.1309 AR 0.3250
Epoch 190 batch 00005: Loss 0.0888 Regression loss 0.0308 Classification loss 0.0581 AP 0.1409 AR 0.3783
Epoch 190 batch 00006: Loss 0.0854 Regression loss 0.0227 Classification loss 0.0627 AP 0.1536 AR 0.3217
Epoch 190 batch 00007: Loss 0.0803 Regression loss 0.0262 Classification loss 0.0541 AP 0.1606 AR 0.3783
Epoch 190 batch 00008: Loss 0.0718 Regression loss 0.0269 Classification loss 0.0448 AP 0.2157 AR 0.4483
Epoch 190 batch 00009: Loss 0.0950 Regression loss 0.0255 Classification loss 0.0695 AP 0.0681 AR 0.1400
Epoch 190 batch 00010: Loss 0.1010 Regression loss 0.0266 Classification loss 0.0744 AP 0.1461 AR 0.3033
Epoch 191 batch 00001: Loss 0.0821 Regression loss 0.0258 Classification loss 0.0563 AP 0.1464 AR 0.2767
Epoch 191 batch 00002: Loss 0.1050 Regression loss 0.0278 Classification loss 0.0773 AP 0.1202 AR 0.2550
Epoch 191 batch 00003: Loss 0.0870 Regression loss 0.0223 Classification loss 0.0647 AP 0.1365 AR 0.3000
Epoch 191 batch 00004: Loss 0.1021 Regression loss 0.0306 Classification loss 0.0715 AP 0.0600 AR 0.1383
Epoch 191 batch 00005: Loss 0.0736 Regression loss 0.0250 Classification loss 0.0486 AP 0.2042 AR 0.4067
Epoch 191 batch 00006: Loss 0.1004 Regression loss 0.0274 Classification loss 0.0730 AP 0.1336 AR 0.3350
Epoch 191 batch 00007: Loss 0.0844 Regression loss 0.0234 Classification loss 0.0611 AP 0.2469 AR 0.4733
Epoch 191 batch 00008: Loss 0.0779 Regression loss 0.0267 Classification loss 0.0512 AP 0.1245 AR 0.2750
Epoch 191 batch 00009: Loss 0.0880 Regression loss 0.0234 Classification loss 0.0646 AP 0.1875 AR 0.4167
Epoch 191 batch 00010: Loss 0.1049 Regression loss 0.0322 Classification loss 0.0727 AP 0.2039 AR 0.4650
Epoch 192 batch 00001: Loss 0.1033 Regression loss 0.0239 Classification loss 0.0794 AP 0.1432 AR 0.3083
Epoch 192 batch 00002: Loss 0.0889 Regression loss 0.0314 Classification loss 0.0575 AP 0.0966 AR 0.2100
Epoch 192 batch 00003: Loss 0.0850 Regression loss 0.0256 Classification loss 0.0595 AP 0.0919 AR 0.1867
Epoch 192 batch 00004: Loss 0.0743 Regression loss 0.0236 Classification loss 0.0507 AP 0.2811 AR 0.5583
Epoch 192 batch 00005: Loss 0.0993 Regression loss 0.0289 Classification loss 0.0704 AP 0.1521 AR 0.3100
Epoch 192 batch 00006: Loss 0.1186 Regression loss 0.0359 Classification loss 0.0827 AP 0.1698 AR 0.3750
Epoch 192 batch 00007: Loss 0.0898 Regression loss 0.0284 Classification loss 0.0614 AP 0.0821 AR 0.2267
Epoch 192 batch 00008: Loss 0.0852 Regression loss 0.0234 Classification loss 0.0618 AP 0.1508 AR 0.3700
Epoch 192 batch 00009: Loss 0.0895 Regression loss 0.0265 Classification loss 0.0630 AP 0.1558 AR 0.3483
Epoch 192 batch 00010: Loss 0.0780 Regression loss 0.0269 Classification loss 0.0511 AP 0.0925 AR 0.2350
Epoch 193 batch 00001: Loss 0.1071 Regression loss 0.0341 Classification loss 0.0730 AP 0.0659 AR 0.1567
Epoch 193 batch 00002: Loss 0.0833 Regression loss 0.0272 Classification loss 0.0561 AP 0.1362 AR 0.3433
Epoch 193 batch 00003: Loss 0.0896 Regression loss 0.0269 Classification loss 0.0628 AP 0.1847 AR 0.4400
Epoch 193 batch 00004: Loss 0.0700 Regression loss 0.0247 Classification loss 0.0453 AP 0.0929 AR 0.2133
Epoch 193 batch 00005: Loss 0.0958 Regression loss 0.0243 Classification loss 0.0715 AP 0.1207 AR 0.2833
Epoch 193 batch 00006: Loss 0.0844 Regression loss 0.0237 Classification loss 0.0607 AP 0.1280 AR 0.2600
Epoch 193 batch 00007: Loss 0.0880 Regression loss 0.0245 Classification loss 0.0635 AP 0.2302 AR 0.5583
Epoch 193 batch 00008: Loss 0.0913 Regression loss 0.0257 Classification loss 0.0656 AP 0.2093 AR 0.4083
Epoch 193 batch 00009: Loss 0.0638 Regression loss 0.0222 Classification loss 0.0416 AP 0.2139 AR 0.4850
Epoch 193 batch 00010: Loss 0.0931 Regression loss 0.0249 Classification loss 0.0682 AP 0.2599 AR 0.4417
Epoch 194 batch 00001: Loss 0.0970 Regression loss 0.0270 Classification loss 0.0699 AP 0.1923 AR 0.4317
Epoch 194 batch 00002: Loss 0.0799 Regression loss 0.0257 Classification loss 0.0543 AP 0.2817 AR 0.4533
Epoch 194 batch 00003: Loss 0.0982 Regression loss 0.0258 Classification loss 0.0724 AP 0.1502 AR 0.2950
Epoch 194 batch 00004: Loss 0.0740 Regression loss 0.0245 Classification loss 0.0496 AP 0.2469 AR 0.4083
Epoch 194 batch 00005: Loss 0.0853 Regression loss 0.0248 Classification loss 0.0605 AP 0.1087 AR 0.2600
Epoch 194 batch 00006: Loss 0.0732 Regression loss 0.0211 Classification loss 0.0521 AP 0.1540 AR 0.3867
Epoch 194 batch 00007: Loss 0.0948 Regression loss 0.0261 Classification loss 0.0687 AP 0.1396 AR 0.4250
Epoch 194 batch 00008: Loss 0.0864 Regression loss 0.0252 Classification loss 0.0613 AP 0.2098 AR 0.4450
Epoch 194 batch 00009: Loss 0.0842 Regression loss 0.0260 Classification loss 0.0582 AP 0.1057 AR 0.2750
Epoch 194 batch 00010: Loss 0.0832 Regression loss 0.0236 Classification loss 0.0596 AP 0.1529 AR 0.3483
Epoch 195 batch 00001: Loss 0.0577 Regression loss 0.0221 Classification loss 0.0356 AP 0.2621 AR 0.5083
Epoch 195 batch 00002: Loss 0.1101 Regression loss 0.0317 Classification loss 0.0784 AP 0.1536 AR 0.3383
Epoch 195 batch 00003: Loss 0.0762 Regression loss 0.0294 Classification loss 0.0468 AP 0.2393 AR 0.4450
Epoch 195 batch 00004: Loss 0.0822 Regression loss 0.0233 Classification loss 0.0589 AP 0.2545 AR 0.4700
Epoch 195 batch 00005: Loss 0.0758 Regression loss 0.0279 Classification loss 0.0479 AP 0.0843 AR 0.1083
Epoch 195 batch 00006: Loss 0.0899 Regression loss 0.0250 Classification loss 0.0649 AP 0.1581 AR 0.4517
Epoch 195 batch 00007: Loss 0.0933 Regression loss 0.0255 Classification loss 0.0678 AP 0.1396 AR 0.2767
Epoch 195 batch 00008: Loss 0.1061 Regression loss 0.0278 Classification loss 0.0784 AP 0.2856 AR 0.5433
Epoch 195 batch 00009: Loss 0.1016 Regression loss 0.0294 Classification loss 0.0722 AP 0.1484 AR 0.3100
Epoch 195 batch 00010: Loss 0.0764 Regression loss 0.0232 Classification loss 0.0532 AP 0.2241 AR 0.4500
Epoch 196 batch 00001: Loss 0.0984 Regression loss 0.0273 Classification loss 0.0712 AP 0.1795 AR 0.5450
Epoch 196 batch 00002: Loss 0.0876 Regression loss 0.0251 Classification loss 0.0625 AP 0.2097 AR 0.4667
Epoch 196 batch 00003: Loss 0.0952 Regression loss 0.0301 Classification loss 0.0651 AP 0.2420 AR 0.4233
Epoch 196 batch 00004: Loss 0.0925 Regression loss 0.0279 Classification loss 0.0646 AP 0.0912 AR 0.2700
Epoch 196 batch 00005: Loss 0.0792 Regression loss 0.0220 Classification loss 0.0573 AP 0.1494 AR 0.3250
Epoch 196 batch 00006: Loss 0.0791 Regression loss 0.0236 Classification loss 0.0555 AP 0.2014 AR 0.4300
Epoch 196 batch 00007: Loss 0.0812 Regression loss 0.0294 Classification loss 0.0518 AP 0.0091 AR 0.0333
Epoch 196 batch 00008: Loss 0.0815 Regression loss 0.0310 Classification loss 0.0505 AP 0.1602 AR 0.4533
Epoch 196 batch 00009: Loss 0.0887 Regression loss 0.0265 Classification loss 0.0622 AP 0.1222 AR 0.3083
Epoch 196 batch 00010: Loss 0.0926 Regression loss 0.0280 Classification loss 0.0646 AP 0.2496 AR 0.4583
Epoch 197 batch 00001: Loss 0.0891 Regression loss 0.0260 Classification loss 0.0632 AP 0.1612 AR 0.4183
Epoch 197 batch 00002: Loss 0.0912 Regression loss 0.0220 Classification loss 0.0692 AP 0.1767 AR 0.3250
Epoch 197 batch 00003: Loss 0.0788 Regression loss 0.0293 Classification loss 0.0495 AP 0.1280 AR 0.2900
Epoch 197 batch 00004: Loss 0.0636 Regression loss 0.0247 Classification loss 0.0389 AP 0.2268 AR 0.5417
Epoch 197 batch 00005: Loss 0.0940 Regression loss 0.0292 Classification loss 0.0648 AP 0.1850 AR 0.2850
Epoch 197 batch 00006: Loss 0.0841 Regression loss 0.0258 Classification loss 0.0584 AP 0.2151 AR 0.4233
Epoch 197 batch 00007: Loss 0.0751 Regression loss 0.0263 Classification loss 0.0487 AP 0.1875 AR 0.4500
Epoch 197 batch 00008: Loss 0.0917 Regression loss 0.0238 Classification loss 0.0679 AP 0.0994 AR 0.2850
Epoch 197 batch 00009: Loss 0.0851 Regression loss 0.0253 Classification loss 0.0598 AP 0.1756 AR 0.3767
Epoch 197 batch 00010: Loss 0.1001 Regression loss 0.0288 Classification loss 0.0714 AP 0.2219 AR 0.4633
Epoch 198 batch 00001: Loss 0.0907 Regression loss 0.0225 Classification loss 0.0682 AP 0.1938 AR 0.2817
Epoch 198 batch 00002: Loss 0.0705 Regression loss 0.0224 Classification loss 0.0481 AP 0.1475 AR 0.3250
Epoch 198 batch 00003: Loss 0.0754 Regression loss 0.0260 Classification loss 0.0494 AP 0.2652 AR 0.6533
Epoch 198 batch 00004: Loss 0.1110 Regression loss 0.0296 Classification loss 0.0814 AP 0.1275 AR 0.3100
Epoch 198 batch 00005: Loss 0.0629 Regression loss 0.0233 Classification loss 0.0396 AP 0.1946 AR 0.4583
Epoch 198 batch 00006: Loss 0.0943 Regression loss 0.0221 Classification loss 0.0722 AP 0.2238 AR 0.4200
Epoch 198 batch 00007: Loss 0.0835 Regression loss 0.0267 Classification loss 0.0569 AP 0.1867 AR 0.5150
Epoch 198 batch 00008: Loss 0.0935 Regression loss 0.0269 Classification loss 0.0666 AP 0.1593 AR 0.3517
Epoch 198 batch 00009: Loss 0.0781 Regression loss 0.0274 Classification loss 0.0507 AP 0.1890 AR 0.3517
Epoch 198 batch 00010: Loss 0.0974 Regression loss 0.0299 Classification loss 0.0675 AP 0.1204 AR 0.2600
Epoch 199 batch 00001: Loss 0.0838 Regression loss 0.0258 Classification loss 0.0579 AP 0.1525 AR 0.3200
Epoch 199 batch 00002: Loss 0.0774 Regression loss 0.0255 Classification loss 0.0520 AP 0.2892 AR 0.4300
Epoch 199 batch 00003: Loss 0.0804 Regression loss 0.0244 Classification loss 0.0560 AP 0.1807 AR 0.3200
Epoch 199 batch 00004: Loss 0.0741 Regression loss 0.0250 Classification loss 0.0492 AP 0.1897 AR 0.2983
Epoch 199 batch 00005: Loss 0.0853 Regression loss 0.0291 Classification loss 0.0562 AP 0.1984 AR 0.4517
Epoch 199 batch 00006: Loss 0.0684 Regression loss 0.0212 Classification loss 0.0472 AP 0.1497 AR 0.4833
Epoch 199 batch 00007: Loss 0.0921 Regression loss 0.0226 Classification loss 0.0695 AP 0.1589 AR 0.3517
Epoch 199 batch 00008: Loss 0.0978 Regression loss 0.0288 Classification loss 0.0690 AP 0.2087 AR 0.3933
Epoch 199 batch 00009: Loss 0.0833 Regression loss 0.0229 Classification loss 0.0604 AP 0.2442 AR 0.4600
Epoch 199 batch 00010: Loss 0.0942 Regression loss 0.0258 Classification loss 0.0684 AP 0.1879 AR 0.4083
Epoch 200 batch 00001: Loss 0.0821 Regression loss 0.0252 Classification loss 0.0569 AP 0.2964 AR 0.5333
Epoch 200 batch 00002: Loss 0.0907 Regression loss 0.0232 Classification loss 0.0675 AP 0.1218 AR 0.2333
Epoch 200 batch 00003: Loss 0.0887 Regression loss 0.0270 Classification loss 0.0617 AP 0.1953 AR 0.4167
Epoch 200 batch 00004: Loss 0.0706 Regression loss 0.0234 Classification loss 0.0472 AP 0.2598 AR 0.3300
Epoch 200 batch 00005: Loss 0.0931 Regression loss 0.0245 Classification loss 0.0685 AP 0.1802 AR 0.4100
Epoch 200 batch 00006: Loss 0.0787 Regression loss 0.0251 Classification loss 0.0537 AP 0.1512 AR 0.3250
Epoch 200 batch 00007: Loss 0.0812 Regression loss 0.0295 Classification loss 0.0518 AP 0.1436 AR 0.3667
Epoch 200 batch 00008: Loss 0.0882 Regression loss 0.0264 Classification loss 0.0618 AP 0.1644 AR 0.4483
Epoch 200 batch 00009: Loss 0.0830 Regression loss 0.0258 Classification loss 0.0572 AP 0.1810 AR 0.4083
Epoch 200 batch 00010: Loss 0.0783 Regression loss 0.0262 Classification loss 0.0520 AP 0.1243 AR 0.2850
Epoch 201 batch 00001: Loss 0.0692 Regression loss 0.0242 Classification loss 0.0450 AP 0.1894 AR 0.4567
Epoch 201 batch 00002: Loss 0.0876 Regression loss 0.0244 Classification loss 0.0632 AP 0.1482 AR 0.3117
Epoch 201 batch 00003: Loss 0.0774 Regression loss 0.0267 Classification loss 0.0507 AP 0.1373 AR 0.3233
Epoch 201 batch 00004: Loss 0.0823 Regression loss 0.0254 Classification loss 0.0569 AP 0.1756 AR 0.3250
Epoch 201 batch 00005: Loss 0.0849 Regression loss 0.0250 Classification loss 0.0598 AP 0.3091 AR 0.5900
Epoch 201 batch 00006: Loss 0.0776 Regression loss 0.0250 Classification loss 0.0526 AP 0.2073 AR 0.3033
Epoch 201 batch 00007: Loss 0.0794 Regression loss 0.0242 Classification loss 0.0552 AP 0.2127 AR 0.4483
Epoch 201 batch 00008: Loss 0.0940 Regression loss 0.0311 Classification loss 0.0629 AP 0.1483 AR 0.4083
Epoch 201 batch 00009: Loss 0.0851 Regression loss 0.0220 Classification loss 0.0631 AP 0.2968 AR 0.5167
Epoch 201 batch 00010: Loss 0.0955 Regression loss 0.0327 Classification loss 0.0629 AP 0.1111 AR 0.2783
Epoch 202 batch 00001: Loss 0.0665 Regression loss 0.0264 Classification loss 0.0400 AP 0.1980 AR 0.3150
Epoch 202 batch 00002: Loss 0.0865 Regression loss 0.0203 Classification loss 0.0663 AP 0.1245 AR 0.2550
Epoch 202 batch 00003: Loss 0.0770 Regression loss 0.0289 Classification loss 0.0481 AP 0.2605 AR 0.5150
Epoch 202 batch 00004: Loss 0.0937 Regression loss 0.0286 Classification loss 0.0651 AP 0.1505 AR 0.3850
Epoch 202 batch 00005: Loss 0.0759 Regression loss 0.0225 Classification loss 0.0534 AP 0.2974 AR 0.4817
Epoch 202 batch 00006: Loss 0.0783 Regression loss 0.0250 Classification loss 0.0533 AP 0.1522 AR 0.2750
Epoch 202 batch 00007: Loss 0.0833 Regression loss 0.0221 Classification loss 0.0612 AP 0.1760 AR 0.3800
Epoch 202 batch 00008: Loss 0.0787 Regression loss 0.0282 Classification loss 0.0506 AP 0.1680 AR 0.3750
Epoch 202 batch 00009: Loss 0.0834 Regression loss 0.0248 Classification loss 0.0586 AP 0.1162 AR 0.3133
Epoch 202 batch 00010: Loss 0.1090 Regression loss 0.0286 Classification loss 0.0804 AP 0.1858 AR 0.3783
Epoch 203 batch 00001: Loss 0.0798 Regression loss 0.0271 Classification loss 0.0527 AP 0.2455 AR 0.4767
Epoch 203 batch 00002: Loss 0.0697 Regression loss 0.0245 Classification loss 0.0452 AP 0.1975 AR 0.4517
Epoch 203 batch 00003: Loss 0.0851 Regression loss 0.0259 Classification loss 0.0592 AP 0.1913 AR 0.4183
Epoch 203 batch 00004: Loss 0.0900 Regression loss 0.0237 Classification loss 0.0663 AP 0.1693 AR 0.3583
Epoch 203 batch 00005: Loss 0.0791 Regression loss 0.0294 Classification loss 0.0497 AP 0.1264 AR 0.3283
Epoch 203 batch 00006: Loss 0.0851 Regression loss 0.0240 Classification loss 0.0611 AP 0.1668 AR 0.3250
Epoch 203 batch 00007: Loss 0.0868 Regression loss 0.0281 Classification loss 0.0587 AP 0.1853 AR 0.4150
Epoch 203 batch 00008: Loss 0.0653 Regression loss 0.0234 Classification loss 0.0419 AP 0.2672 AR 0.3650
Epoch 203 batch 00009: Loss 0.1018 Regression loss 0.0275 Classification loss 0.0743 AP 0.2821 AR 0.4600
Epoch 203 batch 00010: Loss 0.0763 Regression loss 0.0260 Classification loss 0.0502 AP 0.1486 AR 0.3450
Epoch 204 batch 00001: Loss 0.0795 Regression loss 0.0230 Classification loss 0.0565 AP 0.2360 AR 0.4583
Epoch 204 batch 00002: Loss 0.0720 Regression loss 0.0266 Classification loss 0.0454 AP 0.2130 AR 0.4067
Epoch 204 batch 00003: Loss 0.0862 Regression loss 0.0293 Classification loss 0.0569 AP 0.1730 AR 0.3833
Epoch 204 batch 00004: Loss 0.0741 Regression loss 0.0233 Classification loss 0.0508 AP 0.1830 AR 0.3950
Epoch 204 batch 00005: Loss 0.0735 Regression loss 0.0219 Classification loss 0.0515 AP 0.1974 AR 0.5083
Epoch 204 batch 00006: Loss 0.0742 Regression loss 0.0281 Classification loss 0.0461 AP 0.1394 AR 0.4133
Epoch 204 batch 00007: Loss 0.1001 Regression loss 0.0260 Classification loss 0.0741 AP 0.0780 AR 0.1700
Epoch 204 batch 00008: Loss 0.0824 Regression loss 0.0273 Classification loss 0.0551 AP 0.2710 AR 0.5167
Epoch 204 batch 00009: Loss 0.0572 Regression loss 0.0196 Classification loss 0.0376 AP 0.2825 AR 0.5983
Epoch 204 batch 00010: Loss 0.1013 Regression loss 0.0224 Classification loss 0.0789 AP 0.0658 AR 0.0983
Epoch 205 batch 00001: Loss 0.0980 Regression loss 0.0220 Classification loss 0.0760 AP 0.1129 AR 0.2417
Epoch 205 batch 00002: Loss 0.0764 Regression loss 0.0257 Classification loss 0.0507 AP 0.1324 AR 0.3100
Epoch 205 batch 00003: Loss 0.0588 Regression loss 0.0205 Classification loss 0.0383 AP 0.2875 AR 0.4350
Epoch 205 batch 00004: Loss 0.0569 Regression loss 0.0235 Classification loss 0.0334 AP 0.1958 AR 0.4750
Epoch 205 batch 00005: Loss 0.0885 Regression loss 0.0283 Classification loss 0.0602 AP 0.2586 AR 0.3717
Epoch 205 batch 00006: Loss 0.0943 Regression loss 0.0269 Classification loss 0.0675 AP 0.1304 AR 0.3017
Epoch 205 batch 00007: Loss 0.0837 Regression loss 0.0298 Classification loss 0.0539 AP 0.1017 AR 0.2733
Epoch 205 batch 00008: Loss 0.0748 Regression loss 0.0252 Classification loss 0.0495 AP 0.0971 AR 0.2550
Epoch 205 batch 00009: Loss 0.0721 Regression loss 0.0236 Classification loss 0.0485 AP 0.1414 AR 0.2950
Epoch 205 batch 00010: Loss 0.1000 Regression loss 0.0253 Classification loss 0.0747 AP 0.3265 AR 0.6067
Epoch 206 batch 00001: Loss 0.0819 Regression loss 0.0264 Classification loss 0.0554 AP 0.1179 AR 0.2883
Epoch 206 batch 00002: Loss 0.0832 Regression loss 0.0243 Classification loss 0.0589 AP 0.1844 AR 0.4400
Epoch 206 batch 00003: Loss 0.0742 Regression loss 0.0290 Classification loss 0.0452 AP 0.1192 AR 0.2833
Epoch 206 batch 00004: Loss 0.0752 Regression loss 0.0206 Classification loss 0.0546 AP 0.2335 AR 0.4571
Epoch 206 batch 00005: Loss 0.0674 Regression loss 0.0248 Classification loss 0.0427 AP 0.1288 AR 0.2650
Epoch 206 batch 00006: Loss 0.0775 Regression loss 0.0230 Classification loss 0.0546 AP 0.1965 AR 0.2950
Epoch 206 batch 00007: Loss 0.0654 Regression loss 0.0249 Classification loss 0.0405 AP 0.1578 AR 0.3850
Epoch 206 batch 00008: Loss 0.0937 Regression loss 0.0264 Classification loss 0.0672 AP 0.1352 AR 0.3200
Epoch 206 batch 00009: Loss 0.0778 Regression loss 0.0285 Classification loss 0.0493 AP 0.1141 AR 0.2350
Epoch 206 batch 00010: Loss 0.0794 Regression loss 0.0214 Classification loss 0.0580 AP 0.2964 AR 0.5500
Epoch 207 batch 00001: Loss 0.0794 Regression loss 0.0261 Classification loss 0.0533 AP 0.1641 AR 0.3750
Epoch 207 batch 00002: Loss 0.0676 Regression loss 0.0226 Classification loss 0.0450 AP 0.1254 AR 0.3500
Epoch 207 batch 00003: Loss 0.0800 Regression loss 0.0226 Classification loss 0.0575 AP 0.2004 AR 0.4267
Epoch 207 batch 00004: Loss 0.0768 Regression loss 0.0250 Classification loss 0.0518 AP 0.1333 AR 0.2950
Epoch 207 batch 00005: Loss 0.0926 Regression loss 0.0236 Classification loss 0.0689 AP 0.1533 AR 0.3667
Epoch 207 batch 00006: Loss 0.0773 Regression loss 0.0223 Classification loss 0.0550 AP 0.4058 AR 0.6500
Epoch 207 batch 00007: Loss 0.0804 Regression loss 0.0270 Classification loss 0.0534 AP 0.1342 AR 0.3817
Epoch 207 batch 00008: Loss 0.0711 Regression loss 0.0244 Classification loss 0.0467 AP 0.4173 AR 0.5683
Epoch 207 batch 00009: Loss 0.0739 Regression loss 0.0237 Classification loss 0.0503 AP 0.1177 AR 0.2883
Epoch 207 batch 00010: Loss 0.0675 Regression loss 0.0284 Classification loss 0.0391 AP 0.0560 AR 0.1233
Epoch 208 batch 00001: Loss 0.0759 Regression loss 0.0264 Classification loss 0.0495 AP 0.2561 AR 0.5383
Epoch 208 batch 00002: Loss 0.0833 Regression loss 0.0227 Classification loss 0.0607 AP 0.1467 AR 0.2083
Epoch 208 batch 00003: Loss 0.0791 Regression loss 0.0273 Classification loss 0.0518 AP 0.2064 AR 0.5100
Epoch 208 batch 00004: Loss 0.0769 Regression loss 0.0224 Classification loss 0.0546 AP 0.2056 AR 0.4717
Epoch 208 batch 00005: Loss 0.0856 Regression loss 0.0257 Classification loss 0.0599 AP 0.1244 AR 0.3300
Epoch 208 batch 00006: Loss 0.0756 Regression loss 0.0255 Classification loss 0.0501 AP 0.1590 AR 0.3500
Epoch 208 batch 00007: Loss 0.0716 Regression loss 0.0244 Classification loss 0.0472 AP 0.3377 AR 0.6083
Epoch 208 batch 00008: Loss 0.0767 Regression loss 0.0269 Classification loss 0.0498 AP 0.1600 AR 0.2867
Epoch 208 batch 00009: Loss 0.0820 Regression loss 0.0252 Classification loss 0.0567 AP 0.1976 AR 0.3850
Epoch 208 batch 00010: Loss 0.0764 Regression loss 0.0283 Classification loss 0.0481 AP 0.2156 AR 0.3883
Epoch 209 batch 00001: Loss 0.0669 Regression loss 0.0212 Classification loss 0.0457 AP 0.1479 AR 0.2083
Epoch 209 batch 00002: Loss 0.0832 Regression loss 0.0239 Classification loss 0.0593 AP 0.1564 AR 0.3833
Epoch 209 batch 00003: Loss 0.0777 Regression loss 0.0267 Classification loss 0.0511 AP 0.1604 AR 0.3967
Epoch 209 batch 00004: Loss 0.0705 Regression loss 0.0229 Classification loss 0.0476 AP 0.2235 AR 0.5900
Epoch 209 batch 00005: Loss 0.0790 Regression loss 0.0270 Classification loss 0.0520 AP 0.1327 AR 0.3383
Epoch 209 batch 00006: Loss 0.0909 Regression loss 0.0264 Classification loss 0.0645 AP 0.1101 AR 0.2483
Epoch 209 batch 00007: Loss 0.0725 Regression loss 0.0306 Classification loss 0.0420 AP 0.0857 AR 0.2167
Epoch 209 batch 00008: Loss 0.0678 Regression loss 0.0239 Classification loss 0.0439 AP 0.1729 AR 0.3533
Epoch 209 batch 00009: Loss 0.0906 Regression loss 0.0290 Classification loss 0.0615 AP 0.2752 AR 0.4500
Epoch 209 batch 00010: Loss 0.0800 Regression loss 0.0244 Classification loss 0.0556 AP 0.1949 AR 0.4583
Epoch 210 batch 00001: Loss 0.0678 Regression loss 0.0219 Classification loss 0.0459 AP 0.2090 AR 0.4567
Epoch 210 batch 00002: Loss 0.0876 Regression loss 0.0240 Classification loss 0.0637 AP 0.1700 AR 0.4417
Epoch 210 batch 00003: Loss 0.0931 Regression loss 0.0290 Classification loss 0.0641 AP 0.1585 AR 0.3667
Epoch 210 batch 00004: Loss 0.0791 Regression loss 0.0254 Classification loss 0.0537 AP 0.2187 AR 0.5500
Epoch 210 batch 00005: Loss 0.0797 Regression loss 0.0251 Classification loss 0.0546 AP 0.2081 AR 0.4500
Epoch 210 batch 00006: Loss 0.0699 Regression loss 0.0242 Classification loss 0.0457 AP 0.2763 AR 0.5483
Epoch 210 batch 00007: Loss 0.0736 Regression loss 0.0266 Classification loss 0.0470 AP 0.1903 AR 0.3383
Epoch 210 batch 00008: Loss 0.0906 Regression loss 0.0276 Classification loss 0.0630 AP 0.3686 AR 0.5633
Epoch 210 batch 00009: Loss 0.0607 Regression loss 0.0225 Classification loss 0.0382 AP 0.2082 AR 0.4633
Epoch 210 batch 00010: Loss 0.0763 Regression loss 0.0231 Classification loss 0.0532 AP 0.1735 AR 0.3783
Epoch 211 batch 00001: Loss 0.0777 Regression loss 0.0216 Classification loss 0.0561 AP 0.3560 AR 0.5500
Epoch 211 batch 00002: Loss 0.0957 Regression loss 0.0292 Classification loss 0.0665 AP 0.0758 AR 0.1600
Epoch 211 batch 00003: Loss 0.0674 Regression loss 0.0233 Classification loss 0.0441 AP 0.1402 AR 0.3817
Epoch 211 batch 00004: Loss 0.0767 Regression loss 0.0233 Classification loss 0.0534 AP 0.2070 AR 0.3933
Epoch 211 batch 00005: Loss 0.0750 Regression loss 0.0243 Classification loss 0.0507 AP 0.1841 AR 0.3233
Epoch 211 batch 00006: Loss 0.0777 Regression loss 0.0256 Classification loss 0.0520 AP 0.2152 AR 0.4783
Epoch 211 batch 00007: Loss 0.0864 Regression loss 0.0297 Classification loss 0.0567 AP 0.1395 AR 0.3000
Epoch 211 batch 00008: Loss 0.0833 Regression loss 0.0226 Classification loss 0.0607 AP 0.1637 AR 0.4483
Epoch 211 batch 00009: Loss 0.0703 Regression loss 0.0245 Classification loss 0.0458 AP 0.2356 AR 0.5200
Epoch 211 batch 00010: Loss 0.0706 Regression loss 0.0235 Classification loss 0.0471 AP 0.2077 AR 0.4317
Epoch 212 batch 00001: Loss 0.0909 Regression loss 0.0294 Classification loss 0.0615 AP 0.1167 AR 0.3400
Epoch 212 batch 00002: Loss 0.0647 Regression loss 0.0217 Classification loss 0.0430 AP 0.1667 AR 0.3000
Epoch 212 batch 00003: Loss 0.0603 Regression loss 0.0259 Classification loss 0.0343 AP 0.1807 AR 0.3367
Epoch 212 batch 00004: Loss 0.0950 Regression loss 0.0247 Classification loss 0.0702 AP 0.2606 AR 0.4517
Epoch 212 batch 00005: Loss 0.0596 Regression loss 0.0226 Classification loss 0.0370 AP 0.2751 AR 0.4817
Epoch 212 batch 00006: Loss 0.0714 Regression loss 0.0300 Classification loss 0.0414 AP 0.0765 AR 0.1950
Epoch 212 batch 00007: Loss 0.0805 Regression loss 0.0261 Classification loss 0.0544 AP 0.0932 AR 0.2550
Epoch 212 batch 00008: Loss 0.0789 Regression loss 0.0251 Classification loss 0.0538 AP 0.0713 AR 0.1650
Epoch 212 batch 00009: Loss 0.0613 Regression loss 0.0198 Classification loss 0.0415 AP 0.3408 AR 0.5433
Epoch 212 batch 00010: Loss 0.0896 Regression loss 0.0249 Classification loss 0.0648 AP 0.1716 AR 0.3833
Epoch 213 batch 00001: Loss 0.0802 Regression loss 0.0262 Classification loss 0.0540 AP 0.1508 AR 0.2917
Epoch 213 batch 00002: Loss 0.0756 Regression loss 0.0232 Classification loss 0.0524 AP 0.2282 AR 0.5067
Epoch 213 batch 00003: Loss 0.0813 Regression loss 0.0288 Classification loss 0.0524 AP 0.2455 AR 0.4083
Epoch 213 batch 00004: Loss 0.0680 Regression loss 0.0247 Classification loss 0.0432 AP 0.1649 AR 0.3200
Epoch 213 batch 00005: Loss 0.0707 Regression loss 0.0245 Classification loss 0.0462 AP 0.1825 AR 0.4233
Epoch 213 batch 00006: Loss 0.0659 Regression loss 0.0193 Classification loss 0.0466 AP 0.1930 AR 0.3250
Epoch 213 batch 00007: Loss 0.0604 Regression loss 0.0192 Classification loss 0.0412 AP 0.2470 AR 0.5650
Epoch 213 batch 00008: Loss 0.0798 Regression loss 0.0280 Classification loss 0.0517 AP 0.1542 AR 0.3183
Epoch 213 batch 00009: Loss 0.0766 Regression loss 0.0248 Classification loss 0.0518 AP 0.1897 AR 0.4733
Epoch 213 batch 00010: Loss 0.0710 Regression loss 0.0236 Classification loss 0.0475 AP 0.1640 AR 0.2783
Epoch 214 batch 00001: Loss 0.0680 Regression loss 0.0252 Classification loss 0.0428 AP 0.1763 AR 0.4417
Epoch 214 batch 00002: Loss 0.0803 Regression loss 0.0271 Classification loss 0.0532 AP 0.2484 AR 0.5250
Epoch 214 batch 00003: Loss 0.0737 Regression loss 0.0209 Classification loss 0.0528 AP 0.1075 AR 0.2733
Epoch 214 batch 00004: Loss 0.0823 Regression loss 0.0263 Classification loss 0.0560 AP 0.2255 AR 0.3783
Epoch 214 batch 00005: Loss 0.0643 Regression loss 0.0275 Classification loss 0.0368 AP 0.2033 AR 0.3500
Epoch 214 batch 00006: Loss 0.0747 Regression loss 0.0246 Classification loss 0.0501 AP 0.3225 AR 0.5533
Epoch 214 batch 00007: Loss 0.0722 Regression loss 0.0255 Classification loss 0.0468 AP 0.1571 AR 0.3650
Epoch 214 batch 00008: Loss 0.0662 Regression loss 0.0233 Classification loss 0.0430 AP 0.2096 AR 0.5100
Epoch 214 batch 00009: Loss 0.0643 Regression loss 0.0224 Classification loss 0.0419 AP 0.1791 AR 0.2950
Epoch 214 batch 00010: Loss 0.0985 Regression loss 0.0240 Classification loss 0.0745 AP 0.1234 AR 0.3083
Epoch 215 batch 00001: Loss 0.0822 Regression loss 0.0228 Classification loss 0.0594 AP 0.2010 AR 0.4833
Epoch 215 batch 00002: Loss 0.0628 Regression loss 0.0200 Classification loss 0.0428 AP 0.3198 AR 0.5300
Epoch 215 batch 00003: Loss 0.0722 Regression loss 0.0247 Classification loss 0.0475 AP 0.1794 AR 0.3667
Epoch 215 batch 00004: Loss 0.0786 Regression loss 0.0265 Classification loss 0.0521 AP 0.1869 AR 0.3967
Epoch 215 batch 00005: Loss 0.0714 Regression loss 0.0212 Classification loss 0.0501 AP 0.1572 AR 0.3350
Epoch 215 batch 00006: Loss 0.0636 Regression loss 0.0199 Classification loss 0.0437 AP 0.2342 AR 0.4917
Epoch 215 batch 00007: Loss 0.0737 Regression loss 0.0245 Classification loss 0.0492 AP 0.2711 AR 0.4600
Epoch 215 batch 00008: Loss 0.0629 Regression loss 0.0262 Classification loss 0.0367 AP 0.1850 AR 0.4933
Epoch 215 batch 00009: Loss 0.0866 Regression loss 0.0229 Classification loss 0.0637 AP 0.2702 AR 0.5083
Epoch 215 batch 00010: Loss 0.0747 Regression loss 0.0305 Classification loss 0.0441 AP 0.1058 AR 0.2450
Epoch 216 batch 00001: Loss 0.0701 Regression loss 0.0244 Classification loss 0.0457 AP 0.1616 AR 0.3733
Epoch 216 batch 00002: Loss 0.0631 Regression loss 0.0229 Classification loss 0.0402 AP 0.1480 AR 0.3067
Epoch 216 batch 00003: Loss 0.0779 Regression loss 0.0217 Classification loss 0.0563 AP 0.1311 AR 0.2650
Epoch 216 batch 00004: Loss 0.0876 Regression loss 0.0367 Classification loss 0.0508 AP 0.1483 AR 0.2083
Epoch 216 batch 00005: Loss 0.0631 Regression loss 0.0214 Classification loss 0.0417 AP 0.2127 AR 0.4350
Epoch 216 batch 00006: Loss 0.0822 Regression loss 0.0237 Classification loss 0.0585 AP 0.1056 AR 0.2467
Epoch 216 batch 00007: Loss 0.0693 Regression loss 0.0265 Classification loss 0.0428 AP 0.1426 AR 0.2400
Epoch 216 batch 00008: Loss 0.0727 Regression loss 0.0294 Classification loss 0.0433 AP 0.2348 AR 0.3833
Epoch 216 batch 00009: Loss 0.0605 Regression loss 0.0203 Classification loss 0.0401 AP 0.2758 AR 0.5083
Epoch 216 batch 00010: Loss 0.0752 Regression loss 0.0235 Classification loss 0.0517 AP 0.2589 AR 0.5083
Epoch 217 batch 00001: Loss 0.0757 Regression loss 0.0223 Classification loss 0.0534 AP 0.1893 AR 0.4450
Epoch 217 batch 00002: Loss 0.0813 Regression loss 0.0276 Classification loss 0.0538 AP 0.1948 AR 0.4083
Epoch 217 batch 00003: Loss 0.0485 Regression loss 0.0201 Classification loss 0.0284 AP 0.1684 AR 0.4167
Epoch 217 batch 00004: Loss 0.0786 Regression loss 0.0256 Classification loss 0.0530 AP 0.2345 AR 0.4333
Epoch 217 batch 00005: Loss 0.0679 Regression loss 0.0287 Classification loss 0.0392 AP 0.1296 AR 0.3167
Epoch 217 batch 00006: Loss 0.0702 Regression loss 0.0214 Classification loss 0.0488 AP 0.2594 AR 0.5817
Epoch 217 batch 00007: Loss 0.0779 Regression loss 0.0227 Classification loss 0.0551 AP 0.1433 AR 0.2283
Epoch 217 batch 00008: Loss 0.0709 Regression loss 0.0275 Classification loss 0.0434 AP 0.2819 AR 0.5117
Epoch 217 batch 00009: Loss 0.0630 Regression loss 0.0251 Classification loss 0.0379 AP 0.1572 AR 0.3983
Epoch 217 batch 00010: Loss 0.0746 Regression loss 0.0237 Classification loss 0.0509 AP 0.1799 AR 0.3517
Epoch 218 batch 00001: Loss 0.0842 Regression loss 0.0253 Classification loss 0.0589 AP 0.1128 AR 0.2333
Epoch 218 batch 00002: Loss 0.0675 Regression loss 0.0267 Classification loss 0.0409 AP 0.1067 AR 0.2683
Epoch 218 batch 00003: Loss 0.0692 Regression loss 0.0244 Classification loss 0.0448 AP 0.1181 AR 0.2500
Epoch 218 batch 00004: Loss 0.0628 Regression loss 0.0213 Classification loss 0.0416 AP 0.2719 AR 0.5367
Epoch 218 batch 00005: Loss 0.0650 Regression loss 0.0238 Classification loss 0.0411 AP 0.0488 AR 0.1367
Epoch 218 batch 00006: Loss 0.0751 Regression loss 0.0256 Classification loss 0.0495 AP 0.1997 AR 0.2800
Epoch 218 batch 00007: Loss 0.0641 Regression loss 0.0219 Classification loss 0.0422 AP 0.3265 AR 0.6033
Epoch 218 batch 00008: Loss 0.0712 Regression loss 0.0265 Classification loss 0.0448 AP 0.2219 AR 0.5167
Epoch 218 batch 00009: Loss 0.0648 Regression loss 0.0221 Classification loss 0.0427 AP 0.1767 AR 0.3000
Epoch 218 batch 00010: Loss 0.0718 Regression loss 0.0238 Classification loss 0.0480 AP 0.2433 AR 0.4917
Epoch 219 batch 00001: Loss 0.0689 Regression loss 0.0235 Classification loss 0.0454 AP 0.1406 AR 0.2933
Epoch 219 batch 00002: Loss 0.0582 Regression loss 0.0186 Classification loss 0.0396 AP 0.2524 AR 0.4250
Epoch 219 batch 00003: Loss 0.0563 Regression loss 0.0208 Classification loss 0.0355 AP 0.2336 AR 0.5167
Epoch 219 batch 00004: Loss 0.0774 Regression loss 0.0277 Classification loss 0.0497 AP 0.1223 AR 0.1967
Epoch 219 batch 00005: Loss 0.0698 Regression loss 0.0233 Classification loss 0.0465 AP 0.2247 AR 0.4850
Epoch 219 batch 00006: Loss 0.0786 Regression loss 0.0212 Classification loss 0.0574 AP 0.1990 AR 0.3900
Epoch 219 batch 00007: Loss 0.0730 Regression loss 0.0250 Classification loss 0.0480 AP 0.2970 AR 0.6083
Epoch 219 batch 00008: Loss 0.0775 Regression loss 0.0248 Classification loss 0.0527 AP 0.2095 AR 0.3350
Epoch 219 batch 00009: Loss 0.0573 Regression loss 0.0246 Classification loss 0.0327 AP 0.2258 AR 0.5083
Epoch 219 batch 00010: Loss 0.0630 Regression loss 0.0241 Classification loss 0.0389 AP 0.2831 AR 0.5233
Epoch 220 batch 00001: Loss 0.0673 Regression loss 0.0243 Classification loss 0.0430 AP 0.1958 AR 0.3817
Epoch 220 batch 00002: Loss 0.0627 Regression loss 0.0215 Classification loss 0.0412 AP 0.2546 AR 0.4700
Epoch 220 batch 00003: Loss 0.0644 Regression loss 0.0204 Classification loss 0.0440 AP 0.2797 AR 0.4783
Epoch 220 batch 00004: Loss 0.0575 Regression loss 0.0230 Classification loss 0.0345 AP 0.1922 AR 0.4250
Epoch 220 batch 00005: Loss 0.0693 Regression loss 0.0248 Classification loss 0.0445 AP 0.1833 AR 0.5067
Epoch 220 batch 00006: Loss 0.0542 Regression loss 0.0216 Classification loss 0.0326 AP 0.2516 AR 0.4617
Epoch 220 batch 00007: Loss 0.0728 Regression loss 0.0219 Classification loss 0.0508 AP 0.1939 AR 0.4400
Epoch 220 batch 00008: Loss 0.0762 Regression loss 0.0225 Classification loss 0.0537 AP 0.1422 AR 0.3333
Epoch 220 batch 00009: Loss 0.0890 Regression loss 0.0305 Classification loss 0.0585 AP 0.3200 AR 0.4683
Epoch 220 batch 00010: Loss 0.0892 Regression loss 0.0265 Classification loss 0.0627 AP 0.1817 AR 0.4733
Epoch 221 batch 00001: Loss 0.0657 Regression loss 0.0225 Classification loss 0.0431 AP 0.1289 AR 0.2583
Epoch 221 batch 00002: Loss 0.0686 Regression loss 0.0230 Classification loss 0.0456 AP 0.1967 AR 0.5483
Epoch 221 batch 00003: Loss 0.0762 Regression loss 0.0229 Classification loss 0.0533 AP 0.1433 AR 0.3550
Epoch 221 batch 00004: Loss 0.0661 Regression loss 0.0271 Classification loss 0.0389 AP 0.1291 AR 0.2833
Epoch 221 batch 00005: Loss 0.0837 Regression loss 0.0239 Classification loss 0.0598 AP 0.1897 AR 0.3733
Epoch 221 batch 00006: Loss 0.0696 Regression loss 0.0242 Classification loss 0.0454 AP 0.1836 AR 0.3983
Epoch 221 batch 00007: Loss 0.0713 Regression loss 0.0232 Classification loss 0.0480 AP 0.1008 AR 0.1933
Epoch 221 batch 00008: Loss 0.0630 Regression loss 0.0186 Classification loss 0.0445 AP 0.2317 AR 0.4667
Epoch 221 batch 00009: Loss 0.0629 Regression loss 0.0244 Classification loss 0.0385 AP 0.1799 AR 0.3933
Epoch 221 batch 00010: Loss 0.0643 Regression loss 0.0220 Classification loss 0.0423 AP 0.1734 AR 0.2650
Epoch 222 batch 00001: Loss 0.0610 Regression loss 0.0251 Classification loss 0.0358 AP 0.1389 AR 0.2683
Epoch 222 batch 00002: Loss 0.0556 Regression loss 0.0203 Classification loss 0.0353 AP 0.2029 AR 0.4983
Epoch 222 batch 00003: Loss 0.0700 Regression loss 0.0223 Classification loss 0.0477 AP 0.2035 AR 0.3417
Epoch 222 batch 00004: Loss 0.0785 Regression loss 0.0251 Classification loss 0.0535 AP 0.1650 AR 0.3700
Epoch 222 batch 00005: Loss 0.0856 Regression loss 0.0238 Classification loss 0.0618 AP 0.1931 AR 0.3750
Epoch 222 batch 00006: Loss 0.0656 Regression loss 0.0256 Classification loss 0.0401 AP 0.0928 AR 0.2567
Epoch 222 batch 00007: Loss 0.0698 Regression loss 0.0224 Classification loss 0.0474 AP 0.1882 AR 0.4733
Epoch 222 batch 00008: Loss 0.0692 Regression loss 0.0204 Classification loss 0.0488 AP 0.3377 AR 0.6917
Epoch 222 batch 00009: Loss 0.0784 Regression loss 0.0228 Classification loss 0.0556 AP 0.1064 AR 0.2333
Epoch 222 batch 00010: Loss 0.0540 Regression loss 0.0194 Classification loss 0.0346 AP 0.2791 AR 0.4683
Epoch 223 batch 00001: Loss 0.0608 Regression loss 0.0234 Classification loss 0.0375 AP 0.2351 AR 0.4817
Epoch 223 batch 00002: Loss 0.0685 Regression loss 0.0232 Classification loss 0.0453 AP 0.3308 AR 0.4533
Epoch 223 batch 00003: Loss 0.0551 Regression loss 0.0218 Classification loss 0.0333 AP 0.1959 AR 0.3483
Epoch 223 batch 00004: Loss 0.0707 Regression loss 0.0208 Classification loss 0.0499 AP 0.1667 AR 0.3867
Epoch 223 batch 00005: Loss 0.0729 Regression loss 0.0213 Classification loss 0.0517 AP 0.2273 AR 0.5367
Epoch 223 batch 00006: Loss 0.0655 Regression loss 0.0205 Classification loss 0.0450 AP 0.1364 AR 0.2983
Epoch 223 batch 00007: Loss 0.0766 Regression loss 0.0202 Classification loss 0.0565 AP 0.2950 AR 0.4533
Epoch 223 batch 00008: Loss 0.0960 Regression loss 0.0288 Classification loss 0.0672 AP 0.0556 AR 0.1417
Epoch 223 batch 00009: Loss 0.0658 Regression loss 0.0234 Classification loss 0.0424 AP 0.2051 AR 0.4450
Epoch 223 batch 00010: Loss 0.0638 Regression loss 0.0229 Classification loss 0.0409 AP 0.2421 AR 0.4883
Epoch 224 batch 00001: Loss 0.0675 Regression loss 0.0252 Classification loss 0.0423 AP 0.2519 AR 0.4850
Epoch 224 batch 00002: Loss 0.0780 Regression loss 0.0241 Classification loss 0.0539 AP 0.2644 AR 0.4833
Epoch 224 batch 00003: Loss 0.0672 Regression loss 0.0215 Classification loss 0.0458 AP 0.3169 AR 0.5433
Epoch 224 batch 00004: Loss 0.0689 Regression loss 0.0234 Classification loss 0.0456 AP 0.2602 AR 0.6100
Epoch 224 batch 00005: Loss 0.0657 Regression loss 0.0294 Classification loss 0.0362 AP 0.1362 AR 0.3117
Epoch 224 batch 00006: Loss 0.0635 Regression loss 0.0198 Classification loss 0.0436 AP 0.1385 AR 0.2883
Epoch 224 batch 00007: Loss 0.0816 Regression loss 0.0205 Classification loss 0.0611 AP 0.1043 AR 0.2233
Epoch 224 batch 00008: Loss 0.0767 Regression loss 0.0231 Classification loss 0.0536 AP 0.1238 AR 0.3150
Epoch 224 batch 00009: Loss 0.0463 Regression loss 0.0173 Classification loss 0.0290 AP 0.3037 AR 0.5783
Epoch 224 batch 00010: Loss 0.0631 Regression loss 0.0266 Classification loss 0.0364 AP 0.1855 AR 0.2533
Epoch 225 batch 00001: Loss 0.0799 Regression loss 0.0243 Classification loss 0.0556 AP 0.1666 AR 0.3167
Epoch 225 batch 00002: Loss 0.0626 Regression loss 0.0212 Classification loss 0.0415 AP 0.1725 AR 0.3350
Epoch 225 batch 00003: Loss 0.0743 Regression loss 0.0260 Classification loss 0.0484 AP 0.1848 AR 0.4033
Epoch 225 batch 00004: Loss 0.0513 Regression loss 0.0202 Classification loss 0.0311 AP 0.3107 AR 0.5500
Epoch 225 batch 00005: Loss 0.0664 Regression loss 0.0214 Classification loss 0.0451 AP 0.1550 AR 0.3333
Epoch 225 batch 00006: Loss 0.0586 Regression loss 0.0208 Classification loss 0.0378 AP 0.2789 AR 0.5567
Epoch 225 batch 00007: Loss 0.0697 Regression loss 0.0237 Classification loss 0.0460 AP 0.1218 AR 0.2650
Epoch 225 batch 00008: Loss 0.0622 Regression loss 0.0204 Classification loss 0.0418 AP 0.2359 AR 0.4950
Epoch 225 batch 00009: Loss 0.0609 Regression loss 0.0250 Classification loss 0.0359 AP 0.2047 AR 0.3400
Epoch 225 batch 00010: Loss 0.0662 Regression loss 0.0207 Classification loss 0.0456 AP 0.3049 AR 0.4533
Epoch 226 batch 00001: Loss 0.0541 Regression loss 0.0214 Classification loss 0.0327 AP 0.1583 AR 0.2917
Epoch 226 batch 00002: Loss 0.0798 Regression loss 0.0269 Classification loss 0.0529 AP 0.2275 AR 0.4917
Epoch 226 batch 00003: Loss 0.0696 Regression loss 0.0224 Classification loss 0.0472 AP 0.1589 AR 0.3350
Epoch 226 batch 00004: Loss 0.0636 Regression loss 0.0217 Classification loss 0.0419 AP 0.1703 AR 0.3233
Epoch 226 batch 00005: Loss 0.0633 Regression loss 0.0297 Classification loss 0.0336 AP 0.1887 AR 0.3817
Epoch 226 batch 00006: Loss 0.0614 Regression loss 0.0220 Classification loss 0.0394 AP 0.1057 AR 0.2667
Epoch 226 batch 00007: Loss 0.0609 Regression loss 0.0237 Classification loss 0.0371 AP 0.3067 AR 0.4983
Epoch 226 batch 00008: Loss 0.0675 Regression loss 0.0238 Classification loss 0.0437 AP 0.1875 AR 0.4150
Epoch 226 batch 00009: Loss 0.0663 Regression loss 0.0209 Classification loss 0.0455 AP 0.1556 AR 0.3400
Epoch 226 batch 00010: Loss 0.0676 Regression loss 0.0233 Classification loss 0.0443 AP 0.3281 AR 0.4650
Epoch 227 batch 00001: Loss 0.0568 Regression loss 0.0249 Classification loss 0.0319 AP 0.2372 AR 0.3917
Epoch 227 batch 00002: Loss 0.0712 Regression loss 0.0253 Classification loss 0.0459 AP 0.2192 AR 0.3500
Epoch 227 batch 00003: Loss 0.0597 Regression loss 0.0198 Classification loss 0.0400 AP 0.1896 AR 0.4667
Epoch 227 batch 00004: Loss 0.0686 Regression loss 0.0216 Classification loss 0.0470 AP 0.3450 AR 0.6617
Epoch 227 batch 00005: Loss 0.0678 Regression loss 0.0239 Classification loss 0.0438 AP 0.1508 AR 0.3233
Epoch 227 batch 00006: Loss 0.0641 Regression loss 0.0217 Classification loss 0.0424 AP 0.1842 AR 0.3833
Epoch 227 batch 00007: Loss 0.0761 Regression loss 0.0219 Classification loss 0.0542 AP 0.1704 AR 0.3450
Epoch 227 batch 00008: Loss 0.0622 Regression loss 0.0214 Classification loss 0.0408 AP 0.1505 AR 0.2817
Epoch 227 batch 00009: Loss 0.0628 Regression loss 0.0238 Classification loss 0.0390 AP 0.2021 AR 0.4750
Epoch 227 batch 00010: Loss 0.0536 Regression loss 0.0226 Classification loss 0.0309 AP 0.2412 AR 0.4117
Epoch 228 batch 00001: Loss 0.0535 Regression loss 0.0186 Classification loss 0.0350 AP 0.2629 AR 0.4367
Epoch 228 batch 00002: Loss 0.0760 Regression loss 0.0231 Classification loss 0.0529 AP 0.1701 AR 0.3183
Epoch 228 batch 00003: Loss 0.0562 Regression loss 0.0234 Classification loss 0.0328 AP 0.3325 AR 0.7067
Epoch 228 batch 00004: Loss 0.0690 Regression loss 0.0202 Classification loss 0.0488 AP 0.2273 AR 0.4433
Epoch 228 batch 00005: Loss 0.0534 Regression loss 0.0209 Classification loss 0.0325 AP 0.2029 AR 0.3883
Epoch 228 batch 00006: Loss 0.0625 Regression loss 0.0215 Classification loss 0.0409 AP 0.2352 AR 0.3883
Epoch 228 batch 00007: Loss 0.0673 Regression loss 0.0276 Classification loss 0.0397 AP 0.0888 AR 0.1617
Epoch 228 batch 00008: Loss 0.0603 Regression loss 0.0220 Classification loss 0.0384 AP 0.1819 AR 0.2833
Epoch 228 batch 00009: Loss 0.0823 Regression loss 0.0258 Classification loss 0.0565 AP 0.0958 AR 0.2300
Epoch 228 batch 00010: Loss 0.0485 Regression loss 0.0225 Classification loss 0.0260 AP 0.2486 AR 0.4417
Epoch 229 batch 00001: Loss 0.0622 Regression loss 0.0205 Classification loss 0.0417 AP 0.2471 AR 0.4450
Epoch 229 batch 00002: Loss 0.0610 Regression loss 0.0226 Classification loss 0.0384 AP 0.2648 AR 0.4817
Epoch 229 batch 00003: Loss 0.0480 Regression loss 0.0202 Classification loss 0.0278 AP 0.0958 AR 0.1750
Epoch 229 batch 00004: Loss 0.0644 Regression loss 0.0260 Classification loss 0.0384 AP 0.2584 AR 0.4000
Epoch 229 batch 00005: Loss 0.0548 Regression loss 0.0205 Classification loss 0.0343 AP 0.2750 AR 0.5650
Epoch 229 batch 00006: Loss 0.0637 Regression loss 0.0228 Classification loss 0.0409 AP 0.2143 AR 0.4800
Epoch 229 batch 00007: Loss 0.0696 Regression loss 0.0204 Classification loss 0.0492 AP 0.1822 AR 0.4500
Epoch 229 batch 00008: Loss 0.0578 Regression loss 0.0218 Classification loss 0.0360 AP 0.2385 AR 0.6383
Epoch 229 batch 00009: Loss 0.0675 Regression loss 0.0228 Classification loss 0.0447 AP 0.1550 AR 0.3167
Epoch 229 batch 00010: Loss 0.0727 Regression loss 0.0233 Classification loss 0.0493 AP 0.2919 AR 0.5067
Epoch 230 batch 00001: Loss 0.0705 Regression loss 0.0215 Classification loss 0.0490 AP 0.2677 AR 0.4583
Epoch 230 batch 00002: Loss 0.0597 Regression loss 0.0237 Classification loss 0.0360 AP 0.2009 AR 0.4483
Epoch 230 batch 00003: Loss 0.0662 Regression loss 0.0225 Classification loss 0.0437 AP 0.1656 AR 0.2600
Epoch 230 batch 00004: Loss 0.0483 Regression loss 0.0195 Classification loss 0.0288 AP 0.1948 AR 0.4400
Epoch 230 batch 00005: Loss 0.0613 Regression loss 0.0242 Classification loss 0.0371 AP 0.1643 AR 0.3400
Epoch 230 batch 00006: Loss 0.0559 Regression loss 0.0231 Classification loss 0.0328 AP 0.1972 AR 0.4583
Epoch 230 batch 00007: Loss 0.0631 Regression loss 0.0199 Classification loss 0.0432 AP 0.2045 AR 0.5250
Epoch 230 batch 00008: Loss 0.0739 Regression loss 0.0208 Classification loss 0.0531 AP 0.1558 AR 0.4167
Epoch 230 batch 00009: Loss 0.0731 Regression loss 0.0225 Classification loss 0.0506 AP 0.1203 AR 0.2600
Epoch 230 batch 00010: Loss 0.0677 Regression loss 0.0237 Classification loss 0.0440 AP 0.2228 AR 0.4767
Epoch 231 batch 00001: Loss 0.0862 Regression loss 0.0290 Classification loss 0.0572 AP 0.1762 AR 0.3333
Epoch 231 batch 00002: Loss 0.0695 Regression loss 0.0213 Classification loss 0.0482 AP 0.1954 AR 0.4000
Epoch 231 batch 00003: Loss 0.0473 Regression loss 0.0197 Classification loss 0.0277 AP 0.3227 AR 0.6750
Epoch 231 batch 00004: Loss 0.0524 Regression loss 0.0195 Classification loss 0.0328 AP 0.2131 AR 0.5283
Epoch 231 batch 00005: Loss 0.0705 Regression loss 0.0226 Classification loss 0.0479 AP 0.2024 AR 0.3667
Epoch 231 batch 00006: Loss 0.0625 Regression loss 0.0208 Classification loss 0.0417 AP 0.1338 AR 0.3233
Epoch 231 batch 00007: Loss 0.0634 Regression loss 0.0238 Classification loss 0.0396 AP 0.1942 AR 0.4500
Epoch 231 batch 00008: Loss 0.0544 Regression loss 0.0200 Classification loss 0.0344 AP 0.2042 AR 0.3450
Epoch 231 batch 00009: Loss 0.0614 Regression loss 0.0233 Classification loss 0.0381 AP 0.2161 AR 0.4633
Epoch 231 batch 00010: Loss 0.0645 Regression loss 0.0262 Classification loss 0.0382 AP 0.1601 AR 0.3400
Epoch 232 batch 00001: Loss 0.0699 Regression loss 0.0239 Classification loss 0.0460 AP 0.2837 AR 0.5850
Epoch 232 batch 00002: Loss 0.0691 Regression loss 0.0269 Classification loss 0.0423 AP 0.1701 AR 0.3650
Epoch 232 batch 00003: Loss 0.0682 Regression loss 0.0212 Classification loss 0.0470 AP 0.2380 AR 0.6267
Epoch 232 batch 00004: Loss 0.0636 Regression loss 0.0219 Classification loss 0.0416 AP 0.2024 AR 0.3667
Epoch 232 batch 00005: Loss 0.0606 Regression loss 0.0212 Classification loss 0.0394 AP 0.2465 AR 0.5817
Epoch 232 batch 00006: Loss 0.0782 Regression loss 0.0268 Classification loss 0.0514 AP 0.0948 AR 0.2367
Epoch 232 batch 00007: Loss 0.0767 Regression loss 0.0237 Classification loss 0.0530 AP 0.2166 AR 0.4317
Epoch 232 batch 00008: Loss 0.0805 Regression loss 0.0267 Classification loss 0.0538 AP 0.1051 AR 0.2533
Epoch 232 batch 00009: Loss 0.0506 Regression loss 0.0221 Classification loss 0.0285 AP 0.1611 AR 0.3717
Epoch 232 batch 00010: Loss 0.0532 Regression loss 0.0200 Classification loss 0.0332 AP 0.2903 AR 0.4667
Epoch 233 batch 00001: Loss 0.0746 Regression loss 0.0179 Classification loss 0.0567 AP 0.2813 AR 0.3700
Epoch 233 batch 00002: Loss 0.0608 Regression loss 0.0233 Classification loss 0.0375 AP 0.1916 AR 0.3817
Epoch 233 batch 00003: Loss 0.0820 Regression loss 0.0253 Classification loss 0.0567 AP 0.1908 AR 0.4183
Epoch 233 batch 00004: Loss 0.0699 Regression loss 0.0204 Classification loss 0.0495 AP 0.1710 AR 0.3633
Epoch 233 batch 00005: Loss 0.0593 Regression loss 0.0189 Classification loss 0.0404 AP 0.2429 AR 0.3450
Epoch 233 batch 00006: Loss 0.0743 Regression loss 0.0222 Classification loss 0.0521 AP 0.2113 AR 0.3217
Epoch 233 batch 00007: Loss 0.0522 Regression loss 0.0219 Classification loss 0.0303 AP 0.2426 AR 0.5050
Epoch 233 batch 00008: Loss 0.0608 Regression loss 0.0225 Classification loss 0.0384 AP 0.1912 AR 0.4000
Epoch 233 batch 00009: Loss 0.0700 Regression loss 0.0262 Classification loss 0.0438 AP 0.1528 AR 0.4100
Epoch 233 batch 00010: Loss 0.0556 Regression loss 0.0245 Classification loss 0.0311 AP 0.1162 AR 0.3200
Epoch 234 batch 00001: Loss 0.0462 Regression loss 0.0192 Classification loss 0.0270 AP 0.3018 AR 0.4950
Epoch 234 batch 00002: Loss 0.0478 Regression loss 0.0201 Classification loss 0.0277 AP 0.2575 AR 0.5283
Epoch 234 batch 00003: Loss 0.0736 Regression loss 0.0251 Classification loss 0.0485 AP 0.1917 AR 0.4900
Epoch 234 batch 00004: Loss 0.0526 Regression loss 0.0173 Classification loss 0.0353 AP 0.2995 AR 0.4883
Epoch 234 batch 00005: Loss 0.0710 Regression loss 0.0250 Classification loss 0.0459 AP 0.1240 AR 0.2867
Epoch 234 batch 00006: Loss 0.0759 Regression loss 0.0221 Classification loss 0.0538 AP 0.3008 AR 0.4433
Epoch 234 batch 00007: Loss 0.0626 Regression loss 0.0238 Classification loss 0.0388 AP 0.2766 AR 0.4650
Epoch 234 batch 00008: Loss 0.0512 Regression loss 0.0195 Classification loss 0.0317 AP 0.2227 AR 0.4533
Epoch 234 batch 00009: Loss 0.0738 Regression loss 0.0274 Classification loss 0.0463 AP 0.1448 AR 0.4333
Epoch 234 batch 00010: Loss 0.0579 Regression loss 0.0212 Classification loss 0.0367 AP 0.1944 AR 0.4817
Epoch 235 batch 00001: Loss 0.0602 Regression loss 0.0220 Classification loss 0.0381 AP 0.1633 AR 0.3400
Epoch 235 batch 00002: Loss 0.0576 Regression loss 0.0214 Classification loss 0.0362 AP 0.1905 AR 0.3400
Epoch 235 batch 00003: Loss 0.0496 Regression loss 0.0215 Classification loss 0.0282 AP 0.2828 AR 0.5533
Epoch 235 batch 00004: Loss 0.0757 Regression loss 0.0260 Classification loss 0.0497 AP 0.2517 AR 0.3000
Epoch 235 batch 00005: Loss 0.0599 Regression loss 0.0233 Classification loss 0.0366 AP 0.1760 AR 0.3700
Epoch 235 batch 00006: Loss 0.0509 Regression loss 0.0187 Classification loss 0.0322 AP 0.1950 AR 0.4417
Epoch 235 batch 00007: Loss 0.0617 Regression loss 0.0229 Classification loss 0.0388 AP 0.1991 AR 0.4583
Epoch 235 batch 00008: Loss 0.0660 Regression loss 0.0225 Classification loss 0.0435 AP 0.1265 AR 0.3183
Epoch 235 batch 00009: Loss 0.0690 Regression loss 0.0262 Classification loss 0.0428 AP 0.1577 AR 0.3567
Epoch 235 batch 00010: Loss 0.0727 Regression loss 0.0237 Classification loss 0.0490 AP 0.1650 AR 0.4600
Epoch 236 batch 00001: Loss 0.0508 Regression loss 0.0198 Classification loss 0.0310 AP 0.3119 AR 0.5200
Epoch 236 batch 00002: Loss 0.0610 Regression loss 0.0217 Classification loss 0.0392 AP 0.1461 AR 0.2533
Epoch 236 batch 00003: Loss 0.0489 Regression loss 0.0183 Classification loss 0.0307 AP 0.1179 AR 0.2750
Epoch 236 batch 00004: Loss 0.0694 Regression loss 0.0258 Classification loss 0.0436 AP 0.1356 AR 0.3000
Epoch 236 batch 00005: Loss 0.0554 Regression loss 0.0209 Classification loss 0.0345 AP 0.2998 AR 0.4800
Epoch 236 batch 00006: Loss 0.0621 Regression loss 0.0216 Classification loss 0.0404 AP 0.2353 AR 0.4083
Epoch 236 batch 00007: Loss 0.0651 Regression loss 0.0202 Classification loss 0.0449 AP 0.2007 AR 0.3817
Epoch 236 batch 00008: Loss 0.0595 Regression loss 0.0222 Classification loss 0.0372 AP 0.1048 AR 0.2183
Epoch 236 batch 00009: Loss 0.0574 Regression loss 0.0284 Classification loss 0.0290 AP 0.1419 AR 0.3000
Epoch 236 batch 00010: Loss 0.0743 Regression loss 0.0247 Classification loss 0.0496 AP 0.1754 AR 0.5017
Epoch 237 batch 00001: Loss 0.0529 Regression loss 0.0181 Classification loss 0.0348 AP 0.4140 AR 0.6433
Epoch 237 batch 00002: Loss 0.0701 Regression loss 0.0213 Classification loss 0.0488 AP 0.2968 AR 0.5350
Epoch 237 batch 00003: Loss 0.0536 Regression loss 0.0211 Classification loss 0.0325 AP 0.2602 AR 0.5483
Epoch 237 batch 00004: Loss 0.0558 Regression loss 0.0232 Classification loss 0.0326 AP 0.2104 AR 0.3750
Epoch 237 batch 00005: Loss 0.0557 Regression loss 0.0211 Classification loss 0.0346 AP 0.2004 AR 0.4250
Epoch 237 batch 00006: Loss 0.0746 Regression loss 0.0253 Classification loss 0.0493 AP 0.0702 AR 0.1367
Epoch 237 batch 00007: Loss 0.0629 Regression loss 0.0160 Classification loss 0.0470 AP 0.1824 AR 0.3983
Epoch 237 batch 00008: Loss 0.0625 Regression loss 0.0224 Classification loss 0.0400 AP 0.1175 AR 0.2750
Epoch 237 batch 00009: Loss 0.0563 Regression loss 0.0234 Classification loss 0.0328 AP 0.1147 AR 0.3100
Epoch 237 batch 00010: Loss 0.0629 Regression loss 0.0259 Classification loss 0.0370 AP 0.1736 AR 0.4300
Epoch 238 batch 00001: Loss 0.0595 Regression loss 0.0177 Classification loss 0.0418 AP 0.1617 AR 0.2817
Epoch 238 batch 00002: Loss 0.0481 Regression loss 0.0196 Classification loss 0.0285 AP 0.1990 AR 0.4583
Epoch 238 batch 00003: Loss 0.0730 Regression loss 0.0223 Classification loss 0.0507 AP 0.2008 AR 0.4750
Epoch 238 batch 00004: Loss 0.0654 Regression loss 0.0214 Classification loss 0.0440 AP 0.1775 AR 0.4150
Epoch 238 batch 00005: Loss 0.0459 Regression loss 0.0198 Classification loss 0.0260 AP 0.2246 AR 0.5033
Epoch 238 batch 00006: Loss 0.0588 Regression loss 0.0238 Classification loss 0.0350 AP 0.2036 AR 0.5017
Epoch 238 batch 00007: Loss 0.0649 Regression loss 0.0234 Classification loss 0.0415 AP 0.1567 AR 0.3767
Epoch 238 batch 00008: Loss 0.0596 Regression loss 0.0226 Classification loss 0.0370 AP 0.1261 AR 0.2867
Epoch 238 batch 00009: Loss 0.0629 Regression loss 0.0246 Classification loss 0.0383 AP 0.2636 AR 0.4483
Epoch 238 batch 00010: Loss 0.0569 Regression loss 0.0230 Classification loss 0.0339 AP 0.1362 AR 0.2983
Epoch 239 batch 00001: Loss 0.0463 Regression loss 0.0196 Classification loss 0.0267 AP 0.2056 AR 0.4583
Epoch 239 batch 00002: Loss 0.0481 Regression loss 0.0212 Classification loss 0.0270 AP 0.1617 AR 0.3333
Epoch 239 batch 00003: Loss 0.0790 Regression loss 0.0222 Classification loss 0.0568 AP 0.3205 AR 0.5467
Epoch 239 batch 00004: Loss 0.0671 Regression loss 0.0271 Classification loss 0.0400 AP 0.1768 AR 0.3317
Epoch 239 batch 00005: Loss 0.0578 Regression loss 0.0232 Classification loss 0.0345 AP 0.2799 AR 0.5550
Epoch 239 batch 00006: Loss 0.0658 Regression loss 0.0212 Classification loss 0.0446 AP 0.2021 AR 0.3733
Epoch 239 batch 00007: Loss 0.0453 Regression loss 0.0191 Classification loss 0.0262 AP 0.2802 AR 0.5900
Epoch 239 batch 00008: Loss 0.0581 Regression loss 0.0260 Classification loss 0.0322 AP 0.2067 AR 0.3333
Epoch 239 batch 00009: Loss 0.0711 Regression loss 0.0246 Classification loss 0.0465 AP 0.1299 AR 0.2783
Epoch 239 batch 00010: Loss 0.0578 Regression loss 0.0212 Classification loss 0.0365 AP 0.2259 AR 0.4217
Epoch 240 batch 00001: Loss 0.0539 Regression loss 0.0249 Classification loss 0.0290 AP 0.3212 AR 0.4250
Epoch 240 batch 00002: Loss 0.0627 Regression loss 0.0222 Classification loss 0.0405 AP 0.1998 AR 0.4150
Epoch 240 batch 00003: Loss 0.0460 Regression loss 0.0161 Classification loss 0.0299 AP 0.4292 AR 0.7200
Epoch 240 batch 00004: Loss 0.0528 Regression loss 0.0192 Classification loss 0.0337 AP 0.1831 AR 0.2750
Epoch 240 batch 00005: Loss 0.0634 Regression loss 0.0209 Classification loss 0.0425 AP 0.1481 AR 0.4550
Epoch 240 batch 00006: Loss 0.0577 Regression loss 0.0231 Classification loss 0.0347 AP 0.2002 AR 0.3733
Epoch 240 batch 00007: Loss 0.0537 Regression loss 0.0197 Classification loss 0.0339 AP 0.1919 AR 0.4183
Epoch 240 batch 00008: Loss 0.0637 Regression loss 0.0256 Classification loss 0.0381 AP 0.2321 AR 0.5050
Epoch 240 batch 00009: Loss 0.0588 Regression loss 0.0214 Classification loss 0.0374 AP 0.2768 AR 0.5617
Epoch 240 batch 00010: Loss 0.0660 Regression loss 0.0243 Classification loss 0.0416 AP 0.2036 AR 0.4833
Epoch 241 batch 00001: Loss 0.0605 Regression loss 0.0211 Classification loss 0.0394 AP 0.1188 AR 0.2500
Epoch 241 batch 00002: Loss 0.0654 Regression loss 0.0224 Classification loss 0.0429 AP 0.2286 AR 0.4867
Epoch 241 batch 00003: Loss 0.0565 Regression loss 0.0215 Classification loss 0.0350 AP 0.1732 AR 0.3750
Epoch 241 batch 00004: Loss 0.0600 Regression loss 0.0231 Classification loss 0.0369 AP 0.2519 AR 0.4717
Epoch 241 batch 00005: Loss 0.0570 Regression loss 0.0255 Classification loss 0.0315 AP 0.1549 AR 0.3867
Epoch 241 batch 00006: Loss 0.0562 Regression loss 0.0188 Classification loss 0.0374 AP 0.2246 AR 0.5733
Epoch 241 batch 00007: Loss 0.0597 Regression loss 0.0254 Classification loss 0.0342 AP 0.2586 AR 0.4350
Epoch 241 batch 00008: Loss 0.0722 Regression loss 0.0227 Classification loss 0.0494 AP 0.2133 AR 0.3550
Epoch 241 batch 00009: Loss 0.0606 Regression loss 0.0285 Classification loss 0.0321 AP 0.0877 AR 0.2417
Epoch 241 batch 00010: Loss 0.0525 Regression loss 0.0223 Classification loss 0.0303 AP 0.2175 AR 0.3717
Epoch 242 batch 00001: Loss 0.0550 Regression loss 0.0209 Classification loss 0.0341 AP 0.1264 AR 0.2917
Epoch 242 batch 00002: Loss 0.0583 Regression loss 0.0233 Classification loss 0.0350 AP 0.2411 AR 0.3583
Epoch 242 batch 00003: Loss 0.0581 Regression loss 0.0255 Classification loss 0.0326 AP 0.1679 AR 0.3417
Epoch 242 batch 00004: Loss 0.0556 Regression loss 0.0204 Classification loss 0.0351 AP 0.1829 AR 0.3783
Epoch 242 batch 00005: Loss 0.0622 Regression loss 0.0264 Classification loss 0.0358 AP 0.2053 AR 0.3950
Epoch 242 batch 00006: Loss 0.0551 Regression loss 0.0228 Classification loss 0.0322 AP 0.2063 AR 0.4333
Epoch 242 batch 00007: Loss 0.0583 Regression loss 0.0203 Classification loss 0.0379 AP 0.2069 AR 0.4200
Epoch 242 batch 00008: Loss 0.0727 Regression loss 0.0221 Classification loss 0.0506 AP 0.1938 AR 0.3950
Epoch 242 batch 00009: Loss 0.0566 Regression loss 0.0196 Classification loss 0.0370 AP 0.2416 AR 0.4983
Epoch 242 batch 00010: Loss 0.0501 Regression loss 0.0201 Classification loss 0.0301 AP 0.3538 AR 0.7017
Epoch 243 batch 00001: Loss 0.0544 Regression loss 0.0187 Classification loss 0.0357 AP 0.1844 AR 0.4483
Epoch 243 batch 00002: Loss 0.0697 Regression loss 0.0220 Classification loss 0.0477 AP 0.3406 AR 0.6333
Epoch 243 batch 00003: Loss 0.0482 Regression loss 0.0238 Classification loss 0.0243 AP 0.2307 AR 0.4367
Epoch 243 batch 00004: Loss 0.0488 Regression loss 0.0187 Classification loss 0.0300 AP 0.2222 AR 0.5767
Epoch 243 batch 00005: Loss 0.0557 Regression loss 0.0174 Classification loss 0.0383 AP 0.4373 AR 0.7083
Epoch 243 batch 00006: Loss 0.0584 Regression loss 0.0204 Classification loss 0.0380 AP 0.1958 AR 0.3483
Epoch 243 batch 00007: Loss 0.0518 Regression loss 0.0211 Classification loss 0.0307 AP 0.1456 AR 0.2933
Epoch 243 batch 00008: Loss 0.0575 Regression loss 0.0226 Classification loss 0.0349 AP 0.2071 AR 0.4667
Epoch 243 batch 00009: Loss 0.0608 Regression loss 0.0209 Classification loss 0.0398 AP 0.1381 AR 0.3417
Epoch 243 batch 00010: Loss 0.0496 Regression loss 0.0182 Classification loss 0.0314 AP 0.2620 AR 0.5650
Epoch 244 batch 00001: Loss 0.0592 Regression loss 0.0214 Classification loss 0.0378 AP 0.1425 AR 0.3783
Epoch 244 batch 00002: Loss 0.0469 Regression loss 0.0185 Classification loss 0.0284 AP 0.2730 AR 0.6200
Epoch 244 batch 00003: Loss 0.0528 Regression loss 0.0184 Classification loss 0.0344 AP 0.2234 AR 0.4667
Epoch 244 batch 00004: Loss 0.0532 Regression loss 0.0262 Classification loss 0.0270 AP 0.1486 AR 0.3983
Epoch 244 batch 00005: Loss 0.0503 Regression loss 0.0176 Classification loss 0.0327 AP 0.3012 AR 0.5050
Epoch 244 batch 00006: Loss 0.0513 Regression loss 0.0176 Classification loss 0.0337 AP 0.1498 AR 0.3150
Epoch 244 batch 00007: Loss 0.0600 Regression loss 0.0195 Classification loss 0.0405 AP 0.3425 AR 0.5383
Epoch 244 batch 00008: Loss 0.0612 Regression loss 0.0243 Classification loss 0.0369 AP 0.2191 AR 0.3333
Epoch 244 batch 00009: Loss 0.0529 Regression loss 0.0237 Classification loss 0.0292 AP 0.2693 AR 0.4617
Epoch 244 batch 00010: Loss 0.0711 Regression loss 0.0231 Classification loss 0.0480 AP 0.2499 AR 0.4333
Epoch 245 batch 00001: Loss 0.0519 Regression loss 0.0215 Classification loss 0.0304 AP 0.1172 AR 0.2867
Epoch 245 batch 00002: Loss 0.0510 Regression loss 0.0173 Classification loss 0.0336 AP 0.2279 AR 0.4783
Epoch 245 batch 00003: Loss 0.0558 Regression loss 0.0192 Classification loss 0.0366 AP 0.2473 AR 0.4567
Epoch 245 batch 00004: Loss 0.0473 Regression loss 0.0213 Classification loss 0.0260 AP 0.2206 AR 0.4733
Epoch 245 batch 00005: Loss 0.0576 Regression loss 0.0209 Classification loss 0.0368 AP 0.1190 AR 0.2883
Epoch 245 batch 00006: Loss 0.0551 Regression loss 0.0205 Classification loss 0.0346 AP 0.1381 AR 0.2750
Epoch 245 batch 00007: Loss 0.0513 Regression loss 0.0211 Classification loss 0.0302 AP 0.3097 AR 0.5167
Epoch 245 batch 00008: Loss 0.0548 Regression loss 0.0216 Classification loss 0.0332 AP 0.2785 AR 0.5717
Epoch 245 batch 00009: Loss 0.0644 Regression loss 0.0241 Classification loss 0.0403 AP 0.1787 AR 0.3183
Epoch 245 batch 00010: Loss 0.0673 Regression loss 0.0224 Classification loss 0.0449 AP 0.1230 AR 0.2833
Epoch 246 batch 00001: Loss 0.0426 Regression loss 0.0179 Classification loss 0.0246 AP 0.4352 AR 0.6400
Epoch 246 batch 00002: Loss 0.0513 Regression loss 0.0197 Classification loss 0.0316 AP 0.2837 AR 0.4950
Epoch 246 batch 00003: Loss 0.0604 Regression loss 0.0211 Classification loss 0.0394 AP 0.1760 AR 0.4600
Epoch 246 batch 00004: Loss 0.0562 Regression loss 0.0217 Classification loss 0.0345 AP 0.3063 AR 0.6700
Epoch 246 batch 00005: Loss 0.0548 Regression loss 0.0225 Classification loss 0.0323 AP 0.1414 AR 0.3667
Epoch 246 batch 00006: Loss 0.0640 Regression loss 0.0206 Classification loss 0.0434 AP 0.1643 AR 0.3617
Epoch 246 batch 00007: Loss 0.0547 Regression loss 0.0226 Classification loss 0.0321 AP 0.2388 AR 0.4067
Epoch 246 batch 00008: Loss 0.0527 Regression loss 0.0212 Classification loss 0.0315 AP 0.0911 AR 0.1933
Epoch 246 batch 00009: Loss 0.0562 Regression loss 0.0230 Classification loss 0.0332 AP 0.2345 AR 0.4833
Epoch 246 batch 00010: Loss 0.0496 Regression loss 0.0203 Classification loss 0.0293 AP 0.2166 AR 0.4200
Epoch 247 batch 00001: Loss 0.0543 Regression loss 0.0245 Classification loss 0.0298 AP 0.2187 AR 0.3750
Epoch 247 batch 00002: Loss 0.0493 Regression loss 0.0195 Classification loss 0.0298 AP 0.1527 AR 0.4117
Epoch 247 batch 00003: Loss 0.0606 Regression loss 0.0215 Classification loss 0.0391 AP 0.2346 AR 0.5083
Epoch 247 batch 00004: Loss 0.0509 Regression loss 0.0184 Classification loss 0.0325 AP 0.2089 AR 0.4583
Epoch 247 batch 00005: Loss 0.0529 Regression loss 0.0191 Classification loss 0.0339 AP 0.2434 AR 0.5333
Epoch 247 batch 00006: Loss 0.0617 Regression loss 0.0207 Classification loss 0.0409 AP 0.2281 AR 0.4250
Epoch 247 batch 00007: Loss 0.0624 Regression loss 0.0190 Classification loss 0.0433 AP 0.2033 AR 0.3567
Epoch 247 batch 00008: Loss 0.0499 Regression loss 0.0187 Classification loss 0.0312 AP 0.2450 AR 0.5200
Epoch 247 batch 00009: Loss 0.0712 Regression loss 0.0199 Classification loss 0.0513 AP 0.2668 AR 0.6050
Epoch 247 batch 00010: Loss 0.0498 Regression loss 0.0219 Classification loss 0.0279 AP 0.1931 AR 0.3250
Epoch 248 batch 00001: Loss 0.0579 Regression loss 0.0233 Classification loss 0.0346 AP 0.2114 AR 0.4850
Epoch 248 batch 00002: Loss 0.0500 Regression loss 0.0187 Classification loss 0.0313 AP 0.1973 AR 0.4400
Epoch 248 batch 00003: Loss 0.0621 Regression loss 0.0224 Classification loss 0.0397 AP 0.1348 AR 0.3150
Epoch 248 batch 00004: Loss 0.0457 Regression loss 0.0205 Classification loss 0.0253 AP 0.3817 AR 0.6783
Epoch 248 batch 00005: Loss 0.0608 Regression loss 0.0211 Classification loss 0.0397 AP 0.2875 AR 0.5500
Epoch 248 batch 00006: Loss 0.0621 Regression loss 0.0197 Classification loss 0.0424 AP 0.1961 AR 0.5167
Epoch 248 batch 00007: Loss 0.0452 Regression loss 0.0204 Classification loss 0.0248 AP 0.1859 AR 0.4350
Epoch 248 batch 00008: Loss 0.0588 Regression loss 0.0199 Classification loss 0.0388 AP 0.1444 AR 0.2800
Epoch 248 batch 00009: Loss 0.0514 Regression loss 0.0209 Classification loss 0.0305 AP 0.2256 AR 0.5100
Epoch 248 batch 00010: Loss 0.0517 Regression loss 0.0224 Classification loss 0.0293 AP 0.1713 AR 0.3500
Epoch 249 batch 00001: Loss 0.0499 Regression loss 0.0211 Classification loss 0.0288 AP 0.2762 AR 0.4267
Epoch 249 batch 00002: Loss 0.0428 Regression loss 0.0162 Classification loss 0.0266 AP 0.2481 AR 0.5317
Epoch 249 batch 00003: Loss 0.0660 Regression loss 0.0247 Classification loss 0.0412 AP 0.1444 AR 0.3000
Epoch 249 batch 00004: Loss 0.0564 Regression loss 0.0200 Classification loss 0.0364 AP 0.1486 AR 0.3267
Epoch 249 batch 00005: Loss 0.0560 Regression loss 0.0194 Classification loss 0.0366 AP 0.2110 AR 0.4983
Epoch 249 batch 00006: Loss 0.0463 Regression loss 0.0163 Classification loss 0.0300 AP 0.2342 AR 0.4533
Epoch 249 batch 00007: Loss 0.0487 Regression loss 0.0198 Classification loss 0.0288 AP 0.3269 AR 0.6233
Epoch 249 batch 00008: Loss 0.0599 Regression loss 0.0175 Classification loss 0.0424 AP 0.2011 AR 0.4583
Epoch 249 batch 00009: Loss 0.0394 Regression loss 0.0215 Classification loss 0.0179 AP 0.2744 AR 0.4600
Epoch 249 batch 00010: Loss 0.0548 Regression loss 0.0233 Classification loss 0.0315 AP 0.1898 AR 0.3433
Epoch 250 batch 00001: Loss 0.0533 Regression loss 0.0225 Classification loss 0.0309 AP 0.2585 AR 0.4650
Epoch 250 batch 00002: Loss 0.0574 Regression loss 0.0203 Classification loss 0.0371 AP 0.2307 AR 0.4767
Epoch 250 batch 00003: Loss 0.0554 Regression loss 0.0184 Classification loss 0.0370 AP 0.2194 AR 0.4717
Epoch 250 batch 00004: Loss 0.0505 Regression loss 0.0167 Classification loss 0.0338 AP 0.3410 AR 0.6200
Epoch 250 batch 00005: Loss 0.0431 Regression loss 0.0213 Classification loss 0.0218 AP 0.1418 AR 0.2650
Epoch 250 batch 00006: Loss 0.0507 Regression loss 0.0174 Classification loss 0.0333 AP 0.2667 AR 0.5200
Epoch 250 batch 00007: Loss 0.0527 Regression loss 0.0226 Classification loss 0.0300 AP 0.1329 AR 0.2867
Epoch 250 batch 00008: Loss 0.0611 Regression loss 0.0193 Classification loss 0.0418 AP 0.3134 AR 0.6333
Epoch 250 batch 00009: Loss 0.0475 Regression loss 0.0211 Classification loss 0.0265 AP 0.1460 AR 0.2433
Epoch 250 batch 00010: Loss 0.0449 Regression loss 0.0178 Classification loss 0.0271 AP 0.2015 AR 0.4000
Epoch 251 batch 00001: Loss 0.0479 Regression loss 0.0201 Classification loss 0.0278 AP 0.1918 AR 0.3033
Epoch 251 batch 00002: Loss 0.0463 Regression loss 0.0171 Classification loss 0.0292 AP 0.3015 AR 0.4233
Epoch 251 batch 00003: Loss 0.0578 Regression loss 0.0256 Classification loss 0.0322 AP 0.1636 AR 0.4067
Epoch 251 batch 00004: Loss 0.0466 Regression loss 0.0204 Classification loss 0.0262 AP 0.2473 AR 0.6150
Epoch 251 batch 00005: Loss 0.0494 Regression loss 0.0198 Classification loss 0.0296 AP 0.2509 AR 0.5350
Epoch 251 batch 00006: Loss 0.0655 Regression loss 0.0203 Classification loss 0.0451 AP 0.1967 AR 0.4433
Epoch 251 batch 00007: Loss 0.0513 Regression loss 0.0206 Classification loss 0.0307 AP 0.2033 AR 0.3917
Epoch 251 batch 00008: Loss 0.0489 Regression loss 0.0186 Classification loss 0.0303 AP 0.1991 AR 0.3767
Epoch 251 batch 00009: Loss 0.0446 Regression loss 0.0182 Classification loss 0.0264 AP 0.3469 AR 0.6950
Epoch 251 batch 00010: Loss 0.0589 Regression loss 0.0226 Classification loss 0.0364 AP 0.1799 AR 0.3900
Epoch 252 batch 00001: Loss 0.0435 Regression loss 0.0170 Classification loss 0.0265 AP 0.3697 AR 0.5767
Epoch 252 batch 00002: Loss 0.0514 Regression loss 0.0192 Classification loss 0.0322 AP 0.1506 AR 0.2733
Epoch 252 batch 00003: Loss 0.0595 Regression loss 0.0220 Classification loss 0.0375 AP 0.1846 AR 0.3600
Epoch 252 batch 00004: Loss 0.0508 Regression loss 0.0227 Classification loss 0.0282 AP 0.1887 AR 0.4033
Epoch 252 batch 00005: Loss 0.0676 Regression loss 0.0213 Classification loss 0.0463 AP 0.1208 AR 0.2650
Epoch 252 batch 00006: Loss 0.0428 Regression loss 0.0184 Classification loss 0.0244 AP 0.1643 AR 0.3567
Epoch 252 batch 00007: Loss 0.0493 Regression loss 0.0151 Classification loss 0.0341 AP 0.2597 AR 0.6917
Epoch 252 batch 00008: Loss 0.0508 Regression loss 0.0205 Classification loss 0.0303 AP 0.1946 AR 0.4433
Epoch 252 batch 00009: Loss 0.0543 Regression loss 0.0205 Classification loss 0.0338 AP 0.3133 AR 0.5433
Epoch 252 batch 00010: Loss 0.0455 Regression loss 0.0180 Classification loss 0.0275 AP 0.2126 AR 0.3833
Epoch 253 batch 00001: Loss 0.0568 Regression loss 0.0209 Classification loss 0.0359 AP 0.3977 AR 0.5633
Epoch 253 batch 00002: Loss 0.0486 Regression loss 0.0170 Classification loss 0.0316 AP 0.2556 AR 0.5333
Epoch 253 batch 00003: Loss 0.0551 Regression loss 0.0222 Classification loss 0.0329 AP 0.2227 AR 0.5267
Epoch 253 batch 00004: Loss 0.0478 Regression loss 0.0193 Classification loss 0.0285 AP 0.2170 AR 0.5167
Epoch 253 batch 00005: Loss 0.0449 Regression loss 0.0182 Classification loss 0.0267 AP 0.1171 AR 0.2683
Epoch 253 batch 00006: Loss 0.0432 Regression loss 0.0167 Classification loss 0.0265 AP 0.2566 AR 0.5933
Epoch 253 batch 00007: Loss 0.0466 Regression loss 0.0186 Classification loss 0.0280 AP 0.2797 AR 0.5700
Epoch 253 batch 00008: Loss 0.0656 Regression loss 0.0230 Classification loss 0.0427 AP 0.2137 AR 0.4533
Epoch 253 batch 00009: Loss 0.0544 Regression loss 0.0189 Classification loss 0.0355 AP 0.1902 AR 0.3567
Epoch 253 batch 00010: Loss 0.0468 Regression loss 0.0211 Classification loss 0.0257 AP 0.2591 AR 0.4583
Epoch 254 batch 00001: Loss 0.0522 Regression loss 0.0210 Classification loss 0.0311 AP 0.2833 AR 0.5200
Epoch 254 batch 00002: Loss 0.0542 Regression loss 0.0188 Classification loss 0.0355 AP 0.1633 AR 0.2950
Epoch 254 batch 00003: Loss 0.0589 Regression loss 0.0187 Classification loss 0.0401 AP 0.2169 AR 0.4267
Epoch 254 batch 00004: Loss 0.0425 Regression loss 0.0187 Classification loss 0.0238 AP 0.2361 AR 0.5183
Epoch 254 batch 00005: Loss 0.0546 Regression loss 0.0208 Classification loss 0.0338 AP 0.2417 AR 0.3133
Epoch 254 batch 00006: Loss 0.0582 Regression loss 0.0240 Classification loss 0.0341 AP 0.1949 AR 0.3650
Epoch 254 batch 00007: Loss 0.0756 Regression loss 0.0191 Classification loss 0.0565 AP 0.2146 AR 0.4700
Epoch 254 batch 00008: Loss 0.0518 Regression loss 0.0238 Classification loss 0.0281 AP 0.1528 AR 0.3717
Epoch 254 batch 00009: Loss 0.0580 Regression loss 0.0189 Classification loss 0.0391 AP 0.3411 AR 0.5667
Epoch 254 batch 00010: Loss 0.0451 Regression loss 0.0179 Classification loss 0.0271 AP 0.2536 AR 0.3950
Epoch 255 batch 00001: Loss 0.0559 Regression loss 0.0245 Classification loss 0.0314 AP 0.2667 AR 0.4000
Epoch 255 batch 00002: Loss 0.0544 Regression loss 0.0223 Classification loss 0.0321 AP 0.0343 AR 0.1000
Epoch 255 batch 00003: Loss 0.0563 Regression loss 0.0217 Classification loss 0.0346 AP 0.1958 AR 0.3833
Epoch 255 batch 00004: Loss 0.0567 Regression loss 0.0172 Classification loss 0.0395 AP 0.1851 AR 0.3500
Epoch 255 batch 00005: Loss 0.0649 Regression loss 0.0236 Classification loss 0.0413 AP 0.2483 AR 0.5583
Epoch 255 batch 00006: Loss 0.0486 Regression loss 0.0211 Classification loss 0.0275 AP 0.2595 AR 0.5750
Epoch 255 batch 00007: Loss 0.0592 Regression loss 0.0202 Classification loss 0.0390 AP 0.2167 AR 0.4317
Epoch 255 batch 00008: Loss 0.0476 Regression loss 0.0203 Classification loss 0.0273 AP 0.1992 AR 0.4200
Epoch 255 batch 00009: Loss 0.0498 Regression loss 0.0202 Classification loss 0.0297 AP 0.3260 AR 0.5033
Epoch 255 batch 00010: Loss 0.0556 Regression loss 0.0236 Classification loss 0.0320 AP 0.1797 AR 0.3467
Epoch 256 batch 00001: Loss 0.0516 Regression loss 0.0195 Classification loss 0.0321 AP 0.3136 AR 0.7450
Epoch 256 batch 00002: Loss 0.0661 Regression loss 0.0214 Classification loss 0.0446 AP 0.2571 AR 0.3933
Epoch 256 batch 00003: Loss 0.0601 Regression loss 0.0209 Classification loss 0.0392 AP 0.0985 AR 0.1933
Epoch 256 batch 00004: Loss 0.0473 Regression loss 0.0186 Classification loss 0.0287 AP 0.2271 AR 0.3867
Epoch 256 batch 00005: Loss 0.0617 Regression loss 0.0195 Classification loss 0.0422 AP 0.1726 AR 0.3500
Epoch 256 batch 00006: Loss 0.0608 Regression loss 0.0208 Classification loss 0.0400 AP 0.1890 AR 0.3983
Epoch 256 batch 00007: Loss 0.0612 Regression loss 0.0201 Classification loss 0.0411 AP 0.1929 AR 0.4900
Epoch 256 batch 00008: Loss 0.0514 Regression loss 0.0199 Classification loss 0.0316 AP 0.2301 AR 0.4467
Epoch 256 batch 00009: Loss 0.0510 Regression loss 0.0223 Classification loss 0.0287 AP 0.2532 AR 0.5683
Epoch 256 batch 00010: Loss 0.0542 Regression loss 0.0189 Classification loss 0.0353 AP 0.1202 AR 0.2000
Epoch 257 batch 00001: Loss 0.0510 Regression loss 0.0229 Classification loss 0.0282 AP 0.2941 AR 0.5717
Epoch 257 batch 00002: Loss 0.0515 Regression loss 0.0162 Classification loss 0.0353 AP 0.2417 AR 0.4167
Epoch 257 batch 00003: Loss 0.0422 Regression loss 0.0198 Classification loss 0.0224 AP 0.2177 AR 0.4067
Epoch 257 batch 00004: Loss 0.0509 Regression loss 0.0238 Classification loss 0.0271 AP 0.1209 AR 0.2933
Epoch 257 batch 00005: Loss 0.0552 Regression loss 0.0199 Classification loss 0.0353 AP 0.2217 AR 0.4550
Epoch 257 batch 00006: Loss 0.0617 Regression loss 0.0260 Classification loss 0.0357 AP 0.1105 AR 0.2867
Epoch 257 batch 00007: Loss 0.0503 Regression loss 0.0226 Classification loss 0.0277 AP 0.2183 AR 0.4850
Epoch 257 batch 00008: Loss 0.0683 Regression loss 0.0232 Classification loss 0.0451 AP 0.1374 AR 0.2433
Epoch 257 batch 00009: Loss 0.0406 Regression loss 0.0149 Classification loss 0.0257 AP 0.1575 AR 0.2350
Epoch 257 batch 00010: Loss 0.0546 Regression loss 0.0213 Classification loss 0.0333 AP 0.3179 AR 0.6367
Epoch 258 batch 00001: Loss 0.0402 Regression loss 0.0187 Classification loss 0.0215 AP 0.2399 AR 0.5000
Epoch 258 batch 00002: Loss 0.0489 Regression loss 0.0206 Classification loss 0.0283 AP 0.2214 AR 0.3500
Epoch 258 batch 00003: Loss 0.0456 Regression loss 0.0193 Classification loss 0.0263 AP 0.2960 AR 0.4617
Epoch 258 batch 00004: Loss 0.0553 Regression loss 0.0225 Classification loss 0.0327 AP 0.2379 AR 0.4150
Epoch 258 batch 00005: Loss 0.0468 Regression loss 0.0205 Classification loss 0.0263 AP 0.1157 AR 0.2583
Epoch 258 batch 00006: Loss 0.0532 Regression loss 0.0198 Classification loss 0.0334 AP 0.2217 AR 0.3750
Epoch 258 batch 00007: Loss 0.0537 Regression loss 0.0196 Classification loss 0.0341 AP 0.2333 AR 0.5467
Epoch 258 batch 00008: Loss 0.0572 Regression loss 0.0193 Classification loss 0.0379 AP 0.1983 AR 0.4833
Epoch 258 batch 00009: Loss 0.0508 Regression loss 0.0211 Classification loss 0.0296 AP 0.1543 AR 0.3300
Epoch 258 batch 00010: Loss 0.0593 Regression loss 0.0194 Classification loss 0.0399 AP 0.1866 AR 0.3700
Epoch 259 batch 00001: Loss 0.0454 Regression loss 0.0177 Classification loss 0.0277 AP 0.1755 AR 0.4183
Epoch 259 batch 00002: Loss 0.0582 Regression loss 0.0218 Classification loss 0.0364 AP 0.3008 AR 0.5383
Epoch 259 batch 00003: Loss 0.0541 Regression loss 0.0215 Classification loss 0.0326 AP 0.3320 AR 0.5500
Epoch 259 batch 00004: Loss 0.0488 Regression loss 0.0199 Classification loss 0.0288 AP 0.1914 AR 0.3433
Epoch 259 batch 00005: Loss 0.0537 Regression loss 0.0207 Classification loss 0.0330 AP 0.1905 AR 0.3483
Epoch 259 batch 00006: Loss 0.0434 Regression loss 0.0198 Classification loss 0.0236 AP 0.2005 AR 0.4067
Epoch 259 batch 00007: Loss 0.0585 Regression loss 0.0208 Classification loss 0.0377 AP 0.2061 AR 0.3900
Epoch 259 batch 00008: Loss 0.0449 Regression loss 0.0200 Classification loss 0.0249 AP 0.1808 AR 0.4483
Epoch 259 batch 00009: Loss 0.0444 Regression loss 0.0204 Classification loss 0.0240 AP 0.1547 AR 0.3667
Epoch 259 batch 00010: Loss 0.0504 Regression loss 0.0189 Classification loss 0.0315 AP 0.2708 AR 0.3917
Epoch 260 batch 00001: Loss 0.0637 Regression loss 0.0197 Classification loss 0.0440 AP 0.1910 AR 0.3583
Epoch 260 batch 00002: Loss 0.0475 Regression loss 0.0196 Classification loss 0.0279 AP 0.2817 AR 0.5550
Epoch 260 batch 00003: Loss 0.0428 Regression loss 0.0187 Classification loss 0.0241 AP 0.2545 AR 0.4350
Epoch 260 batch 00004: Loss 0.0499 Regression loss 0.0206 Classification loss 0.0293 AP 0.3323 AR 0.6350
Epoch 260 batch 00005: Loss 0.0518 Regression loss 0.0184 Classification loss 0.0334 AP 0.1671 AR 0.3567
Epoch 260 batch 00006: Loss 0.0440 Regression loss 0.0188 Classification loss 0.0252 AP 0.2262 AR 0.4133
Epoch 260 batch 00007: Loss 0.0422 Regression loss 0.0196 Classification loss 0.0226 AP 0.2279 AR 0.5000
Epoch 260 batch 00008: Loss 0.0464 Regression loss 0.0162 Classification loss 0.0302 AP 0.3564 AR 0.7150
Epoch 260 batch 00009: Loss 0.0549 Regression loss 0.0241 Classification loss 0.0308 AP 0.3416 AR 0.5800
Epoch 260 batch 00010: Loss 0.0468 Regression loss 0.0216 Classification loss 0.0252 AP 0.2471 AR 0.5467
Epoch 261 batch 00001: Loss 0.0485 Regression loss 0.0172 Classification loss 0.0313 AP 0.3329 AR 0.4750
Epoch 261 batch 00002: Loss 0.0481 Regression loss 0.0182 Classification loss 0.0299 AP 0.2679 AR 0.5067
Epoch 261 batch 00003: Loss 0.0411 Regression loss 0.0184 Classification loss 0.0226 AP 0.2048 AR 0.4517
Epoch 261 batch 00004: Loss 0.0504 Regression loss 0.0201 Classification loss 0.0303 AP 0.2551 AR 0.3650
Epoch 261 batch 00005: Loss 0.0509 Regression loss 0.0197 Classification loss 0.0312 AP 0.1769 AR 0.3417
Epoch 261 batch 00006: Loss 0.0561 Regression loss 0.0197 Classification loss 0.0364 AP 0.1529 AR 0.3100
Epoch 261 batch 00007: Loss 0.0496 Regression loss 0.0213 Classification loss 0.0283 AP 0.1822 AR 0.3833
Epoch 261 batch 00008: Loss 0.0423 Regression loss 0.0185 Classification loss 0.0237 AP 0.1551 AR 0.3767
Epoch 261 batch 00009: Loss 0.0449 Regression loss 0.0187 Classification loss 0.0263 AP 0.2452 AR 0.3783
Epoch 261 batch 00010: Loss 0.0426 Regression loss 0.0170 Classification loss 0.0257 AP 0.1922 AR 0.3817
Epoch 262 batch 00001: Loss 0.0558 Regression loss 0.0209 Classification loss 0.0349 AP 0.1649 AR 0.3733
Epoch 262 batch 00002: Loss 0.0424 Regression loss 0.0191 Classification loss 0.0233 AP 0.3063 AR 0.5317
Epoch 262 batch 00003: Loss 0.0550 Regression loss 0.0212 Classification loss 0.0338 AP 0.1962 AR 0.3400
Epoch 262 batch 00004: Loss 0.0476 Regression loss 0.0168 Classification loss 0.0308 AP 0.2067 AR 0.4833
Epoch 262 batch 00005: Loss 0.0528 Regression loss 0.0231 Classification loss 0.0297 AP 0.1301 AR 0.2617
Epoch 262 batch 00006: Loss 0.0432 Regression loss 0.0187 Classification loss 0.0245 AP 0.2786 AR 0.5000
Epoch 262 batch 00007: Loss 0.0361 Regression loss 0.0198 Classification loss 0.0163 AP 0.1746 AR 0.4567
Epoch 262 batch 00008: Loss 0.0478 Regression loss 0.0206 Classification loss 0.0273 AP 0.1171 AR 0.3050
Epoch 262 batch 00009: Loss 0.0484 Regression loss 0.0174 Classification loss 0.0309 AP 0.2561 AR 0.4483
Epoch 262 batch 00010: Loss 0.0554 Regression loss 0.0188 Classification loss 0.0366 AP 0.1601 AR 0.3533
Epoch 263 batch 00001: Loss 0.0364 Regression loss 0.0185 Classification loss 0.0180 AP 0.1196 AR 0.2867
Epoch 263 batch 00002: Loss 0.0442 Regression loss 0.0219 Classification loss 0.0223 AP 0.1506 AR 0.3300
Epoch 263 batch 00003: Loss 0.0417 Regression loss 0.0172 Classification loss 0.0245 AP 0.3227 AR 0.6300
Epoch 263 batch 00004: Loss 0.0532 Regression loss 0.0208 Classification loss 0.0324 AP 0.1464 AR 0.3117
Epoch 263 batch 00005: Loss 0.0454 Regression loss 0.0206 Classification loss 0.0248 AP 0.2025 AR 0.4700
Epoch 263 batch 00006: Loss 0.0458 Regression loss 0.0193 Classification loss 0.0265 AP 0.2308 AR 0.4117
Epoch 263 batch 00007: Loss 0.0489 Regression loss 0.0203 Classification loss 0.0286 AP 0.1551 AR 0.2833
Epoch 263 batch 00008: Loss 0.0611 Regression loss 0.0245 Classification loss 0.0365 AP 0.2332 AR 0.4067
Epoch 263 batch 00009: Loss 0.0449 Regression loss 0.0170 Classification loss 0.0278 AP 0.2929 AR 0.6083
Epoch 263 batch 00010: Loss 0.0599 Regression loss 0.0233 Classification loss 0.0366 AP 0.2316 AR 0.5050
Epoch 264 batch 00001: Loss 0.0470 Regression loss 0.0207 Classification loss 0.0264 AP 0.1518 AR 0.3483
Epoch 264 batch 00002: Loss 0.0500 Regression loss 0.0219 Classification loss 0.0282 AP 0.0991 AR 0.2283
Epoch 264 batch 00003: Loss 0.0510 Regression loss 0.0196 Classification loss 0.0314 AP 0.2258 AR 0.3800
Epoch 264 batch 00004: Loss 0.0623 Regression loss 0.0205 Classification loss 0.0418 AP 0.2291 AR 0.4500
Epoch 264 batch 00005: Loss 0.0409 Regression loss 0.0186 Classification loss 0.0223 AP 0.1975 AR 0.4233
Epoch 264 batch 00006: Loss 0.0390 Regression loss 0.0158 Classification loss 0.0232 AP 0.2694 AR 0.5233
Epoch 264 batch 00007: Loss 0.0493 Regression loss 0.0184 Classification loss 0.0309 AP 0.1033 AR 0.2067
Epoch 264 batch 00008: Loss 0.0415 Regression loss 0.0199 Classification loss 0.0216 AP 0.1897 AR 0.5150
Epoch 264 batch 00009: Loss 0.0465 Regression loss 0.0192 Classification loss 0.0273 AP 0.2629 AR 0.4900
Epoch 264 batch 00010: Loss 0.0422 Regression loss 0.0209 Classification loss 0.0213 AP 0.3727 AR 0.5767
Epoch 265 batch 00001: Loss 0.0446 Regression loss 0.0192 Classification loss 0.0255 AP 0.2178 AR 0.4150
Epoch 265 batch 00002: Loss 0.0384 Regression loss 0.0203 Classification loss 0.0181 AP 0.1533 AR 0.3167
Epoch 265 batch 00003: Loss 0.0544 Regression loss 0.0171 Classification loss 0.0373 AP 0.2485 AR 0.5400
Epoch 265 batch 00004: Loss 0.0497 Regression loss 0.0195 Classification loss 0.0302 AP 0.2938 AR 0.4300
Epoch 265 batch 00005: Loss 0.0407 Regression loss 0.0170 Classification loss 0.0237 AP 0.1833 AR 0.4000
Epoch 265 batch 00006: Loss 0.0401 Regression loss 0.0163 Classification loss 0.0238 AP 0.2975 AR 0.5167
Epoch 265 batch 00007: Loss 0.0457 Regression loss 0.0208 Classification loss 0.0249 AP 0.2679 AR 0.5550
Epoch 265 batch 00008: Loss 0.0453 Regression loss 0.0177 Classification loss 0.0275 AP 0.2289 AR 0.3783
Epoch 265 batch 00009: Loss 0.0412 Regression loss 0.0179 Classification loss 0.0233 AP 0.2258 AR 0.5267
Epoch 265 batch 00010: Loss 0.0436 Regression loss 0.0194 Classification loss 0.0241 AP 0.2531 AR 0.5333
Epoch 266 batch 00001: Loss 0.0481 Regression loss 0.0193 Classification loss 0.0289 AP 0.1989 AR 0.3833
Epoch 266 batch 00002: Loss 0.0421 Regression loss 0.0197 Classification loss 0.0225 AP 0.2818 AR 0.5250
Epoch 266 batch 00003: Loss 0.0444 Regression loss 0.0180 Classification loss 0.0264 AP 0.1803 AR 0.3900
Epoch 266 batch 00004: Loss 0.0440 Regression loss 0.0179 Classification loss 0.0262 AP 0.1850 AR 0.3033
Epoch 266 batch 00005: Loss 0.0423 Regression loss 0.0203 Classification loss 0.0220 AP 0.2365 AR 0.4650
Epoch 266 batch 00006: Loss 0.0404 Regression loss 0.0188 Classification loss 0.0216 AP 0.2348 AR 0.4817
Epoch 266 batch 00007: Loss 0.0430 Regression loss 0.0197 Classification loss 0.0234 AP 0.1723 AR 0.4167
Epoch 266 batch 00008: Loss 0.0448 Regression loss 0.0165 Classification loss 0.0283 AP 0.3782 AR 0.4983
Epoch 266 batch 00009: Loss 0.0468 Regression loss 0.0185 Classification loss 0.0283 AP 0.1757 AR 0.3517
Epoch 266 batch 00010: Loss 0.0539 Regression loss 0.0203 Classification loss 0.0336 AP 0.1544 AR 0.3667
Epoch 267 batch 00001: Loss 0.0550 Regression loss 0.0209 Classification loss 0.0341 AP 0.1577 AR 0.3500
Epoch 267 batch 00002: Loss 0.0393 Regression loss 0.0190 Classification loss 0.0204 AP 0.2106 AR 0.5583
Epoch 267 batch 00003: Loss 0.0454 Regression loss 0.0211 Classification loss 0.0243 AP 0.2019 AR 0.4150
Epoch 267 batch 00004: Loss 0.0493 Regression loss 0.0198 Classification loss 0.0295 AP 0.2389 AR 0.5183
Epoch 267 batch 00005: Loss 0.0553 Regression loss 0.0209 Classification loss 0.0344 AP 0.2095 AR 0.3950
Epoch 267 batch 00006: Loss 0.0462 Regression loss 0.0219 Classification loss 0.0243 AP 0.3237 AR 0.5750
Epoch 267 batch 00007: Loss 0.0364 Regression loss 0.0181 Classification loss 0.0183 AP 0.3890 AR 0.6950
Epoch 267 batch 00008: Loss 0.0449 Regression loss 0.0202 Classification loss 0.0247 AP 0.2267 AR 0.4567
Epoch 267 batch 00009: Loss 0.0417 Regression loss 0.0178 Classification loss 0.0239 AP 0.3288 AR 0.5300
Epoch 267 batch 00010: Loss 0.0385 Regression loss 0.0173 Classification loss 0.0212 AP 0.2152 AR 0.4233
Epoch 268 batch 00001: Loss 0.0466 Regression loss 0.0252 Classification loss 0.0214 AP 0.1217 AR 0.3167
Epoch 268 batch 00002: Loss 0.0398 Regression loss 0.0192 Classification loss 0.0206 AP 0.2961 AR 0.4667
Epoch 268 batch 00003: Loss 0.0464 Regression loss 0.0201 Classification loss 0.0263 AP 0.2298 AR 0.4750
Epoch 268 batch 00004: Loss 0.0564 Regression loss 0.0196 Classification loss 0.0368 AP 0.1973 AR 0.3683
Epoch 268 batch 00005: Loss 0.0499 Regression loss 0.0252 Classification loss 0.0247 AP 0.2389 AR 0.5450
Epoch 268 batch 00006: Loss 0.0440 Regression loss 0.0217 Classification loss 0.0224 AP 0.3010 AR 0.5367
Epoch 268 batch 00007: Loss 0.0394 Regression loss 0.0167 Classification loss 0.0227 AP 0.1536 AR 0.3250
Epoch 268 batch 00008: Loss 0.0437 Regression loss 0.0179 Classification loss 0.0258 AP 0.1776 AR 0.3317
Epoch 268 batch 00009: Loss 0.0453 Regression loss 0.0171 Classification loss 0.0282 AP 0.1860 AR 0.3900
Epoch 268 batch 00010: Loss 0.0468 Regression loss 0.0215 Classification loss 0.0252 AP 0.0877 AR 0.1200
Epoch 269 batch 00001: Loss 0.0489 Regression loss 0.0196 Classification loss 0.0293 AP 0.2137 AR 0.3750
Epoch 269 batch 00002: Loss 0.0406 Regression loss 0.0190 Classification loss 0.0215 AP 0.2352 AR 0.4600
Epoch 269 batch 00003: Loss 0.0555 Regression loss 0.0227 Classification loss 0.0328 AP 0.1732 AR 0.3267
Epoch 269 batch 00004: Loss 0.0407 Regression loss 0.0170 Classification loss 0.0237 AP 0.1600 AR 0.3150
Epoch 269 batch 00005: Loss 0.0572 Regression loss 0.0221 Classification loss 0.0351 AP 0.2498 AR 0.4950
Epoch 269 batch 00006: Loss 0.0423 Regression loss 0.0200 Classification loss 0.0223 AP 0.2352 AR 0.5117
Epoch 269 batch 00007: Loss 0.0412 Regression loss 0.0188 Classification loss 0.0223 AP 0.1401 AR 0.3333
Epoch 269 batch 00008: Loss 0.0377 Regression loss 0.0175 Classification loss 0.0202 AP 0.3012 AR 0.5117
Epoch 269 batch 00009: Loss 0.0463 Regression loss 0.0180 Classification loss 0.0284 AP 0.2535 AR 0.5117
Epoch 269 batch 00010: Loss 0.0513 Regression loss 0.0191 Classification loss 0.0322 AP 0.1513 AR 0.3433
Epoch 270 batch 00001: Loss 0.0467 Regression loss 0.0170 Classification loss 0.0297 AP 0.1643 AR 0.3533
Epoch 270 batch 00002: Loss 0.0444 Regression loss 0.0178 Classification loss 0.0266 AP 0.1861 AR 0.5133
Epoch 270 batch 00003: Loss 0.0418 Regression loss 0.0199 Classification loss 0.0219 AP 0.2094 AR 0.4550
Epoch 270 batch 00004: Loss 0.0502 Regression loss 0.0199 Classification loss 0.0303 AP 0.2406 AR 0.4450
Epoch 270 batch 00005: Loss 0.0500 Regression loss 0.0205 Classification loss 0.0295 AP 0.1853 AR 0.4150
Epoch 270 batch 00006: Loss 0.0443 Regression loss 0.0216 Classification loss 0.0227 AP 0.2935 AR 0.4683
Epoch 270 batch 00007: Loss 0.0445 Regression loss 0.0175 Classification loss 0.0271 AP 0.2625 AR 0.4733
Epoch 270 batch 00008: Loss 0.0378 Regression loss 0.0186 Classification loss 0.0193 AP 0.3427 AR 0.5550
Epoch 270 batch 00009: Loss 0.0514 Regression loss 0.0229 Classification loss 0.0285 AP 0.2734 AR 0.4983
Epoch 270 batch 00010: Loss 0.0532 Regression loss 0.0207 Classification loss 0.0326 AP 0.2669 AR 0.6600
Epoch 271 batch 00001: Loss 0.0413 Regression loss 0.0198 Classification loss 0.0215 AP 0.1525 AR 0.3250
Epoch 271 batch 00002: Loss 0.0385 Regression loss 0.0198 Classification loss 0.0187 AP 0.2049 AR 0.3950
Epoch 271 batch 00003: Loss 0.0558 Regression loss 0.0232 Classification loss 0.0327 AP 0.2544 AR 0.3883
Epoch 271 batch 00004: Loss 0.0440 Regression loss 0.0199 Classification loss 0.0241 AP 0.2155 AR 0.4000
Epoch 271 batch 00005: Loss 0.0576 Regression loss 0.0212 Classification loss 0.0365 AP 0.2209 AR 0.4233
Epoch 271 batch 00006: Loss 0.0329 Regression loss 0.0187 Classification loss 0.0142 AP 0.4192 AR 0.8467
Epoch 271 batch 00007: Loss 0.0451 Regression loss 0.0220 Classification loss 0.0231 AP 0.1540 AR 0.3217
Epoch 271 batch 00008: Loss 0.0501 Regression loss 0.0181 Classification loss 0.0320 AP 0.2217 AR 0.5650
Epoch 271 batch 00009: Loss 0.0406 Regression loss 0.0158 Classification loss 0.0248 AP 0.2771 AR 0.4450
Epoch 271 batch 00010: Loss 0.0487 Regression loss 0.0186 Classification loss 0.0300 AP 0.2383 AR 0.4550
Epoch 272 batch 00001: Loss 0.0459 Regression loss 0.0219 Classification loss 0.0241 AP 0.2490 AR 0.5567
Epoch 272 batch 00002: Loss 0.0364 Regression loss 0.0149 Classification loss 0.0215 AP 0.3117 AR 0.3833
Epoch 272 batch 00003: Loss 0.0409 Regression loss 0.0202 Classification loss 0.0207 AP 0.3138 AR 0.5117
Epoch 272 batch 00004: Loss 0.0422 Regression loss 0.0162 Classification loss 0.0260 AP 0.3414 AR 0.6383
Epoch 272 batch 00005: Loss 0.0435 Regression loss 0.0175 Classification loss 0.0260 AP 0.2536 AR 0.4917
Epoch 272 batch 00006: Loss 0.0531 Regression loss 0.0189 Classification loss 0.0342 AP 0.2788 AR 0.5550
Epoch 272 batch 00007: Loss 0.0372 Regression loss 0.0177 Classification loss 0.0195 AP 0.3046 AR 0.4667
Epoch 272 batch 00008: Loss 0.0402 Regression loss 0.0215 Classification loss 0.0187 AP 0.0779 AR 0.1833
Epoch 272 batch 00009: Loss 0.0439 Regression loss 0.0161 Classification loss 0.0278 AP 0.1956 AR 0.4500
Epoch 272 batch 00010: Loss 0.0452 Regression loss 0.0208 Classification loss 0.0245 AP 0.2284 AR 0.4983
Epoch 273 batch 00001: Loss 0.0420 Regression loss 0.0175 Classification loss 0.0246 AP 0.2660 AR 0.6617
Epoch 273 batch 00002: Loss 0.0415 Regression loss 0.0189 Classification loss 0.0226 AP 0.3914 AR 0.5583
Epoch 273 batch 00003: Loss 0.0370 Regression loss 0.0175 Classification loss 0.0195 AP 0.2794 AR 0.5983
Epoch 273 batch 00004: Loss 0.0556 Regression loss 0.0184 Classification loss 0.0372 AP 0.2637 AR 0.5250
Epoch 273 batch 00005: Loss 0.0464 Regression loss 0.0195 Classification loss 0.0269 AP 0.2196 AR 0.4100
Epoch 273 batch 00006: Loss 0.0360 Regression loss 0.0166 Classification loss 0.0194 AP 0.3829 AR 0.6417
Epoch 273 batch 00007: Loss 0.0462 Regression loss 0.0179 Classification loss 0.0282 AP 0.2508 AR 0.5667
Epoch 273 batch 00008: Loss 0.0424 Regression loss 0.0218 Classification loss 0.0206 AP 0.2745 AR 0.5433
Epoch 273 batch 00009: Loss 0.0401 Regression loss 0.0188 Classification loss 0.0214 AP 0.1591 AR 0.3983
Epoch 273 batch 00010: Loss 0.0431 Regression loss 0.0197 Classification loss 0.0235 AP 0.3696 AR 0.5167
Epoch 274 batch 00001: Loss 0.0431 Regression loss 0.0171 Classification loss 0.0260 AP 0.2712 AR 0.4900
Epoch 274 batch 00002: Loss 0.0455 Regression loss 0.0162 Classification loss 0.0293 AP 0.2036 AR 0.4083
Epoch 274 batch 00003: Loss 0.0433 Regression loss 0.0206 Classification loss 0.0227 AP 0.1883 AR 0.5200
Epoch 274 batch 00004: Loss 0.0416 Regression loss 0.0211 Classification loss 0.0205 AP 0.2680 AR 0.4833
Epoch 274 batch 00005: Loss 0.0505 Regression loss 0.0211 Classification loss 0.0294 AP 0.2053 AR 0.4433
Epoch 274 batch 00006: Loss 0.0373 Regression loss 0.0149 Classification loss 0.0223 AP 0.2890 AR 0.5950
Epoch 274 batch 00007: Loss 0.0396 Regression loss 0.0178 Classification loss 0.0218 AP 0.2279 AR 0.4500
Epoch 274 batch 00008: Loss 0.0364 Regression loss 0.0184 Classification loss 0.0180 AP 0.3215 AR 0.4500
Epoch 274 batch 00009: Loss 0.0408 Regression loss 0.0188 Classification loss 0.0221 AP 0.2394 AR 0.4167
Epoch 274 batch 00010: Loss 0.0376 Regression loss 0.0180 Classification loss 0.0195 AP 0.1850 AR 0.3433
Epoch 275 batch 00001: Loss 0.0415 Regression loss 0.0176 Classification loss 0.0239 AP 0.3874 AR 0.5783
Epoch 275 batch 00002: Loss 0.0405 Regression loss 0.0183 Classification loss 0.0222 AP 0.1927 AR 0.4633
Epoch 275 batch 00003: Loss 0.0351 Regression loss 0.0171 Classification loss 0.0179 AP 0.2469 AR 0.4583
Epoch 275 batch 00004: Loss 0.0445 Regression loss 0.0206 Classification loss 0.0239 AP 0.2858 AR 0.5117
Epoch 275 batch 00005: Loss 0.0485 Regression loss 0.0184 Classification loss 0.0301 AP 0.2437 AR 0.4650
Epoch 275 batch 00006: Loss 0.0457 Regression loss 0.0177 Classification loss 0.0280 AP 0.3156 AR 0.4250
Epoch 275 batch 00007: Loss 0.0387 Regression loss 0.0177 Classification loss 0.0210 AP 0.2385 AR 0.3917
Epoch 275 batch 00008: Loss 0.0439 Regression loss 0.0195 Classification loss 0.0244 AP 0.1743 AR 0.4217
Epoch 275 batch 00009: Loss 0.0442 Regression loss 0.0163 Classification loss 0.0279 AP 0.2233 AR 0.5000
Epoch 275 batch 00010: Loss 0.0416 Regression loss 0.0211 Classification loss 0.0205 AP 0.2347 AR 0.5500
Epoch 276 batch 00001: Loss 0.0396 Regression loss 0.0194 Classification loss 0.0201 AP 0.1504 AR 0.3583
Epoch 276 batch 00002: Loss 0.0322 Regression loss 0.0171 Classification loss 0.0152 AP 0.1940 AR 0.4100
Epoch 276 batch 00003: Loss 0.0377 Regression loss 0.0157 Classification loss 0.0220 AP 0.3367 AR 0.6083
Epoch 276 batch 00004: Loss 0.0513 Regression loss 0.0205 Classification loss 0.0308 AP 0.2847 AR 0.4350
Epoch 276 batch 00005: Loss 0.0490 Regression loss 0.0203 Classification loss 0.0287 AP 0.2043 AR 0.4500
Epoch 276 batch 00006: Loss 0.0408 Regression loss 0.0175 Classification loss 0.0233 AP 0.2271 AR 0.5050
Epoch 276 batch 00007: Loss 0.0419 Regression loss 0.0182 Classification loss 0.0237 AP 0.2067 AR 0.4033
Epoch 276 batch 00008: Loss 0.0412 Regression loss 0.0168 Classification loss 0.0244 AP 0.3006 AR 0.5633
Epoch 276 batch 00009: Loss 0.0552 Regression loss 0.0192 Classification loss 0.0361 AP 0.1962 AR 0.4500
Epoch 276 batch 00010: Loss 0.0458 Regression loss 0.0170 Classification loss 0.0288 AP 0.2619 AR 0.5667
Epoch 277 batch 00001: Loss 0.0358 Regression loss 0.0171 Classification loss 0.0187 AP 0.1906 AR 0.3400
Epoch 277 batch 00002: Loss 0.0551 Regression loss 0.0218 Classification loss 0.0333 AP 0.3737 AR 0.6333
Epoch 277 batch 00003: Loss 0.0551 Regression loss 0.0199 Classification loss 0.0352 AP 0.2701 AR 0.5750
Epoch 277 batch 00004: Loss 0.0444 Regression loss 0.0177 Classification loss 0.0267 AP 0.2711 AR 0.5517
Epoch 277 batch 00005: Loss 0.0414 Regression loss 0.0197 Classification loss 0.0217 AP 0.2650 AR 0.5250
Epoch 277 batch 00006: Loss 0.0354 Regression loss 0.0147 Classification loss 0.0207 AP 0.2263 AR 0.5667
Epoch 277 batch 00007: Loss 0.0501 Regression loss 0.0189 Classification loss 0.0312 AP 0.1740 AR 0.3900
Epoch 277 batch 00008: Loss 0.0409 Regression loss 0.0168 Classification loss 0.0242 AP 0.1557 AR 0.3183
Epoch 277 batch 00009: Loss 0.0481 Regression loss 0.0226 Classification loss 0.0254 AP 0.2761 AR 0.5333
Epoch 277 batch 00010: Loss 0.0457 Regression loss 0.0179 Classification loss 0.0278 AP 0.3432 AR 0.6100
Epoch 278 batch 00001: Loss 0.0390 Regression loss 0.0169 Classification loss 0.0221 AP 0.2641 AR 0.5833
Epoch 278 batch 00002: Loss 0.0456 Regression loss 0.0196 Classification loss 0.0260 AP 0.2306 AR 0.5333
Epoch 278 batch 00003: Loss 0.0439 Regression loss 0.0218 Classification loss 0.0221 AP 0.1725 AR 0.3717
Epoch 278 batch 00004: Loss 0.0393 Regression loss 0.0191 Classification loss 0.0202 AP 0.2459 AR 0.4667
Epoch 278 batch 00005: Loss 0.0392 Regression loss 0.0199 Classification loss 0.0193 AP 0.2166 AR 0.4917
Epoch 278 batch 00006: Loss 0.0482 Regression loss 0.0225 Classification loss 0.0257 AP 0.1748 AR 0.3850
Epoch 278 batch 00007: Loss 0.0453 Regression loss 0.0201 Classification loss 0.0252 AP 0.2693 AR 0.4983
Epoch 278 batch 00008: Loss 0.0534 Regression loss 0.0193 Classification loss 0.0341 AP 0.1610 AR 0.3333
Epoch 278 batch 00009: Loss 0.0432 Regression loss 0.0203 Classification loss 0.0229 AP 0.3133 AR 0.5867
Epoch 278 batch 00010: Loss 0.0419 Regression loss 0.0164 Classification loss 0.0255 AP 0.4542 AR 0.7150
Epoch 279 batch 00001: Loss 0.0467 Regression loss 0.0172 Classification loss 0.0295 AP 0.1910 AR 0.5083
Epoch 279 batch 00002: Loss 0.0441 Regression loss 0.0189 Classification loss 0.0252 AP 0.2015 AR 0.3933
Epoch 279 batch 00003: Loss 0.0566 Regression loss 0.0202 Classification loss 0.0365 AP 0.2438 AR 0.3583
Epoch 279 batch 00004: Loss 0.0469 Regression loss 0.0181 Classification loss 0.0288 AP 0.2303 AR 0.4667
Epoch 279 batch 00005: Loss 0.0393 Regression loss 0.0155 Classification loss 0.0238 AP 0.2308 AR 0.5000
Epoch 279 batch 00006: Loss 0.0421 Regression loss 0.0192 Classification loss 0.0229 AP 0.2028 AR 0.3750
Epoch 279 batch 00007: Loss 0.0426 Regression loss 0.0233 Classification loss 0.0194 AP 0.2844 AR 0.6200
Epoch 279 batch 00008: Loss 0.0414 Regression loss 0.0203 Classification loss 0.0210 AP 0.2218 AR 0.3867
Epoch 279 batch 00009: Loss 0.0476 Regression loss 0.0232 Classification loss 0.0244 AP 0.2147 AR 0.5017
Epoch 279 batch 00010: Loss 0.0433 Regression loss 0.0195 Classification loss 0.0237 AP 0.3150 AR 0.5300
Epoch 280 batch 00001: Loss 0.0357 Regression loss 0.0174 Classification loss 0.0183 AP 0.3118 AR 0.6233
Epoch 280 batch 00002: Loss 0.0315 Regression loss 0.0174 Classification loss 0.0141 AP 0.3352 AR 0.5917
Epoch 280 batch 00003: Loss 0.0401 Regression loss 0.0178 Classification loss 0.0222 AP 0.2718 AR 0.4700
Epoch 280 batch 00004: Loss 0.0448 Regression loss 0.0196 Classification loss 0.0252 AP 0.3391 AR 0.4800
Epoch 280 batch 00005: Loss 0.0502 Regression loss 0.0218 Classification loss 0.0283 AP 0.2620 AR 0.4483
Epoch 280 batch 00006: Loss 0.0367 Regression loss 0.0180 Classification loss 0.0186 AP 0.1786 AR 0.3767
Epoch 280 batch 00007: Loss 0.0390 Regression loss 0.0169 Classification loss 0.0221 AP 0.2663 AR 0.5850
Epoch 280 batch 00008: Loss 0.0365 Regression loss 0.0193 Classification loss 0.0172 AP 0.2764 AR 0.5150
Epoch 280 batch 00009: Loss 0.0468 Regression loss 0.0184 Classification loss 0.0284 AP 0.2379 AR 0.5150
Epoch 280 batch 00010: Loss 0.0490 Regression loss 0.0166 Classification loss 0.0324 AP 0.2920 AR 0.5700
Epoch 281 batch 00001: Loss 0.0335 Regression loss 0.0167 Classification loss 0.0167 AP 0.2815 AR 0.6117
Epoch 281 batch 00002: Loss 0.0462 Regression loss 0.0176 Classification loss 0.0286 AP 0.1964 AR 0.4650
Epoch 281 batch 00003: Loss 0.0375 Regression loss 0.0160 Classification loss 0.0215 AP 0.2519 AR 0.4967
Epoch 281 batch 00004: Loss 0.0452 Regression loss 0.0183 Classification loss 0.0269 AP 0.2141 AR 0.4183
Epoch 281 batch 00005: Loss 0.0395 Regression loss 0.0167 Classification loss 0.0228 AP 0.1873 AR 0.4633
Epoch 281 batch 00006: Loss 0.0359 Regression loss 0.0190 Classification loss 0.0170 AP 0.2889 AR 0.6583
Epoch 281 batch 00007: Loss 0.0405 Regression loss 0.0180 Classification loss 0.0225 AP 0.3056 AR 0.4600
Epoch 281 batch 00008: Loss 0.0393 Regression loss 0.0165 Classification loss 0.0228 AP 0.3883 AR 0.7083
Epoch 281 batch 00009: Loss 0.0386 Regression loss 0.0178 Classification loss 0.0208 AP 0.2812 AR 0.4900
Epoch 281 batch 00010: Loss 0.0439 Regression loss 0.0172 Classification loss 0.0267 AP 0.1182 AR 0.2400
Epoch 282 batch 00001: Loss 0.0399 Regression loss 0.0182 Classification loss 0.0217 AP 0.2218 AR 0.3933
Epoch 282 batch 00002: Loss 0.0440 Regression loss 0.0193 Classification loss 0.0247 AP 0.3500 AR 0.7400
Epoch 282 batch 00003: Loss 0.0362 Regression loss 0.0183 Classification loss 0.0179 AP 0.2639 AR 0.6600
Epoch 282 batch 00004: Loss 0.0403 Regression loss 0.0159 Classification loss 0.0244 AP 0.2783 AR 0.5650
Epoch 282 batch 00005: Loss 0.0461 Regression loss 0.0151 Classification loss 0.0311 AP 0.2879 AR 0.4817
Epoch 282 batch 00006: Loss 0.0336 Regression loss 0.0146 Classification loss 0.0190 AP 0.3607 AR 0.6017
Epoch 282 batch 00007: Loss 0.0374 Regression loss 0.0165 Classification loss 0.0209 AP 0.3044 AR 0.6000
Epoch 282 batch 00008: Loss 0.0450 Regression loss 0.0191 Classification loss 0.0258 AP 0.2917 AR 0.5133
Epoch 282 batch 00009: Loss 0.0377 Regression loss 0.0157 Classification loss 0.0220 AP 0.3079 AR 0.6750
Epoch 282 batch 00010: Loss 0.0415 Regression loss 0.0234 Classification loss 0.0181 AP 0.1444 AR 0.2583
Epoch 283 batch 00001: Loss 0.0362 Regression loss 0.0156 Classification loss 0.0206 AP 0.2481 AR 0.5600
Epoch 283 batch 00002: Loss 0.0350 Regression loss 0.0135 Classification loss 0.0216 AP 0.3594 AR 0.6967
Epoch 283 batch 00003: Loss 0.0370 Regression loss 0.0162 Classification loss 0.0208 AP 0.2352 AR 0.4483
Epoch 283 batch 00004: Loss 0.0336 Regression loss 0.0165 Classification loss 0.0171 AP 0.3146 AR 0.5883
Epoch 283 batch 00005: Loss 0.0422 Regression loss 0.0190 Classification loss 0.0231 AP 0.2231 AR 0.3733
Epoch 283 batch 00006: Loss 0.0425 Regression loss 0.0170 Classification loss 0.0255 AP 0.1902 AR 0.4833
Epoch 283 batch 00007: Loss 0.0377 Regression loss 0.0155 Classification loss 0.0222 AP 0.2911 AR 0.5900
Epoch 283 batch 00008: Loss 0.0403 Regression loss 0.0218 Classification loss 0.0185 AP 0.3243 AR 0.5983
Epoch 283 batch 00009: Loss 0.0552 Regression loss 0.0174 Classification loss 0.0378 AP 0.2319 AR 0.5300
Epoch 283 batch 00010: Loss 0.0429 Regression loss 0.0192 Classification loss 0.0236 AP 0.1371 AR 0.2650
Epoch 284 batch 00001: Loss 0.0335 Regression loss 0.0161 Classification loss 0.0174 AP 0.1772 AR 0.3100
Epoch 284 batch 00002: Loss 0.0390 Regression loss 0.0158 Classification loss 0.0232 AP 0.2355 AR 0.4317
Epoch 284 batch 00003: Loss 0.0519 Regression loss 0.0185 Classification loss 0.0334 AP 0.1875 AR 0.3683
Epoch 284 batch 00004: Loss 0.0401 Regression loss 0.0185 Classification loss 0.0216 AP 0.2344 AR 0.4833
Epoch 284 batch 00005: Loss 0.0351 Regression loss 0.0178 Classification loss 0.0173 AP 0.1900 AR 0.3933
Epoch 284 batch 00006: Loss 0.0300 Regression loss 0.0185 Classification loss 0.0114 AP 0.3133 AR 0.6333
Epoch 284 batch 00007: Loss 0.0382 Regression loss 0.0160 Classification loss 0.0222 AP 0.3058 AR 0.5933
Epoch 284 batch 00008: Loss 0.0338 Regression loss 0.0164 Classification loss 0.0173 AP 0.2069 AR 0.3433
Epoch 284 batch 00009: Loss 0.0313 Regression loss 0.0178 Classification loss 0.0134 AP 0.3307 AR 0.5750
Epoch 284 batch 00010: Loss 0.0498 Regression loss 0.0178 Classification loss 0.0319 AP 0.2765 AR 0.5033
Epoch 285 batch 00001: Loss 0.0378 Regression loss 0.0166 Classification loss 0.0211 AP 0.2729 AR 0.3800
Epoch 285 batch 00002: Loss 0.0333 Regression loss 0.0152 Classification loss 0.0180 AP 0.4030 AR 0.6900
Epoch 285 batch 00003: Loss 0.0387 Regression loss 0.0152 Classification loss 0.0236 AP 0.2483 AR 0.5083
Epoch 285 batch 00004: Loss 0.0404 Regression loss 0.0176 Classification loss 0.0228 AP 0.2338 AR 0.4333
Epoch 285 batch 00005: Loss 0.0303 Regression loss 0.0143 Classification loss 0.0160 AP 0.2116 AR 0.5083
Epoch 285 batch 00006: Loss 0.0396 Regression loss 0.0173 Classification loss 0.0223 AP 0.2647 AR 0.5500
Epoch 285 batch 00007: Loss 0.0379 Regression loss 0.0177 Classification loss 0.0202 AP 0.3208 AR 0.5650
Epoch 285 batch 00008: Loss 0.0404 Regression loss 0.0204 Classification loss 0.0200 AP 0.1878 AR 0.5033
Epoch 285 batch 00009: Loss 0.0378 Regression loss 0.0186 Classification loss 0.0192 AP 0.3131 AR 0.6133
Epoch 285 batch 00010: Loss 0.0428 Regression loss 0.0185 Classification loss 0.0243 AP 0.1855 AR 0.4050
Epoch 286 batch 00001: Loss 0.0415 Regression loss 0.0185 Classification loss 0.0230 AP 0.2015 AR 0.3733
Epoch 286 batch 00002: Loss 0.0335 Regression loss 0.0186 Classification loss 0.0149 AP 0.2404 AR 0.4367
Epoch 286 batch 00003: Loss 0.0420 Regression loss 0.0192 Classification loss 0.0228 AP 0.3627 AR 0.6567
Epoch 286 batch 00004: Loss 0.0367 Regression loss 0.0180 Classification loss 0.0186 AP 0.2286 AR 0.5333
Epoch 286 batch 00005: Loss 0.0365 Regression loss 0.0134 Classification loss 0.0231 AP 0.2530 AR 0.5400
Epoch 286 batch 00006: Loss 0.0356 Regression loss 0.0167 Classification loss 0.0189 AP 0.2821 AR 0.6333
Epoch 286 batch 00007: Loss 0.0415 Regression loss 0.0203 Classification loss 0.0212 AP 0.1682 AR 0.3600
Epoch 286 batch 00008: Loss 0.0392 Regression loss 0.0188 Classification loss 0.0204 AP 0.2021 AR 0.3767
Epoch 286 batch 00009: Loss 0.0379 Regression loss 0.0162 Classification loss 0.0217 AP 0.3698 AR 0.6350
Epoch 286 batch 00010: Loss 0.0416 Regression loss 0.0181 Classification loss 0.0235 AP 0.2276 AR 0.4017
Epoch 287 batch 00001: Loss 0.0419 Regression loss 0.0219 Classification loss 0.0200 AP 0.1882 AR 0.4400
Epoch 287 batch 00002: Loss 0.0317 Regression loss 0.0147 Classification loss 0.0170 AP 0.1958 AR 0.4083
Epoch 287 batch 00003: Loss 0.0334 Regression loss 0.0166 Classification loss 0.0168 AP 0.4228 AR 0.7083
Epoch 287 batch 00004: Loss 0.0429 Regression loss 0.0172 Classification loss 0.0258 AP 0.1815 AR 0.4150
Epoch 287 batch 00005: Loss 0.0433 Regression loss 0.0182 Classification loss 0.0251 AP 0.3075 AR 0.6733
Epoch 287 batch 00006: Loss 0.0413 Regression loss 0.0218 Classification loss 0.0196 AP 0.1778 AR 0.4067
Epoch 287 batch 00007: Loss 0.0384 Regression loss 0.0167 Classification loss 0.0218 AP 0.2344 AR 0.4400
Epoch 287 batch 00008: Loss 0.0358 Regression loss 0.0163 Classification loss 0.0195 AP 0.2124 AR 0.4167
Epoch 287 batch 00009: Loss 0.0430 Regression loss 0.0192 Classification loss 0.0239 AP 0.2341 AR 0.5033
Epoch 287 batch 00010: Loss 0.0336 Regression loss 0.0153 Classification loss 0.0183 AP 0.2328 AR 0.4667
Epoch 288 batch 00001: Loss 0.0311 Regression loss 0.0165 Classification loss 0.0146 AP 0.2337 AR 0.4967
Epoch 288 batch 00002: Loss 0.0496 Regression loss 0.0196 Classification loss 0.0300 AP 0.2015 AR 0.3983
Epoch 288 batch 00003: Loss 0.0369 Regression loss 0.0190 Classification loss 0.0179 AP 0.2628 AR 0.4733
Epoch 288 batch 00004: Loss 0.0420 Regression loss 0.0182 Classification loss 0.0238 AP 0.1866 AR 0.3317
Epoch 288 batch 00005: Loss 0.0395 Regression loss 0.0163 Classification loss 0.0232 AP 0.2540 AR 0.4650
Epoch 288 batch 00006: Loss 0.0314 Regression loss 0.0161 Classification loss 0.0153 AP 0.4283 AR 0.7917
Epoch 288 batch 00007: Loss 0.0410 Regression loss 0.0146 Classification loss 0.0264 AP 0.2094 AR 0.5483
Epoch 288 batch 00008: Loss 0.0409 Regression loss 0.0199 Classification loss 0.0210 AP 0.2612 AR 0.5233
Epoch 288 batch 00009: Loss 0.0373 Regression loss 0.0188 Classification loss 0.0185 AP 0.2073 AR 0.4867
Epoch 288 batch 00010: Loss 0.0410 Regression loss 0.0176 Classification loss 0.0233 AP 0.3627 AR 0.6100
Epoch 289 batch 00001: Loss 0.0337 Regression loss 0.0162 Classification loss 0.0174 AP 0.3203 AR 0.4750
Epoch 289 batch 00002: Loss 0.0350 Regression loss 0.0180 Classification loss 0.0169 AP 0.2418 AR 0.5267
Epoch 289 batch 00003: Loss 0.0502 Regression loss 0.0186 Classification loss 0.0316 AP 0.2321 AR 0.3500
Epoch 289 batch 00004: Loss 0.0487 Regression loss 0.0182 Classification loss 0.0304 AP 0.2579 AR 0.4933
Epoch 289 batch 00005: Loss 0.0323 Regression loss 0.0146 Classification loss 0.0177 AP 0.2397 AR 0.4617
Epoch 289 batch 00006: Loss 0.0414 Regression loss 0.0173 Classification loss 0.0241 AP 0.2262 AR 0.5617
Epoch 289 batch 00007: Loss 0.0367 Regression loss 0.0154 Classification loss 0.0213 AP 0.1889 AR 0.4167
Epoch 289 batch 00008: Loss 0.0435 Regression loss 0.0170 Classification loss 0.0266 AP 0.3219 AR 0.5833
Epoch 289 batch 00009: Loss 0.0355 Regression loss 0.0165 Classification loss 0.0190 AP 0.3748 AR 0.6667
Epoch 289 batch 00010: Loss 0.0343 Regression loss 0.0183 Classification loss 0.0160 AP 0.2202 AR 0.4483
Epoch 290 batch 00001: Loss 0.0365 Regression loss 0.0194 Classification loss 0.0170 AP 0.1760 AR 0.3583
Epoch 290 batch 00002: Loss 0.0323 Regression loss 0.0143 Classification loss 0.0181 AP 0.3450 AR 0.5333
Epoch 290 batch 00003: Loss 0.0498 Regression loss 0.0197 Classification loss 0.0302 AP 0.2767 AR 0.5217
Epoch 290 batch 00004: Loss 0.0359 Regression loss 0.0159 Classification loss 0.0200 AP 0.2081 AR 0.3850
Epoch 290 batch 00005: Loss 0.0378 Regression loss 0.0159 Classification loss 0.0219 AP 0.2685 AR 0.5733
Epoch 290 batch 00006: Loss 0.0420 Regression loss 0.0200 Classification loss 0.0220 AP 0.2120 AR 0.4583
Epoch 290 batch 00007: Loss 0.0350 Regression loss 0.0181 Classification loss 0.0169 AP 0.2286 AR 0.4833
Epoch 290 batch 00008: Loss 0.0420 Regression loss 0.0166 Classification loss 0.0255 AP 0.3860 AR 0.6933
Epoch 290 batch 00009: Loss 0.0320 Regression loss 0.0165 Classification loss 0.0155 AP 0.2707 AR 0.5700
Epoch 290 batch 00010: Loss 0.0380 Regression loss 0.0155 Classification loss 0.0225 AP 0.4024 AR 0.6650
Epoch 291 batch 00001: Loss 0.0407 Regression loss 0.0167 Classification loss 0.0239 AP 0.2419 AR 0.4467
Epoch 291 batch 00002: Loss 0.0422 Regression loss 0.0152 Classification loss 0.0269 AP 0.3275 AR 0.4867
Epoch 291 batch 00003: Loss 0.0326 Regression loss 0.0160 Classification loss 0.0166 AP 0.3082 AR 0.6017
Epoch 291 batch 00004: Loss 0.0366 Regression loss 0.0165 Classification loss 0.0201 AP 0.3731 AR 0.7867
Epoch 291 batch 00005: Loss 0.0365 Regression loss 0.0178 Classification loss 0.0187 AP 0.2298 AR 0.4033
Epoch 291 batch 00006: Loss 0.0404 Regression loss 0.0165 Classification loss 0.0239 AP 0.1935 AR 0.3667
Epoch 291 batch 00007: Loss 0.0307 Regression loss 0.0164 Classification loss 0.0143 AP 0.2263 AR 0.5233
Epoch 291 batch 00008: Loss 0.0364 Regression loss 0.0165 Classification loss 0.0199 AP 0.2491 AR 0.4767
Epoch 291 batch 00009: Loss 0.0444 Regression loss 0.0203 Classification loss 0.0240 AP 0.2149 AR 0.4650
Epoch 291 batch 00010: Loss 0.0326 Regression loss 0.0183 Classification loss 0.0143 AP 0.2997 AR 0.5750
Epoch 292 batch 00001: Loss 0.0310 Regression loss 0.0171 Classification loss 0.0140 AP 0.2970 AR 0.5633
Epoch 292 batch 00002: Loss 0.0377 Regression loss 0.0168 Classification loss 0.0208 AP 0.1635 AR 0.3583
Epoch 292 batch 00003: Loss 0.0417 Regression loss 0.0177 Classification loss 0.0240 AP 0.2341 AR 0.5667
Epoch 292 batch 00004: Loss 0.0351 Regression loss 0.0169 Classification loss 0.0181 AP 0.2633 AR 0.4683
Epoch 292 batch 00005: Loss 0.0353 Regression loss 0.0138 Classification loss 0.0215 AP 0.4827 AR 0.6683
Epoch 292 batch 00006: Loss 0.0393 Regression loss 0.0165 Classification loss 0.0227 AP 0.2575 AR 0.4567
Epoch 292 batch 00007: Loss 0.0439 Regression loss 0.0191 Classification loss 0.0248 AP 0.1971 AR 0.4583
Epoch 292 batch 00008: Loss 0.0335 Regression loss 0.0178 Classification loss 0.0157 AP 0.2797 AR 0.5567
Epoch 292 batch 00009: Loss 0.0380 Regression loss 0.0175 Classification loss 0.0205 AP 0.2080 AR 0.4250
Epoch 292 batch 00010: Loss 0.0340 Regression loss 0.0147 Classification loss 0.0193 AP 0.2294 AR 0.5350
Epoch 293 batch 00001: Loss 0.0360 Regression loss 0.0168 Classification loss 0.0192 AP 0.2294 AR 0.4900
Epoch 293 batch 00002: Loss 0.0366 Regression loss 0.0158 Classification loss 0.0208 AP 0.3817 AR 0.6167
Epoch 293 batch 00003: Loss 0.0373 Regression loss 0.0201 Classification loss 0.0172 AP 0.1768 AR 0.3417
Epoch 293 batch 00004: Loss 0.0351 Regression loss 0.0164 Classification loss 0.0187 AP 0.2539 AR 0.5517
Epoch 293 batch 00005: Loss 0.0372 Regression loss 0.0146 Classification loss 0.0226 AP 0.1810 AR 0.3450
Epoch 293 batch 00006: Loss 0.0395 Regression loss 0.0161 Classification loss 0.0234 AP 0.3776 AR 0.6500
Epoch 293 batch 00007: Loss 0.0431 Regression loss 0.0148 Classification loss 0.0282 AP 0.4112 AR 0.6767
Epoch 293 batch 00008: Loss 0.0463 Regression loss 0.0187 Classification loss 0.0276 AP 0.2161 AR 0.3817
Epoch 293 batch 00009: Loss 0.0291 Regression loss 0.0173 Classification loss 0.0118 AP 0.2586 AR 0.5350
Epoch 293 batch 00010: Loss 0.0357 Regression loss 0.0185 Classification loss 0.0173 AP 0.3129 AR 0.6833
Epoch 294 batch 00001: Loss 0.0341 Regression loss 0.0164 Classification loss 0.0178 AP 0.2964 AR 0.6250
Epoch 294 batch 00002: Loss 0.0354 Regression loss 0.0152 Classification loss 0.0202 AP 0.3842 AR 0.7183
Epoch 294 batch 00003: Loss 0.0402 Regression loss 0.0193 Classification loss 0.0209 AP 0.1872 AR 0.4400
Epoch 294 batch 00004: Loss 0.0340 Regression loss 0.0185 Classification loss 0.0155 AP 0.2294 AR 0.5833
Epoch 294 batch 00005: Loss 0.0411 Regression loss 0.0203 Classification loss 0.0209 AP 0.3579 AR 0.5767
Epoch 294 batch 00006: Loss 0.0416 Regression loss 0.0164 Classification loss 0.0251 AP 0.2902 AR 0.6267
Epoch 294 batch 00007: Loss 0.0486 Regression loss 0.0184 Classification loss 0.0301 AP 0.1969 AR 0.5133
Epoch 294 batch 00008: Loss 0.0499 Regression loss 0.0210 Classification loss 0.0288 AP 0.2370 AR 0.3950
Epoch 294 batch 00009: Loss 0.0320 Regression loss 0.0158 Classification loss 0.0162 AP 0.1999 AR 0.4217
Epoch 294 batch 00010: Loss 0.0415 Regression loss 0.0218 Classification loss 0.0197 AP 0.2179 AR 0.3750
Epoch 295 batch 00001: Loss 0.0340 Regression loss 0.0162 Classification loss 0.0179 AP 0.1831 AR 0.3867
Epoch 295 batch 00002: Loss 0.0493 Regression loss 0.0173 Classification loss 0.0319 AP 0.2192 AR 0.4500
Epoch 295 batch 00003: Loss 0.0353 Regression loss 0.0177 Classification loss 0.0176 AP 0.3310 AR 0.6167
Epoch 295 batch 00004: Loss 0.0374 Regression loss 0.0180 Classification loss 0.0193 AP 0.1795 AR 0.4250
Epoch 295 batch 00005: Loss 0.0358 Regression loss 0.0183 Classification loss 0.0176 AP 0.3128 AR 0.6283
Epoch 295 batch 00006: Loss 0.0367 Regression loss 0.0187 Classification loss 0.0180 AP 0.2135 AR 0.4333
Epoch 295 batch 00007: Loss 0.0366 Regression loss 0.0193 Classification loss 0.0173 AP 0.1129 AR 0.2983
Epoch 295 batch 00008: Loss 0.0392 Regression loss 0.0173 Classification loss 0.0219 AP 0.1384 AR 0.1850
Epoch 295 batch 00009: Loss 0.0376 Regression loss 0.0182 Classification loss 0.0193 AP 0.3122 AR 0.4667
Epoch 295 batch 00010: Loss 0.0354 Regression loss 0.0203 Classification loss 0.0151 AP 0.2036 AR 0.5017
Epoch 296 batch 00001: Loss 0.0328 Regression loss 0.0161 Classification loss 0.0167 AP 0.3006 AR 0.5867
Epoch 296 batch 00002: Loss 0.0349 Regression loss 0.0205 Classification loss 0.0144 AP 0.1227 AR 0.3250
Epoch 296 batch 00003: Loss 0.0401 Regression loss 0.0202 Classification loss 0.0199 AP 0.2172 AR 0.4017
Epoch 296 batch 00004: Loss 0.0319 Regression loss 0.0142 Classification loss 0.0177 AP 0.2754 AR 0.4483
Epoch 296 batch 00005: Loss 0.0371 Regression loss 0.0195 Classification loss 0.0177 AP 0.1363 AR 0.2467
Epoch 296 batch 00006: Loss 0.0362 Regression loss 0.0168 Classification loss 0.0194 AP 0.2386 AR 0.3583
Epoch 296 batch 00007: Loss 0.0414 Regression loss 0.0195 Classification loss 0.0219 AP 0.2694 AR 0.5483
Epoch 296 batch 00008: Loss 0.0337 Regression loss 0.0168 Classification loss 0.0168 AP 0.1174 AR 0.3033
Epoch 296 batch 00009: Loss 0.0414 Regression loss 0.0180 Classification loss 0.0234 AP 0.5089 AR 0.8150
Epoch 296 batch 00010: Loss 0.0376 Regression loss 0.0196 Classification loss 0.0179 AP 0.2162 AR 0.4183
Epoch 297 batch 00001: Loss 0.0408 Regression loss 0.0194 Classification loss 0.0214 AP 0.1450 AR 0.2617
Epoch 297 batch 00002: Loss 0.0394 Regression loss 0.0175 Classification loss 0.0219 AP 0.1264 AR 0.3900
Epoch 297 batch 00003: Loss 0.0464 Regression loss 0.0239 Classification loss 0.0225 AP 0.1139 AR 0.2517
Epoch 297 batch 00004: Loss 0.0335 Regression loss 0.0168 Classification loss 0.0167 AP 0.2139 AR 0.3833
Epoch 297 batch 00005: Loss 0.0316 Regression loss 0.0165 Classification loss 0.0151 AP 0.5000 AR 0.6750
Epoch 297 batch 00006: Loss 0.0420 Regression loss 0.0200 Classification loss 0.0220 AP 0.3638 AR 0.6767
Epoch 297 batch 00007: Loss 0.0400 Regression loss 0.0176 Classification loss 0.0225 AP 0.1798 AR 0.4250
Epoch 297 batch 00008: Loss 0.0339 Regression loss 0.0181 Classification loss 0.0158 AP 0.2822 AR 0.5067
Epoch 297 batch 00009: Loss 0.0292 Regression loss 0.0162 Classification loss 0.0130 AP 0.3526 AR 0.5450
Epoch 297 batch 00010: Loss 0.0323 Regression loss 0.0156 Classification loss 0.0166 AP 0.4075 AR 0.6500
Epoch 298 batch 00001: Loss 0.0413 Regression loss 0.0186 Classification loss 0.0227 AP 0.1929 AR 0.4017
Epoch 298 batch 00002: Loss 0.0286 Regression loss 0.0154 Classification loss 0.0132 AP 0.1119 AR 0.2583
Epoch 298 batch 00003: Loss 0.0336 Regression loss 0.0166 Classification loss 0.0170 AP 0.3009 AR 0.6483
Epoch 298 batch 00004: Loss 0.0337 Regression loss 0.0162 Classification loss 0.0175 AP 0.2220 AR 0.3633
Epoch 298 batch 00005: Loss 0.0411 Regression loss 0.0226 Classification loss 0.0185 AP 0.2392 AR 0.4100
Epoch 298 batch 00006: Loss 0.0377 Regression loss 0.0155 Classification loss 0.0222 AP 0.3065 AR 0.6183
Epoch 298 batch 00007: Loss 0.0380 Regression loss 0.0215 Classification loss 0.0165 AP 0.1638 AR 0.3317
Epoch 298 batch 00008: Loss 0.0350 Regression loss 0.0174 Classification loss 0.0175 AP 0.1643 AR 0.3200
Epoch 298 batch 00009: Loss 0.0363 Regression loss 0.0180 Classification loss 0.0183 AP 0.1956 AR 0.4250
Epoch 298 batch 00010: Loss 0.0295 Regression loss 0.0156 Classification loss 0.0139 AP 0.3580 AR 0.6517
Epoch 299 batch 00001: Loss 0.0297 Regression loss 0.0137 Classification loss 0.0159 AP 0.2083 AR 0.3900
Epoch 299 batch 00002: Loss 0.0387 Regression loss 0.0204 Classification loss 0.0184 AP 0.1316 AR 0.3333
Epoch 299 batch 00003: Loss 0.0359 Regression loss 0.0156 Classification loss 0.0203 AP 0.2937 AR 0.6167
Epoch 299 batch 00004: Loss 0.0354 Regression loss 0.0182 Classification loss 0.0172 AP 0.2486 AR 0.4683
Epoch 299 batch 00005: Loss 0.0420 Regression loss 0.0190 Classification loss 0.0230 AP 0.1708 AR 0.3017
Epoch 299 batch 00006: Loss 0.0388 Regression loss 0.0192 Classification loss 0.0196 AP 0.2032 AR 0.4017
Epoch 299 batch 00007: Loss 0.0323 Regression loss 0.0184 Classification loss 0.0139 AP 0.2010 AR 0.4750
Epoch 299 batch 00008: Loss 0.0308 Regression loss 0.0143 Classification loss 0.0164 AP 0.3856 AR 0.5800
Epoch 299 batch 00009: Loss 0.0363 Regression loss 0.0190 Classification loss 0.0173 AP 0.2723 AR 0.5300
Epoch 299 batch 00010: Loss 0.0411 Regression loss 0.0177 Classification loss 0.0234 AP 0.2960 AR 0.4983
Epoch 300 batch 00001: Loss 0.0390 Regression loss 0.0187 Classification loss 0.0203 AP 0.2167 AR 0.4833
Epoch 300 batch 00002: Loss 0.0360 Regression loss 0.0205 Classification loss 0.0154 AP 0.2205 AR 0.4017
Epoch 300 batch 00003: Loss 0.0408 Regression loss 0.0170 Classification loss 0.0237 AP 0.4045 AR 0.5850
Epoch 300 batch 00004: Loss 0.0339 Regression loss 0.0175 Classification loss 0.0165 AP 0.3889 AR 0.6850
Epoch 300 batch 00005: Loss 0.0385 Regression loss 0.0176 Classification loss 0.0209 AP 0.3514 AR 0.6350
Epoch 300 batch 00006: Loss 0.0358 Regression loss 0.0187 Classification loss 0.0171 AP 0.1890 AR 0.4250
Epoch 300 batch 00007: Loss 0.0344 Regression loss 0.0191 Classification loss 0.0153 AP 0.1544 AR 0.3450
Epoch 300 batch 00008: Loss 0.0340 Regression loss 0.0185 Classification loss 0.0156 AP 0.2570 AR 0.4500
Epoch 300 batch 00009: Loss 0.0381 Regression loss 0.0185 Classification loss 0.0196 AP 0.3694 AR 0.6500
Epoch 300 batch 00010: Loss 0.0372 Regression loss 0.0181 Classification loss 0.0191 AP 0.2947 AR 0.4467
Epoch 301 batch 00001: Loss 0.0377 Regression loss 0.0219 Classification loss 0.0158 AP 0.2095 AR 0.3850
Epoch 301 batch 00002: Loss 0.0385 Regression loss 0.0180 Classification loss 0.0205 AP 0.4317 AR 0.7483
Epoch 301 batch 00003: Loss 0.0393 Regression loss 0.0184 Classification loss 0.0209 AP 0.2153 AR 0.4450
Epoch 301 batch 00004: Loss 0.0306 Regression loss 0.0157 Classification loss 0.0150 AP 0.2531 AR 0.4733
Epoch 301 batch 00005: Loss 0.0352 Regression loss 0.0157 Classification loss 0.0195 AP 0.1721 AR 0.4283
Epoch 301 batch 00006: Loss 0.0296 Regression loss 0.0172 Classification loss 0.0124 AP 0.3247 AR 0.6550
Epoch 301 batch 00007: Loss 0.0367 Regression loss 0.0172 Classification loss 0.0195 AP 0.2236 AR 0.4833
Epoch 301 batch 00008: Loss 0.0364 Regression loss 0.0170 Classification loss 0.0193 AP 0.3655 AR 0.5917
Epoch 301 batch 00009: Loss 0.0340 Regression loss 0.0173 Classification loss 0.0167 AP 0.3246 AR 0.6233
Epoch 301 batch 00010: Loss 0.0402 Regression loss 0.0189 Classification loss 0.0213 AP 0.1868 AR 0.3967
Epoch 302 batch 00001: Loss 0.0346 Regression loss 0.0153 Classification loss 0.0194 AP 0.3262 AR 0.6417
Epoch 302 batch 00002: Loss 0.0300 Regression loss 0.0176 Classification loss 0.0124 AP 0.2111 AR 0.4533
Epoch 302 batch 00003: Loss 0.0310 Regression loss 0.0144 Classification loss 0.0166 AP 0.3160 AR 0.5733
Epoch 302 batch 00004: Loss 0.0358 Regression loss 0.0175 Classification loss 0.0182 AP 0.2121 AR 0.4433
Epoch 302 batch 00005: Loss 0.0443 Regression loss 0.0150 Classification loss 0.0293 AP 0.1773 AR 0.4567
Epoch 302 batch 00006: Loss 0.0322 Regression loss 0.0171 Classification loss 0.0151 AP 0.1875 AR 0.4367
Epoch 302 batch 00007: Loss 0.0368 Regression loss 0.0184 Classification loss 0.0184 AP 0.2494 AR 0.5150
Epoch 302 batch 00008: Loss 0.0386 Regression loss 0.0174 Classification loss 0.0213 AP 0.3927 AR 0.5867
Epoch 302 batch 00009: Loss 0.0391 Regression loss 0.0180 Classification loss 0.0211 AP 0.2269 AR 0.4617
Epoch 302 batch 00010: Loss 0.0414 Regression loss 0.0181 Classification loss 0.0233 AP 0.2260 AR 0.3733
Epoch 303 batch 00001: Loss 0.0317 Regression loss 0.0174 Classification loss 0.0143 AP 0.3896 AR 0.7200
Epoch 303 batch 00002: Loss 0.0328 Regression loss 0.0171 Classification loss 0.0157 AP 0.2456 AR 0.4583
Epoch 303 batch 00003: Loss 0.0338 Regression loss 0.0187 Classification loss 0.0151 AP 0.1942 AR 0.4317
Epoch 303 batch 00004: Loss 0.0385 Regression loss 0.0195 Classification loss 0.0190 AP 0.2040 AR 0.5050
Epoch 303 batch 00005: Loss 0.0432 Regression loss 0.0192 Classification loss 0.0240 AP 0.2128 AR 0.5417
Epoch 303 batch 00006: Loss 0.0351 Regression loss 0.0155 Classification loss 0.0196 AP 0.2298 AR 0.4933
Epoch 303 batch 00007: Loss 0.0308 Regression loss 0.0150 Classification loss 0.0157 AP 0.3364 AR 0.5917
Epoch 303 batch 00008: Loss 0.0323 Regression loss 0.0163 Classification loss 0.0161 AP 0.4537 AR 0.6800
Epoch 303 batch 00009: Loss 0.0370 Regression loss 0.0151 Classification loss 0.0219 AP 0.4677 AR 0.6217
Epoch 303 batch 00010: Loss 0.0476 Regression loss 0.0185 Classification loss 0.0291 AP 0.1242 AR 0.2750
Epoch 304 batch 00001: Loss 0.0341 Regression loss 0.0152 Classification loss 0.0189 AP 0.3845 AR 0.5817
Epoch 304 batch 00002: Loss 0.0414 Regression loss 0.0172 Classification loss 0.0242 AP 0.2624 AR 0.4983
Epoch 304 batch 00003: Loss 0.0348 Regression loss 0.0145 Classification loss 0.0202 AP 0.2512 AR 0.5650
Epoch 304 batch 00004: Loss 0.0343 Regression loss 0.0153 Classification loss 0.0190 AP 0.1933 AR 0.4717
Epoch 304 batch 00005: Loss 0.0393 Regression loss 0.0155 Classification loss 0.0238 AP 0.2684 AR 0.5683
Epoch 304 batch 00006: Loss 0.0394 Regression loss 0.0189 Classification loss 0.0204 AP 0.1952 AR 0.4300
Epoch 304 batch 00007: Loss 0.0408 Regression loss 0.0194 Classification loss 0.0215 AP 0.1675 AR 0.3300
Epoch 304 batch 00008: Loss 0.0308 Regression loss 0.0161 Classification loss 0.0146 AP 0.3537 AR 0.5833
Epoch 304 batch 00009: Loss 0.0273 Regression loss 0.0143 Classification loss 0.0130 AP 0.1962 AR 0.3917
Epoch 304 batch 00010: Loss 0.0348 Regression loss 0.0196 Classification loss 0.0152 AP 0.1367 AR 0.2600
Epoch 305 batch 00001: Loss 0.0380 Regression loss 0.0166 Classification loss 0.0214 AP 0.3517 AR 0.7583
Epoch 305 batch 00002: Loss 0.0326 Regression loss 0.0174 Classification loss 0.0152 AP 0.3208 AR 0.5167
Epoch 305 batch 00003: Loss 0.0299 Regression loss 0.0173 Classification loss 0.0126 AP 0.1889 AR 0.3833
Epoch 305 batch 00004: Loss 0.0345 Regression loss 0.0158 Classification loss 0.0187 AP 0.2917 AR 0.5233
Epoch 305 batch 00005: Loss 0.0345 Regression loss 0.0169 Classification loss 0.0177 AP 0.2782 AR 0.5800
Epoch 305 batch 00006: Loss 0.0347 Regression loss 0.0180 Classification loss 0.0167 AP 0.3331 AR 0.6583
Epoch 305 batch 00007: Loss 0.0288 Regression loss 0.0114 Classification loss 0.0174 AP 0.1733 AR 0.3500
Epoch 305 batch 00008: Loss 0.0285 Regression loss 0.0130 Classification loss 0.0155 AP 0.3135 AR 0.5317
Epoch 305 batch 00009: Loss 0.0321 Regression loss 0.0149 Classification loss 0.0172 AP 0.3605 AR 0.6333
Epoch 305 batch 00010: Loss 0.0446 Regression loss 0.0187 Classification loss 0.0259 AP 0.2817 AR 0.5067
Epoch 306 batch 00001: Loss 0.0310 Regression loss 0.0153 Classification loss 0.0157 AP 0.4222 AR 0.7333
Epoch 306 batch 00002: Loss 0.0356 Regression loss 0.0165 Classification loss 0.0192 AP 0.2251 AR 0.3917
Epoch 306 batch 00003: Loss 0.0322 Regression loss 0.0167 Classification loss 0.0155 AP 0.4081 AR 0.6033
Epoch 306 batch 00004: Loss 0.0288 Regression loss 0.0170 Classification loss 0.0119 AP 0.3800 AR 0.6100
Epoch 306 batch 00005: Loss 0.0356 Regression loss 0.0169 Classification loss 0.0187 AP 0.2859 AR 0.4750
Epoch 306 batch 00006: Loss 0.0293 Regression loss 0.0134 Classification loss 0.0158 AP 0.2771 AR 0.5750
Epoch 306 batch 00007: Loss 0.0337 Regression loss 0.0153 Classification loss 0.0184 AP 0.3042 AR 0.6200
Epoch 306 batch 00008: Loss 0.0484 Regression loss 0.0213 Classification loss 0.0272 AP 0.1389 AR 0.2883
Epoch 306 batch 00009: Loss 0.0266 Regression loss 0.0121 Classification loss 0.0145 AP 0.2792 AR 0.5683
Epoch 306 batch 00010: Loss 0.0346 Regression loss 0.0147 Classification loss 0.0199 AP 0.2966 AR 0.5083
Epoch 307 batch 00001: Loss 0.0328 Regression loss 0.0152 Classification loss 0.0176 AP 0.4042 AR 0.5367
Epoch 307 batch 00002: Loss 0.0375 Regression loss 0.0152 Classification loss 0.0223 AP 0.2583 AR 0.4667
Epoch 307 batch 00003: Loss 0.0293 Regression loss 0.0139 Classification loss 0.0153 AP 0.3377 AR 0.6433
Epoch 307 batch 00004: Loss 0.0314 Regression loss 0.0160 Classification loss 0.0154 AP 0.2366 AR 0.4450
Epoch 307 batch 00005: Loss 0.0327 Regression loss 0.0146 Classification loss 0.0180 AP 0.2641 AR 0.5383
Epoch 307 batch 00006: Loss 0.0385 Regression loss 0.0169 Classification loss 0.0216 AP 0.3303 AR 0.5250
Epoch 307 batch 00007: Loss 0.0302 Regression loss 0.0159 Classification loss 0.0143 AP 0.3772 AR 0.6250
Epoch 307 batch 00008: Loss 0.0359 Regression loss 0.0176 Classification loss 0.0183 AP 0.2788 AR 0.5017
Epoch 307 batch 00009: Loss 0.0338 Regression loss 0.0142 Classification loss 0.0195 AP 0.3768 AR 0.7067
Epoch 307 batch 00010: Loss 0.0280 Regression loss 0.0159 Classification loss 0.0121 AP 0.3229 AR 0.5667
Epoch 308 batch 00001: Loss 0.0418 Regression loss 0.0150 Classification loss 0.0269 AP 0.2393 AR 0.4917
Epoch 308 batch 00002: Loss 0.0362 Regression loss 0.0180 Classification loss 0.0182 AP 0.3173 AR 0.6267
Epoch 308 batch 00003: Loss 0.0312 Regression loss 0.0149 Classification loss 0.0163 AP 0.3567 AR 0.6100
Epoch 308 batch 00004: Loss 0.0330 Regression loss 0.0164 Classification loss 0.0166 AP 0.2273 AR 0.5300
Epoch 308 batch 00005: Loss 0.0326 Regression loss 0.0167 Classification loss 0.0159 AP 0.3030 AR 0.6750
Epoch 308 batch 00006: Loss 0.0298 Regression loss 0.0161 Classification loss 0.0137 AP 0.3817 AR 0.7367
Epoch 308 batch 00007: Loss 0.0308 Regression loss 0.0145 Classification loss 0.0163 AP 0.3044 AR 0.5167
Epoch 308 batch 00008: Loss 0.0321 Regression loss 0.0144 Classification loss 0.0177 AP 0.2183 AR 0.4567
Epoch 308 batch 00009: Loss 0.0424 Regression loss 0.0197 Classification loss 0.0226 AP 0.2410 AR 0.3383
Epoch 308 batch 00010: Loss 0.0406 Regression loss 0.0199 Classification loss 0.0207 AP 0.3363 AR 0.6417
Epoch 309 batch 00001: Loss 0.0403 Regression loss 0.0137 Classification loss 0.0266 AP 0.4421 AR 0.6250
Epoch 309 batch 00002: Loss 0.0328 Regression loss 0.0152 Classification loss 0.0176 AP 0.3161 AR 0.6433
Epoch 309 batch 00003: Loss 0.0345 Regression loss 0.0172 Classification loss 0.0173 AP 0.2948 AR 0.5283
Epoch 309 batch 00004: Loss 0.0394 Regression loss 0.0172 Classification loss 0.0222 AP 0.2366 AR 0.4833
Epoch 309 batch 00005: Loss 0.0320 Regression loss 0.0170 Classification loss 0.0150 AP 0.2043 AR 0.4733
Epoch 309 batch 00006: Loss 0.0349 Regression loss 0.0176 Classification loss 0.0174 AP 0.2242 AR 0.5167
Epoch 309 batch 00007: Loss 0.0314 Regression loss 0.0176 Classification loss 0.0138 AP 0.1901 AR 0.4083
Epoch 309 batch 00008: Loss 0.0345 Regression loss 0.0159 Classification loss 0.0186 AP 0.3525 AR 0.6367
Epoch 309 batch 00009: Loss 0.0367 Regression loss 0.0215 Classification loss 0.0152 AP 0.1855 AR 0.2650
Epoch 309 batch 00010: Loss 0.0421 Regression loss 0.0196 Classification loss 0.0225 AP 0.2333 AR 0.3117
Epoch 310 batch 00001: Loss 0.0326 Regression loss 0.0141 Classification loss 0.0184 AP 0.2643 AR 0.5433
Epoch 310 batch 00002: Loss 0.0386 Regression loss 0.0191 Classification loss 0.0195 AP 0.2883 AR 0.5617
Epoch 310 batch 00003: Loss 0.0418 Regression loss 0.0224 Classification loss 0.0194 AP 0.3394 AR 0.6033
Epoch 310 batch 00004: Loss 0.0305 Regression loss 0.0175 Classification loss 0.0129 AP 0.1888 AR 0.3633
Epoch 310 batch 00005: Loss 0.0351 Regression loss 0.0196 Classification loss 0.0155 AP 0.2278 AR 0.5250
Epoch 310 batch 00006: Loss 0.0351 Regression loss 0.0172 Classification loss 0.0179 AP 0.3507 AR 0.6583
Epoch 310 batch 00007: Loss 0.0325 Regression loss 0.0189 Classification loss 0.0137 AP 0.2477 AR 0.5650
Epoch 310 batch 00008: Loss 0.0341 Regression loss 0.0174 Classification loss 0.0167 AP 0.3418 AR 0.6133
Epoch 310 batch 00009: Loss 0.0307 Regression loss 0.0144 Classification loss 0.0163 AP 0.2783 AR 0.5483
Epoch 310 batch 00010: Loss 0.0311 Regression loss 0.0166 Classification loss 0.0145 AP 0.2657 AR 0.4917
Epoch 311 batch 00001: Loss 0.0308 Regression loss 0.0189 Classification loss 0.0119 AP 0.3408 AR 0.6917
Epoch 311 batch 00002: Loss 0.0331 Regression loss 0.0188 Classification loss 0.0143 AP 0.1175 AR 0.2400
Epoch 311 batch 00003: Loss 0.0322 Regression loss 0.0159 Classification loss 0.0163 AP 0.3508 AR 0.5500
Epoch 311 batch 00004: Loss 0.0364 Regression loss 0.0188 Classification loss 0.0176 AP 0.1927 AR 0.3683
Epoch 311 batch 00005: Loss 0.0378 Regression loss 0.0147 Classification loss 0.0231 AP 0.2929 AR 0.5350
Epoch 311 batch 00006: Loss 0.0329 Regression loss 0.0171 Classification loss 0.0158 AP 0.2733 AR 0.5400
Epoch 311 batch 00007: Loss 0.0318 Regression loss 0.0167 Classification loss 0.0150 AP 0.1982 AR 0.4200
Epoch 311 batch 00008: Loss 0.0314 Regression loss 0.0153 Classification loss 0.0161 AP 0.2979 AR 0.6767
Epoch 311 batch 00009: Loss 0.0292 Regression loss 0.0150 Classification loss 0.0143 AP 0.4241 AR 0.6000
Epoch 311 batch 00010: Loss 0.0302 Regression loss 0.0157 Classification loss 0.0145 AP 0.3250 AR 0.5000
Epoch 312 batch 00001: Loss 0.0258 Regression loss 0.0170 Classification loss 0.0089 AP 0.3548 AR 0.6967
Epoch 312 batch 00002: Loss 0.0432 Regression loss 0.0222 Classification loss 0.0210 AP 0.2277 AR 0.4050
Epoch 312 batch 00003: Loss 0.0323 Regression loss 0.0160 Classification loss 0.0163 AP 0.1560 AR 0.3917
Epoch 312 batch 00004: Loss 0.0375 Regression loss 0.0169 Classification loss 0.0206 AP 0.1933 AR 0.4333
Epoch 312 batch 00005: Loss 0.0286 Regression loss 0.0152 Classification loss 0.0134 AP 0.4781 AR 0.7417
Epoch 312 batch 00006: Loss 0.0392 Regression loss 0.0203 Classification loss 0.0189 AP 0.2043 AR 0.4333
Epoch 312 batch 00007: Loss 0.0340 Regression loss 0.0182 Classification loss 0.0158 AP 0.1912 AR 0.3100
Epoch 312 batch 00008: Loss 0.0329 Regression loss 0.0177 Classification loss 0.0152 AP 0.1991 AR 0.4300
Epoch 312 batch 00009: Loss 0.0269 Regression loss 0.0169 Classification loss 0.0100 AP 0.2728 AR 0.5933
Epoch 312 batch 00010: Loss 0.0301 Regression loss 0.0128 Classification loss 0.0173 AP 0.3306 AR 0.5100
Epoch 313 batch 00001: Loss 0.0374 Regression loss 0.0193 Classification loss 0.0181 AP 0.2560 AR 0.4967
Epoch 313 batch 00002: Loss 0.0294 Regression loss 0.0167 Classification loss 0.0127 AP 0.3425 AR 0.5550
Epoch 313 batch 00003: Loss 0.0325 Regression loss 0.0182 Classification loss 0.0143 AP 0.2348 AR 0.4183
Epoch 313 batch 00004: Loss 0.0335 Regression loss 0.0170 Classification loss 0.0165 AP 0.3150 AR 0.4517
Epoch 313 batch 00005: Loss 0.0378 Regression loss 0.0140 Classification loss 0.0238 AP 0.3010 AR 0.6250
Epoch 313 batch 00006: Loss 0.0279 Regression loss 0.0171 Classification loss 0.0108 AP 0.2750 AR 0.5500
Epoch 313 batch 00007: Loss 0.0331 Regression loss 0.0158 Classification loss 0.0173 AP 0.2976 AR 0.5750
Epoch 313 batch 00008: Loss 0.0342 Regression loss 0.0172 Classification loss 0.0170 AP 0.2431 AR 0.6000
Epoch 313 batch 00009: Loss 0.0274 Regression loss 0.0131 Classification loss 0.0144 AP 0.3019 AR 0.5983
Epoch 313 batch 00010: Loss 0.0323 Regression loss 0.0177 Classification loss 0.0146 AP 0.2593 AR 0.4183
Epoch 314 batch 00001: Loss 0.0334 Regression loss 0.0161 Classification loss 0.0172 AP 0.3284 AR 0.6350
Epoch 314 batch 00002: Loss 0.0267 Regression loss 0.0146 Classification loss 0.0121 AP 0.1677 AR 0.3750
Epoch 314 batch 00003: Loss 0.0329 Regression loss 0.0151 Classification loss 0.0178 AP 0.2208 AR 0.4267
Epoch 314 batch 00004: Loss 0.0296 Regression loss 0.0166 Classification loss 0.0130 AP 0.3338 AR 0.6483
Epoch 314 batch 00005: Loss 0.0364 Regression loss 0.0171 Classification loss 0.0193 AP 0.3229 AR 0.4817
Epoch 314 batch 00006: Loss 0.0297 Regression loss 0.0145 Classification loss 0.0152 AP 0.4059 AR 0.5517
Epoch 314 batch 00007: Loss 0.0307 Regression loss 0.0140 Classification loss 0.0167 AP 0.4077 AR 0.5767
Epoch 314 batch 00008: Loss 0.0324 Regression loss 0.0176 Classification loss 0.0148 AP 0.3126 AR 0.5683
Epoch 314 batch 00009: Loss 0.0311 Regression loss 0.0159 Classification loss 0.0152 AP 0.3148 AR 0.5483
Epoch 314 batch 00010: Loss 0.0354 Regression loss 0.0172 Classification loss 0.0182 AP 0.2980 AR 0.6083
Epoch 315 batch 00001: Loss 0.0302 Regression loss 0.0115 Classification loss 0.0187 AP 0.3812 AR 0.6700
Epoch 315 batch 00002: Loss 0.0354 Regression loss 0.0185 Classification loss 0.0169 AP 0.2782 AR 0.6917
Epoch 315 batch 00003: Loss 0.0292 Regression loss 0.0160 Classification loss 0.0132 AP 0.2795 AR 0.5750
Epoch 315 batch 00004: Loss 0.0256 Regression loss 0.0136 Classification loss 0.0121 AP 0.5037 AR 0.7333
Epoch 315 batch 00005: Loss 0.0338 Regression loss 0.0194 Classification loss 0.0144 AP 0.3634 AR 0.5050
Epoch 315 batch 00006: Loss 0.0303 Regression loss 0.0129 Classification loss 0.0174 AP 0.3577 AR 0.6650
Epoch 315 batch 00007: Loss 0.0429 Regression loss 0.0199 Classification loss 0.0230 AP 0.1238 AR 0.2483
Epoch 315 batch 00008: Loss 0.0273 Regression loss 0.0140 Classification loss 0.0133 AP 0.3181 AR 0.5517
Epoch 315 batch 00009: Loss 0.0351 Regression loss 0.0197 Classification loss 0.0154 AP 0.2176 AR 0.4817
Epoch 315 batch 00010: Loss 0.0339 Regression loss 0.0177 Classification loss 0.0161 AP 0.2696 AR 0.4883
Epoch 316 batch 00001: Loss 0.0288 Regression loss 0.0150 Classification loss 0.0138 AP 0.2215 AR 0.4750
Epoch 316 batch 00002: Loss 0.0301 Regression loss 0.0171 Classification loss 0.0129 AP 0.2182 AR 0.3967
Epoch 316 batch 00003: Loss 0.0312 Regression loss 0.0138 Classification loss 0.0174 AP 0.3129 AR 0.6200
Epoch 316 batch 00004: Loss 0.0267 Regression loss 0.0147 Classification loss 0.0120 AP 0.3325 AR 0.5300
Epoch 316 batch 00005: Loss 0.0286 Regression loss 0.0149 Classification loss 0.0137 AP 0.4894 AR 0.6417
Epoch 316 batch 00006: Loss 0.0316 Regression loss 0.0142 Classification loss 0.0174 AP 0.3977 AR 0.8400
Epoch 316 batch 00007: Loss 0.0279 Regression loss 0.0161 Classification loss 0.0118 AP 0.4536 AR 0.8333
Epoch 316 batch 00008: Loss 0.0341 Regression loss 0.0164 Classification loss 0.0177 AP 0.2593 AR 0.4400
Epoch 316 batch 00009: Loss 0.0331 Regression loss 0.0169 Classification loss 0.0162 AP 0.2701 AR 0.5000
Epoch 316 batch 00010: Loss 0.0284 Regression loss 0.0148 Classification loss 0.0136 AP 0.3552 AR 0.5667
Epoch 317 batch 00001: Loss 0.0291 Regression loss 0.0135 Classification loss 0.0156 AP 0.3425 AR 0.6317
Epoch 317 batch 00002: Loss 0.0273 Regression loss 0.0166 Classification loss 0.0107 AP 0.1402 AR 0.2800
Epoch 317 batch 00003: Loss 0.0327 Regression loss 0.0160 Classification loss 0.0167 AP 0.2199 AR 0.3817
Epoch 317 batch 00004: Loss 0.0326 Regression loss 0.0144 Classification loss 0.0182 AP 0.4210 AR 0.7100
Epoch 317 batch 00005: Loss 0.0278 Regression loss 0.0140 Classification loss 0.0138 AP 0.2828 AR 0.4900
Epoch 317 batch 00006: Loss 0.0262 Regression loss 0.0139 Classification loss 0.0123 AP 0.4442 AR 0.7733
Epoch 317 batch 00007: Loss 0.0317 Regression loss 0.0154 Classification loss 0.0164 AP 0.2868 AR 0.4950
Epoch 317 batch 00008: Loss 0.0241 Regression loss 0.0152 Classification loss 0.0089 AP 0.4810 AR 0.7167
Epoch 317 batch 00009: Loss 0.0275 Regression loss 0.0134 Classification loss 0.0141 AP 0.3629 AR 0.6750
Epoch 317 batch 00010: Loss 0.0377 Regression loss 0.0165 Classification loss 0.0211 AP 0.3311 AR 0.6867
Epoch 318 batch 00001: Loss 0.0315 Regression loss 0.0160 Classification loss 0.0155 AP 0.2281 AR 0.4317
Epoch 318 batch 00002: Loss 0.0335 Regression loss 0.0166 Classification loss 0.0170 AP 0.2386 AR 0.4650
Epoch 318 batch 00003: Loss 0.0272 Regression loss 0.0152 Classification loss 0.0120 AP 0.2730 AR 0.5333
Epoch 318 batch 00004: Loss 0.0227 Regression loss 0.0143 Classification loss 0.0084 AP 0.3433 AR 0.5633
Epoch 318 batch 00005: Loss 0.0303 Regression loss 0.0139 Classification loss 0.0164 AP 0.3198 AR 0.6750
Epoch 318 batch 00006: Loss 0.0289 Regression loss 0.0142 Classification loss 0.0147 AP 0.3405 AR 0.5967
Epoch 318 batch 00007: Loss 0.0354 Regression loss 0.0154 Classification loss 0.0200 AP 0.3074 AR 0.5767
Epoch 318 batch 00008: Loss 0.0277 Regression loss 0.0125 Classification loss 0.0152 AP 0.3702 AR 0.5667
Epoch 318 batch 00009: Loss 0.0287 Regression loss 0.0146 Classification loss 0.0141 AP 0.5338 AR 0.8267
Epoch 318 batch 00010: Loss 0.0312 Regression loss 0.0179 Classification loss 0.0133 AP 0.2950 AR 0.4900
Epoch 319 batch 00001: Loss 0.0287 Regression loss 0.0152 Classification loss 0.0135 AP 0.3726 AR 0.5650
Epoch 319 batch 00002: Loss 0.0253 Regression loss 0.0128 Classification loss 0.0125 AP 0.3224 AR 0.6933
Epoch 319 batch 00003: Loss 0.0325 Regression loss 0.0134 Classification loss 0.0191 AP 0.3418 AR 0.6250
Epoch 319 batch 00004: Loss 0.0345 Regression loss 0.0177 Classification loss 0.0168 AP 0.2769 AR 0.5117
Epoch 319 batch 00005: Loss 0.0294 Regression loss 0.0165 Classification loss 0.0129 AP 0.2702 AR 0.5350
Epoch 319 batch 00006: Loss 0.0323 Regression loss 0.0141 Classification loss 0.0182 AP 0.3117 AR 0.6833
Epoch 319 batch 00007: Loss 0.0283 Regression loss 0.0133 Classification loss 0.0150 AP 0.3771 AR 0.4917
Epoch 319 batch 00008: Loss 0.0310 Regression loss 0.0164 Classification loss 0.0147 AP 0.3379 AR 0.6883
Epoch 319 batch 00009: Loss 0.0284 Regression loss 0.0147 Classification loss 0.0136 AP 0.1719 AR 0.3900
Epoch 319 batch 00010: Loss 0.0345 Regression loss 0.0154 Classification loss 0.0192 AP 0.3619 AR 0.7167
Epoch 320 batch 00001: Loss 0.0253 Regression loss 0.0129 Classification loss 0.0124 AP 0.3317 AR 0.6017
Epoch 320 batch 00002: Loss 0.0297 Regression loss 0.0163 Classification loss 0.0133 AP 0.3205 AR 0.6500
Epoch 320 batch 00003: Loss 0.0300 Regression loss 0.0160 Classification loss 0.0140 AP 0.2316 AR 0.4667
Epoch 320 batch 00004: Loss 0.0342 Regression loss 0.0163 Classification loss 0.0179 AP 0.3489 AR 0.5500
Epoch 320 batch 00005: Loss 0.0326 Regression loss 0.0137 Classification loss 0.0189 AP 0.3355 AR 0.6350
Epoch 320 batch 00006: Loss 0.0293 Regression loss 0.0169 Classification loss 0.0124 AP 0.3842 AR 0.6250
Epoch 320 batch 00007: Loss 0.0361 Regression loss 0.0149 Classification loss 0.0212 AP 0.3756 AR 0.6317
Epoch 320 batch 00008: Loss 0.0313 Regression loss 0.0161 Classification loss 0.0153 AP 0.2581 AR 0.5250
Epoch 320 batch 00009: Loss 0.0267 Regression loss 0.0142 Classification loss 0.0125 AP 0.3251 AR 0.6817
Epoch 320 batch 00010: Loss 0.0245 Regression loss 0.0125 Classification loss 0.0120 AP 0.2458 AR 0.4333
Epoch 321 batch 00001: Loss 0.0226 Regression loss 0.0107 Classification loss 0.0119 AP 0.4081 AR 0.6500
Epoch 321 batch 00002: Loss 0.0253 Regression loss 0.0126 Classification loss 0.0127 AP 0.3473 AR 0.5833
Epoch 321 batch 00003: Loss 0.0363 Regression loss 0.0180 Classification loss 0.0183 AP 0.2507 AR 0.5383
Epoch 321 batch 00004: Loss 0.0310 Regression loss 0.0162 Classification loss 0.0147 AP 0.3544 AR 0.5467
Epoch 321 batch 00005: Loss 0.0277 Regression loss 0.0152 Classification loss 0.0126 AP 0.1625 AR 0.3267
Epoch 321 batch 00006: Loss 0.0263 Regression loss 0.0151 Classification loss 0.0112 AP 0.2404 AR 0.5050
Epoch 321 batch 00007: Loss 0.0296 Regression loss 0.0132 Classification loss 0.0164 AP 0.2386 AR 0.4833
Epoch 321 batch 00008: Loss 0.0333 Regression loss 0.0153 Classification loss 0.0180 AP 0.3358 AR 0.6050
Epoch 321 batch 00009: Loss 0.0315 Regression loss 0.0164 Classification loss 0.0151 AP 0.3600 AR 0.6250
Epoch 321 batch 00010: Loss 0.0281 Regression loss 0.0154 Classification loss 0.0128 AP 0.2929 AR 0.6417
Epoch 322 batch 00001: Loss 0.0276 Regression loss 0.0133 Classification loss 0.0143 AP 0.3525 AR 0.5417
Epoch 322 batch 00002: Loss 0.0262 Regression loss 0.0158 Classification loss 0.0104 AP 0.3367 AR 0.5867
Epoch 322 batch 00003: Loss 0.0273 Regression loss 0.0134 Classification loss 0.0139 AP 0.5504 AR 0.7433
Epoch 322 batch 00004: Loss 0.0313 Regression loss 0.0142 Classification loss 0.0172 AP 0.2147 AR 0.4250
Epoch 322 batch 00005: Loss 0.0311 Regression loss 0.0156 Classification loss 0.0155 AP 0.3912 AR 0.6783
Epoch 322 batch 00006: Loss 0.0265 Regression loss 0.0138 Classification loss 0.0127 AP 0.2704 AR 0.5367
Epoch 322 batch 00007: Loss 0.0294 Regression loss 0.0162 Classification loss 0.0133 AP 0.3394 AR 0.6333
Epoch 322 batch 00008: Loss 0.0285 Regression loss 0.0136 Classification loss 0.0150 AP 0.2254 AR 0.5450
Epoch 322 batch 00009: Loss 0.0316 Regression loss 0.0164 Classification loss 0.0152 AP 0.2667 AR 0.4250
Epoch 322 batch 00010: Loss 0.0265 Regression loss 0.0131 Classification loss 0.0134 AP 0.4219 AR 0.8317
Epoch 323 batch 00001: Loss 0.0243 Regression loss 0.0142 Classification loss 0.0101 AP 0.3183 AR 0.5033
Epoch 323 batch 00002: Loss 0.0350 Regression loss 0.0165 Classification loss 0.0185 AP 0.2505 AR 0.5083
Epoch 323 batch 00003: Loss 0.0301 Regression loss 0.0142 Classification loss 0.0159 AP 0.3908 AR 0.7100
Epoch 323 batch 00004: Loss 0.0297 Regression loss 0.0130 Classification loss 0.0167 AP 0.2646 AR 0.5150
Epoch 323 batch 00005: Loss 0.0253 Regression loss 0.0128 Classification loss 0.0124 AP 0.3667 AR 0.6083
Epoch 323 batch 00006: Loss 0.0307 Regression loss 0.0167 Classification loss 0.0140 AP 0.3254 AR 0.5083
Epoch 323 batch 00007: Loss 0.0232 Regression loss 0.0142 Classification loss 0.0090 AP 0.3597 AR 0.5383
Epoch 323 batch 00008: Loss 0.0301 Regression loss 0.0156 Classification loss 0.0145 AP 0.2658 AR 0.5983
Epoch 323 batch 00009: Loss 0.0305 Regression loss 0.0164 Classification loss 0.0140 AP 0.2176 AR 0.3967
Epoch 323 batch 00010: Loss 0.0261 Regression loss 0.0132 Classification loss 0.0128 AP 0.3410 AR 0.7333
Epoch 324 batch 00001: Loss 0.0189 Regression loss 0.0118 Classification loss 0.0071 AP 0.4286 AR 0.5417
Epoch 324 batch 00002: Loss 0.0318 Regression loss 0.0141 Classification loss 0.0177 AP 0.3394 AR 0.6600
Epoch 324 batch 00003: Loss 0.0257 Regression loss 0.0120 Classification loss 0.0137 AP 0.3439 AR 0.6900
Epoch 324 batch 00004: Loss 0.0253 Regression loss 0.0116 Classification loss 0.0136 AP 0.4575 AR 0.7983
Epoch 324 batch 00005: Loss 0.0294 Regression loss 0.0154 Classification loss 0.0140 AP 0.3728 AR 0.5167
Epoch 324 batch 00006: Loss 0.0303 Regression loss 0.0167 Classification loss 0.0136 AP 0.3233 AR 0.6167
Epoch 324 batch 00007: Loss 0.0348 Regression loss 0.0157 Classification loss 0.0191 AP 0.2343 AR 0.4617
Epoch 324 batch 00008: Loss 0.0280 Regression loss 0.0162 Classification loss 0.0118 AP 0.2802 AR 0.6517
Epoch 324 batch 00009: Loss 0.0289 Regression loss 0.0151 Classification loss 0.0139 AP 0.2772 AR 0.4067
Epoch 324 batch 00010: Loss 0.0293 Regression loss 0.0150 Classification loss 0.0143 AP 0.4160 AR 0.8550
Epoch 325 batch 00001: Loss 0.0236 Regression loss 0.0109 Classification loss 0.0127 AP 0.3112 AR 0.4833
Epoch 325 batch 00002: Loss 0.0270 Regression loss 0.0155 Classification loss 0.0114 AP 0.3517 AR 0.6283
Epoch 325 batch 00003: Loss 0.0319 Regression loss 0.0140 Classification loss 0.0180 AP 0.3584 AR 0.5833
Epoch 325 batch 00004: Loss 0.0285 Regression loss 0.0156 Classification loss 0.0129 AP 0.2864 AR 0.5767
Epoch 325 batch 00005: Loss 0.0337 Regression loss 0.0137 Classification loss 0.0200 AP 0.2827 AR 0.6150
Epoch 325 batch 00006: Loss 0.0258 Regression loss 0.0141 Classification loss 0.0117 AP 0.2841 AR 0.5350
Epoch 325 batch 00007: Loss 0.0284 Regression loss 0.0184 Classification loss 0.0100 AP 0.2929 AR 0.6000
Epoch 325 batch 00008: Loss 0.0286 Regression loss 0.0147 Classification loss 0.0139 AP 0.2326 AR 0.4417
Epoch 325 batch 00009: Loss 0.0353 Regression loss 0.0182 Classification loss 0.0170 AP 0.2821 AR 0.5217
Epoch 325 batch 00010: Loss 0.0276 Regression loss 0.0151 Classification loss 0.0125 AP 0.2751 AR 0.5733
Epoch 326 batch 00001: Loss 0.0265 Regression loss 0.0137 Classification loss 0.0128 AP 0.4334 AR 0.7033
Epoch 326 batch 00002: Loss 0.0349 Regression loss 0.0156 Classification loss 0.0192 AP 0.4333 AR 0.8250
Epoch 326 batch 00003: Loss 0.0304 Regression loss 0.0157 Classification loss 0.0148 AP 0.3071 AR 0.6283
Epoch 326 batch 00004: Loss 0.0246 Regression loss 0.0128 Classification loss 0.0118 AP 0.3408 AR 0.6000
Epoch 326 batch 00005: Loss 0.0282 Regression loss 0.0152 Classification loss 0.0129 AP 0.2179 AR 0.4200
Epoch 326 batch 00006: Loss 0.0273 Regression loss 0.0166 Classification loss 0.0107 AP 0.3327 AR 0.6383
Epoch 326 batch 00007: Loss 0.0293 Regression loss 0.0160 Classification loss 0.0133 AP 0.2908 AR 0.4400
Epoch 326 batch 00008: Loss 0.0316 Regression loss 0.0152 Classification loss 0.0164 AP 0.2420 AR 0.5417
Epoch 326 batch 00009: Loss 0.0287 Regression loss 0.0163 Classification loss 0.0124 AP 0.2517 AR 0.5083
Epoch 326 batch 00010: Loss 0.0377 Regression loss 0.0198 Classification loss 0.0179 AP 0.2025 AR 0.4617
Epoch 327 batch 00001: Loss 0.0298 Regression loss 0.0158 Classification loss 0.0140 AP 0.3450 AR 0.5933
Epoch 327 batch 00002: Loss 0.0282 Regression loss 0.0156 Classification loss 0.0126 AP 0.4056 AR 0.6200
Epoch 327 batch 00003: Loss 0.0321 Regression loss 0.0162 Classification loss 0.0158 AP 0.2402 AR 0.4417
Epoch 327 batch 00004: Loss 0.0249 Regression loss 0.0138 Classification loss 0.0110 AP 0.2761 AR 0.5783
Epoch 327 batch 00005: Loss 0.0271 Regression loss 0.0145 Classification loss 0.0125 AP 0.3468 AR 0.5500
Epoch 327 batch 00006: Loss 0.0281 Regression loss 0.0172 Classification loss 0.0109 AP 0.2530 AR 0.6250
Epoch 327 batch 00007: Loss 0.0302 Regression loss 0.0169 Classification loss 0.0133 AP 0.2474 AR 0.4450
Epoch 327 batch 00008: Loss 0.0372 Regression loss 0.0163 Classification loss 0.0208 AP 0.3486 AR 0.6067
Epoch 327 batch 00009: Loss 0.0212 Regression loss 0.0115 Classification loss 0.0096 AP 0.4407 AR 0.8150
Epoch 327 batch 00010: Loss 0.0300 Regression loss 0.0153 Classification loss 0.0148 AP 0.2286 AR 0.4500
Epoch 328 batch 00001: Loss 0.0235 Regression loss 0.0128 Classification loss 0.0107 AP 0.3183 AR 0.6267
Epoch 328 batch 00002: Loss 0.0226 Regression loss 0.0120 Classification loss 0.0105 AP 0.4671 AR 0.7167
Epoch 328 batch 00003: Loss 0.0347 Regression loss 0.0158 Classification loss 0.0189 AP 0.3294 AR 0.6750
Epoch 328 batch 00004: Loss 0.0290 Regression loss 0.0138 Classification loss 0.0152 AP 0.3290 AR 0.5733
Epoch 328 batch 00005: Loss 0.0271 Regression loss 0.0153 Classification loss 0.0118 AP 0.2636 AR 0.5933
Epoch 328 batch 00006: Loss 0.0316 Regression loss 0.0162 Classification loss 0.0154 AP 0.2894 AR 0.5750
Epoch 328 batch 00007: Loss 0.0280 Regression loss 0.0144 Classification loss 0.0136 AP 0.2752 AR 0.4650
Epoch 328 batch 00008: Loss 0.0264 Regression loss 0.0149 Classification loss 0.0115 AP 0.3974 AR 0.7167
Epoch 328 batch 00009: Loss 0.0274 Regression loss 0.0148 Classification loss 0.0126 AP 0.2146 AR 0.4717
Epoch 328 batch 00010: Loss 0.0309 Regression loss 0.0180 Classification loss 0.0129 AP 0.1758 AR 0.3150
Epoch 329 batch 00001: Loss 0.0279 Regression loss 0.0134 Classification loss 0.0145 AP 0.3209 AR 0.5750
Epoch 329 batch 00002: Loss 0.0227 Regression loss 0.0147 Classification loss 0.0080 AP 0.3769 AR 0.6383
Epoch 329 batch 00003: Loss 0.0293 Regression loss 0.0149 Classification loss 0.0144 AP 0.3879 AR 0.6167
Epoch 329 batch 00004: Loss 0.0259 Regression loss 0.0140 Classification loss 0.0119 AP 0.3677 AR 0.6450
Epoch 329 batch 00005: Loss 0.0298 Regression loss 0.0155 Classification loss 0.0144 AP 0.2631 AR 0.3900
Epoch 329 batch 00006: Loss 0.0255 Regression loss 0.0141 Classification loss 0.0114 AP 0.4055 AR 0.8033
Epoch 329 batch 00007: Loss 0.0301 Regression loss 0.0158 Classification loss 0.0144 AP 0.2168 AR 0.4050
Epoch 329 batch 00008: Loss 0.0330 Regression loss 0.0163 Classification loss 0.0167 AP 0.2092 AR 0.4933
Epoch 329 batch 00009: Loss 0.0302 Regression loss 0.0129 Classification loss 0.0173 AP 0.3517 AR 0.5600
Epoch 329 batch 00010: Loss 0.0275 Regression loss 0.0142 Classification loss 0.0133 AP 0.2022 AR 0.4217
Epoch 330 batch 00001: Loss 0.0280 Regression loss 0.0153 Classification loss 0.0127 AP 0.3725 AR 0.9000
Epoch 330 batch 00002: Loss 0.0281 Regression loss 0.0145 Classification loss 0.0136 AP 0.2633 AR 0.5200
Epoch 330 batch 00003: Loss 0.0267 Regression loss 0.0140 Classification loss 0.0127 AP 0.3183 AR 0.6033
Epoch 330 batch 00004: Loss 0.0289 Regression loss 0.0149 Classification loss 0.0140 AP 0.3724 AR 0.6733
Epoch 330 batch 00005: Loss 0.0300 Regression loss 0.0165 Classification loss 0.0135 AP 0.3833 AR 0.5967
Epoch 330 batch 00006: Loss 0.0274 Regression loss 0.0131 Classification loss 0.0143 AP 0.4081 AR 0.5633
Epoch 330 batch 00007: Loss 0.0227 Regression loss 0.0121 Classification loss 0.0106 AP 0.2617 AR 0.5000
Epoch 330 batch 00008: Loss 0.0321 Regression loss 0.0147 Classification loss 0.0174 AP 0.3512 AR 0.6250
Epoch 330 batch 00009: Loss 0.0278 Regression loss 0.0140 Classification loss 0.0138 AP 0.4263 AR 0.6100
Epoch 330 batch 00010: Loss 0.0265 Regression loss 0.0145 Classification loss 0.0120 AP 0.2700 AR 0.4483
Epoch 331 batch 00001: Loss 0.0237 Regression loss 0.0150 Classification loss 0.0087 AP 0.3345 AR 0.5750
Epoch 331 batch 00002: Loss 0.0270 Regression loss 0.0132 Classification loss 0.0138 AP 0.2769 AR 0.5367
Epoch 331 batch 00003: Loss 0.0315 Regression loss 0.0144 Classification loss 0.0171 AP 0.3437 AR 0.4750
Epoch 331 batch 00004: Loss 0.0255 Regression loss 0.0136 Classification loss 0.0119 AP 0.2777 AR 0.6467
Epoch 331 batch 00005: Loss 0.0272 Regression loss 0.0148 Classification loss 0.0124 AP 0.4386 AR 0.7150
Epoch 331 batch 00006: Loss 0.0297 Regression loss 0.0135 Classification loss 0.0162 AP 0.2042 AR 0.4650
Epoch 331 batch 00007: Loss 0.0345 Regression loss 0.0145 Classification loss 0.0200 AP 0.2269 AR 0.3883
Epoch 331 batch 00008: Loss 0.0253 Regression loss 0.0137 Classification loss 0.0116 AP 0.4873 AR 0.7250
Epoch 331 batch 00009: Loss 0.0284 Regression loss 0.0148 Classification loss 0.0136 AP 0.2421 AR 0.4033
Epoch 331 batch 00010: Loss 0.0338 Regression loss 0.0150 Classification loss 0.0188 AP 0.3586 AR 0.6083
Epoch 332 batch 00001: Loss 0.0236 Regression loss 0.0129 Classification loss 0.0107 AP 0.3194 AR 0.6033
Epoch 332 batch 00002: Loss 0.0291 Regression loss 0.0140 Classification loss 0.0150 AP 0.3927 AR 0.7167
Epoch 332 batch 00003: Loss 0.0284 Regression loss 0.0141 Classification loss 0.0143 AP 0.4128 AR 0.7650
Epoch 332 batch 00004: Loss 0.0289 Regression loss 0.0164 Classification loss 0.0125 AP 0.3851 AR 0.8200
Epoch 332 batch 00005: Loss 0.0343 Regression loss 0.0164 Classification loss 0.0179 AP 0.2042 AR 0.3917
Epoch 332 batch 00006: Loss 0.0250 Regression loss 0.0117 Classification loss 0.0133 AP 0.4574 AR 0.5983
Epoch 332 batch 00007: Loss 0.0292 Regression loss 0.0163 Classification loss 0.0129 AP 0.2279 AR 0.4950
Epoch 332 batch 00008: Loss 0.0322 Regression loss 0.0145 Classification loss 0.0177 AP 0.2057 AR 0.4217
Epoch 332 batch 00009: Loss 0.0273 Regression loss 0.0146 Classification loss 0.0126 AP 0.2458 AR 0.5400
Epoch 332 batch 00010: Loss 0.0284 Regression loss 0.0153 Classification loss 0.0131 AP 0.2713 AR 0.4800
Epoch 333 batch 00001: Loss 0.0275 Regression loss 0.0144 Classification loss 0.0132 AP 0.3067 AR 0.6250
Epoch 333 batch 00002: Loss 0.0249 Regression loss 0.0144 Classification loss 0.0105 AP 0.3119 AR 0.6067
Epoch 333 batch 00003: Loss 0.0269 Regression loss 0.0122 Classification loss 0.0147 AP 0.3605 AR 0.5467
Epoch 333 batch 00004: Loss 0.0208 Regression loss 0.0123 Classification loss 0.0084 AP 0.4956 AR 0.7400
Epoch 333 batch 00005: Loss 0.0294 Regression loss 0.0162 Classification loss 0.0132 AP 0.2457 AR 0.4900
Epoch 333 batch 00006: Loss 0.0335 Regression loss 0.0162 Classification loss 0.0173 AP 0.1189 AR 0.2750
Epoch 333 batch 00007: Loss 0.0265 Regression loss 0.0142 Classification loss 0.0123 AP 0.2508 AR 0.4750
Epoch 333 batch 00008: Loss 0.0298 Regression loss 0.0147 Classification loss 0.0151 AP 0.1815 AR 0.3800
Epoch 333 batch 00009: Loss 0.0264 Regression loss 0.0135 Classification loss 0.0129 AP 0.2100 AR 0.4150
Epoch 333 batch 00010: Loss 0.0263 Regression loss 0.0159 Classification loss 0.0104 AP 0.3549 AR 0.7267
Epoch 334 batch 00001: Loss 0.0275 Regression loss 0.0145 Classification loss 0.0130 AP 0.2689 AR 0.5083
Epoch 334 batch 00002: Loss 0.0245 Regression loss 0.0121 Classification loss 0.0124 AP 0.3988 AR 0.6967
Epoch 334 batch 00003: Loss 0.0307 Regression loss 0.0145 Classification loss 0.0162 AP 0.4226 AR 0.7000
Epoch 334 batch 00004: Loss 0.0323 Regression loss 0.0155 Classification loss 0.0168 AP 0.3451 AR 0.5450
Epoch 334 batch 00005: Loss 0.0254 Regression loss 0.0147 Classification loss 0.0107 AP 0.3262 AR 0.6167
Epoch 334 batch 00006: Loss 0.0212 Regression loss 0.0130 Classification loss 0.0082 AP 0.3645 AR 0.6667
Epoch 334 batch 00007: Loss 0.0236 Regression loss 0.0128 Classification loss 0.0108 AP 0.3552 AR 0.5933
Epoch 334 batch 00008: Loss 0.0283 Regression loss 0.0160 Classification loss 0.0123 AP 0.2795 AR 0.5433
Epoch 334 batch 00009: Loss 0.0264 Regression loss 0.0127 Classification loss 0.0137 AP 0.3073 AR 0.6250
Epoch 334 batch 00010: Loss 0.0241 Regression loss 0.0114 Classification loss 0.0128 AP 0.3657 AR 0.6500
Epoch 335 batch 00001: Loss 0.0253 Regression loss 0.0134 Classification loss 0.0118 AP 0.4153 AR 0.7433
Epoch 335 batch 00002: Loss 0.0252 Regression loss 0.0127 Classification loss 0.0125 AP 0.3319 AR 0.6267
Epoch 335 batch 00003: Loss 0.0253 Regression loss 0.0133 Classification loss 0.0120 AP 0.3708 AR 0.6900
Epoch 335 batch 00004: Loss 0.0243 Regression loss 0.0151 Classification loss 0.0092 AP 0.3367 AR 0.4900
Epoch 335 batch 00005: Loss 0.0300 Regression loss 0.0136 Classification loss 0.0164 AP 0.3512 AR 0.5567
Epoch 335 batch 00006: Loss 0.0304 Regression loss 0.0150 Classification loss 0.0154 AP 0.4381 AR 0.7367
Epoch 335 batch 00007: Loss 0.0212 Regression loss 0.0107 Classification loss 0.0105 AP 0.3969 AR 0.6917
Epoch 335 batch 00008: Loss 0.0234 Regression loss 0.0128 Classification loss 0.0106 AP 0.3479 AR 0.5400
Epoch 335 batch 00009: Loss 0.0223 Regression loss 0.0145 Classification loss 0.0078 AP 0.3202 AR 0.6717
Epoch 335 batch 00010: Loss 0.0272 Regression loss 0.0150 Classification loss 0.0121 AP 0.2939 AR 0.5283
Epoch 336 batch 00001: Loss 0.0243 Regression loss 0.0120 Classification loss 0.0123 AP 0.3944 AR 0.6417
Epoch 336 batch 00002: Loss 0.0236 Regression loss 0.0118 Classification loss 0.0118 AP 0.3337 AR 0.5050
Epoch 336 batch 00003: Loss 0.0253 Regression loss 0.0150 Classification loss 0.0102 AP 0.3592 AR 0.5800
Epoch 336 batch 00004: Loss 0.0251 Regression loss 0.0133 Classification loss 0.0118 AP 0.3373 AR 0.5917
Epoch 336 batch 00005: Loss 0.0237 Regression loss 0.0150 Classification loss 0.0087 AP 0.2692 AR 0.5283
Epoch 336 batch 00006: Loss 0.0261 Regression loss 0.0125 Classification loss 0.0136 AP 0.2970 AR 0.6750
Epoch 336 batch 00007: Loss 0.0230 Regression loss 0.0127 Classification loss 0.0103 AP 0.3833 AR 0.6400
Epoch 336 batch 00008: Loss 0.0323 Regression loss 0.0157 Classification loss 0.0166 AP 0.1858 AR 0.3483
Epoch 336 batch 00009: Loss 0.0277 Regression loss 0.0145 Classification loss 0.0132 AP 0.4631 AR 0.7217
Epoch 336 batch 00010: Loss 0.0265 Regression loss 0.0125 Classification loss 0.0140 AP 0.3298 AR 0.5350
Epoch 337 batch 00001: Loss 0.0229 Regression loss 0.0140 Classification loss 0.0089 AP 0.2940 AR 0.5117
Epoch 337 batch 00002: Loss 0.0237 Regression loss 0.0121 Classification loss 0.0116 AP 0.4287 AR 0.8417
Epoch 337 batch 00003: Loss 0.0251 Regression loss 0.0133 Classification loss 0.0118 AP 0.2433 AR 0.4917
Epoch 337 batch 00004: Loss 0.0255 Regression loss 0.0146 Classification loss 0.0109 AP 0.3021 AR 0.6000
Epoch 337 batch 00005: Loss 0.0259 Regression loss 0.0141 Classification loss 0.0118 AP 0.2814 AR 0.5300
Epoch 337 batch 00006: Loss 0.0281 Regression loss 0.0156 Classification loss 0.0125 AP 0.3331 AR 0.4767
Epoch 337 batch 00007: Loss 0.0265 Regression loss 0.0130 Classification loss 0.0135 AP 0.3305 AR 0.6883
Epoch 337 batch 00008: Loss 0.0276 Regression loss 0.0152 Classification loss 0.0124 AP 0.1152 AR 0.2333
Epoch 337 batch 00009: Loss 0.0268 Regression loss 0.0146 Classification loss 0.0122 AP 0.4719 AR 0.6283
Epoch 337 batch 00010: Loss 0.0317 Regression loss 0.0138 Classification loss 0.0179 AP 0.3880 AR 0.6967
Epoch 338 batch 00001: Loss 0.0296 Regression loss 0.0189 Classification loss 0.0108 AP 0.1452 AR 0.3100
Epoch 338 batch 00002: Loss 0.0236 Regression loss 0.0122 Classification loss 0.0114 AP 0.3167 AR 0.5500
Epoch 338 batch 00003: Loss 0.0307 Regression loss 0.0164 Classification loss 0.0143 AP 0.3110 AR 0.4583
Epoch 338 batch 00004: Loss 0.0184 Regression loss 0.0121 Classification loss 0.0063 AP 0.4640 AR 0.6917
Epoch 338 batch 00005: Loss 0.0368 Regression loss 0.0176 Classification loss 0.0192 AP 0.1695 AR 0.3533
Epoch 338 batch 00006: Loss 0.0265 Regression loss 0.0156 Classification loss 0.0109 AP 0.2965 AR 0.5083
Epoch 338 batch 00007: Loss 0.0332 Regression loss 0.0168 Classification loss 0.0164 AP 0.3337 AR 0.5467
Epoch 338 batch 00008: Loss 0.0297 Regression loss 0.0172 Classification loss 0.0125 AP 0.4215 AR 0.6500
Epoch 338 batch 00009: Loss 0.0253 Regression loss 0.0141 Classification loss 0.0111 AP 0.2471 AR 0.4767
Epoch 338 batch 00010: Loss 0.0273 Regression loss 0.0173 Classification loss 0.0100 AP 0.2504 AR 0.3700
Epoch 339 batch 00001: Loss 0.0281 Regression loss 0.0131 Classification loss 0.0149 AP 0.2262 AR 0.3817
Epoch 339 batch 00002: Loss 0.0235 Regression loss 0.0152 Classification loss 0.0083 AP 0.2224 AR 0.4067
Epoch 339 batch 00003: Loss 0.0288 Regression loss 0.0167 Classification loss 0.0122 AP 0.2807 AR 0.5100
Epoch 339 batch 00004: Loss 0.0261 Regression loss 0.0146 Classification loss 0.0115 AP 0.4552 AR 0.7450
Epoch 339 batch 00005: Loss 0.0297 Regression loss 0.0160 Classification loss 0.0137 AP 0.2333 AR 0.4233
Epoch 339 batch 00006: Loss 0.0320 Regression loss 0.0160 Classification loss 0.0160 AP 0.1606 AR 0.3600
Epoch 339 batch 00007: Loss 0.0314 Regression loss 0.0184 Classification loss 0.0130 AP 0.3461 AR 0.6000
Epoch 339 batch 00008: Loss 0.0255 Regression loss 0.0139 Classification loss 0.0116 AP 0.4267 AR 0.8033
Epoch 339 batch 00009: Loss 0.0311 Regression loss 0.0165 Classification loss 0.0146 AP 0.3311 AR 0.5583
Epoch 339 batch 00010: Loss 0.0234 Regression loss 0.0123 Classification loss 0.0110 AP 0.2476 AR 0.3767
Epoch 340 batch 00001: Loss 0.0233 Regression loss 0.0125 Classification loss 0.0108 AP 0.3900 AR 0.7433
Epoch 340 batch 00002: Loss 0.0240 Regression loss 0.0136 Classification loss 0.0105 AP 0.2825 AR 0.5483
Epoch 340 batch 00003: Loss 0.0260 Regression loss 0.0170 Classification loss 0.0089 AP 0.2438 AR 0.4833
Epoch 340 batch 00004: Loss 0.0286 Regression loss 0.0140 Classification loss 0.0147 AP 0.3344 AR 0.6917
Epoch 340 batch 00005: Loss 0.0276 Regression loss 0.0141 Classification loss 0.0136 AP 0.2247 AR 0.4633
Epoch 340 batch 00006: Loss 0.0231 Regression loss 0.0137 Classification loss 0.0095 AP 0.1472 AR 0.3200
Epoch 340 batch 00007: Loss 0.0277 Regression loss 0.0144 Classification loss 0.0133 AP 0.5256 AR 0.8567
Epoch 340 batch 00008: Loss 0.0279 Regression loss 0.0168 Classification loss 0.0111 AP 0.3995 AR 0.5583
Epoch 340 batch 00009: Loss 0.0254 Regression loss 0.0131 Classification loss 0.0123 AP 0.2922 AR 0.5233
Epoch 340 batch 00010: Loss 0.0241 Regression loss 0.0127 Classification loss 0.0114 AP 0.3258 AR 0.6000
Epoch 341 batch 00001: Loss 0.0258 Regression loss 0.0138 Classification loss 0.0120 AP 0.3910 AR 0.6983
Epoch 341 batch 00002: Loss 0.0238 Regression loss 0.0121 Classification loss 0.0117 AP 0.4610 AR 0.6467
Epoch 341 batch 00003: Loss 0.0244 Regression loss 0.0143 Classification loss 0.0101 AP 0.3783 AR 0.6133
Epoch 341 batch 00004: Loss 0.0238 Regression loss 0.0149 Classification loss 0.0090 AP 0.2781 AR 0.5350
Epoch 341 batch 00005: Loss 0.0238 Regression loss 0.0133 Classification loss 0.0105 AP 0.4211 AR 0.6717
Epoch 341 batch 00006: Loss 0.0233 Regression loss 0.0136 Classification loss 0.0096 AP 0.2433 AR 0.4883
Epoch 341 batch 00007: Loss 0.0259 Regression loss 0.0144 Classification loss 0.0116 AP 0.2111 AR 0.3800
Epoch 341 batch 00008: Loss 0.0303 Regression loss 0.0142 Classification loss 0.0160 AP 0.3602 AR 0.6150
Epoch 341 batch 00009: Loss 0.0232 Regression loss 0.0135 Classification loss 0.0096 AP 0.2473 AR 0.5250
Epoch 341 batch 00010: Loss 0.0284 Regression loss 0.0130 Classification loss 0.0154 AP 0.3353 AR 0.6517
Epoch 342 batch 00001: Loss 0.0219 Regression loss 0.0107 Classification loss 0.0112 AP 0.3081 AR 0.5683
Epoch 342 batch 00002: Loss 0.0243 Regression loss 0.0140 Classification loss 0.0102 AP 0.3762 AR 0.6083
Epoch 342 batch 00003: Loss 0.0281 Regression loss 0.0132 Classification loss 0.0149 AP 0.3222 AR 0.4817
Epoch 342 batch 00004: Loss 0.0238 Regression loss 0.0137 Classification loss 0.0101 AP 0.3568 AR 0.5650
Epoch 342 batch 00005: Loss 0.0267 Regression loss 0.0146 Classification loss 0.0121 AP 0.3276 AR 0.5133
Epoch 342 batch 00006: Loss 0.0246 Regression loss 0.0126 Classification loss 0.0120 AP 0.3019 AR 0.5833
Epoch 342 batch 00007: Loss 0.0242 Regression loss 0.0142 Classification loss 0.0099 AP 0.4036 AR 0.5900
Epoch 342 batch 00008: Loss 0.0237 Regression loss 0.0111 Classification loss 0.0125 AP 0.3926 AR 0.6767
Epoch 342 batch 00009: Loss 0.0248 Regression loss 0.0134 Classification loss 0.0114 AP 0.3486 AR 0.6350
Epoch 342 batch 00010: Loss 0.0275 Regression loss 0.0146 Classification loss 0.0129 AP 0.2589 AR 0.4333
Epoch 343 batch 00001: Loss 0.0224 Regression loss 0.0119 Classification loss 0.0105 AP 0.2333 AR 0.4500
Epoch 343 batch 00002: Loss 0.0226 Regression loss 0.0125 Classification loss 0.0101 AP 0.2552 AR 0.5617
Epoch 343 batch 00003: Loss 0.0240 Regression loss 0.0121 Classification loss 0.0119 AP 0.2705 AR 0.5183
Epoch 343 batch 00004: Loss 0.0217 Regression loss 0.0127 Classification loss 0.0090 AP 0.5702 AR 0.8550
Epoch 343 batch 00005: Loss 0.0301 Regression loss 0.0157 Classification loss 0.0144 AP 0.2662 AR 0.3617
Epoch 343 batch 00006: Loss 0.0288 Regression loss 0.0150 Classification loss 0.0138 AP 0.3006 AR 0.6067
Epoch 343 batch 00007: Loss 0.0256 Regression loss 0.0130 Classification loss 0.0125 AP 0.3550 AR 0.5350
Epoch 343 batch 00008: Loss 0.0258 Regression loss 0.0139 Classification loss 0.0119 AP 0.2600 AR 0.4433
Epoch 343 batch 00009: Loss 0.0301 Regression loss 0.0163 Classification loss 0.0138 AP 0.2262 AR 0.5117
Epoch 343 batch 00010: Loss 0.0244 Regression loss 0.0133 Classification loss 0.0110 AP 0.3275 AR 0.7083
Epoch 344 batch 00001: Loss 0.0250 Regression loss 0.0146 Classification loss 0.0104 AP 0.3072 AR 0.4483
Epoch 344 batch 00002: Loss 0.0241 Regression loss 0.0127 Classification loss 0.0114 AP 0.2419 AR 0.4317
Epoch 344 batch 00003: Loss 0.0230 Regression loss 0.0126 Classification loss 0.0104 AP 0.4671 AR 0.6717
Epoch 344 batch 00004: Loss 0.0294 Regression loss 0.0149 Classification loss 0.0146 AP 0.2144 AR 0.4783
Epoch 344 batch 00005: Loss 0.0265 Regression loss 0.0148 Classification loss 0.0118 AP 0.3033 AR 0.5550
Epoch 344 batch 00006: Loss 0.0237 Regression loss 0.0115 Classification loss 0.0122 AP 0.3107 AR 0.6000
Epoch 344 batch 00007: Loss 0.0256 Regression loss 0.0140 Classification loss 0.0116 AP 0.2622 AR 0.4917
Epoch 344 batch 00008: Loss 0.0253 Regression loss 0.0146 Classification loss 0.0107 AP 0.4107 AR 0.7000
Epoch 344 batch 00009: Loss 0.0217 Regression loss 0.0118 Classification loss 0.0099 AP 0.3900 AR 0.6600
Epoch 344 batch 00010: Loss 0.0223 Regression loss 0.0118 Classification loss 0.0105 AP 0.4643 AR 0.5800
Epoch 345 batch 00001: Loss 0.0218 Regression loss 0.0116 Classification loss 0.0102 AP 0.5400 AR 0.6967
Epoch 345 batch 00002: Loss 0.0239 Regression loss 0.0118 Classification loss 0.0121 AP 0.3364 AR 0.6083
Epoch 345 batch 00003: Loss 0.0257 Regression loss 0.0143 Classification loss 0.0114 AP 0.4316 AR 0.7267
Epoch 345 batch 00004: Loss 0.0234 Regression loss 0.0136 Classification loss 0.0099 AP 0.2896 AR 0.5783
Epoch 345 batch 00005: Loss 0.0218 Regression loss 0.0126 Classification loss 0.0092 AP 0.3486 AR 0.5383
Epoch 345 batch 00006: Loss 0.0246 Regression loss 0.0128 Classification loss 0.0118 AP 0.4489 AR 0.8000
Epoch 345 batch 00007: Loss 0.0292 Regression loss 0.0150 Classification loss 0.0142 AP 0.2849 AR 0.6467
Epoch 345 batch 00008: Loss 0.0211 Regression loss 0.0120 Classification loss 0.0091 AP 0.4170 AR 0.6450
Epoch 345 batch 00009: Loss 0.0217 Regression loss 0.0121 Classification loss 0.0096 AP 0.3250 AR 0.7017
Epoch 345 batch 00010: Loss 0.0281 Regression loss 0.0147 Classification loss 0.0135 AP 0.3548 AR 0.4767
Epoch 346 batch 00001: Loss 0.0253 Regression loss 0.0142 Classification loss 0.0111 AP 0.3403 AR 0.6950
Epoch 346 batch 00002: Loss 0.0271 Regression loss 0.0142 Classification loss 0.0129 AP 0.3991 AR 0.5733
Epoch 346 batch 00003: Loss 0.0243 Regression loss 0.0116 Classification loss 0.0128 AP 0.4692 AR 0.6283
Epoch 346 batch 00004: Loss 0.0253 Regression loss 0.0146 Classification loss 0.0107 AP 0.2373 AR 0.4067
Epoch 346 batch 00005: Loss 0.0236 Regression loss 0.0125 Classification loss 0.0111 AP 0.3564 AR 0.7017
Epoch 346 batch 00006: Loss 0.0285 Regression loss 0.0154 Classification loss 0.0131 AP 0.2179 AR 0.4483
Epoch 346 batch 00007: Loss 0.0225 Regression loss 0.0125 Classification loss 0.0100 AP 0.3333 AR 0.6667
Epoch 346 batch 00008: Loss 0.0217 Regression loss 0.0138 Classification loss 0.0080 AP 0.3230 AR 0.7367
Epoch 346 batch 00009: Loss 0.0274 Regression loss 0.0140 Classification loss 0.0134 AP 0.4228 AR 0.6183
Epoch 346 batch 00010: Loss 0.0250 Regression loss 0.0134 Classification loss 0.0116 AP 0.3483 AR 0.6117
Epoch 347 batch 00001: Loss 0.0236 Regression loss 0.0139 Classification loss 0.0097 AP 0.4230 AR 0.7800
Epoch 347 batch 00002: Loss 0.0269 Regression loss 0.0151 Classification loss 0.0118 AP 0.2630 AR 0.4133
Epoch 347 batch 00003: Loss 0.0261 Regression loss 0.0129 Classification loss 0.0131 AP 0.4050 AR 0.5950
Epoch 347 batch 00004: Loss 0.0271 Regression loss 0.0140 Classification loss 0.0131 AP 0.4724 AR 0.8067
Epoch 347 batch 00005: Loss 0.0273 Regression loss 0.0164 Classification loss 0.0109 AP 0.4158 AR 0.6433
Epoch 347 batch 00006: Loss 0.0273 Regression loss 0.0150 Classification loss 0.0123 AP 0.2883 AR 0.5017
Epoch 347 batch 00007: Loss 0.0269 Regression loss 0.0130 Classification loss 0.0139 AP 0.2733 AR 0.4833
Epoch 347 batch 00008: Loss 0.0195 Regression loss 0.0120 Classification loss 0.0075 AP 0.2756 AR 0.5350
Epoch 347 batch 00009: Loss 0.0236 Regression loss 0.0141 Classification loss 0.0096 AP 0.4329 AR 0.6333
Epoch 347 batch 00010: Loss 0.0212 Regression loss 0.0128 Classification loss 0.0084 AP 0.3714 AR 0.6750
Epoch 348 batch 00001: Loss 0.0257 Regression loss 0.0156 Classification loss 0.0100 AP 0.3419 AR 0.6717
Epoch 348 batch 00002: Loss 0.0288 Regression loss 0.0129 Classification loss 0.0159 AP 0.4187 AR 0.5917
Epoch 348 batch 00003: Loss 0.0255 Regression loss 0.0151 Classification loss 0.0105 AP 0.3394 AR 0.5700
Epoch 348 batch 00004: Loss 0.0197 Regression loss 0.0105 Classification loss 0.0092 AP 0.4250 AR 0.6600
Epoch 348 batch 00005: Loss 0.0258 Regression loss 0.0134 Classification loss 0.0123 AP 0.2952 AR 0.5500
Epoch 348 batch 00006: Loss 0.0243 Regression loss 0.0127 Classification loss 0.0116 AP 0.2831 AR 0.4950
Epoch 348 batch 00007: Loss 0.0257 Regression loss 0.0143 Classification loss 0.0114 AP 0.3177 AR 0.6417
Epoch 348 batch 00008: Loss 0.0256 Regression loss 0.0150 Classification loss 0.0106 AP 0.3508 AR 0.5683
Epoch 348 batch 00009: Loss 0.0244 Regression loss 0.0135 Classification loss 0.0109 AP 0.3967 AR 0.5817
Epoch 348 batch 00010: Loss 0.0264 Regression loss 0.0121 Classification loss 0.0143 AP 0.1726 AR 0.3317
Epoch 349 batch 00001: Loss 0.0290 Regression loss 0.0139 Classification loss 0.0151 AP 0.2255 AR 0.4467
Epoch 349 batch 00002: Loss 0.0246 Regression loss 0.0131 Classification loss 0.0114 AP 0.3445 AR 0.6433
Epoch 349 batch 00003: Loss 0.0248 Regression loss 0.0128 Classification loss 0.0120 AP 0.2846 AR 0.4833
Epoch 349 batch 00004: Loss 0.0213 Regression loss 0.0114 Classification loss 0.0099 AP 0.3292 AR 0.5917
Epoch 349 batch 00005: Loss 0.0249 Regression loss 0.0129 Classification loss 0.0120 AP 0.2857 AR 0.5000
Epoch 349 batch 00006: Loss 0.0243 Regression loss 0.0143 Classification loss 0.0100 AP 0.2093 AR 0.4867
Epoch 349 batch 00007: Loss 0.0211 Regression loss 0.0139 Classification loss 0.0072 AP 0.3928 AR 0.5917
Epoch 349 batch 00008: Loss 0.0256 Regression loss 0.0136 Classification loss 0.0120 AP 0.3797 AR 0.6500
Epoch 349 batch 00009: Loss 0.0281 Regression loss 0.0141 Classification loss 0.0139 AP 0.3633 AR 0.5367
Epoch 349 batch 00010: Loss 0.0201 Regression loss 0.0123 Classification loss 0.0078 AP 0.3892 AR 0.7300
Epoch 350 batch 00001: Loss 0.0217 Regression loss 0.0136 Classification loss 0.0081 AP 0.2506 AR 0.4500
Epoch 350 batch 00002: Loss 0.0205 Regression loss 0.0111 Classification loss 0.0094 AP 0.5226 AR 0.7083
Epoch 350 batch 00003: Loss 0.0216 Regression loss 0.0128 Classification loss 0.0088 AP 0.5011 AR 0.8383
Epoch 350 batch 00004: Loss 0.0298 Regression loss 0.0137 Classification loss 0.0161 AP 0.2629 AR 0.4983
Epoch 350 batch 00005: Loss 0.0229 Regression loss 0.0116 Classification loss 0.0113 AP 0.3724 AR 0.6717
Epoch 350 batch 00006: Loss 0.0239 Regression loss 0.0119 Classification loss 0.0120 AP 0.3448 AR 0.6633
Epoch 350 batch 00007: Loss 0.0266 Regression loss 0.0101 Classification loss 0.0165 AP 0.5533 AR 0.8167
Epoch 350 batch 00008: Loss 0.0252 Regression loss 0.0132 Classification loss 0.0121 AP 0.2701 AR 0.5233
Epoch 350 batch 00009: Loss 0.0247 Regression loss 0.0149 Classification loss 0.0097 AP 0.2583 AR 0.4433
Epoch 350 batch 00010: Loss 0.0245 Regression loss 0.0155 Classification loss 0.0090 AP 0.2560 AR 0.5667
Epoch 351 batch 00001: Loss 0.0227 Regression loss 0.0124 Classification loss 0.0103 AP 0.3509 AR 0.7017
Epoch 351 batch 00002: Loss 0.0264 Regression loss 0.0133 Classification loss 0.0131 AP 0.2519 AR 0.4083
Epoch 351 batch 00003: Loss 0.0275 Regression loss 0.0165 Classification loss 0.0111 AP 0.2475 AR 0.4417
Epoch 351 batch 00004: Loss 0.0266 Regression loss 0.0140 Classification loss 0.0126 AP 0.4979 AR 0.5900
Epoch 351 batch 00005: Loss 0.0209 Regression loss 0.0124 Classification loss 0.0085 AP 0.3904 AR 0.7333
Epoch 351 batch 00006: Loss 0.0220 Regression loss 0.0121 Classification loss 0.0099 AP 0.3817 AR 0.5683
Epoch 351 batch 00007: Loss 0.0255 Regression loss 0.0116 Classification loss 0.0138 AP 0.2562 AR 0.5567
Epoch 351 batch 00008: Loss 0.0268 Regression loss 0.0157 Classification loss 0.0112 AP 0.1784 AR 0.3833
Epoch 351 batch 00009: Loss 0.0233 Regression loss 0.0119 Classification loss 0.0114 AP 0.3808 AR 0.7017
Epoch 351 batch 00010: Loss 0.0245 Regression loss 0.0144 Classification loss 0.0100 AP 0.3911 AR 0.6183
Epoch 352 batch 00001: Loss 0.0238 Regression loss 0.0146 Classification loss 0.0092 AP 0.3744 AR 0.5367
Epoch 352 batch 00002: Loss 0.0209 Regression loss 0.0103 Classification loss 0.0106 AP 0.2912 AR 0.5033
Epoch 352 batch 00003: Loss 0.0229 Regression loss 0.0125 Classification loss 0.0104 AP 0.2805 AR 0.5417
Epoch 352 batch 00004: Loss 0.0256 Regression loss 0.0134 Classification loss 0.0122 AP 0.3131 AR 0.5300
Epoch 352 batch 00005: Loss 0.0238 Regression loss 0.0131 Classification loss 0.0107 AP 0.2828 AR 0.5400
Epoch 352 batch 00006: Loss 0.0231 Regression loss 0.0112 Classification loss 0.0118 AP 0.3198 AR 0.5033
Epoch 352 batch 00007: Loss 0.0209 Regression loss 0.0135 Classification loss 0.0074 AP 0.2975 AR 0.5017
Epoch 352 batch 00008: Loss 0.0223 Regression loss 0.0143 Classification loss 0.0080 AP 0.3612 AR 0.5917
Epoch 352 batch 00009: Loss 0.0234 Regression loss 0.0121 Classification loss 0.0114 AP 0.3390 AR 0.5967
Epoch 352 batch 00010: Loss 0.0278 Regression loss 0.0134 Classification loss 0.0143 AP 0.2742 AR 0.6250
Epoch 353 batch 00001: Loss 0.0236 Regression loss 0.0122 Classification loss 0.0113 AP 0.3975 AR 0.6483
Epoch 353 batch 00002: Loss 0.0230 Regression loss 0.0125 Classification loss 0.0104 AP 0.4033 AR 0.7600
Epoch 353 batch 00003: Loss 0.0241 Regression loss 0.0121 Classification loss 0.0121 AP 0.2771 AR 0.4667
Epoch 353 batch 00004: Loss 0.0196 Regression loss 0.0130 Classification loss 0.0066 AP 0.4050 AR 0.5833
Epoch 353 batch 00005: Loss 0.0216 Regression loss 0.0116 Classification loss 0.0100 AP 0.4026 AR 0.6750
Epoch 353 batch 00006: Loss 0.0218 Regression loss 0.0134 Classification loss 0.0085 AP 0.3077 AR 0.6117
Epoch 353 batch 00007: Loss 0.0227 Regression loss 0.0118 Classification loss 0.0109 AP 0.3581 AR 0.6433
Epoch 353 batch 00008: Loss 0.0223 Regression loss 0.0131 Classification loss 0.0092 AP 0.4048 AR 0.6000
Epoch 353 batch 00009: Loss 0.0227 Regression loss 0.0139 Classification loss 0.0089 AP 0.2636 AR 0.5483
Epoch 353 batch 00010: Loss 0.0300 Regression loss 0.0139 Classification loss 0.0161 AP 0.2925 AR 0.4817
Epoch 354 batch 00001: Loss 0.0261 Regression loss 0.0138 Classification loss 0.0123 AP 0.3844 AR 0.6200
Epoch 354 batch 00002: Loss 0.0228 Regression loss 0.0133 Classification loss 0.0095 AP 0.2931 AR 0.4800
Epoch 354 batch 00003: Loss 0.0215 Regression loss 0.0112 Classification loss 0.0103 AP 0.3762 AR 0.5467
Epoch 354 batch 00004: Loss 0.0297 Regression loss 0.0139 Classification loss 0.0158 AP 0.3667 AR 0.6833
Epoch 354 batch 00005: Loss 0.0252 Regression loss 0.0144 Classification loss 0.0108 AP 0.4249 AR 0.6900
Epoch 354 batch 00006: Loss 0.0224 Regression loss 0.0124 Classification loss 0.0099 AP 0.3283 AR 0.6233
Epoch 354 batch 00007: Loss 0.0193 Regression loss 0.0123 Classification loss 0.0071 AP 0.2536 AR 0.4883
Epoch 354 batch 00008: Loss 0.0230 Regression loss 0.0117 Classification loss 0.0113 AP 0.2995 AR 0.5417
Epoch 354 batch 00009: Loss 0.0250 Regression loss 0.0123 Classification loss 0.0127 AP 0.2414 AR 0.4200
Epoch 354 batch 00010: Loss 0.0218 Regression loss 0.0148 Classification loss 0.0070 AP 0.3152 AR 0.6500
Epoch 355 batch 00001: Loss 0.0262 Regression loss 0.0140 Classification loss 0.0123 AP 0.4080 AR 0.6767
Epoch 355 batch 00002: Loss 0.0220 Regression loss 0.0124 Classification loss 0.0096 AP 0.2527 AR 0.5467
Epoch 355 batch 00003: Loss 0.0236 Regression loss 0.0122 Classification loss 0.0113 AP 0.3876 AR 0.5683
Epoch 355 batch 00004: Loss 0.0235 Regression loss 0.0127 Classification loss 0.0108 AP 0.3678 AR 0.5850
Epoch 355 batch 00005: Loss 0.0280 Regression loss 0.0153 Classification loss 0.0127 AP 0.1950 AR 0.3667
Epoch 355 batch 00006: Loss 0.0218 Regression loss 0.0133 Classification loss 0.0085 AP 0.2089 AR 0.4183
Epoch 355 batch 00007: Loss 0.0179 Regression loss 0.0104 Classification loss 0.0075 AP 0.3327 AR 0.7250
Epoch 355 batch 00008: Loss 0.0208 Regression loss 0.0114 Classification loss 0.0093 AP 0.4179 AR 0.7450
Epoch 355 batch 00009: Loss 0.0247 Regression loss 0.0144 Classification loss 0.0103 AP 0.2319 AR 0.4000
Epoch 355 batch 00010: Loss 0.0222 Regression loss 0.0116 Classification loss 0.0106 AP 0.3040 AR 0.4850
Epoch 356 batch 00001: Loss 0.0217 Regression loss 0.0148 Classification loss 0.0069 AP 0.2250 AR 0.4467
Epoch 356 batch 00002: Loss 0.0239 Regression loss 0.0119 Classification loss 0.0119 AP 0.1976 AR 0.4083
Epoch 356 batch 00003: Loss 0.0235 Regression loss 0.0128 Classification loss 0.0108 AP 0.3886 AR 0.5233
Epoch 356 batch 00004: Loss 0.0253 Regression loss 0.0152 Classification loss 0.0101 AP 0.3387 AR 0.6100
Epoch 356 batch 00005: Loss 0.0211 Regression loss 0.0129 Classification loss 0.0083 AP 0.3625 AR 0.5117
Epoch 356 batch 00006: Loss 0.0243 Regression loss 0.0136 Classification loss 0.0107 AP 0.4182 AR 0.7350
Epoch 356 batch 00007: Loss 0.0228 Regression loss 0.0124 Classification loss 0.0104 AP 0.2301 AR 0.3700
Epoch 356 batch 00008: Loss 0.0229 Regression loss 0.0125 Classification loss 0.0104 AP 0.3879 AR 0.6917
Epoch 356 batch 00009: Loss 0.0254 Regression loss 0.0120 Classification loss 0.0134 AP 0.3765 AR 0.7017
Epoch 356 batch 00010: Loss 0.0221 Regression loss 0.0119 Classification loss 0.0102 AP 0.3618 AR 0.5433
Epoch 357 batch 00001: Loss 0.0200 Regression loss 0.0110 Classification loss 0.0090 AP 0.3723 AR 0.5817
Epoch 357 batch 00002: Loss 0.0239 Regression loss 0.0140 Classification loss 0.0099 AP 0.3020 AR 0.6500
Epoch 357 batch 00003: Loss 0.0237 Regression loss 0.0129 Classification loss 0.0108 AP 0.2297 AR 0.3650
Epoch 357 batch 00004: Loss 0.0182 Regression loss 0.0120 Classification loss 0.0061 AP 0.3415 AR 0.6183
Epoch 357 batch 00005: Loss 0.0251 Regression loss 0.0124 Classification loss 0.0127 AP 0.3457 AR 0.7350
Epoch 357 batch 00006: Loss 0.0224 Regression loss 0.0123 Classification loss 0.0101 AP 0.3176 AR 0.6683
Epoch 357 batch 00007: Loss 0.0210 Regression loss 0.0131 Classification loss 0.0079 AP 0.4210 AR 0.6117
Epoch 357 batch 00008: Loss 0.0219 Regression loss 0.0131 Classification loss 0.0088 AP 0.2557 AR 0.5017
Epoch 357 batch 00009: Loss 0.0197 Regression loss 0.0102 Classification loss 0.0095 AP 0.5262 AR 0.9333
Epoch 357 batch 00010: Loss 0.0246 Regression loss 0.0138 Classification loss 0.0108 AP 0.3381 AR 0.5600
Epoch 358 batch 00001: Loss 0.0241 Regression loss 0.0145 Classification loss 0.0095 AP 0.2733 AR 0.4183
Epoch 358 batch 00002: Loss 0.0198 Regression loss 0.0120 Classification loss 0.0077 AP 0.3749 AR 0.5600
Epoch 358 batch 00003: Loss 0.0236 Regression loss 0.0112 Classification loss 0.0124 AP 0.3827 AR 0.7000
Epoch 358 batch 00004: Loss 0.0221 Regression loss 0.0139 Classification loss 0.0081 AP 0.2436 AR 0.5017
Epoch 358 batch 00005: Loss 0.0247 Regression loss 0.0119 Classification loss 0.0128 AP 0.3208 AR 0.5750
Epoch 358 batch 00006: Loss 0.0197 Regression loss 0.0118 Classification loss 0.0078 AP 0.3970 AR 0.6700
Epoch 358 batch 00007: Loss 0.0278 Regression loss 0.0135 Classification loss 0.0143 AP 0.3561 AR 0.4817
Epoch 358 batch 00008: Loss 0.0263 Regression loss 0.0154 Classification loss 0.0109 AP 0.2844 AR 0.4567
Epoch 358 batch 00009: Loss 0.0192 Regression loss 0.0119 Classification loss 0.0073 AP 0.4107 AR 0.7167
Epoch 358 batch 00010: Loss 0.0244 Regression loss 0.0127 Classification loss 0.0117 AP 0.2161 AR 0.4483
Epoch 359 batch 00001: Loss 0.0201 Regression loss 0.0124 Classification loss 0.0077 AP 0.2829 AR 0.5100
Epoch 359 batch 00002: Loss 0.0191 Regression loss 0.0106 Classification loss 0.0085 AP 0.3394 AR 0.6117
Epoch 359 batch 00003: Loss 0.0181 Regression loss 0.0109 Classification loss 0.0072 AP 0.3419 AR 0.6550
Epoch 359 batch 00004: Loss 0.0203 Regression loss 0.0118 Classification loss 0.0085 AP 0.5329 AR 0.7250
Epoch 359 batch 00005: Loss 0.0239 Regression loss 0.0121 Classification loss 0.0118 AP 0.3925 AR 0.6267
Epoch 359 batch 00006: Loss 0.0244 Regression loss 0.0155 Classification loss 0.0089 AP 0.3548 AR 0.6017
Epoch 359 batch 00007: Loss 0.0214 Regression loss 0.0117 Classification loss 0.0097 AP 0.2851 AR 0.6583
Epoch 359 batch 00008: Loss 0.0302 Regression loss 0.0135 Classification loss 0.0167 AP 0.2983 AR 0.6250
Epoch 359 batch 00009: Loss 0.0243 Regression loss 0.0137 Classification loss 0.0106 AP 0.2932 AR 0.5333
Epoch 359 batch 00010: Loss 0.0208 Regression loss 0.0106 Classification loss 0.0101 AP 0.3670 AR 0.6267
Epoch 360 batch 00001: Loss 0.0238 Regression loss 0.0143 Classification loss 0.0094 AP 0.4375 AR 0.6817
Epoch 360 batch 00002: Loss 0.0212 Regression loss 0.0131 Classification loss 0.0081 AP 0.3194 AR 0.6267
Epoch 360 batch 00003: Loss 0.0196 Regression loss 0.0114 Classification loss 0.0082 AP 0.5033 AR 0.6383
Epoch 360 batch 00004: Loss 0.0244 Regression loss 0.0152 Classification loss 0.0092 AP 0.1744 AR 0.2667
Epoch 360 batch 00005: Loss 0.0220 Regression loss 0.0127 Classification loss 0.0093 AP 0.3833 AR 0.7883
Epoch 360 batch 00006: Loss 0.0278 Regression loss 0.0142 Classification loss 0.0136 AP 0.2635 AR 0.4367
Epoch 360 batch 00007: Loss 0.0206 Regression loss 0.0123 Classification loss 0.0083 AP 0.3807 AR 0.6000
Epoch 360 batch 00008: Loss 0.0240 Regression loss 0.0140 Classification loss 0.0100 AP 0.2854 AR 0.5833
Epoch 360 batch 00009: Loss 0.0225 Regression loss 0.0116 Classification loss 0.0110 AP 0.3671 AR 0.6517
Epoch 360 batch 00010: Loss 0.0259 Regression loss 0.0147 Classification loss 0.0112 AP 0.2518 AR 0.5000
Epoch 361 batch 00001: Loss 0.0218 Regression loss 0.0113 Classification loss 0.0105 AP 0.2296 AR 0.4617
Epoch 361 batch 00002: Loss 0.0215 Regression loss 0.0141 Classification loss 0.0074 AP 0.2621 AR 0.4867
Epoch 361 batch 00003: Loss 0.0229 Regression loss 0.0127 Classification loss 0.0102 AP 0.3761 AR 0.6333
Epoch 361 batch 00004: Loss 0.0312 Regression loss 0.0126 Classification loss 0.0186 AP 0.3541 AR 0.5283
Epoch 361 batch 00005: Loss 0.0246 Regression loss 0.0122 Classification loss 0.0124 AP 0.2702 AR 0.5667
Epoch 361 batch 00006: Loss 0.0219 Regression loss 0.0114 Classification loss 0.0105 AP 0.3706 AR 0.5600
Epoch 361 batch 00007: Loss 0.0218 Regression loss 0.0118 Classification loss 0.0100 AP 0.3933 AR 0.8350
Epoch 361 batch 00008: Loss 0.0234 Regression loss 0.0154 Classification loss 0.0080 AP 0.3095 AR 0.4933
Epoch 361 batch 00009: Loss 0.0210 Regression loss 0.0112 Classification loss 0.0098 AP 0.4171 AR 0.6467
Epoch 361 batch 00010: Loss 0.0247 Regression loss 0.0138 Classification loss 0.0109 AP 0.2636 AR 0.4617
Epoch 362 batch 00001: Loss 0.0225 Regression loss 0.0136 Classification loss 0.0088 AP 0.2436 AR 0.3250
Epoch 362 batch 00002: Loss 0.0190 Regression loss 0.0097 Classification loss 0.0094 AP 0.4856 AR 0.8767
Epoch 362 batch 00003: Loss 0.0235 Regression loss 0.0133 Classification loss 0.0103 AP 0.3676 AR 0.5533
Epoch 362 batch 00004: Loss 0.0237 Regression loss 0.0118 Classification loss 0.0118 AP 0.2369 AR 0.4967
Epoch 362 batch 00005: Loss 0.0211 Regression loss 0.0131 Classification loss 0.0080 AP 0.2624 AR 0.4650
Epoch 362 batch 00006: Loss 0.0192 Regression loss 0.0120 Classification loss 0.0071 AP 0.5094 AR 0.7117
Epoch 362 batch 00007: Loss 0.0267 Regression loss 0.0139 Classification loss 0.0128 AP 0.3781 AR 0.7250
Epoch 362 batch 00008: Loss 0.0229 Regression loss 0.0147 Classification loss 0.0082 AP 0.3672 AR 0.6800
Epoch 362 batch 00009: Loss 0.0230 Regression loss 0.0132 Classification loss 0.0098 AP 0.1963 AR 0.3900
Epoch 362 batch 00010: Loss 0.0230 Regression loss 0.0143 Classification loss 0.0087 AP 0.2543 AR 0.4733
Epoch 363 batch 00001: Loss 0.0235 Regression loss 0.0145 Classification loss 0.0090 AP 0.3827 AR 0.6200
Epoch 363 batch 00002: Loss 0.0171 Regression loss 0.0103 Classification loss 0.0067 AP 0.3873 AR 0.6883
Epoch 363 batch 00003: Loss 0.0258 Regression loss 0.0135 Classification loss 0.0123 AP 0.2756 AR 0.5150
Epoch 363 batch 00004: Loss 0.0198 Regression loss 0.0120 Classification loss 0.0077 AP 0.2242 AR 0.4833
Epoch 363 batch 00005: Loss 0.0211 Regression loss 0.0135 Classification loss 0.0077 AP 0.3227 AR 0.6417
Epoch 363 batch 00006: Loss 0.0225 Regression loss 0.0125 Classification loss 0.0100 AP 0.3277 AR 0.5283
Epoch 363 batch 00007: Loss 0.0212 Regression loss 0.0115 Classification loss 0.0097 AP 0.3279 AR 0.6333
Epoch 363 batch 00008: Loss 0.0201 Regression loss 0.0128 Classification loss 0.0072 AP 0.4369 AR 0.6583
Epoch 363 batch 00009: Loss 0.0257 Regression loss 0.0126 Classification loss 0.0131 AP 0.3640 AR 0.5183
Epoch 363 batch 00010: Loss 0.0229 Regression loss 0.0131 Classification loss 0.0098 AP 0.2555 AR 0.4133
Epoch 364 batch 00001: Loss 0.0191 Regression loss 0.0116 Classification loss 0.0075 AP 0.2658 AR 0.4967
Epoch 364 batch 00002: Loss 0.0221 Regression loss 0.0128 Classification loss 0.0093 AP 0.4821 AR 0.6983
Epoch 364 batch 00003: Loss 0.0198 Regression loss 0.0109 Classification loss 0.0089 AP 0.4492 AR 0.7250
Epoch 364 batch 00004: Loss 0.0209 Regression loss 0.0106 Classification loss 0.0104 AP 0.2583 AR 0.5217
Epoch 364 batch 00005: Loss 0.0235 Regression loss 0.0123 Classification loss 0.0112 AP 0.2960 AR 0.5917
Epoch 364 batch 00006: Loss 0.0228 Regression loss 0.0126 Classification loss 0.0102 AP 0.3682 AR 0.5583
Epoch 364 batch 00007: Loss 0.0257 Regression loss 0.0160 Classification loss 0.0098 AP 0.3237 AR 0.6000
Epoch 364 batch 00008: Loss 0.0229 Regression loss 0.0130 Classification loss 0.0099 AP 0.3782 AR 0.6567
Epoch 364 batch 00009: Loss 0.0177 Regression loss 0.0107 Classification loss 0.0070 AP 0.4919 AR 0.7000
Epoch 364 batch 00010: Loss 0.0193 Regression loss 0.0109 Classification loss 0.0084 AP 0.3542 AR 0.5533
Epoch 365 batch 00001: Loss 0.0218 Regression loss 0.0116 Classification loss 0.0102 AP 0.4534 AR 0.6817
Epoch 365 batch 00002: Loss 0.0186 Regression loss 0.0121 Classification loss 0.0065 AP 0.3327 AR 0.6100
Epoch 365 batch 00003: Loss 0.0180 Regression loss 0.0111 Classification loss 0.0069 AP 0.4280 AR 0.7633
Epoch 365 batch 00004: Loss 0.0209 Regression loss 0.0129 Classification loss 0.0080 AP 0.2044 AR 0.2967
Epoch 365 batch 00005: Loss 0.0231 Regression loss 0.0124 Classification loss 0.0107 AP 0.3802 AR 0.7667
Epoch 365 batch 00006: Loss 0.0212 Regression loss 0.0118 Classification loss 0.0094 AP 0.2998 AR 0.5750
Epoch 365 batch 00007: Loss 0.0249 Regression loss 0.0119 Classification loss 0.0130 AP 0.3607 AR 0.6750
Epoch 365 batch 00008: Loss 0.0226 Regression loss 0.0119 Classification loss 0.0106 AP 0.4381 AR 0.6133
Epoch 365 batch 00009: Loss 0.0206 Regression loss 0.0124 Classification loss 0.0083 AP 0.3852 AR 0.6033
Epoch 365 batch 00010: Loss 0.0246 Regression loss 0.0145 Classification loss 0.0101 AP 0.1895 AR 0.3483
Epoch 366 batch 00001: Loss 0.0243 Regression loss 0.0132 Classification loss 0.0111 AP 0.2675 AR 0.4933
Epoch 366 batch 00002: Loss 0.0187 Regression loss 0.0109 Classification loss 0.0078 AP 0.3594 AR 0.5267
Epoch 366 batch 00003: Loss 0.0164 Regression loss 0.0106 Classification loss 0.0058 AP 0.2616 AR 0.5017
Epoch 366 batch 00004: Loss 0.0215 Regression loss 0.0122 Classification loss 0.0093 AP 0.4348 AR 0.6517
Epoch 366 batch 00005: Loss 0.0193 Regression loss 0.0096 Classification loss 0.0097 AP 0.4317 AR 0.7467
Epoch 366 batch 00006: Loss 0.0258 Regression loss 0.0118 Classification loss 0.0139 AP 0.4370 AR 0.6900
Epoch 366 batch 00007: Loss 0.0207 Regression loss 0.0115 Classification loss 0.0091 AP 0.4091 AR 0.7183
Epoch 366 batch 00008: Loss 0.0197 Regression loss 0.0109 Classification loss 0.0087 AP 0.4518 AR 0.7267
Epoch 366 batch 00009: Loss 0.0235 Regression loss 0.0155 Classification loss 0.0080 AP 0.2626 AR 0.4983
Epoch 366 batch 00010: Loss 0.0187 Regression loss 0.0119 Classification loss 0.0068 AP 0.3729 AR 0.6250
Epoch 367 batch 00001: Loss 0.0222 Regression loss 0.0126 Classification loss 0.0096 AP 0.4083 AR 0.6650
Epoch 367 batch 00002: Loss 0.0221 Regression loss 0.0125 Classification loss 0.0096 AP 0.3527 AR 0.6417
Epoch 367 batch 00003: Loss 0.0200 Regression loss 0.0119 Classification loss 0.0081 AP 0.2690 AR 0.5667
Epoch 367 batch 00004: Loss 0.0171 Regression loss 0.0117 Classification loss 0.0053 AP 0.3789 AR 0.6100
Epoch 367 batch 00005: Loss 0.0210 Regression loss 0.0121 Classification loss 0.0090 AP 0.3071 AR 0.5167
Epoch 367 batch 00006: Loss 0.0208 Regression loss 0.0123 Classification loss 0.0086 AP 0.2038 AR 0.4900
Epoch 367 batch 00007: Loss 0.0243 Regression loss 0.0140 Classification loss 0.0104 AP 0.2554 AR 0.5233
Epoch 367 batch 00008: Loss 0.0175 Regression loss 0.0123 Classification loss 0.0052 AP 0.3133 AR 0.5183
Epoch 367 batch 00009: Loss 0.0209 Regression loss 0.0118 Classification loss 0.0091 AP 0.4000 AR 0.6183
Epoch 367 batch 00010: Loss 0.0275 Regression loss 0.0152 Classification loss 0.0124 AP 0.3550 AR 0.6033
Epoch 368 batch 00001: Loss 0.0229 Regression loss 0.0129 Classification loss 0.0100 AP 0.2749 AR 0.5183
Epoch 368 batch 00002: Loss 0.0239 Regression loss 0.0125 Classification loss 0.0114 AP 0.4875 AR 0.6533
Epoch 368 batch 00003: Loss 0.0194 Regression loss 0.0122 Classification loss 0.0071 AP 0.2776 AR 0.5150
Epoch 368 batch 00004: Loss 0.0199 Regression loss 0.0121 Classification loss 0.0078 AP 0.3583 AR 0.6250
Epoch 368 batch 00005: Loss 0.0196 Regression loss 0.0136 Classification loss 0.0060 AP 0.2777 AR 0.5317
Epoch 368 batch 00006: Loss 0.0219 Regression loss 0.0115 Classification loss 0.0103 AP 0.3909 AR 0.6867
Epoch 368 batch 00007: Loss 0.0244 Regression loss 0.0134 Classification loss 0.0110 AP 0.3098 AR 0.5717
Epoch 368 batch 00008: Loss 0.0220 Regression loss 0.0136 Classification loss 0.0084 AP 0.2210 AR 0.4333
Epoch 368 batch 00009: Loss 0.0199 Regression loss 0.0108 Classification loss 0.0091 AP 0.3104 AR 0.5500
Epoch 368 batch 00010: Loss 0.0238 Regression loss 0.0134 Classification loss 0.0105 AP 0.2574 AR 0.6067
Epoch 369 batch 00001: Loss 0.0196 Regression loss 0.0109 Classification loss 0.0087 AP 0.5180 AR 0.7767
Epoch 369 batch 00002: Loss 0.0207 Regression loss 0.0136 Classification loss 0.0071 AP 0.3917 AR 0.5067
Epoch 369 batch 00003: Loss 0.0198 Regression loss 0.0133 Classification loss 0.0066 AP 0.2062 AR 0.4667
Epoch 369 batch 00004: Loss 0.0232 Regression loss 0.0166 Classification loss 0.0066 AP 0.2083 AR 0.3500
Epoch 369 batch 00005: Loss 0.0229 Regression loss 0.0124 Classification loss 0.0105 AP 0.2745 AR 0.5517
Epoch 369 batch 00006: Loss 0.0228 Regression loss 0.0134 Classification loss 0.0093 AP 0.3241 AR 0.6083
Epoch 369 batch 00007: Loss 0.0203 Regression loss 0.0115 Classification loss 0.0088 AP 0.3440 AR 0.6333
Epoch 369 batch 00008: Loss 0.0210 Regression loss 0.0145 Classification loss 0.0065 AP 0.2825 AR 0.6433
Epoch 369 batch 00009: Loss 0.0239 Regression loss 0.0138 Classification loss 0.0101 AP 0.3810 AR 0.6833
Epoch 369 batch 00010: Loss 0.0255 Regression loss 0.0129 Classification loss 0.0126 AP 0.3700 AR 0.5583
Epoch 370 batch 00001: Loss 0.0198 Regression loss 0.0115 Classification loss 0.0084 AP 0.3861 AR 0.7367
Epoch 370 batch 00002: Loss 0.0176 Regression loss 0.0125 Classification loss 0.0051 AP 0.3674 AR 0.5883
Epoch 370 batch 00003: Loss 0.0226 Regression loss 0.0124 Classification loss 0.0102 AP 0.3188 AR 0.6233
Epoch 370 batch 00004: Loss 0.0197 Regression loss 0.0100 Classification loss 0.0097 AP 0.3124 AR 0.5350
Epoch 370 batch 00005: Loss 0.0222 Regression loss 0.0134 Classification loss 0.0089 AP 0.4683 AR 0.6600
Epoch 370 batch 00006: Loss 0.0210 Regression loss 0.0137 Classification loss 0.0073 AP 0.3877 AR 0.7183
Epoch 370 batch 00007: Loss 0.0186 Regression loss 0.0107 Classification loss 0.0079 AP 0.4220 AR 0.6500
Epoch 370 batch 00008: Loss 0.0200 Regression loss 0.0123 Classification loss 0.0077 AP 0.4222 AR 0.6350
Epoch 370 batch 00009: Loss 0.0204 Regression loss 0.0125 Classification loss 0.0079 AP 0.4126 AR 0.6467
Epoch 370 batch 00010: Loss 0.0259 Regression loss 0.0132 Classification loss 0.0127 AP 0.3065 AR 0.4983
Epoch 371 batch 00001: Loss 0.0227 Regression loss 0.0108 Classification loss 0.0120 AP 0.3126 AR 0.5633
Epoch 371 batch 00002: Loss 0.0190 Regression loss 0.0120 Classification loss 0.0070 AP 0.3401 AR 0.6533
Epoch 371 batch 00003: Loss 0.0213 Regression loss 0.0129 Classification loss 0.0084 AP 0.4189 AR 0.8017
Epoch 371 batch 00004: Loss 0.0203 Regression loss 0.0121 Classification loss 0.0082 AP 0.3138 AR 0.6233
Epoch 371 batch 00005: Loss 0.0208 Regression loss 0.0118 Classification loss 0.0091 AP 0.2300 AR 0.4167
Epoch 371 batch 00006: Loss 0.0221 Regression loss 0.0108 Classification loss 0.0113 AP 0.3619 AR 0.6000
Epoch 371 batch 00007: Loss 0.0195 Regression loss 0.0121 Classification loss 0.0074 AP 0.3108 AR 0.5750
Epoch 371 batch 00008: Loss 0.0209 Regression loss 0.0112 Classification loss 0.0097 AP 0.4816 AR 0.7017
Epoch 371 batch 00009: Loss 0.0237 Regression loss 0.0113 Classification loss 0.0124 AP 0.3231 AR 0.5500
Epoch 371 batch 00010: Loss 0.0200 Regression loss 0.0139 Classification loss 0.0061 AP 0.3619 AR 0.5767
Epoch 372 batch 00001: Loss 0.0190 Regression loss 0.0119 Classification loss 0.0071 AP 0.2705 AR 0.5133
Epoch 372 batch 00002: Loss 0.0193 Regression loss 0.0109 Classification loss 0.0084 AP 0.4383 AR 0.6767
Epoch 372 batch 00003: Loss 0.0222 Regression loss 0.0132 Classification loss 0.0089 AP 0.3225 AR 0.5017
Epoch 372 batch 00004: Loss 0.0252 Regression loss 0.0160 Classification loss 0.0092 AP 0.2206 AR 0.4683
Epoch 372 batch 00005: Loss 0.0197 Regression loss 0.0108 Classification loss 0.0088 AP 0.2175 AR 0.4583
Epoch 372 batch 00006: Loss 0.0248 Regression loss 0.0130 Classification loss 0.0118 AP 0.4004 AR 0.6417
Epoch 372 batch 00007: Loss 0.0201 Regression loss 0.0125 Classification loss 0.0076 AP 0.3203 AR 0.6500
Epoch 372 batch 00008: Loss 0.0199 Regression loss 0.0113 Classification loss 0.0086 AP 0.4795 AR 0.7850
Epoch 372 batch 00009: Loss 0.0184 Regression loss 0.0111 Classification loss 0.0072 AP 0.4592 AR 0.7583
Epoch 372 batch 00010: Loss 0.0167 Regression loss 0.0099 Classification loss 0.0068 AP 0.3383 AR 0.5667
Epoch 373 batch 00001: Loss 0.0183 Regression loss 0.0097 Classification loss 0.0086 AP 0.5194 AR 0.7367
Epoch 373 batch 00002: Loss 0.0199 Regression loss 0.0105 Classification loss 0.0094 AP 0.3786 AR 0.6500
Epoch 373 batch 00003: Loss 0.0186 Regression loss 0.0113 Classification loss 0.0073 AP 0.4450 AR 0.7300
Epoch 373 batch 00004: Loss 0.0226 Regression loss 0.0149 Classification loss 0.0076 AP 0.4229 AR 0.7800
Epoch 373 batch 00005: Loss 0.0233 Regression loss 0.0126 Classification loss 0.0108 AP 0.2359 AR 0.3950
Epoch 373 batch 00006: Loss 0.0237 Regression loss 0.0119 Classification loss 0.0118 AP 0.4025 AR 0.6200
Epoch 373 batch 00007: Loss 0.0189 Regression loss 0.0117 Classification loss 0.0073 AP 0.3115 AR 0.5967
Epoch 373 batch 00008: Loss 0.0183 Regression loss 0.0123 Classification loss 0.0061 AP 0.2919 AR 0.4850
Epoch 373 batch 00009: Loss 0.0239 Regression loss 0.0120 Classification loss 0.0119 AP 0.2105 AR 0.3833
Epoch 373 batch 00010: Loss 0.0175 Regression loss 0.0106 Classification loss 0.0069 AP 0.3758 AR 0.5433
Epoch 374 batch 00001: Loss 0.0174 Regression loss 0.0104 Classification loss 0.0071 AP 0.4933 AR 0.6417
Epoch 374 batch 00002: Loss 0.0208 Regression loss 0.0112 Classification loss 0.0096 AP 0.5037 AR 0.8117
Epoch 374 batch 00003: Loss 0.0225 Regression loss 0.0118 Classification loss 0.0106 AP 0.4637 AR 0.6400
Epoch 374 batch 00004: Loss 0.0198 Regression loss 0.0121 Classification loss 0.0077 AP 0.4225 AR 0.6700
Epoch 374 batch 00005: Loss 0.0199 Regression loss 0.0126 Classification loss 0.0072 AP 0.4019 AR 0.6300
Epoch 374 batch 00006: Loss 0.0202 Regression loss 0.0123 Classification loss 0.0078 AP 0.4032 AR 0.6817
Epoch 374 batch 00007: Loss 0.0198 Regression loss 0.0121 Classification loss 0.0077 AP 0.3510 AR 0.6033
Epoch 374 batch 00008: Loss 0.0229 Regression loss 0.0129 Classification loss 0.0100 AP 0.3221 AR 0.5867
Epoch 374 batch 00009: Loss 0.0240 Regression loss 0.0122 Classification loss 0.0118 AP 0.3052 AR 0.5083
Epoch 374 batch 00010: Loss 0.0178 Regression loss 0.0099 Classification loss 0.0078 AP 0.3685 AR 0.7717
Epoch 375 batch 00001: Loss 0.0180 Regression loss 0.0111 Classification loss 0.0069 AP 0.4554 AR 0.7467
Epoch 375 batch 00002: Loss 0.0206 Regression loss 0.0131 Classification loss 0.0075 AP 0.3667 AR 0.7017
Epoch 375 batch 00003: Loss 0.0199 Regression loss 0.0120 Classification loss 0.0078 AP 0.3549 AR 0.6417
Epoch 375 batch 00004: Loss 0.0185 Regression loss 0.0090 Classification loss 0.0095 AP 0.4277 AR 0.6933
Epoch 375 batch 00005: Loss 0.0243 Regression loss 0.0141 Classification loss 0.0103 AP 0.4470 AR 0.6417
Epoch 375 batch 00006: Loss 0.0207 Regression loss 0.0100 Classification loss 0.0107 AP 0.4487 AR 0.7350
Epoch 375 batch 00007: Loss 0.0178 Regression loss 0.0115 Classification loss 0.0063 AP 0.3745 AR 0.6550
Epoch 375 batch 00008: Loss 0.0193 Regression loss 0.0107 Classification loss 0.0086 AP 0.2952 AR 0.4400
Epoch 375 batch 00009: Loss 0.0184 Regression loss 0.0107 Classification loss 0.0077 AP 0.2700 AR 0.5400
Epoch 375 batch 00010: Loss 0.0192 Regression loss 0.0117 Classification loss 0.0076 AP 0.2494 AR 0.5400
Epoch 376 batch 00001: Loss 0.0184 Regression loss 0.0124 Classification loss 0.0060 AP 0.4694 AR 0.7217
Epoch 376 batch 00002: Loss 0.0216 Regression loss 0.0131 Classification loss 0.0085 AP 0.3641 AR 0.6267
Epoch 376 batch 00003: Loss 0.0209 Regression loss 0.0129 Classification loss 0.0081 AP 0.3682 AR 0.6467
Epoch 376 batch 00004: Loss 0.0222 Regression loss 0.0115 Classification loss 0.0107 AP 0.4250 AR 0.7717
Epoch 376 batch 00005: Loss 0.0204 Regression loss 0.0125 Classification loss 0.0079 AP 0.2267 AR 0.3467
Epoch 376 batch 00006: Loss 0.0168 Regression loss 0.0118 Classification loss 0.0051 AP 0.3875 AR 0.7467
Epoch 376 batch 00007: Loss 0.0205 Regression loss 0.0108 Classification loss 0.0096 AP 0.3708 AR 0.5950
Epoch 376 batch 00008: Loss 0.0213 Regression loss 0.0106 Classification loss 0.0107 AP 0.4012 AR 0.5717
Epoch 376 batch 00009: Loss 0.0167 Regression loss 0.0086 Classification loss 0.0081 AP 0.3733 AR 0.7050
Epoch 376 batch 00010: Loss 0.0169 Regression loss 0.0110 Classification loss 0.0059 AP 0.3858 AR 0.5783
Epoch 377 batch 00001: Loss 0.0206 Regression loss 0.0118 Classification loss 0.0088 AP 0.4222 AR 0.7917
Epoch 377 batch 00002: Loss 0.0195 Regression loss 0.0128 Classification loss 0.0067 AP 0.4583 AR 0.6750
Epoch 377 batch 00003: Loss 0.0204 Regression loss 0.0121 Classification loss 0.0084 AP 0.2952 AR 0.5533
Epoch 377 batch 00004: Loss 0.0207 Regression loss 0.0109 Classification loss 0.0098 AP 0.3693 AR 0.5467
Epoch 377 batch 00005: Loss 0.0189 Regression loss 0.0105 Classification loss 0.0083 AP 0.4691 AR 0.8300
Epoch 377 batch 00006: Loss 0.0172 Regression loss 0.0114 Classification loss 0.0058 AP 0.3924 AR 0.6483
Epoch 377 batch 00007: Loss 0.0189 Regression loss 0.0121 Classification loss 0.0068 AP 0.3700 AR 0.7800
Epoch 377 batch 00008: Loss 0.0213 Regression loss 0.0120 Classification loss 0.0092 AP 0.2929 AR 0.5583
Epoch 377 batch 00009: Loss 0.0208 Regression loss 0.0119 Classification loss 0.0089 AP 0.2412 AR 0.3950
Epoch 377 batch 00010: Loss 0.0185 Regression loss 0.0117 Classification loss 0.0069 AP 0.4810 AR 0.7300
Epoch 378 batch 00001: Loss 0.0191 Regression loss 0.0111 Classification loss 0.0080 AP 0.2750 AR 0.5733
Epoch 378 batch 00002: Loss 0.0206 Regression loss 0.0128 Classification loss 0.0078 AP 0.3970 AR 0.6967
Epoch 378 batch 00003: Loss 0.0213 Regression loss 0.0130 Classification loss 0.0083 AP 0.3846 AR 0.6800
Epoch 378 batch 00004: Loss 0.0199 Regression loss 0.0114 Classification loss 0.0086 AP 0.3082 AR 0.5933
Epoch 378 batch 00005: Loss 0.0219 Regression loss 0.0128 Classification loss 0.0092 AP 0.3082 AR 0.5500
Epoch 378 batch 00006: Loss 0.0221 Regression loss 0.0130 Classification loss 0.0092 AP 0.3669 AR 0.7367
Epoch 378 batch 00007: Loss 0.0205 Regression loss 0.0129 Classification loss 0.0076 AP 0.3579 AR 0.5067
Epoch 378 batch 00008: Loss 0.0219 Regression loss 0.0144 Classification loss 0.0074 AP 0.2186 AR 0.5333
Epoch 378 batch 00009: Loss 0.0205 Regression loss 0.0122 Classification loss 0.0082 AP 0.4263 AR 0.6350
Epoch 378 batch 00010: Loss 0.0171 Regression loss 0.0104 Classification loss 0.0067 AP 0.5696 AR 0.8483
Epoch 379 batch 00001: Loss 0.0192 Regression loss 0.0122 Classification loss 0.0070 AP 0.4197 AR 0.6317
Epoch 379 batch 00002: Loss 0.0201 Regression loss 0.0121 Classification loss 0.0080 AP 0.4721 AR 0.7067
Epoch 379 batch 00003: Loss 0.0203 Regression loss 0.0117 Classification loss 0.0086 AP 0.4381 AR 0.6283
Epoch 379 batch 00004: Loss 0.0195 Regression loss 0.0102 Classification loss 0.0094 AP 0.4611 AR 0.7400
Epoch 379 batch 00005: Loss 0.0191 Regression loss 0.0109 Classification loss 0.0082 AP 0.2771 AR 0.4833
Epoch 379 batch 00006: Loss 0.0180 Regression loss 0.0109 Classification loss 0.0071 AP 0.4592 AR 0.7767
Epoch 379 batch 00007: Loss 0.0208 Regression loss 0.0124 Classification loss 0.0084 AP 0.3229 AR 0.6350
Epoch 379 batch 00008: Loss 0.0178 Regression loss 0.0112 Classification loss 0.0066 AP 0.2668 AR 0.4567
Epoch 379 batch 00009: Loss 0.0270 Regression loss 0.0137 Classification loss 0.0133 AP 0.3293 AR 0.6017
Epoch 379 batch 00010: Loss 0.0189 Regression loss 0.0101 Classification loss 0.0087 AP 0.3319 AR 0.5917
Epoch 380 batch 00001: Loss 0.0193 Regression loss 0.0121 Classification loss 0.0072 AP 0.3285 AR 0.6050
Epoch 380 batch 00002: Loss 0.0173 Regression loss 0.0106 Classification loss 0.0066 AP 0.4667 AR 0.5783
Epoch 380 batch 00003: Loss 0.0252 Regression loss 0.0122 Classification loss 0.0130 AP 0.4386 AR 0.6750
Epoch 380 batch 00004: Loss 0.0190 Regression loss 0.0119 Classification loss 0.0071 AP 0.3386 AR 0.5450
Epoch 380 batch 00005: Loss 0.0186 Regression loss 0.0122 Classification loss 0.0065 AP 0.4638 AR 0.6633
Epoch 380 batch 00006: Loss 0.0182 Regression loss 0.0117 Classification loss 0.0065 AP 0.2242 AR 0.4233
Epoch 380 batch 00007: Loss 0.0220 Regression loss 0.0107 Classification loss 0.0113 AP 0.4420 AR 0.8417
Epoch 380 batch 00008: Loss 0.0231 Regression loss 0.0134 Classification loss 0.0097 AP 0.3670 AR 0.5833
Epoch 380 batch 00009: Loss 0.0249 Regression loss 0.0146 Classification loss 0.0104 AP 0.3378 AR 0.6117
Epoch 380 batch 00010: Loss 0.0190 Regression loss 0.0102 Classification loss 0.0089 AP 0.4607 AR 0.6700
Epoch 381 batch 00001: Loss 0.0224 Regression loss 0.0115 Classification loss 0.0109 AP 0.4123 AR 0.6567
Epoch 381 batch 00002: Loss 0.0232 Regression loss 0.0117 Classification loss 0.0115 AP 0.4189 AR 0.7050
Epoch 381 batch 00003: Loss 0.0206 Regression loss 0.0121 Classification loss 0.0085 AP 0.4161 AR 0.5933
Epoch 381 batch 00004: Loss 0.0219 Regression loss 0.0111 Classification loss 0.0107 AP 0.3202 AR 0.5667
Epoch 381 batch 00005: Loss 0.0221 Regression loss 0.0114 Classification loss 0.0107 AP 0.2093 AR 0.4217
Epoch 381 batch 00006: Loss 0.0240 Regression loss 0.0129 Classification loss 0.0111 AP 0.3692 AR 0.6700
Epoch 381 batch 00007: Loss 0.0214 Regression loss 0.0135 Classification loss 0.0080 AP 0.3644 AR 0.6983
Epoch 381 batch 00008: Loss 0.0194 Regression loss 0.0123 Classification loss 0.0070 AP 0.2994 AR 0.6667
Epoch 381 batch 00009: Loss 0.0194 Regression loss 0.0119 Classification loss 0.0075 AP 0.3860 AR 0.6083
Epoch 381 batch 00010: Loss 0.0232 Regression loss 0.0107 Classification loss 0.0125 AP 0.4792 AR 0.6933
Epoch 382 batch 00001: Loss 0.0198 Regression loss 0.0118 Classification loss 0.0080 AP 0.4100 AR 0.6400
Epoch 382 batch 00002: Loss 0.0182 Regression loss 0.0114 Classification loss 0.0067 AP 0.3400 AR 0.6000
Epoch 382 batch 00003: Loss 0.0241 Regression loss 0.0157 Classification loss 0.0083 AP 0.3765 AR 0.5717
Epoch 382 batch 00004: Loss 0.0221 Regression loss 0.0123 Classification loss 0.0099 AP 0.3094 AR 0.5683
Epoch 382 batch 00005: Loss 0.0225 Regression loss 0.0123 Classification loss 0.0102 AP 0.3827 AR 0.6567
Epoch 382 batch 00006: Loss 0.0165 Regression loss 0.0105 Classification loss 0.0060 AP 0.4312 AR 0.6567
Epoch 382 batch 00007: Loss 0.0220 Regression loss 0.0147 Classification loss 0.0073 AP 0.2333 AR 0.4250
Epoch 382 batch 00008: Loss 0.0251 Regression loss 0.0126 Classification loss 0.0125 AP 0.4717 AR 0.6467
Epoch 382 batch 00009: Loss 0.0228 Regression loss 0.0115 Classification loss 0.0113 AP 0.5079 AR 0.8067
Epoch 382 batch 00010: Loss 0.0184 Regression loss 0.0104 Classification loss 0.0079 AP 0.3245 AR 0.6433
Epoch 383 batch 00001: Loss 0.0212 Regression loss 0.0125 Classification loss 0.0087 AP 0.2667 AR 0.5217
Epoch 383 batch 00002: Loss 0.0179 Regression loss 0.0120 Classification loss 0.0060 AP 0.2743 AR 0.5583
Epoch 383 batch 00003: Loss 0.0182 Regression loss 0.0095 Classification loss 0.0087 AP 0.4636 AR 0.8000
Epoch 383 batch 00004: Loss 0.0201 Regression loss 0.0127 Classification loss 0.0074 AP 0.3054 AR 0.5367
Epoch 383 batch 00005: Loss 0.0230 Regression loss 0.0129 Classification loss 0.0102 AP 0.2965 AR 0.5600
Epoch 383 batch 00006: Loss 0.0204 Regression loss 0.0127 Classification loss 0.0077 AP 0.4169 AR 0.7217
Epoch 383 batch 00007: Loss 0.0236 Regression loss 0.0126 Classification loss 0.0110 AP 0.4600 AR 0.6067
Epoch 383 batch 00008: Loss 0.0221 Regression loss 0.0146 Classification loss 0.0074 AP 0.5500 AR 0.6233
Epoch 383 batch 00009: Loss 0.0199 Regression loss 0.0129 Classification loss 0.0070 AP 0.3512 AR 0.5517
Epoch 383 batch 00010: Loss 0.0184 Regression loss 0.0111 Classification loss 0.0073 AP 0.1833 AR 0.4117
Epoch 384 batch 00001: Loss 0.0180 Regression loss 0.0134 Classification loss 0.0046 AP 0.2105 AR 0.4133
Epoch 384 batch 00002: Loss 0.0203 Regression loss 0.0135 Classification loss 0.0068 AP 0.2867 AR 0.5917
Epoch 384 batch 00003: Loss 0.0221 Regression loss 0.0142 Classification loss 0.0079 AP 0.2192 AR 0.4417
Epoch 384 batch 00004: Loss 0.0220 Regression loss 0.0112 Classification loss 0.0107 AP 0.3753 AR 0.6333
Epoch 384 batch 00005: Loss 0.0207 Regression loss 0.0115 Classification loss 0.0093 AP 0.2329 AR 0.4217
Epoch 384 batch 00006: Loss 0.0176 Regression loss 0.0108 Classification loss 0.0068 AP 0.5754 AR 0.8383
Epoch 384 batch 00007: Loss 0.0232 Regression loss 0.0130 Classification loss 0.0102 AP 0.4387 AR 0.6250
Epoch 384 batch 00008: Loss 0.0194 Regression loss 0.0111 Classification loss 0.0084 AP 0.4545 AR 0.7350
Epoch 384 batch 00009: Loss 0.0181 Regression loss 0.0132 Classification loss 0.0049 AP 0.4741 AR 0.8217
Epoch 384 batch 00010: Loss 0.0193 Regression loss 0.0123 Classification loss 0.0070 AP 0.3342 AR 0.5500
Epoch 385 batch 00001: Loss 0.0183 Regression loss 0.0123 Classification loss 0.0060 AP 0.3815 AR 0.6500
Epoch 385 batch 00002: Loss 0.0153 Regression loss 0.0099 Classification loss 0.0054 AP 0.3232 AR 0.4983
Epoch 385 batch 00003: Loss 0.0214 Regression loss 0.0122 Classification loss 0.0092 AP 0.2945 AR 0.5567
Epoch 385 batch 00004: Loss 0.0187 Regression loss 0.0124 Classification loss 0.0063 AP 0.2849 AR 0.5250
Epoch 385 batch 00005: Loss 0.0201 Regression loss 0.0113 Classification loss 0.0087 AP 0.3674 AR 0.7650
Epoch 385 batch 00006: Loss 0.0172 Regression loss 0.0114 Classification loss 0.0057 AP 0.3755 AR 0.6167
Epoch 385 batch 00007: Loss 0.0229 Regression loss 0.0123 Classification loss 0.0106 AP 0.3885 AR 0.6200
Epoch 385 batch 00008: Loss 0.0211 Regression loss 0.0142 Classification loss 0.0069 AP 0.2774 AR 0.5233
Epoch 385 batch 00009: Loss 0.0168 Regression loss 0.0113 Classification loss 0.0055 AP 0.3900 AR 0.7000
Epoch 385 batch 00010: Loss 0.0210 Regression loss 0.0131 Classification loss 0.0079 AP 0.3839 AR 0.6417
Epoch 386 batch 00001: Loss 0.0196 Regression loss 0.0108 Classification loss 0.0088 AP 0.2708 AR 0.4850
Epoch 386 batch 00002: Loss 0.0224 Regression loss 0.0147 Classification loss 0.0077 AP 0.3524 AR 0.5017
Epoch 386 batch 00003: Loss 0.0166 Regression loss 0.0117 Classification loss 0.0049 AP 0.2639 AR 0.5333
Epoch 386 batch 00004: Loss 0.0177 Regression loss 0.0121 Classification loss 0.0056 AP 0.3054 AR 0.5683
Epoch 386 batch 00005: Loss 0.0173 Regression loss 0.0103 Classification loss 0.0070 AP 0.2948 AR 0.6750
Epoch 386 batch 00006: Loss 0.0172 Regression loss 0.0110 Classification loss 0.0062 AP 0.3538 AR 0.6000
Epoch 386 batch 00007: Loss 0.0225 Regression loss 0.0117 Classification loss 0.0108 AP 0.3844 AR 0.6550
Epoch 386 batch 00008: Loss 0.0187 Regression loss 0.0122 Classification loss 0.0065 AP 0.4525 AR 0.6517
Epoch 386 batch 00009: Loss 0.0167 Regression loss 0.0104 Classification loss 0.0062 AP 0.3911 AR 0.6233
Epoch 386 batch 00010: Loss 0.0194 Regression loss 0.0120 Classification loss 0.0075 AP 0.3318 AR 0.5100
Epoch 387 batch 00001: Loss 0.0194 Regression loss 0.0105 Classification loss 0.0088 AP 0.3464 AR 0.5467
Epoch 387 batch 00002: Loss 0.0197 Regression loss 0.0113 Classification loss 0.0084 AP 0.3262 AR 0.6417
Epoch 387 batch 00003: Loss 0.0177 Regression loss 0.0103 Classification loss 0.0073 AP 0.3673 AR 0.5650
Epoch 387 batch 00004: Loss 0.0171 Regression loss 0.0111 Classification loss 0.0059 AP 0.3945 AR 0.6250
Epoch 387 batch 00005: Loss 0.0237 Regression loss 0.0127 Classification loss 0.0110 AP 0.3186 AR 0.6317
Epoch 387 batch 00006: Loss 0.0162 Regression loss 0.0113 Classification loss 0.0048 AP 0.3560 AR 0.5833
Epoch 387 batch 00007: Loss 0.0163 Regression loss 0.0109 Classification loss 0.0054 AP 0.3471 AR 0.6533
Epoch 387 batch 00008: Loss 0.0167 Regression loss 0.0101 Classification loss 0.0066 AP 0.4706 AR 0.7417
Epoch 387 batch 00009: Loss 0.0181 Regression loss 0.0118 Classification loss 0.0064 AP 0.3116 AR 0.5233
Epoch 387 batch 00010: Loss 0.0184 Regression loss 0.0120 Classification loss 0.0064 AP 0.3069 AR 0.4967
Epoch 388 batch 00001: Loss 0.0176 Regression loss 0.0109 Classification loss 0.0068 AP 0.3580 AR 0.5933
Epoch 388 batch 00002: Loss 0.0148 Regression loss 0.0098 Classification loss 0.0050 AP 0.4466 AR 0.6800
Epoch 388 batch 00003: Loss 0.0182 Regression loss 0.0106 Classification loss 0.0075 AP 0.1962 AR 0.3783
Epoch 388 batch 00004: Loss 0.0176 Regression loss 0.0110 Classification loss 0.0065 AP 0.4083 AR 0.6833
Epoch 388 batch 00005: Loss 0.0186 Regression loss 0.0109 Classification loss 0.0077 AP 0.4357 AR 0.6250
Epoch 388 batch 00006: Loss 0.0206 Regression loss 0.0121 Classification loss 0.0086 AP 0.3752 AR 0.6867
Epoch 388 batch 00007: Loss 0.0164 Regression loss 0.0100 Classification loss 0.0064 AP 0.3561 AR 0.5350
Epoch 388 batch 00008: Loss 0.0173 Regression loss 0.0102 Classification loss 0.0071 AP 0.3079 AR 0.7250
Epoch 388 batch 00009: Loss 0.0196 Regression loss 0.0120 Classification loss 0.0076 AP 0.3381 AR 0.6200
Epoch 388 batch 00010: Loss 0.0171 Regression loss 0.0108 Classification loss 0.0063 AP 0.3223 AR 0.6167
Epoch 389 batch 00001: Loss 0.0157 Regression loss 0.0113 Classification loss 0.0044 AP 0.3176 AR 0.4583
Epoch 389 batch 00002: Loss 0.0183 Regression loss 0.0120 Classification loss 0.0064 AP 0.3129 AR 0.4917
Epoch 389 batch 00003: Loss 0.0167 Regression loss 0.0103 Classification loss 0.0064 AP 0.4193 AR 0.6867
Epoch 389 batch 00004: Loss 0.0170 Regression loss 0.0106 Classification loss 0.0064 AP 0.4095 AR 0.6133
Epoch 389 batch 00005: Loss 0.0202 Regression loss 0.0108 Classification loss 0.0094 AP 0.3033 AR 0.5600
Epoch 389 batch 00006: Loss 0.0184 Regression loss 0.0107 Classification loss 0.0077 AP 0.4212 AR 0.6367
Epoch 389 batch 00007: Loss 0.0173 Regression loss 0.0101 Classification loss 0.0072 AP 0.3579 AR 0.6867
Epoch 389 batch 00008: Loss 0.0196 Regression loss 0.0125 Classification loss 0.0071 AP 0.2744 AR 0.3600
Epoch 389 batch 00009: Loss 0.0166 Regression loss 0.0092 Classification loss 0.0074 AP 0.4205 AR 0.7417
Epoch 389 batch 00010: Loss 0.0212 Regression loss 0.0118 Classification loss 0.0094 AP 0.4798 AR 0.7900
Epoch 390 batch 00001: Loss 0.0173 Regression loss 0.0100 Classification loss 0.0073 AP 0.4795 AR 0.7233
Epoch 390 batch 00002: Loss 0.0163 Regression loss 0.0105 Classification loss 0.0058 AP 0.5202 AR 0.8300
Epoch 390 batch 00003: Loss 0.0216 Regression loss 0.0131 Classification loss 0.0085 AP 0.4139 AR 0.6817
Epoch 390 batch 00004: Loss 0.0164 Regression loss 0.0110 Classification loss 0.0054 AP 0.3207 AR 0.4583
Epoch 390 batch 00005: Loss 0.0190 Regression loss 0.0118 Classification loss 0.0072 AP 0.4551 AR 0.8100
Epoch 390 batch 00006: Loss 0.0193 Regression loss 0.0128 Classification loss 0.0065 AP 0.3167 AR 0.6183
Epoch 390 batch 00007: Loss 0.0178 Regression loss 0.0119 Classification loss 0.0058 AP 0.3921 AR 0.7467
Epoch 390 batch 00008: Loss 0.0193 Regression loss 0.0116 Classification loss 0.0078 AP 0.2265 AR 0.3483
Epoch 390 batch 00009: Loss 0.0177 Regression loss 0.0100 Classification loss 0.0078 AP 0.3533 AR 0.6800
Epoch 390 batch 00010: Loss 0.0190 Regression loss 0.0104 Classification loss 0.0086 AP 0.4230 AR 0.7150
Epoch 391 batch 00001: Loss 0.0170 Regression loss 0.0097 Classification loss 0.0073 AP 0.3512 AR 0.6167
Epoch 391 batch 00002: Loss 0.0170 Regression loss 0.0104 Classification loss 0.0066 AP 0.5094 AR 0.7433
Epoch 391 batch 00003: Loss 0.0160 Regression loss 0.0101 Classification loss 0.0059 AP 0.4839 AR 0.7167
Epoch 391 batch 00004: Loss 0.0188 Regression loss 0.0107 Classification loss 0.0080 AP 0.5023 AR 0.8017
Epoch 391 batch 00005: Loss 0.0208 Regression loss 0.0135 Classification loss 0.0073 AP 0.4217 AR 0.6650
Epoch 391 batch 00006: Loss 0.0185 Regression loss 0.0119 Classification loss 0.0066 AP 0.3429 AR 0.5250
Epoch 391 batch 00007: Loss 0.0191 Regression loss 0.0116 Classification loss 0.0075 AP 0.2568 AR 0.4950
Epoch 391 batch 00008: Loss 0.0158 Regression loss 0.0103 Classification loss 0.0055 AP 0.4376 AR 0.6583
Epoch 391 batch 00009: Loss 0.0201 Regression loss 0.0111 Classification loss 0.0090 AP 0.3927 AR 0.6817
Epoch 391 batch 00010: Loss 0.0193 Regression loss 0.0113 Classification loss 0.0080 AP 0.4048 AR 0.5533
Epoch 392 batch 00001: Loss 0.0156 Regression loss 0.0106 Classification loss 0.0050 AP 0.3119 AR 0.5650
Epoch 392 batch 00002: Loss 0.0202 Regression loss 0.0122 Classification loss 0.0080 AP 0.3476 AR 0.5300
Epoch 392 batch 00003: Loss 0.0173 Regression loss 0.0111 Classification loss 0.0062 AP 0.3470 AR 0.5783
Epoch 392 batch 00004: Loss 0.0191 Regression loss 0.0099 Classification loss 0.0092 AP 0.5103 AR 0.7233
Epoch 392 batch 00005: Loss 0.0174 Regression loss 0.0105 Classification loss 0.0068 AP 0.4436 AR 0.7950
Epoch 392 batch 00006: Loss 0.0182 Regression loss 0.0112 Classification loss 0.0070 AP 0.2885 AR 0.5083
Epoch 392 batch 00007: Loss 0.0180 Regression loss 0.0107 Classification loss 0.0074 AP 0.3623 AR 0.7250
Epoch 392 batch 00008: Loss 0.0193 Regression loss 0.0117 Classification loss 0.0076 AP 0.2804 AR 0.5250
Epoch 392 batch 00009: Loss 0.0169 Regression loss 0.0103 Classification loss 0.0066 AP 0.2445 AR 0.5483
Epoch 392 batch 00010: Loss 0.0164 Regression loss 0.0110 Classification loss 0.0054 AP 0.4540 AR 0.7300
Epoch 393 batch 00001: Loss 0.0173 Regression loss 0.0108 Classification loss 0.0065 AP 0.4095 AR 0.7100
Epoch 393 batch 00002: Loss 0.0166 Regression loss 0.0092 Classification loss 0.0074 AP 0.2710 AR 0.4550
Epoch 393 batch 00003: Loss 0.0194 Regression loss 0.0102 Classification loss 0.0092 AP 0.2785 AR 0.5517
Epoch 393 batch 00004: Loss 0.0180 Regression loss 0.0125 Classification loss 0.0055 AP 0.3692 AR 0.6333
Epoch 393 batch 00005: Loss 0.0176 Regression loss 0.0103 Classification loss 0.0073 AP 0.3690 AR 0.6250
Epoch 393 batch 00006: Loss 0.0203 Regression loss 0.0115 Classification loss 0.0088 AP 0.3843 AR 0.7767
Epoch 393 batch 00007: Loss 0.0176 Regression loss 0.0115 Classification loss 0.0061 AP 0.4190 AR 0.6767
Epoch 393 batch 00008: Loss 0.0186 Regression loss 0.0108 Classification loss 0.0077 AP 0.4574 AR 0.7000
Epoch 393 batch 00009: Loss 0.0168 Regression loss 0.0101 Classification loss 0.0068 AP 0.3664 AR 0.6333
Epoch 393 batch 00010: Loss 0.0192 Regression loss 0.0116 Classification loss 0.0077 AP 0.4207 AR 0.6733
Epoch 394 batch 00001: Loss 0.0163 Regression loss 0.0090 Classification loss 0.0073 AP 0.5276 AR 0.8300
Epoch 394 batch 00002: Loss 0.0161 Regression loss 0.0108 Classification loss 0.0053 AP 0.3824 AR 0.6583
Epoch 394 batch 00003: Loss 0.0189 Regression loss 0.0104 Classification loss 0.0085 AP 0.3587 AR 0.6350
Epoch 394 batch 00004: Loss 0.0171 Regression loss 0.0108 Classification loss 0.0063 AP 0.2653 AR 0.4767
Epoch 394 batch 00005: Loss 0.0164 Regression loss 0.0112 Classification loss 0.0052 AP 0.3957 AR 0.6450
Epoch 394 batch 00006: Loss 0.0185 Regression loss 0.0120 Classification loss 0.0065 AP 0.4526 AR 0.6183
Epoch 394 batch 00007: Loss 0.0157 Regression loss 0.0091 Classification loss 0.0066 AP 0.4500 AR 0.6333
Epoch 394 batch 00008: Loss 0.0189 Regression loss 0.0098 Classification loss 0.0091 AP 0.2515 AR 0.4983
Epoch 394 batch 00009: Loss 0.0183 Regression loss 0.0102 Classification loss 0.0082 AP 0.4500 AR 0.6300
Epoch 394 batch 00010: Loss 0.0168 Regression loss 0.0114 Classification loss 0.0053 AP 0.2695 AR 0.4600
Epoch 395 batch 00001: Loss 0.0152 Regression loss 0.0104 Classification loss 0.0048 AP 0.2869 AR 0.4600
Epoch 395 batch 00002: Loss 0.0167 Regression loss 0.0107 Classification loss 0.0061 AP 0.3486 AR 0.6467
Epoch 395 batch 00003: Loss 0.0175 Regression loss 0.0104 Classification loss 0.0071 AP 0.3741 AR 0.7417
Epoch 395 batch 00004: Loss 0.0163 Regression loss 0.0098 Classification loss 0.0065 AP 0.4444 AR 0.6733
Epoch 395 batch 00005: Loss 0.0141 Regression loss 0.0096 Classification loss 0.0046 AP 0.3829 AR 0.6350
Epoch 395 batch 00006: Loss 0.0199 Regression loss 0.0111 Classification loss 0.0088 AP 0.3575 AR 0.5550
Epoch 395 batch 00007: Loss 0.0201 Regression loss 0.0111 Classification loss 0.0090 AP 0.4432 AR 0.7200
Epoch 395 batch 00008: Loss 0.0187 Regression loss 0.0115 Classification loss 0.0071 AP 0.4758 AR 0.6500
Epoch 395 batch 00009: Loss 0.0173 Regression loss 0.0103 Classification loss 0.0070 AP 0.2673 AR 0.4083
Epoch 395 batch 00010: Loss 0.0184 Regression loss 0.0106 Classification loss 0.0078 AP 0.3850 AR 0.7550
Epoch 396 batch 00001: Loss 0.0185 Regression loss 0.0114 Classification loss 0.0071 AP 0.4131 AR 0.7083
Epoch 396 batch 00002: Loss 0.0209 Regression loss 0.0124 Classification loss 0.0085 AP 0.3038 AR 0.6783
Epoch 396 batch 00003: Loss 0.0192 Regression loss 0.0129 Classification loss 0.0063 AP 0.4200 AR 0.6833
Epoch 396 batch 00004: Loss 0.0162 Regression loss 0.0097 Classification loss 0.0065 AP 0.2995 AR 0.6000
Epoch 396 batch 00005: Loss 0.0183 Regression loss 0.0104 Classification loss 0.0079 AP 0.3554 AR 0.6450
Epoch 396 batch 00006: Loss 0.0163 Regression loss 0.0108 Classification loss 0.0055 AP 0.4536 AR 0.7167
Epoch 396 batch 00007: Loss 0.0173 Regression loss 0.0094 Classification loss 0.0078 AP 0.4213 AR 0.6533
Epoch 396 batch 00008: Loss 0.0159 Regression loss 0.0102 Classification loss 0.0056 AP 0.2590 AR 0.4583
Epoch 396 batch 00009: Loss 0.0174 Regression loss 0.0107 Classification loss 0.0068 AP 0.4017 AR 0.6550
Epoch 396 batch 00010: Loss 0.0167 Regression loss 0.0107 Classification loss 0.0060 AP 0.5054 AR 0.7267
Epoch 397 batch 00001: Loss 0.0173 Regression loss 0.0100 Classification loss 0.0074 AP 0.4943 AR 0.6900
Epoch 397 batch 00002: Loss 0.0183 Regression loss 0.0115 Classification loss 0.0068 AP 0.4235 AR 0.7917
Epoch 397 batch 00003: Loss 0.0175 Regression loss 0.0090 Classification loss 0.0085 AP 0.4393 AR 0.7800
Epoch 397 batch 00004: Loss 0.0175 Regression loss 0.0113 Classification loss 0.0062 AP 0.2487 AR 0.3950
Epoch 397 batch 00005: Loss 0.0191 Regression loss 0.0112 Classification loss 0.0079 AP 0.4143 AR 0.5867
Epoch 397 batch 00006: Loss 0.0170 Regression loss 0.0097 Classification loss 0.0073 AP 0.3638 AR 0.5633
Epoch 397 batch 00007: Loss 0.0154 Regression loss 0.0106 Classification loss 0.0048 AP 0.3772 AR 0.6483
Epoch 397 batch 00008: Loss 0.0146 Regression loss 0.0101 Classification loss 0.0046 AP 0.3461 AR 0.6417
Epoch 397 batch 00009: Loss 0.0168 Regression loss 0.0113 Classification loss 0.0055 AP 0.3198 AR 0.5500
Epoch 397 batch 00010: Loss 0.0185 Regression loss 0.0098 Classification loss 0.0086 AP 0.3757 AR 0.6483
Epoch 398 batch 00001: Loss 0.0182 Regression loss 0.0107 Classification loss 0.0075 AP 0.2607 AR 0.5167
Epoch 398 batch 00002: Loss 0.0212 Regression loss 0.0122 Classification loss 0.0090 AP 0.4487 AR 0.7367
Epoch 398 batch 00003: Loss 0.0188 Regression loss 0.0113 Classification loss 0.0076 AP 0.3469 AR 0.5867
Epoch 398 batch 00004: Loss 0.0141 Regression loss 0.0084 Classification loss 0.0058 AP 0.5494 AR 0.7583
Epoch 398 batch 00005: Loss 0.0153 Regression loss 0.0109 Classification loss 0.0044 AP 0.4584 AR 0.6817
Epoch 398 batch 00006: Loss 0.0158 Regression loss 0.0100 Classification loss 0.0058 AP 0.3713 AR 0.6700
Epoch 398 batch 00007: Loss 0.0144 Regression loss 0.0090 Classification loss 0.0054 AP 0.4988 AR 0.7750
Epoch 398 batch 00008: Loss 0.0219 Regression loss 0.0137 Classification loss 0.0082 AP 0.1759 AR 0.3900
Epoch 398 batch 00009: Loss 0.0181 Regression loss 0.0107 Classification loss 0.0073 AP 0.2650 AR 0.5000
Epoch 398 batch 00010: Loss 0.0168 Regression loss 0.0100 Classification loss 0.0067 AP 0.5205 AR 0.8500
Epoch 399 batch 00001: Loss 0.0152 Regression loss 0.0087 Classification loss 0.0065 AP 0.5309 AR 0.7550
Epoch 399 batch 00002: Loss 0.0191 Regression loss 0.0105 Classification loss 0.0087 AP 0.2978 AR 0.5850
Epoch 399 batch 00003: Loss 0.0199 Regression loss 0.0119 Classification loss 0.0080 AP 0.3645 AR 0.5667
Epoch 399 batch 00004: Loss 0.0194 Regression loss 0.0107 Classification loss 0.0087 AP 0.4989 AR 0.6917
Epoch 399 batch 00005: Loss 0.0169 Regression loss 0.0116 Classification loss 0.0054 AP 0.2971 AR 0.5333
Epoch 399 batch 00006: Loss 0.0169 Regression loss 0.0106 Classification loss 0.0062 AP 0.4159 AR 0.7350
Epoch 399 batch 00007: Loss 0.0174 Regression loss 0.0116 Classification loss 0.0058 AP 0.3029 AR 0.6183
Epoch 399 batch 00008: Loss 0.0163 Regression loss 0.0105 Classification loss 0.0058 AP 0.4626 AR 0.7367
Epoch 399 batch 00009: Loss 0.0177 Regression loss 0.0094 Classification loss 0.0083 AP 0.3417 AR 0.7333
Epoch 399 batch 00010: Loss 0.0140 Regression loss 0.0100 Classification loss 0.0040 AP 0.3234 AR 0.6167
Epoch 400 batch 00001: Loss 0.0174 Regression loss 0.0101 Classification loss 0.0073 AP 0.4565 AR 0.7217
Epoch 400 batch 00002: Loss 0.0176 Regression loss 0.0105 Classification loss 0.0071 AP 0.3576 AR 0.6750
Epoch 400 batch 00003: Loss 0.0173 Regression loss 0.0104 Classification loss 0.0069 AP 0.5563 AR 0.7833
Epoch 400 batch 00004: Loss 0.0183 Regression loss 0.0107 Classification loss 0.0076 AP 0.2539 AR 0.5633
Epoch 400 batch 00005: Loss 0.0162 Regression loss 0.0102 Classification loss 0.0060 AP 0.4269 AR 0.5500
Epoch 400 batch 00006: Loss 0.0169 Regression loss 0.0098 Classification loss 0.0071 AP 0.3275 AR 0.6283
Epoch 400 batch 00007: Loss 0.0173 Regression loss 0.0105 Classification loss 0.0068 AP 0.3533 AR 0.6917
Epoch 400 batch 00008: Loss 0.0141 Regression loss 0.0095 Classification loss 0.0046 AP 0.4308 AR 0.7600
Epoch 400 batch 00009: Loss 0.0193 Regression loss 0.0111 Classification loss 0.0082 AP 0.3675 AR 0.6083
Epoch 400 batch 00010: Loss 0.0160 Regression loss 0.0104 Classification loss 0.0056 AP 0.3364 AR 0.5150
Epoch 401 batch 00001: Loss 0.0180 Regression loss 0.0113 Classification loss 0.0067 AP 0.2521 AR 0.5250
Epoch 401 batch 00002: Loss 0.0181 Regression loss 0.0110 Classification loss 0.0071 AP 0.2898 AR 0.5567
Epoch 401 batch 00003: Loss 0.0175 Regression loss 0.0101 Classification loss 0.0074 AP 0.5076 AR 0.6000
Epoch 401 batch 00004: Loss 0.0173 Regression loss 0.0107 Classification loss 0.0066 AP 0.3669 AR 0.5750
Epoch 401 batch 00005: Loss 0.0185 Regression loss 0.0108 Classification loss 0.0076 AP 0.4579 AR 0.6450
Epoch 401 batch 00006: Loss 0.0209 Regression loss 0.0112 Classification loss 0.0096 AP 0.3768 AR 0.6617
Epoch 401 batch 00007: Loss 0.0162 Regression loss 0.0106 Classification loss 0.0056 AP 0.3616 AR 0.6183
Epoch 401 batch 00008: Loss 0.0150 Regression loss 0.0102 Classification loss 0.0048 AP 0.2833 AR 0.5800
Epoch 401 batch 00009: Loss 0.0182 Regression loss 0.0127 Classification loss 0.0055 AP 0.2781 AR 0.5250
Epoch 401 batch 00010: Loss 0.0217 Regression loss 0.0134 Classification loss 0.0083 AP 0.4271 AR 0.7933
Epoch 402 batch 00001: Loss 0.0164 Regression loss 0.0103 Classification loss 0.0061 AP 0.3693 AR 0.6100
Epoch 402 batch 00002: Loss 0.0164 Regression loss 0.0105 Classification loss 0.0059 AP 0.3865 AR 0.5950
Epoch 402 batch 00003: Loss 0.0206 Regression loss 0.0111 Classification loss 0.0096 AP 0.3310 AR 0.5250
Epoch 402 batch 00004: Loss 0.0180 Regression loss 0.0097 Classification loss 0.0083 AP 0.4067 AR 0.5833
Epoch 402 batch 00005: Loss 0.0174 Regression loss 0.0134 Classification loss 0.0040 AP 0.2475 AR 0.4417
Epoch 402 batch 00006: Loss 0.0166 Regression loss 0.0117 Classification loss 0.0049 AP 0.3156 AR 0.5917
Epoch 402 batch 00007: Loss 0.0176 Regression loss 0.0097 Classification loss 0.0079 AP 0.4468 AR 0.7200
Epoch 402 batch 00008: Loss 0.0206 Regression loss 0.0122 Classification loss 0.0084 AP 0.2291 AR 0.4550
Epoch 402 batch 00009: Loss 0.0192 Regression loss 0.0128 Classification loss 0.0064 AP 0.3008 AR 0.5383
Epoch 402 batch 00010: Loss 0.0160 Regression loss 0.0101 Classification loss 0.0060 AP 0.5580 AR 0.8800
Epoch 403 batch 00001: Loss 0.0168 Regression loss 0.0100 Classification loss 0.0068 AP 0.4717 AR 0.6867
Epoch 403 batch 00002: Loss 0.0158 Regression loss 0.0094 Classification loss 0.0064 AP 0.4339 AR 0.6850
Epoch 403 batch 00003: Loss 0.0182 Regression loss 0.0102 Classification loss 0.0081 AP 0.5321 AR 0.7417
Epoch 403 batch 00004: Loss 0.0189 Regression loss 0.0103 Classification loss 0.0086 AP 0.2558 AR 0.5450
Epoch 403 batch 00005: Loss 0.0188 Regression loss 0.0119 Classification loss 0.0069 AP 0.4166 AR 0.5667
Epoch 403 batch 00006: Loss 0.0166 Regression loss 0.0107 Classification loss 0.0059 AP 0.3546 AR 0.6667
Epoch 403 batch 00007: Loss 0.0184 Regression loss 0.0106 Classification loss 0.0078 AP 0.4831 AR 0.7517
Epoch 403 batch 00008: Loss 0.0144 Regression loss 0.0101 Classification loss 0.0043 AP 0.4231 AR 0.8000
Epoch 403 batch 00009: Loss 0.0174 Regression loss 0.0124 Classification loss 0.0049 AP 0.2967 AR 0.4983
Epoch 403 batch 00010: Loss 0.0197 Regression loss 0.0117 Classification loss 0.0080 AP 0.1591 AR 0.2917
Epoch 404 batch 00001: Loss 0.0193 Regression loss 0.0118 Classification loss 0.0075 AP 0.2116 AR 0.4000
Epoch 404 batch 00002: Loss 0.0153 Regression loss 0.0109 Classification loss 0.0044 AP 0.2771 AR 0.4417
Epoch 404 batch 00003: Loss 0.0151 Regression loss 0.0096 Classification loss 0.0055 AP 0.5867 AR 0.8050
Epoch 404 batch 00004: Loss 0.0162 Regression loss 0.0096 Classification loss 0.0066 AP 0.4406 AR 0.6700
Epoch 404 batch 00005: Loss 0.0182 Regression loss 0.0107 Classification loss 0.0075 AP 0.4498 AR 0.7000
Epoch 404 batch 00006: Loss 0.0178 Regression loss 0.0118 Classification loss 0.0060 AP 0.3508 AR 0.5183
Epoch 404 batch 00007: Loss 0.0184 Regression loss 0.0105 Classification loss 0.0080 AP 0.3744 AR 0.5867
Epoch 404 batch 00008: Loss 0.0189 Regression loss 0.0120 Classification loss 0.0069 AP 0.2154 AR 0.5000
Epoch 404 batch 00009: Loss 0.0192 Regression loss 0.0121 Classification loss 0.0071 AP 0.4124 AR 0.7233
Epoch 404 batch 00010: Loss 0.0187 Regression loss 0.0098 Classification loss 0.0089 AP 0.3073 AR 0.5300
Epoch 405 batch 00001: Loss 0.0200 Regression loss 0.0124 Classification loss 0.0076 AP 0.2686 AR 0.5267
Epoch 405 batch 00002: Loss 0.0179 Regression loss 0.0095 Classification loss 0.0084 AP 0.5190 AR 0.7050
Epoch 405 batch 00003: Loss 0.0175 Regression loss 0.0088 Classification loss 0.0087 AP 0.3977 AR 0.6833
Epoch 405 batch 00004: Loss 0.0154 Regression loss 0.0105 Classification loss 0.0049 AP 0.4154 AR 0.5800
Epoch 405 batch 00005: Loss 0.0162 Regression loss 0.0101 Classification loss 0.0061 AP 0.2450 AR 0.4833
Epoch 405 batch 00006: Loss 0.0180 Regression loss 0.0134 Classification loss 0.0046 AP 0.3189 AR 0.5400
Epoch 405 batch 00007: Loss 0.0185 Regression loss 0.0104 Classification loss 0.0081 AP 0.3458 AR 0.6150
Epoch 405 batch 00008: Loss 0.0197 Regression loss 0.0121 Classification loss 0.0077 AP 0.4625 AR 0.7700
Epoch 405 batch 00009: Loss 0.0165 Regression loss 0.0097 Classification loss 0.0068 AP 0.4342 AR 0.6000
Epoch 405 batch 00010: Loss 0.0223 Regression loss 0.0135 Classification loss 0.0088 AP 0.4168 AR 0.6300
Epoch 406 batch 00001: Loss 0.0157 Regression loss 0.0116 Classification loss 0.0041 AP 0.2683 AR 0.4667
Epoch 406 batch 00002: Loss 0.0194 Regression loss 0.0145 Classification loss 0.0049 AP 0.3106 AR 0.5450
Epoch 406 batch 00003: Loss 0.0170 Regression loss 0.0123 Classification loss 0.0047 AP 0.2587 AR 0.4583
Epoch 406 batch 00004: Loss 0.0185 Regression loss 0.0094 Classification loss 0.0091 AP 0.4812 AR 0.8117
Epoch 406 batch 00005: Loss 0.0195 Regression loss 0.0103 Classification loss 0.0092 AP 0.2893 AR 0.4767
Epoch 406 batch 00006: Loss 0.0192 Regression loss 0.0128 Classification loss 0.0064 AP 0.2533 AR 0.4717
Epoch 406 batch 00007: Loss 0.0161 Regression loss 0.0097 Classification loss 0.0064 AP 0.3723 AR 0.7033
Epoch 406 batch 00008: Loss 0.0187 Regression loss 0.0117 Classification loss 0.0070 AP 0.3577 AR 0.5433
Epoch 406 batch 00009: Loss 0.0147 Regression loss 0.0094 Classification loss 0.0053 AP 0.3232 AR 0.6017
Epoch 406 batch 00010: Loss 0.0138 Regression loss 0.0088 Classification loss 0.0049 AP 0.5524 AR 0.7250
Epoch 407 batch 00001: Loss 0.0168 Regression loss 0.0105 Classification loss 0.0064 AP 0.4120 AR 0.6333
Epoch 407 batch 00002: Loss 0.0152 Regression loss 0.0099 Classification loss 0.0054 AP 0.4496 AR 0.6800
Epoch 407 batch 00003: Loss 0.0165 Regression loss 0.0116 Classification loss 0.0049 AP 0.3139 AR 0.5233
Epoch 407 batch 00004: Loss 0.0186 Regression loss 0.0103 Classification loss 0.0083 AP 0.3119 AR 0.5433
Epoch 407 batch 00005: Loss 0.0144 Regression loss 0.0089 Classification loss 0.0055 AP 0.5300 AR 0.7100
Epoch 407 batch 00006: Loss 0.0168 Regression loss 0.0106 Classification loss 0.0061 AP 0.2771 AR 0.5400
Epoch 407 batch 00007: Loss 0.0184 Regression loss 0.0114 Classification loss 0.0069 AP 0.4250 AR 0.5650
Epoch 407 batch 00008: Loss 0.0193 Regression loss 0.0129 Classification loss 0.0064 AP 0.2637 AR 0.5533
Epoch 407 batch 00009: Loss 0.0117 Regression loss 0.0074 Classification loss 0.0043 AP 0.3638 AR 0.6767
Epoch 407 batch 00010: Loss 0.0179 Regression loss 0.0104 Classification loss 0.0075 AP 0.3167 AR 0.6500
Epoch 408 batch 00001: Loss 0.0158 Regression loss 0.0098 Classification loss 0.0060 AP 0.4569 AR 0.7817
Epoch 408 batch 00002: Loss 0.0191 Regression loss 0.0126 Classification loss 0.0065 AP 0.3417 AR 0.5833
Epoch 408 batch 00003: Loss 0.0141 Regression loss 0.0087 Classification loss 0.0053 AP 0.4845 AR 0.7550
Epoch 408 batch 00004: Loss 0.0162 Regression loss 0.0101 Classification loss 0.0061 AP 0.3490 AR 0.5667
Epoch 408 batch 00005: Loss 0.0193 Regression loss 0.0115 Classification loss 0.0077 AP 0.3445 AR 0.6567
Epoch 408 batch 00006: Loss 0.0156 Regression loss 0.0094 Classification loss 0.0062 AP 0.5300 AR 0.7583
Epoch 408 batch 00007: Loss 0.0174 Regression loss 0.0122 Classification loss 0.0051 AP 0.2688 AR 0.6450
Epoch 408 batch 00008: Loss 0.0182 Regression loss 0.0126 Classification loss 0.0057 AP 0.2710 AR 0.4967
Epoch 408 batch 00009: Loss 0.0136 Regression loss 0.0094 Classification loss 0.0042 AP 0.4488 AR 0.6833
Epoch 408 batch 00010: Loss 0.0174 Regression loss 0.0108 Classification loss 0.0065 AP 0.2839 AR 0.5600
Epoch 409 batch 00001: Loss 0.0189 Regression loss 0.0123 Classification loss 0.0065 AP 0.3262 AR 0.5250
Epoch 409 batch 00002: Loss 0.0148 Regression loss 0.0081 Classification loss 0.0067 AP 0.4027 AR 0.6567
Epoch 409 batch 00003: Loss 0.0178 Regression loss 0.0123 Classification loss 0.0055 AP 0.3151 AR 0.6583
Epoch 409 batch 00004: Loss 0.0171 Regression loss 0.0115 Classification loss 0.0056 AP 0.4350 AR 0.5667
Epoch 409 batch 00005: Loss 0.0168 Regression loss 0.0101 Classification loss 0.0067 AP 0.3764 AR 0.7683
Epoch 409 batch 00006: Loss 0.0181 Regression loss 0.0102 Classification loss 0.0079 AP 0.4833 AR 0.8000
Epoch 409 batch 00007: Loss 0.0165 Regression loss 0.0101 Classification loss 0.0064 AP 0.4933 AR 0.7883
Epoch 409 batch 00008: Loss 0.0145 Regression loss 0.0098 Classification loss 0.0047 AP 0.4182 AR 0.6517
Epoch 409 batch 00009: Loss 0.0168 Regression loss 0.0114 Classification loss 0.0054 AP 0.3411 AR 0.5850
Epoch 409 batch 00010: Loss 0.0159 Regression loss 0.0106 Classification loss 0.0054 AP 0.3363 AR 0.5500
Epoch 410 batch 00001: Loss 0.0176 Regression loss 0.0115 Classification loss 0.0061 AP 0.3766 AR 0.6733
Epoch 410 batch 00002: Loss 0.0155 Regression loss 0.0096 Classification loss 0.0059 AP 0.4633 AR 0.6833
Epoch 410 batch 00003: Loss 0.0190 Regression loss 0.0112 Classification loss 0.0078 AP 0.3433 AR 0.6333
Epoch 410 batch 00004: Loss 0.0158 Regression loss 0.0103 Classification loss 0.0055 AP 0.3171 AR 0.5533
Epoch 410 batch 00005: Loss 0.0147 Regression loss 0.0095 Classification loss 0.0051 AP 0.5979 AR 0.7467
Epoch 410 batch 00006: Loss 0.0149 Regression loss 0.0080 Classification loss 0.0069 AP 0.3717 AR 0.7167
Epoch 410 batch 00007: Loss 0.0149 Regression loss 0.0091 Classification loss 0.0058 AP 0.3752 AR 0.7633
Epoch 410 batch 00008: Loss 0.0160 Regression loss 0.0109 Classification loss 0.0051 AP 0.4613 AR 0.7833
Epoch 410 batch 00009: Loss 0.0171 Regression loss 0.0103 Classification loss 0.0068 AP 0.4844 AR 0.7400
Epoch 410 batch 00010: Loss 0.0162 Regression loss 0.0093 Classification loss 0.0069 AP 0.2925 AR 0.5467
Epoch 411 batch 00001: Loss 0.0158 Regression loss 0.0089 Classification loss 0.0068 AP 0.4655 AR 0.7967
Epoch 411 batch 00002: Loss 0.0152 Regression loss 0.0103 Classification loss 0.0049 AP 0.3019 AR 0.4667
Epoch 411 batch 00003: Loss 0.0137 Regression loss 0.0095 Classification loss 0.0042 AP 0.4967 AR 0.8083
Epoch 411 batch 00004: Loss 0.0138 Regression loss 0.0086 Classification loss 0.0052 AP 0.3554 AR 0.6883
Epoch 411 batch 00005: Loss 0.0166 Regression loss 0.0098 Classification loss 0.0068 AP 0.3432 AR 0.5333
Epoch 411 batch 00006: Loss 0.0171 Regression loss 0.0102 Classification loss 0.0068 AP 0.3400 AR 0.6550
Epoch 411 batch 00007: Loss 0.0169 Regression loss 0.0099 Classification loss 0.0070 AP 0.4095 AR 0.7083
Epoch 411 batch 00008: Loss 0.0202 Regression loss 0.0109 Classification loss 0.0092 AP 0.3074 AR 0.5050
Epoch 411 batch 00009: Loss 0.0186 Regression loss 0.0119 Classification loss 0.0067 AP 0.3224 AR 0.6500
Epoch 411 batch 00010: Loss 0.0180 Regression loss 0.0106 Classification loss 0.0074 AP 0.4371 AR 0.6000
Epoch 412 batch 00001: Loss 0.0152 Regression loss 0.0100 Classification loss 0.0052 AP 0.3729 AR 0.5433
Epoch 412 batch 00002: Loss 0.0155 Regression loss 0.0095 Classification loss 0.0059 AP 0.3677 AR 0.5050
Epoch 412 batch 00003: Loss 0.0171 Regression loss 0.0100 Classification loss 0.0071 AP 0.2352 AR 0.4700
Epoch 412 batch 00004: Loss 0.0183 Regression loss 0.0112 Classification loss 0.0072 AP 0.3265 AR 0.6600
Epoch 412 batch 00005: Loss 0.0192 Regression loss 0.0118 Classification loss 0.0074 AP 0.3236 AR 0.5550
Epoch 412 batch 00006: Loss 0.0138 Regression loss 0.0098 Classification loss 0.0040 AP 0.3722 AR 0.5967
Epoch 412 batch 00007: Loss 0.0163 Regression loss 0.0112 Classification loss 0.0050 AP 0.4160 AR 0.5250
Epoch 412 batch 00008: Loss 0.0171 Regression loss 0.0104 Classification loss 0.0068 AP 0.3506 AR 0.5817
Epoch 412 batch 00009: Loss 0.0163 Regression loss 0.0106 Classification loss 0.0057 AP 0.3740 AR 0.6583
Epoch 412 batch 00010: Loss 0.0142 Regression loss 0.0084 Classification loss 0.0059 AP 0.3761 AR 0.7433
Epoch 413 batch 00001: Loss 0.0156 Regression loss 0.0098 Classification loss 0.0058 AP 0.3523 AR 0.6400
Epoch 413 batch 00002: Loss 0.0166 Regression loss 0.0098 Classification loss 0.0068 AP 0.3789 AR 0.7200
Epoch 413 batch 00003: Loss 0.0159 Regression loss 0.0098 Classification loss 0.0061 AP 0.2889 AR 0.5167
Epoch 413 batch 00004: Loss 0.0165 Regression loss 0.0112 Classification loss 0.0052 AP 0.2055 AR 0.4000
Epoch 413 batch 00005: Loss 0.0171 Regression loss 0.0113 Classification loss 0.0058 AP 0.3085 AR 0.4683
Epoch 413 batch 00006: Loss 0.0139 Regression loss 0.0089 Classification loss 0.0050 AP 0.5237 AR 0.7717
Epoch 413 batch 00007: Loss 0.0152 Regression loss 0.0104 Classification loss 0.0048 AP 0.4545 AR 0.6583
Epoch 413 batch 00008: Loss 0.0170 Regression loss 0.0111 Classification loss 0.0059 AP 0.4086 AR 0.7267
Epoch 413 batch 00009: Loss 0.0142 Regression loss 0.0097 Classification loss 0.0045 AP 0.4386 AR 0.6483
Epoch 413 batch 00010: Loss 0.0164 Regression loss 0.0104 Classification loss 0.0061 AP 0.3581 AR 0.6717
Epoch 414 batch 00001: Loss 0.0150 Regression loss 0.0084 Classification loss 0.0066 AP 0.3570 AR 0.6583
Epoch 414 batch 00002: Loss 0.0162 Regression loss 0.0118 Classification loss 0.0044 AP 0.3424 AR 0.5783
Epoch 414 batch 00003: Loss 0.0141 Regression loss 0.0097 Classification loss 0.0044 AP 0.5489 AR 0.7833
Epoch 414 batch 00004: Loss 0.0185 Regression loss 0.0130 Classification loss 0.0055 AP 0.2310 AR 0.3500
Epoch 414 batch 00005: Loss 0.0147 Regression loss 0.0103 Classification loss 0.0043 AP 0.4038 AR 0.7483
Epoch 414 batch 00006: Loss 0.0147 Regression loss 0.0103 Classification loss 0.0044 AP 0.4387 AR 0.7600
Epoch 414 batch 00007: Loss 0.0154 Regression loss 0.0101 Classification loss 0.0053 AP 0.3195 AR 0.6433
Epoch 414 batch 00008: Loss 0.0207 Regression loss 0.0099 Classification loss 0.0108 AP 0.6233 AR 0.7883
Epoch 414 batch 00009: Loss 0.0142 Regression loss 0.0088 Classification loss 0.0054 AP 0.3710 AR 0.5317
Epoch 414 batch 00010: Loss 0.0177 Regression loss 0.0095 Classification loss 0.0082 AP 0.3774 AR 0.6833
Epoch 415 batch 00001: Loss 0.0205 Regression loss 0.0104 Classification loss 0.0102 AP 0.3670 AR 0.7700
Epoch 415 batch 00002: Loss 0.0148 Regression loss 0.0099 Classification loss 0.0049 AP 0.2952 AR 0.7000
Epoch 415 batch 00003: Loss 0.0173 Regression loss 0.0103 Classification loss 0.0070 AP 0.3075 AR 0.6000
Epoch 415 batch 00004: Loss 0.0159 Regression loss 0.0098 Classification loss 0.0060 AP 0.4381 AR 0.5350
Epoch 415 batch 00005: Loss 0.0174 Regression loss 0.0115 Classification loss 0.0060 AP 0.3548 AR 0.5783
Epoch 415 batch 00006: Loss 0.0192 Regression loss 0.0115 Classification loss 0.0078 AP 0.2749 AR 0.5183
Epoch 415 batch 00007: Loss 0.0146 Regression loss 0.0099 Classification loss 0.0048 AP 0.4204 AR 0.7150
Epoch 415 batch 00008: Loss 0.0157 Regression loss 0.0097 Classification loss 0.0059 AP 0.5050 AR 0.7517
Epoch 415 batch 00009: Loss 0.0176 Regression loss 0.0101 Classification loss 0.0076 AP 0.4005 AR 0.7717
Epoch 415 batch 00010: Loss 0.0141 Regression loss 0.0100 Classification loss 0.0041 AP 0.3342 AR 0.5917
Epoch 416 batch 00001: Loss 0.0161 Regression loss 0.0105 Classification loss 0.0056 AP 0.4100 AR 0.5983
Epoch 416 batch 00002: Loss 0.0170 Regression loss 0.0091 Classification loss 0.0079 AP 0.4927 AR 0.8333
Epoch 416 batch 00003: Loss 0.0139 Regression loss 0.0092 Classification loss 0.0047 AP 0.3429 AR 0.6367
Epoch 416 batch 00004: Loss 0.0222 Regression loss 0.0127 Classification loss 0.0096 AP 0.3400 AR 0.5367
Epoch 416 batch 00005: Loss 0.0159 Regression loss 0.0107 Classification loss 0.0052 AP 0.4971 AR 0.7350
Epoch 416 batch 00006: Loss 0.0149 Regression loss 0.0095 Classification loss 0.0053 AP 0.4106 AR 0.5817
Epoch 416 batch 00007: Loss 0.0190 Regression loss 0.0118 Classification loss 0.0072 AP 0.2996 AR 0.6417
Epoch 416 batch 00008: Loss 0.0179 Regression loss 0.0112 Classification loss 0.0067 AP 0.3405 AR 0.7183
Epoch 416 batch 00009: Loss 0.0163 Regression loss 0.0110 Classification loss 0.0053 AP 0.4145 AR 0.6550
Epoch 416 batch 00010: Loss 0.0138 Regression loss 0.0088 Classification loss 0.0050 AP 0.4761 AR 0.7217
Epoch 417 batch 00001: Loss 0.0170 Regression loss 0.0099 Classification loss 0.0071 AP 0.3952 AR 0.6150
Epoch 417 batch 00002: Loss 0.0136 Regression loss 0.0076 Classification loss 0.0059 AP 0.7329 AR 0.8917
Epoch 417 batch 00003: Loss 0.0143 Regression loss 0.0093 Classification loss 0.0051 AP 0.4286 AR 0.6700
Epoch 417 batch 00004: Loss 0.0160 Regression loss 0.0101 Classification loss 0.0060 AP 0.1712 AR 0.3167
Epoch 417 batch 00005: Loss 0.0173 Regression loss 0.0111 Classification loss 0.0063 AP 0.3157 AR 0.5433
Epoch 417 batch 00006: Loss 0.0176 Regression loss 0.0116 Classification loss 0.0061 AP 0.2840 AR 0.5333
Epoch 417 batch 00007: Loss 0.0142 Regression loss 0.0091 Classification loss 0.0051 AP 0.3367 AR 0.7100
Epoch 417 batch 00008: Loss 0.0155 Regression loss 0.0096 Classification loss 0.0060 AP 0.5002 AR 0.7967
Epoch 417 batch 00009: Loss 0.0150 Regression loss 0.0096 Classification loss 0.0054 AP 0.3825 AR 0.6083
Epoch 417 batch 00010: Loss 0.0149 Regression loss 0.0097 Classification loss 0.0052 AP 0.4083 AR 0.6817
Epoch 418 batch 00001: Loss 0.0180 Regression loss 0.0101 Classification loss 0.0079 AP 0.4043 AR 0.7600
Epoch 418 batch 00002: Loss 0.0143 Regression loss 0.0096 Classification loss 0.0047 AP 0.4800 AR 0.6367
Epoch 418 batch 00003: Loss 0.0159 Regression loss 0.0090 Classification loss 0.0070 AP 0.3129 AR 0.5250
Epoch 418 batch 00004: Loss 0.0179 Regression loss 0.0124 Classification loss 0.0055 AP 0.3005 AR 0.5250
Epoch 418 batch 00005: Loss 0.0170 Regression loss 0.0098 Classification loss 0.0072 AP 0.2964 AR 0.5767
Epoch 418 batch 00006: Loss 0.0146 Regression loss 0.0088 Classification loss 0.0058 AP 0.4552 AR 0.6433
Epoch 418 batch 00007: Loss 0.0135 Regression loss 0.0096 Classification loss 0.0039 AP 0.4127 AR 0.6067
Epoch 418 batch 00008: Loss 0.0163 Regression loss 0.0111 Classification loss 0.0052 AP 0.2783 AR 0.6133
Epoch 418 batch 00009: Loss 0.0159 Regression loss 0.0097 Classification loss 0.0061 AP 0.5173 AR 0.6683
Epoch 418 batch 00010: Loss 0.0133 Regression loss 0.0087 Classification loss 0.0046 AP 0.4304 AR 0.6917
Epoch 419 batch 00001: Loss 0.0143 Regression loss 0.0089 Classification loss 0.0054 AP 0.3848 AR 0.7217
Epoch 419 batch 00002: Loss 0.0150 Regression loss 0.0098 Classification loss 0.0052 AP 0.4767 AR 0.7633
Epoch 419 batch 00003: Loss 0.0162 Regression loss 0.0101 Classification loss 0.0061 AP 0.4519 AR 0.7150
Epoch 419 batch 00004: Loss 0.0129 Regression loss 0.0082 Classification loss 0.0048 AP 0.5344 AR 0.7200
Epoch 419 batch 00005: Loss 0.0152 Regression loss 0.0106 Classification loss 0.0046 AP 0.3479 AR 0.6500
Epoch 419 batch 00006: Loss 0.0150 Regression loss 0.0100 Classification loss 0.0051 AP 0.3267 AR 0.5283
Epoch 419 batch 00007: Loss 0.0137 Regression loss 0.0094 Classification loss 0.0044 AP 0.5378 AR 0.7100
Epoch 419 batch 00008: Loss 0.0168 Regression loss 0.0089 Classification loss 0.0080 AP 0.2929 AR 0.4917
Epoch 419 batch 00009: Loss 0.0160 Regression loss 0.0085 Classification loss 0.0074 AP 0.2929 AR 0.6667
Epoch 419 batch 00010: Loss 0.0153 Regression loss 0.0108 Classification loss 0.0046 AP 0.3676 AR 0.5700
Epoch 420 batch 00001: Loss 0.0137 Regression loss 0.0077 Classification loss 0.0060 AP 0.5280 AR 0.7150
Epoch 420 batch 00002: Loss 0.0152 Regression loss 0.0099 Classification loss 0.0053 AP 0.4980 AR 0.7750
Epoch 420 batch 00003: Loss 0.0178 Regression loss 0.0125 Classification loss 0.0054 AP 0.2868 AR 0.4817
Epoch 420 batch 00004: Loss 0.0147 Regression loss 0.0086 Classification loss 0.0060 AP 0.3317 AR 0.6200
Epoch 420 batch 00005: Loss 0.0141 Regression loss 0.0097 Classification loss 0.0044 AP 0.5012 AR 0.8667
Epoch 420 batch 00006: Loss 0.0141 Regression loss 0.0101 Classification loss 0.0040 AP 0.3890 AR 0.6000
Epoch 420 batch 00007: Loss 0.0152 Regression loss 0.0106 Classification loss 0.0047 AP 0.3138 AR 0.5883
Epoch 420 batch 00008: Loss 0.0194 Regression loss 0.0110 Classification loss 0.0084 AP 0.4512 AR 0.6383
Epoch 420 batch 00009: Loss 0.0140 Regression loss 0.0092 Classification loss 0.0049 AP 0.2680 AR 0.5333
Epoch 420 batch 00010: Loss 0.0175 Regression loss 0.0115 Classification loss 0.0059 AP 0.3571 AR 0.5700
Epoch 421 batch 00001: Loss 0.0160 Regression loss 0.0101 Classification loss 0.0059 AP 0.4904 AR 0.7350
Epoch 421 batch 00002: Loss 0.0163 Regression loss 0.0114 Classification loss 0.0049 AP 0.3732 AR 0.5250
Epoch 421 batch 00003: Loss 0.0152 Regression loss 0.0101 Classification loss 0.0051 AP 0.4305 AR 0.7800
Epoch 421 batch 00004: Loss 0.0145 Regression loss 0.0097 Classification loss 0.0048 AP 0.3757 AR 0.6717
Epoch 421 batch 00005: Loss 0.0166 Regression loss 0.0111 Classification loss 0.0056 AP 0.4116 AR 0.6000
Epoch 421 batch 00006: Loss 0.0158 Regression loss 0.0113 Classification loss 0.0044 AP 0.3828 AR 0.7117
Epoch 421 batch 00007: Loss 0.0166 Regression loss 0.0101 Classification loss 0.0066 AP 0.4917 AR 0.7817
Epoch 421 batch 00008: Loss 0.0151 Regression loss 0.0103 Classification loss 0.0047 AP 0.3517 AR 0.6133
Epoch 421 batch 00009: Loss 0.0153 Regression loss 0.0109 Classification loss 0.0045 AP 0.2631 AR 0.4917
Epoch 421 batch 00010: Loss 0.0142 Regression loss 0.0074 Classification loss 0.0069 AP 0.5587 AR 0.7950
Epoch 422 batch 00001: Loss 0.0165 Regression loss 0.0106 Classification loss 0.0059 AP 0.3562 AR 0.6167
Epoch 422 batch 00002: Loss 0.0144 Regression loss 0.0104 Classification loss 0.0039 AP 0.4195 AR 0.6400
Epoch 422 batch 00003: Loss 0.0171 Regression loss 0.0110 Classification loss 0.0060 AP 0.4776 AR 0.6500
Epoch 422 batch 00004: Loss 0.0140 Regression loss 0.0087 Classification loss 0.0053 AP 0.5327 AR 0.8467
Epoch 422 batch 00005: Loss 0.0162 Regression loss 0.0101 Classification loss 0.0062 AP 0.2533 AR 0.4800
Epoch 422 batch 00006: Loss 0.0150 Regression loss 0.0096 Classification loss 0.0053 AP 0.3281 AR 0.5400
Epoch 422 batch 00007: Loss 0.0142 Regression loss 0.0089 Classification loss 0.0053 AP 0.4277 AR 0.7667
Epoch 422 batch 00008: Loss 0.0138 Regression loss 0.0092 Classification loss 0.0045 AP 0.3711 AR 0.5867
Epoch 422 batch 00009: Loss 0.0139 Regression loss 0.0090 Classification loss 0.0049 AP 0.4626 AR 0.6917
Epoch 422 batch 00010: Loss 0.0155 Regression loss 0.0109 Classification loss 0.0046 AP 0.4967 AR 0.6650
Epoch 423 batch 00001: Loss 0.0143 Regression loss 0.0115 Classification loss 0.0028 AP 0.3383 AR 0.5717
Epoch 423 batch 00002: Loss 0.0163 Regression loss 0.0090 Classification loss 0.0073 AP 0.4007 AR 0.6217
Epoch 423 batch 00003: Loss 0.0148 Regression loss 0.0091 Classification loss 0.0057 AP 0.3733 AR 0.5900
Epoch 423 batch 00004: Loss 0.0140 Regression loss 0.0100 Classification loss 0.0040 AP 0.3411 AR 0.5783
Epoch 423 batch 00005: Loss 0.0119 Regression loss 0.0090 Classification loss 0.0030 AP 0.3469 AR 0.7167
Epoch 423 batch 00006: Loss 0.0145 Regression loss 0.0102 Classification loss 0.0043 AP 0.3967 AR 0.6367
Epoch 423 batch 00007: Loss 0.0172 Regression loss 0.0108 Classification loss 0.0064 AP 0.3967 AR 0.5667
Epoch 423 batch 00008: Loss 0.0136 Regression loss 0.0086 Classification loss 0.0051 AP 0.4205 AR 0.6767
Epoch 423 batch 00009: Loss 0.0144 Regression loss 0.0087 Classification loss 0.0057 AP 0.3278 AR 0.4900
Epoch 423 batch 00010: Loss 0.0177 Regression loss 0.0104 Classification loss 0.0073 AP 0.3076 AR 0.4883
Epoch 424 batch 00001: Loss 0.0145 Regression loss 0.0096 Classification loss 0.0049 AP 0.4260 AR 0.6250
Epoch 424 batch 00002: Loss 0.0141 Regression loss 0.0092 Classification loss 0.0049 AP 0.3785 AR 0.6017
Epoch 424 batch 00003: Loss 0.0157 Regression loss 0.0091 Classification loss 0.0066 AP 0.6439 AR 0.8850
Epoch 424 batch 00004: Loss 0.0147 Regression loss 0.0107 Classification loss 0.0040 AP 0.3392 AR 0.5567
Epoch 424 batch 00005: Loss 0.0150 Regression loss 0.0089 Classification loss 0.0062 AP 0.2417 AR 0.4000
Epoch 424 batch 00006: Loss 0.0115 Regression loss 0.0085 Classification loss 0.0030 AP 0.3905 AR 0.6583
Epoch 424 batch 00007: Loss 0.0158 Regression loss 0.0107 Classification loss 0.0052 AP 0.4589 AR 0.6917
Epoch 424 batch 00008: Loss 0.0155 Regression loss 0.0087 Classification loss 0.0068 AP 0.3930 AR 0.7533
Epoch 424 batch 00009: Loss 0.0157 Regression loss 0.0088 Classification loss 0.0069 AP 0.3942 AR 0.7717
Epoch 424 batch 00010: Loss 0.0164 Regression loss 0.0110 Classification loss 0.0054 AP 0.3892 AR 0.7100
Epoch 425 batch 00001: Loss 0.0154 Regression loss 0.0098 Classification loss 0.0056 AP 0.4071 AR 0.6700
Epoch 425 batch 00002: Loss 0.0143 Regression loss 0.0100 Classification loss 0.0043 AP 0.3563 AR 0.5150
Epoch 425 batch 00003: Loss 0.0157 Regression loss 0.0119 Classification loss 0.0038 AP 0.4083 AR 0.6900
Epoch 425 batch 00004: Loss 0.0142 Regression loss 0.0092 Classification loss 0.0050 AP 0.4637 AR 0.6917
Epoch 425 batch 00005: Loss 0.0183 Regression loss 0.0109 Classification loss 0.0074 AP 0.3674 AR 0.6033
Epoch 425 batch 00006: Loss 0.0158 Regression loss 0.0115 Classification loss 0.0042 AP 0.2852 AR 0.4467
Epoch 425 batch 00007: Loss 0.0161 Regression loss 0.0102 Classification loss 0.0059 AP 0.3323 AR 0.5683
Epoch 425 batch 00008: Loss 0.0202 Regression loss 0.0113 Classification loss 0.0089 AP 0.3186 AR 0.5783
Epoch 425 batch 00009: Loss 0.0153 Regression loss 0.0117 Classification loss 0.0036 AP 0.3489 AR 0.6583
Epoch 425 batch 00010: Loss 0.0129 Regression loss 0.0084 Classification loss 0.0045 AP 0.3800 AR 0.5467
Epoch 426 batch 00001: Loss 0.0144 Regression loss 0.0109 Classification loss 0.0035 AP 0.4982 AR 0.7183
Epoch 426 batch 00002: Loss 0.0132 Regression loss 0.0096 Classification loss 0.0036 AP 0.3907 AR 0.6433
Epoch 426 batch 00003: Loss 0.0139 Regression loss 0.0103 Classification loss 0.0037 AP 0.3147 AR 0.6233
Epoch 426 batch 00004: Loss 0.0176 Regression loss 0.0119 Classification loss 0.0057 AP 0.3274 AR 0.4900
Epoch 426 batch 00005: Loss 0.0151 Regression loss 0.0096 Classification loss 0.0055 AP 0.5356 AR 0.7650
Epoch 426 batch 00006: Loss 0.0163 Regression loss 0.0104 Classification loss 0.0059 AP 0.2960 AR 0.5083
Epoch 426 batch 00007: Loss 0.0188 Regression loss 0.0121 Classification loss 0.0067 AP 0.2408 AR 0.4733
Epoch 426 batch 00008: Loss 0.0142 Regression loss 0.0091 Classification loss 0.0051 AP 0.4667 AR 0.6217
Epoch 426 batch 00009: Loss 0.0150 Regression loss 0.0095 Classification loss 0.0055 AP 0.4545 AR 0.7000
Epoch 426 batch 00010: Loss 0.0168 Regression loss 0.0100 Classification loss 0.0068 AP 0.3587 AR 0.4883
Epoch 427 batch 00001: Loss 0.0148 Regression loss 0.0081 Classification loss 0.0068 AP 0.2930 AR 0.4800
Epoch 427 batch 00002: Loss 0.0180 Regression loss 0.0127 Classification loss 0.0053 AP 0.2271 AR 0.3833
Epoch 427 batch 00003: Loss 0.0145 Regression loss 0.0086 Classification loss 0.0059 AP 0.4810 AR 0.6667
Epoch 427 batch 00004: Loss 0.0158 Regression loss 0.0094 Classification loss 0.0064 AP 0.3326 AR 0.6767
Epoch 427 batch 00005: Loss 0.0149 Regression loss 0.0115 Classification loss 0.0034 AP 0.4972 AR 0.6400
Epoch 427 batch 00006: Loss 0.0130 Regression loss 0.0099 Classification loss 0.0031 AP 0.4481 AR 0.6767
Epoch 427 batch 00007: Loss 0.0156 Regression loss 0.0099 Classification loss 0.0057 AP 0.4502 AR 0.6600
Epoch 427 batch 00008: Loss 0.0161 Regression loss 0.0089 Classification loss 0.0073 AP 0.3789 AR 0.6350
Epoch 427 batch 00009: Loss 0.0148 Regression loss 0.0100 Classification loss 0.0048 AP 0.4476 AR 0.5950
Epoch 427 batch 00010: Loss 0.0134 Regression loss 0.0090 Classification loss 0.0044 AP 0.3439 AR 0.6500
Epoch 428 batch 00001: Loss 0.0152 Regression loss 0.0090 Classification loss 0.0062 AP 0.3682 AR 0.6500
Epoch 428 batch 00002: Loss 0.0155 Regression loss 0.0104 Classification loss 0.0051 AP 0.3913 AR 0.6717
Epoch 428 batch 00003: Loss 0.0177 Regression loss 0.0113 Classification loss 0.0064 AP 0.2784 AR 0.4700
Epoch 428 batch 00004: Loss 0.0125 Regression loss 0.0087 Classification loss 0.0038 AP 0.5019 AR 0.7800
Epoch 428 batch 00005: Loss 0.0159 Regression loss 0.0112 Classification loss 0.0047 AP 0.3400 AR 0.5400
Epoch 428 batch 00006: Loss 0.0132 Regression loss 0.0094 Classification loss 0.0038 AP 0.4647 AR 0.6967
Epoch 428 batch 00007: Loss 0.0146 Regression loss 0.0103 Classification loss 0.0043 AP 0.3980 AR 0.7100
Epoch 428 batch 00008: Loss 0.0148 Regression loss 0.0100 Classification loss 0.0048 AP 0.1179 AR 0.2583
Epoch 428 batch 00009: Loss 0.0155 Regression loss 0.0098 Classification loss 0.0057 AP 0.5790 AR 0.8050
Epoch 428 batch 00010: Loss 0.0140 Regression loss 0.0082 Classification loss 0.0058 AP 0.4343 AR 0.7583
Epoch 429 batch 00001: Loss 0.0138 Regression loss 0.0086 Classification loss 0.0052 AP 0.3193 AR 0.4500
Epoch 429 batch 00002: Loss 0.0147 Regression loss 0.0094 Classification loss 0.0053 AP 0.4311 AR 0.6883
Epoch 429 batch 00003: Loss 0.0141 Regression loss 0.0094 Classification loss 0.0047 AP 0.3219 AR 0.5300
Epoch 429 batch 00004: Loss 0.0146 Regression loss 0.0083 Classification loss 0.0063 AP 0.3190 AR 0.5617
Epoch 429 batch 00005: Loss 0.0160 Regression loss 0.0100 Classification loss 0.0061 AP 0.4275 AR 0.7967
Epoch 429 batch 00006: Loss 0.0150 Regression loss 0.0115 Classification loss 0.0035 AP 0.4098 AR 0.7000
Epoch 429 batch 00007: Loss 0.0158 Regression loss 0.0088 Classification loss 0.0069 AP 0.4267 AR 0.5133
Epoch 429 batch 00008: Loss 0.0126 Regression loss 0.0093 Classification loss 0.0034 AP 0.5683 AR 0.7117
Epoch 429 batch 00009: Loss 0.0178 Regression loss 0.0110 Classification loss 0.0068 AP 0.2961 AR 0.5183
Epoch 429 batch 00010: Loss 0.0138 Regression loss 0.0094 Classification loss 0.0044 AP 0.4125 AR 0.7000
Epoch 430 batch 00001: Loss 0.0151 Regression loss 0.0089 Classification loss 0.0062 AP 0.4004 AR 0.5817
Epoch 430 batch 00002: Loss 0.0125 Regression loss 0.0081 Classification loss 0.0044 AP 0.5317 AR 0.8667
Epoch 430 batch 00003: Loss 0.0125 Regression loss 0.0079 Classification loss 0.0046 AP 0.4607 AR 0.6500
Epoch 430 batch 00004: Loss 0.0146 Regression loss 0.0096 Classification loss 0.0050 AP 0.4449 AR 0.6917
Epoch 430 batch 00005: Loss 0.0152 Regression loss 0.0103 Classification loss 0.0049 AP 0.3964 AR 0.7083
Epoch 430 batch 00006: Loss 0.0124 Regression loss 0.0085 Classification loss 0.0038 AP 0.4803 AR 0.8233
Epoch 430 batch 00007: Loss 0.0135 Regression loss 0.0088 Classification loss 0.0047 AP 0.3513 AR 0.6583
Epoch 430 batch 00008: Loss 0.0137 Regression loss 0.0096 Classification loss 0.0041 AP 0.4186 AR 0.6867
Epoch 430 batch 00009: Loss 0.0148 Regression loss 0.0095 Classification loss 0.0054 AP 0.2258 AR 0.4000
Epoch 430 batch 00010: Loss 0.0113 Regression loss 0.0077 Classification loss 0.0036 AP 0.4566 AR 0.6683
Epoch 431 batch 00001: Loss 0.0136 Regression loss 0.0082 Classification loss 0.0053 AP 0.5186 AR 0.8300
Epoch 431 batch 00002: Loss 0.0127 Regression loss 0.0087 Classification loss 0.0040 AP 0.6288 AR 0.8933
Epoch 431 batch 00003: Loss 0.0141 Regression loss 0.0094 Classification loss 0.0046 AP 0.3117 AR 0.4933
Epoch 431 batch 00004: Loss 0.0134 Regression loss 0.0105 Classification loss 0.0029 AP 0.3743 AR 0.6917
Epoch 431 batch 00005: Loss 0.0156 Regression loss 0.0100 Classification loss 0.0056 AP 0.4762 AR 0.6533
Epoch 431 batch 00006: Loss 0.0138 Regression loss 0.0083 Classification loss 0.0055 AP 0.3693 AR 0.5700
Epoch 431 batch 00007: Loss 0.0135 Regression loss 0.0086 Classification loss 0.0049 AP 0.2189 AR 0.4267
Epoch 431 batch 00008: Loss 0.0163 Regression loss 0.0115 Classification loss 0.0048 AP 0.3345 AR 0.5733
Epoch 431 batch 00009: Loss 0.0122 Regression loss 0.0084 Classification loss 0.0037 AP 0.3395 AR 0.5950
Epoch 431 batch 00010: Loss 0.0129 Regression loss 0.0078 Classification loss 0.0051 AP 0.3658 AR 0.6150
Epoch 432 batch 00001: Loss 0.0127 Regression loss 0.0090 Classification loss 0.0038 AP 0.3516 AR 0.5633
Epoch 432 batch 00002: Loss 0.0156 Regression loss 0.0099 Classification loss 0.0057 AP 0.2879 AR 0.4817
Epoch 432 batch 00003: Loss 0.0152 Regression loss 0.0116 Classification loss 0.0036 AP 0.3758 AR 0.5833
Epoch 432 batch 00004: Loss 0.0140 Regression loss 0.0089 Classification loss 0.0051 AP 0.3576 AR 0.6467
Epoch 432 batch 00005: Loss 0.0160 Regression loss 0.0112 Classification loss 0.0048 AP 0.4350 AR 0.5867
Epoch 432 batch 00006: Loss 0.0142 Regression loss 0.0091 Classification loss 0.0050 AP 0.4133 AR 0.6267
Epoch 432 batch 00007: Loss 0.0159 Regression loss 0.0106 Classification loss 0.0053 AP 0.3162 AR 0.5083
Epoch 432 batch 00008: Loss 0.0105 Regression loss 0.0078 Classification loss 0.0027 AP 0.4850 AR 0.7100
Epoch 432 batch 00009: Loss 0.0125 Regression loss 0.0082 Classification loss 0.0043 AP 0.3215 AR 0.6250
Epoch 432 batch 00010: Loss 0.0168 Regression loss 0.0101 Classification loss 0.0067 AP 0.4493 AR 0.7317
Epoch 433 batch 00001: Loss 0.0150 Regression loss 0.0108 Classification loss 0.0042 AP 0.3583 AR 0.5700
Epoch 433 batch 00002: Loss 0.0129 Regression loss 0.0084 Classification loss 0.0044 AP 0.4345 AR 0.7100
Epoch 433 batch 00003: Loss 0.0158 Regression loss 0.0104 Classification loss 0.0054 AP 0.3786 AR 0.5567
Epoch 433 batch 00004: Loss 0.0136 Regression loss 0.0095 Classification loss 0.0041 AP 0.3686 AR 0.6167
Epoch 433 batch 00005: Loss 0.0147 Regression loss 0.0094 Classification loss 0.0053 AP 0.3649 AR 0.5967
Epoch 433 batch 00006: Loss 0.0142 Regression loss 0.0106 Classification loss 0.0036 AP 0.3504 AR 0.5300
Epoch 433 batch 00007: Loss 0.0173 Regression loss 0.0112 Classification loss 0.0061 AP 0.2898 AR 0.4717
Epoch 433 batch 00008: Loss 0.0132 Regression loss 0.0085 Classification loss 0.0046 AP 0.3555 AR 0.7083
Epoch 433 batch 00009: Loss 0.0147 Regression loss 0.0089 Classification loss 0.0057 AP 0.3247 AR 0.6083
Epoch 433 batch 00010: Loss 0.0128 Regression loss 0.0081 Classification loss 0.0047 AP 0.4277 AR 0.6700
Epoch 434 batch 00001: Loss 0.0137 Regression loss 0.0093 Classification loss 0.0045 AP 0.4376 AR 0.7783
Epoch 434 batch 00002: Loss 0.0187 Regression loss 0.0106 Classification loss 0.0081 AP 0.3204 AR 0.5167
Epoch 434 batch 00003: Loss 0.0116 Regression loss 0.0081 Classification loss 0.0035 AP 0.4333 AR 0.7233
Epoch 434 batch 00004: Loss 0.0144 Regression loss 0.0104 Classification loss 0.0040 AP 0.4544 AR 0.7433
Epoch 434 batch 00005: Loss 0.0144 Regression loss 0.0091 Classification loss 0.0053 AP 0.4053 AR 0.7883
Epoch 434 batch 00006: Loss 0.0144 Regression loss 0.0099 Classification loss 0.0046 AP 0.3923 AR 0.6100
Epoch 434 batch 00007: Loss 0.0151 Regression loss 0.0095 Classification loss 0.0056 AP 0.3743 AR 0.7167
Epoch 434 batch 00008: Loss 0.0136 Regression loss 0.0090 Classification loss 0.0046 AP 0.6133 AR 0.9250
Epoch 434 batch 00009: Loss 0.0147 Regression loss 0.0102 Classification loss 0.0045 AP 0.4280 AR 0.7433
Epoch 434 batch 00010: Loss 0.0156 Regression loss 0.0122 Classification loss 0.0034 AP 0.2833 AR 0.4583
Epoch 435 batch 00001: Loss 0.0146 Regression loss 0.0107 Classification loss 0.0038 AP 0.5234 AR 0.6750
Epoch 435 batch 00002: Loss 0.0139 Regression loss 0.0089 Classification loss 0.0050 AP 0.5108 AR 0.7300
Epoch 435 batch 00003: Loss 0.0148 Regression loss 0.0098 Classification loss 0.0050 AP 0.4048 AR 0.6500
Epoch 435 batch 00004: Loss 0.0177 Regression loss 0.0112 Classification loss 0.0066 AP 0.2267 AR 0.4750
Epoch 435 batch 00005: Loss 0.0165 Regression loss 0.0100 Classification loss 0.0065 AP 0.3929 AR 0.5567
Epoch 435 batch 00006: Loss 0.0151 Regression loss 0.0107 Classification loss 0.0045 AP 0.4716 AR 0.7117
Epoch 435 batch 00007: Loss 0.0172 Regression loss 0.0114 Classification loss 0.0058 AP 0.2290 AR 0.4617
Epoch 435 batch 00008: Loss 0.0117 Regression loss 0.0089 Classification loss 0.0027 AP 0.3360 AR 0.7250
Epoch 435 batch 00009: Loss 0.0155 Regression loss 0.0115 Classification loss 0.0041 AP 0.3361 AR 0.6183
Epoch 435 batch 00010: Loss 0.0155 Regression loss 0.0101 Classification loss 0.0054 AP 0.4454 AR 0.6367
Epoch 436 batch 00001: Loss 0.0175 Regression loss 0.0115 Classification loss 0.0060 AP 0.3061 AR 0.5000
Epoch 436 batch 00002: Loss 0.0134 Regression loss 0.0087 Classification loss 0.0046 AP 0.3510 AR 0.6850
Epoch 436 batch 00003: Loss 0.0151 Regression loss 0.0117 Classification loss 0.0034 AP 0.3950 AR 0.6183
Epoch 436 batch 00004: Loss 0.0163 Regression loss 0.0109 Classification loss 0.0054 AP 0.3224 AR 0.5883
Epoch 436 batch 00005: Loss 0.0160 Regression loss 0.0103 Classification loss 0.0057 AP 0.3446 AR 0.5233
Epoch 436 batch 00006: Loss 0.0142 Regression loss 0.0093 Classification loss 0.0049 AP 0.3993 AR 0.6950
Epoch 436 batch 00007: Loss 0.0144 Regression loss 0.0109 Classification loss 0.0035 AP 0.3114 AR 0.5050
Epoch 436 batch 00008: Loss 0.0145 Regression loss 0.0100 Classification loss 0.0044 AP 0.3333 AR 0.6500
Epoch 436 batch 00009: Loss 0.0123 Regression loss 0.0073 Classification loss 0.0050 AP 0.4339 AR 0.6383
Epoch 436 batch 00010: Loss 0.0158 Regression loss 0.0112 Classification loss 0.0046 AP 0.3447 AR 0.5150
Epoch 437 batch 00001: Loss 0.0158 Regression loss 0.0108 Classification loss 0.0050 AP 0.2577 AR 0.4650
Epoch 437 batch 00002: Loss 0.0136 Regression loss 0.0096 Classification loss 0.0041 AP 0.5324 AR 0.8750
Epoch 437 batch 00003: Loss 0.0141 Regression loss 0.0099 Classification loss 0.0042 AP 0.4571 AR 0.6100
Epoch 437 batch 00004: Loss 0.0146 Regression loss 0.0112 Classification loss 0.0034 AP 0.3805 AR 0.6350
Epoch 437 batch 00005: Loss 0.0137 Regression loss 0.0088 Classification loss 0.0049 AP 0.5735 AR 0.8467
Epoch 437 batch 00006: Loss 0.0162 Regression loss 0.0106 Classification loss 0.0056 AP 0.3713 AR 0.5600
Epoch 437 batch 00007: Loss 0.0138 Regression loss 0.0097 Classification loss 0.0040 AP 0.4702 AR 0.6950
Epoch 437 batch 00008: Loss 0.0144 Regression loss 0.0095 Classification loss 0.0049 AP 0.2852 AR 0.4533
Epoch 437 batch 00009: Loss 0.0142 Regression loss 0.0102 Classification loss 0.0041 AP 0.3681 AR 0.7117
Epoch 437 batch 00010: Loss 0.0135 Regression loss 0.0089 Classification loss 0.0046 AP 0.5060 AR 0.7583
Epoch 438 batch 00001: Loss 0.0130 Regression loss 0.0086 Classification loss 0.0044 AP 0.4225 AR 0.6583
Epoch 438 batch 00002: Loss 0.0128 Regression loss 0.0081 Classification loss 0.0046 AP 0.3982 AR 0.6517
Epoch 438 batch 00003: Loss 0.0131 Regression loss 0.0102 Classification loss 0.0029 AP 0.4114 AR 0.6833
Epoch 438 batch 00004: Loss 0.0128 Regression loss 0.0080 Classification loss 0.0048 AP 0.4315 AR 0.7600
Epoch 438 batch 00005: Loss 0.0127 Regression loss 0.0089 Classification loss 0.0038 AP 0.5238 AR 0.7900
Epoch 438 batch 00006: Loss 0.0140 Regression loss 0.0097 Classification loss 0.0043 AP 0.4179 AR 0.7067
Epoch 438 batch 00007: Loss 0.0142 Regression loss 0.0092 Classification loss 0.0050 AP 0.2921 AR 0.4600
Epoch 438 batch 00008: Loss 0.0159 Regression loss 0.0089 Classification loss 0.0070 AP 0.4765 AR 0.6400
Epoch 438 batch 00009: Loss 0.0113 Regression loss 0.0083 Classification loss 0.0029 AP 0.3969 AR 0.6750
Epoch 438 batch 00010: Loss 0.0154 Regression loss 0.0104 Classification loss 0.0049 AP 0.3750 AR 0.6667
Epoch 439 batch 00001: Loss 0.0132 Regression loss 0.0085 Classification loss 0.0048 AP 0.4179 AR 0.6467
Epoch 439 batch 00002: Loss 0.0117 Regression loss 0.0081 Classification loss 0.0036 AP 0.3525 AR 0.5300
Epoch 439 batch 00003: Loss 0.0130 Regression loss 0.0096 Classification loss 0.0035 AP 0.2910 AR 0.5967
Epoch 439 batch 00004: Loss 0.0112 Regression loss 0.0081 Classification loss 0.0031 AP 0.5173 AR 0.7767
Epoch 439 batch 00005: Loss 0.0131 Regression loss 0.0088 Classification loss 0.0042 AP 0.4356 AR 0.6717
Epoch 439 batch 00006: Loss 0.0151 Regression loss 0.0088 Classification loss 0.0063 AP 0.3511 AR 0.6500
Epoch 439 batch 00007: Loss 0.0141 Regression loss 0.0095 Classification loss 0.0046 AP 0.5374 AR 0.7667
Epoch 439 batch 00008: Loss 0.0159 Regression loss 0.0102 Classification loss 0.0057 AP 0.5150 AR 0.7133
Epoch 439 batch 00009: Loss 0.0141 Regression loss 0.0093 Classification loss 0.0047 AP 0.3443 AR 0.5133
Epoch 439 batch 00010: Loss 0.0129 Regression loss 0.0078 Classification loss 0.0051 AP 0.4087 AR 0.7200
Epoch 440 batch 00001: Loss 0.0143 Regression loss 0.0101 Classification loss 0.0042 AP 0.4976 AR 0.7000
Epoch 440 batch 00002: Loss 0.0163 Regression loss 0.0100 Classification loss 0.0063 AP 0.3606 AR 0.6350
Epoch 440 batch 00003: Loss 0.0153 Regression loss 0.0114 Classification loss 0.0038 AP 0.2625 AR 0.3950
Epoch 440 batch 00004: Loss 0.0132 Regression loss 0.0091 Classification loss 0.0041 AP 0.4417 AR 0.6517
Epoch 440 batch 00005: Loss 0.0135 Regression loss 0.0103 Classification loss 0.0032 AP 0.6200 AR 0.7750
Epoch 440 batch 00006: Loss 0.0170 Regression loss 0.0118 Classification loss 0.0051 AP 0.2202 AR 0.3767
Epoch 440 batch 00007: Loss 0.0173 Regression loss 0.0127 Classification loss 0.0046 AP 0.1697 AR 0.3067
Epoch 440 batch 00008: Loss 0.0145 Regression loss 0.0085 Classification loss 0.0060 AP 0.3847 AR 0.8083
Epoch 440 batch 00009: Loss 0.0170 Regression loss 0.0128 Classification loss 0.0043 AP 0.2548 AR 0.4767
Epoch 440 batch 00010: Loss 0.0142 Regression loss 0.0102 Classification loss 0.0039 AP 0.4605 AR 0.6400
Epoch 441 batch 00001: Loss 0.0180 Regression loss 0.0129 Classification loss 0.0051 AP 0.3422 AR 0.6583
Epoch 441 batch 00002: Loss 0.0145 Regression loss 0.0101 Classification loss 0.0044 AP 0.4516 AR 0.6583
Epoch 441 batch 00003: Loss 0.0140 Regression loss 0.0094 Classification loss 0.0046 AP 0.4292 AR 0.5750
Epoch 441 batch 00004: Loss 0.0184 Regression loss 0.0130 Classification loss 0.0054 AP 0.5117 AR 0.6800
Epoch 441 batch 00005: Loss 0.0163 Regression loss 0.0118 Classification loss 0.0045 AP 0.3112 AR 0.4383
Epoch 441 batch 00006: Loss 0.0155 Regression loss 0.0114 Classification loss 0.0041 AP 0.1883 AR 0.3250
Epoch 441 batch 00007: Loss 0.0150 Regression loss 0.0096 Classification loss 0.0054 AP 0.3998 AR 0.6700
Epoch 441 batch 00008: Loss 0.0146 Regression loss 0.0093 Classification loss 0.0053 AP 0.4940 AR 0.7833
Epoch 441 batch 00009: Loss 0.0156 Regression loss 0.0107 Classification loss 0.0049 AP 0.3151 AR 0.6883
Epoch 441 batch 00010: Loss 0.0148 Regression loss 0.0099 Classification loss 0.0048 AP 0.3673 AR 0.6500
Epoch 442 batch 00001: Loss 0.0124 Regression loss 0.0089 Classification loss 0.0035 AP 0.4395 AR 0.6550
Epoch 442 batch 00002: Loss 0.0138 Regression loss 0.0090 Classification loss 0.0048 AP 0.3518 AR 0.5433
Epoch 442 batch 00003: Loss 0.0117 Regression loss 0.0075 Classification loss 0.0041 AP 0.4638 AR 0.7317
Epoch 442 batch 00004: Loss 0.0111 Regression loss 0.0080 Classification loss 0.0031 AP 0.3717 AR 0.6567
Epoch 442 batch 00005: Loss 0.0130 Regression loss 0.0083 Classification loss 0.0047 AP 0.3611 AR 0.6100
Epoch 442 batch 00006: Loss 0.0134 Regression loss 0.0091 Classification loss 0.0043 AP 0.5449 AR 0.8517
Epoch 442 batch 00007: Loss 0.0129 Regression loss 0.0076 Classification loss 0.0054 AP 0.4741 AR 0.8417
Epoch 442 batch 00008: Loss 0.0145 Regression loss 0.0089 Classification loss 0.0056 AP 0.3970 AR 0.6200
Epoch 442 batch 00009: Loss 0.0147 Regression loss 0.0084 Classification loss 0.0063 AP 0.4583 AR 0.6500
Epoch 442 batch 00010: Loss 0.0138 Regression loss 0.0101 Classification loss 0.0037 AP 0.3369 AR 0.4833
Epoch 443 batch 00001: Loss 0.0116 Regression loss 0.0076 Classification loss 0.0040 AP 0.4439 AR 0.7583
Epoch 443 batch 00002: Loss 0.0139 Regression loss 0.0083 Classification loss 0.0056 AP 0.4820 AR 0.7917
Epoch 443 batch 00003: Loss 0.0139 Regression loss 0.0089 Classification loss 0.0051 AP 0.4419 AR 0.6483
Epoch 443 batch 00004: Loss 0.0149 Regression loss 0.0107 Classification loss 0.0042 AP 0.3927 AR 0.6467
Epoch 443 batch 00005: Loss 0.0126 Regression loss 0.0087 Classification loss 0.0039 AP 0.4659 AR 0.7317
Epoch 443 batch 00006: Loss 0.0131 Regression loss 0.0097 Classification loss 0.0034 AP 0.4133 AR 0.5617
Epoch 443 batch 00007: Loss 0.0132 Regression loss 0.0091 Classification loss 0.0040 AP 0.1570 AR 0.3333
Epoch 443 batch 00008: Loss 0.0127 Regression loss 0.0091 Classification loss 0.0035 AP 0.4906 AR 0.7050
Epoch 443 batch 00009: Loss 0.0158 Regression loss 0.0089 Classification loss 0.0069 AP 0.5044 AR 0.7333
Epoch 443 batch 00010: Loss 0.0142 Regression loss 0.0091 Classification loss 0.0051 AP 0.4108 AR 0.6083
Epoch 444 batch 00001: Loss 0.0132 Regression loss 0.0089 Classification loss 0.0042 AP 0.3900 AR 0.6950
Epoch 444 batch 00002: Loss 0.0115 Regression loss 0.0076 Classification loss 0.0039 AP 0.3291 AR 0.5933
Epoch 444 batch 00003: Loss 0.0140 Regression loss 0.0093 Classification loss 0.0047 AP 0.3405 AR 0.5500
Epoch 444 batch 00004: Loss 0.0107 Regression loss 0.0076 Classification loss 0.0031 AP 0.5942 AR 0.8433
Epoch 444 batch 00005: Loss 0.0127 Regression loss 0.0082 Classification loss 0.0045 AP 0.5283 AR 0.8000
Epoch 444 batch 00006: Loss 0.0137 Regression loss 0.0089 Classification loss 0.0047 AP 0.4125 AR 0.7233
Epoch 444 batch 00007: Loss 0.0138 Regression loss 0.0082 Classification loss 0.0056 AP 0.3977 AR 0.5733
Epoch 444 batch 00008: Loss 0.0129 Regression loss 0.0082 Classification loss 0.0047 AP 0.4721 AR 0.6500
Epoch 444 batch 00009: Loss 0.0130 Regression loss 0.0081 Classification loss 0.0050 AP 0.4349 AR 0.7117
Epoch 444 batch 00010: Loss 0.0128 Regression loss 0.0090 Classification loss 0.0037 AP 0.3900 AR 0.6850
Epoch 445 batch 00001: Loss 0.0122 Regression loss 0.0081 Classification loss 0.0040 AP 0.4779 AR 0.7050
Epoch 445 batch 00002: Loss 0.0135 Regression loss 0.0080 Classification loss 0.0055 AP 0.4638 AR 0.7083
Epoch 445 batch 00003: Loss 0.0130 Regression loss 0.0079 Classification loss 0.0051 AP 0.4395 AR 0.7383
Epoch 445 batch 00004: Loss 0.0101 Regression loss 0.0070 Classification loss 0.0031 AP 0.5070 AR 0.7983
Epoch 445 batch 00005: Loss 0.0141 Regression loss 0.0090 Classification loss 0.0051 AP 0.3869 AR 0.5550
Epoch 445 batch 00006: Loss 0.0129 Regression loss 0.0088 Classification loss 0.0041 AP 0.3894 AR 0.6317
Epoch 445 batch 00007: Loss 0.0153 Regression loss 0.0101 Classification loss 0.0052 AP 0.2718 AR 0.4533
Epoch 445 batch 00008: Loss 0.0135 Regression loss 0.0084 Classification loss 0.0051 AP 0.3475 AR 0.6250
Epoch 445 batch 00009: Loss 0.0102 Regression loss 0.0075 Classification loss 0.0027 AP 0.3631 AR 0.7083
Epoch 445 batch 00010: Loss 0.0124 Regression loss 0.0088 Classification loss 0.0036 AP 0.4458 AR 0.7667
Epoch 446 batch 00001: Loss 0.0128 Regression loss 0.0083 Classification loss 0.0045 AP 0.3797 AR 0.6800
Epoch 446 batch 00002: Loss 0.0109 Regression loss 0.0078 Classification loss 0.0031 AP 0.5667 AR 0.8000
Epoch 446 batch 00003: Loss 0.0119 Regression loss 0.0089 Classification loss 0.0031 AP 0.2473 AR 0.3167
Epoch 446 batch 00004: Loss 0.0144 Regression loss 0.0094 Classification loss 0.0050 AP 0.4567 AR 0.8050
Epoch 446 batch 00005: Loss 0.0123 Regression loss 0.0081 Classification loss 0.0042 AP 0.3361 AR 0.6367
Epoch 446 batch 00006: Loss 0.0136 Regression loss 0.0087 Classification loss 0.0049 AP 0.5119 AR 0.8017
Epoch 446 batch 00007: Loss 0.0123 Regression loss 0.0086 Classification loss 0.0037 AP 0.3403 AR 0.5717
Epoch 446 batch 00008: Loss 0.0121 Regression loss 0.0069 Classification loss 0.0052 AP 0.3877 AR 0.6683
Epoch 446 batch 00009: Loss 0.0133 Regression loss 0.0089 Classification loss 0.0044 AP 0.4958 AR 0.7933
Epoch 446 batch 00010: Loss 0.0122 Regression loss 0.0090 Classification loss 0.0032 AP 0.4329 AR 0.6767
Epoch 447 batch 00001: Loss 0.0143 Regression loss 0.0091 Classification loss 0.0052 AP 0.4517 AR 0.6417
Epoch 447 batch 00002: Loss 0.0130 Regression loss 0.0088 Classification loss 0.0041 AP 0.3719 AR 0.6750
Epoch 447 batch 00003: Loss 0.0105 Regression loss 0.0071 Classification loss 0.0034 AP 0.6025 AR 0.7517
Epoch 447 batch 00004: Loss 0.0126 Regression loss 0.0088 Classification loss 0.0038 AP 0.3845 AR 0.6917
Epoch 447 batch 00005: Loss 0.0144 Regression loss 0.0095 Classification loss 0.0049 AP 0.3436 AR 0.5983
Epoch 447 batch 00006: Loss 0.0128 Regression loss 0.0086 Classification loss 0.0041 AP 0.4546 AR 0.7867
Epoch 447 batch 00007: Loss 0.0121 Regression loss 0.0090 Classification loss 0.0031 AP 0.4017 AR 0.6233
Epoch 447 batch 00008: Loss 0.0134 Regression loss 0.0080 Classification loss 0.0054 AP 0.4702 AR 0.6900
Epoch 447 batch 00009: Loss 0.0129 Regression loss 0.0080 Classification loss 0.0050 AP 0.2152 AR 0.4250
Epoch 447 batch 00010: Loss 0.0100 Regression loss 0.0065 Classification loss 0.0035 AP 0.4382 AR 0.7383
Epoch 448 batch 00001: Loss 0.0128 Regression loss 0.0080 Classification loss 0.0048 AP 0.3696 AR 0.6300
Epoch 448 batch 00002: Loss 0.0135 Regression loss 0.0089 Classification loss 0.0045 AP 0.3429 AR 0.5200
Epoch 448 batch 00003: Loss 0.0129 Regression loss 0.0091 Classification loss 0.0038 AP 0.4114 AR 0.6133
Epoch 448 batch 00004: Loss 0.0101 Regression loss 0.0073 Classification loss 0.0029 AP 0.4248 AR 0.6417
Epoch 448 batch 00005: Loss 0.0119 Regression loss 0.0076 Classification loss 0.0044 AP 0.3441 AR 0.7050
Epoch 448 batch 00006: Loss 0.0151 Regression loss 0.0086 Classification loss 0.0065 AP 0.4462 AR 0.6800
Epoch 448 batch 00007: Loss 0.0102 Regression loss 0.0072 Classification loss 0.0030 AP 0.5330 AR 0.8850
Epoch 448 batch 00008: Loss 0.0120 Regression loss 0.0077 Classification loss 0.0042 AP 0.5019 AR 0.6717
Epoch 448 batch 00009: Loss 0.0119 Regression loss 0.0075 Classification loss 0.0043 AP 0.4679 AR 0.7667
Epoch 448 batch 00010: Loss 0.0122 Regression loss 0.0080 Classification loss 0.0042 AP 0.4981 AR 0.6150
Epoch 449 batch 00001: Loss 0.0124 Regression loss 0.0082 Classification loss 0.0042 AP 0.3589 AR 0.6033
Epoch 449 batch 00002: Loss 0.0129 Regression loss 0.0088 Classification loss 0.0041 AP 0.4595 AR 0.6200
Epoch 449 batch 00003: Loss 0.0116 Regression loss 0.0075 Classification loss 0.0041 AP 0.4979 AR 0.7467
Epoch 449 batch 00004: Loss 0.0116 Regression loss 0.0075 Classification loss 0.0041 AP 0.4315 AR 0.7733
Epoch 449 batch 00005: Loss 0.0095 Regression loss 0.0069 Classification loss 0.0026 AP 0.4365 AR 0.7667
Epoch 449 batch 00006: Loss 0.0114 Regression loss 0.0092 Classification loss 0.0023 AP 0.4757 AR 0.6933
Epoch 449 batch 00007: Loss 0.0132 Regression loss 0.0081 Classification loss 0.0050 AP 0.4315 AR 0.6800
Epoch 449 batch 00008: Loss 0.0116 Regression loss 0.0082 Classification loss 0.0034 AP 0.3107 AR 0.5800
